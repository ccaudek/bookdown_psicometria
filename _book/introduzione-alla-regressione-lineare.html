<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Capitolo 1 Introduzione alla regressione lineare | PSICOMETRIA</title>
<meta name="author" content="Corrado Caudek">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.6.4/header-attrs.js"></script><script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.5.3/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.5.3/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.3.9000/tabs.js"></script><script src="libs/bs3compat-0.2.3.9000/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">PSICOMETRIA</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Benvenuti</a></li>
<li><a class="active" href="introduzione-alla-regressione-lineare.html"><span class="header-section-number">1</span> Introduzione alla regressione lineare</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="introduzione-alla-regressione-lineare" class="section level1" number="1">
<h1>
<span class="header-section-number">Capitolo 1</span> Introduzione alla regressione lineare<a class="anchor" aria-label="anchor" href="#introduzione-alla-regressione-lineare"><i class="fas fa-link"></i></a>
</h1>
<p>In questo capitolo verrà presentata un’introduzione “pratica” all’analisi della regressione, nella quale ci preoccuperemo di capire a cosa serve a come si interpretano i risultati che tale metodo statistico produce. Nel capitolo successivo, gli stessi argomenti verranno trattati in un modo più “formale” e con maggiori approfondimenti teorici. Questo capitolo contiene <em>tutto quello che c’è da sapere</em> e <em>non si può non sapere</em> su questo argomento. L’ho pensato per i miei laureandi, ovvero per degli studenti che devono usare queste procedure statistiche per risolvere un problema pratico (quello di concludere la tesi). L’altro capitolo è più convenzionalmente “didattico” ed è stato pensato in primo luogo per chi deve dare l’esame di Psicometria. Questo primo capitolo su questo tema può essere dunque pensato come un’introduzione “gentile” a ciò che verrà discusso nel prossimo capitolo.</p>
<div id="regressione-bivariata" class="section level2" number="1.1">
<h2>
<span class="header-section-number">1.1</span> Regressione bivariata<a class="anchor" aria-label="anchor" href="#regressione-bivariata"><i class="fas fa-link"></i></a>
</h2>
<p>La regressione bivariata si pone il problema di descrivere la relazione statistica <em>lineare</em> che intercorre tra due variabili, <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>. Per relazione “statistica” intendo dire che, nel caso dei dati campionari <span class="math inline">\(\{x, y\}\)</span> di cui si occupa il modello di regressione, non c’è mai una “perfetta” relazione lineare (ovvero, i punti del diagramma a dispersione di <span class="math inline">\(\{x, y\}\)</span> non si situano su una retta). In alcuni casi, quando guardiamo il diagramma a dispersione di <span class="math inline">\(\{x, y\}\)</span> ci rendiamo conto che, in effetti, i punti <span class="math inline">\(\{x, y\}\)</span>, anche se non si dispongono su una retta, sono sparpagliati attorno ad una retta “virtuale” che passa attraverso la nube di punti. In una tale situazione (che è una delle tante possibili, non l’unica), è ragionevole descrivere la relazione tra le variabili <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> mediante la retta che, al meglio, <strong>approssima</strong> la nube di punti nel diagramma a disperiosne. L’analisi di regressione si pone il problema di trovare l’inclinazione di quella retta che passa il più vicino possibile ai punti del diagramma a dispersione di <span class="math inline">\(\{x, y\}\)</span>.</p>
<div id="scioglimento-ghiaccio-marino" class="section level3" number="1.1.1">
<h3>
<span class="header-section-number">1.1.1</span> Scioglimento ghiaccio marino<a class="anchor" aria-label="anchor" href="#scioglimento-ghiaccio-marino"><i class="fas fa-link"></i></a>
</h3>
<p>Uno degli impatti più importanti dei cambiamenti climatici che stanno investendo il nostro Pianeta è la riduzione dell’estensione della calotta di ghiaccio marino artico. Esploriamo come l’estensione del ghiaccio marino artico sta cambiando nel tempo utilizzando un modello lineare. I dati sono forniti da <a href="https://nsidc.org">The National Snow and Ice Data Center</a> e sono espressi in milioni di chilometri quadrati.</p>
<p>I dati sono i seguenti:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">seaice</span><span class="op">)</span>
<span class="co">#&gt;    year extent_north extent_south</span>
<span class="co">#&gt; 1  1979       12.328       11.700</span>
<span class="co">#&gt; 2  1980       12.337       11.230</span>
<span class="co">#&gt; 3  1981       12.127       11.435</span>
<span class="co">#&gt; 4  1982       12.447       11.640</span>
<span class="co">#&gt; 5  1983       12.332       11.389</span>
<span class="co">#&gt; 6  1984       11.910       11.454</span>
<span class="co">#&gt; 7  1985       11.995       11.618</span>
<span class="co">#&gt; 8  1986       12.203       11.088</span>
<span class="co">#&gt; 9  1987       12.135       11.554</span>
<span class="co">#&gt; 10 1988       11.923       12.131</span>
<span class="co">#&gt; 11 1989       11.967       11.426</span>
<span class="co">#&gt; 12 1990       11.694       11.410</span>
<span class="co">#&gt; 13 1991       11.749       11.545</span>
<span class="co">#&gt; 14 1992       12.110       11.399</span>
<span class="co">#&gt; 15 1993       11.923       11.420</span>
<span class="co">#&gt; 16 1994       12.011       11.774</span>
<span class="co">#&gt; 17 1995       11.415       11.795</span>
<span class="co">#&gt; 18 1996       11.841       11.769</span>
<span class="co">#&gt; 19 1997       11.668       11.390</span>
<span class="co">#&gt; 20 1998       11.757       11.738</span>
<span class="co">#&gt; 21 1999       11.691       11.761</span>
<span class="co">#&gt; 22 2000       11.508       11.747</span>
<span class="co">#&gt; 23 2001       11.600       11.673</span>
<span class="co">#&gt; 24 2002       11.363       11.222</span>
<span class="co">#&gt; 25 2003       11.397       11.969</span>
<span class="co">#&gt; 26 2004       11.240       11.961</span>
<span class="co">#&gt; 27 2005       10.907       11.695</span>
<span class="co">#&gt; 28 2006       10.773       11.461</span>
<span class="co">#&gt; 29 2007       10.474       11.687</span>
<span class="co">#&gt; 30 2008       10.978       12.239</span>
<span class="co">#&gt; 31 2009       10.932       12.049</span>
<span class="co">#&gt; 32 2010       10.711       12.107</span>
<span class="co">#&gt; 33 2011       10.483       11.501</span>
<span class="co">#&gt; 34 2012       10.406       12.004</span>
<span class="co">#&gt; 35 2013       10.897       12.524</span>
<span class="co">#&gt; 36 2014       10.790       12.776</span>
<span class="co">#&gt; 37 2015       10.566       12.414</span>
<span class="co">#&gt; 38 2016       10.151       11.156</span>
<span class="co">#&gt; 39 2017       10.373       10.693</span></code></pre></div>
<p>Quale domanda di ricerca possiamo porci con questi dati? Propongo la seguente domanda.</p>
<p><strong>Domanda di ricerca:</strong> l’estensione del ghiaccio marino artico sta diminuendo nel tempo?</p>
<p>Per esplorare la risposta a questa domanda, iniziamo a creare una rappresentazione grafica dei dati. Dato che abbiamo due variabi continue (il tempo, espresso in anni, e l’estensione del ghiaccio marino artico, in milioni di chilometri quadrati), questi dati possono essere rappresentati graficamente mediante un diagramma a dispersione.
Vogliamo sapere come varia l’estensione del ghiaccio marino artico in funzione del tempo e quindi disegnamo i dati ponendo la variabile tempo sull’asse delle ascisse e l’estensione del ghiaccio marino artico sull’asse delle ordinate.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">seaice</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">year</span>, <span class="va">extent_north</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<p><img src="39_intro_reglin_files/figure-html/unnamed-chunk-5-1.png" width="90%" style="display: block; margin: auto;">
Guardando la figura vediamo che è ragionevole descrivere la relazione tra l’estensione del ghiaccio marino artico (chiamiamolo <span class="math inline">\(y\)</span>) e il tempo (chiamiamolo <span class="math inline">\(x\)</span>) mediante una retta. Aggiungiamo dunque una retta al diagramma a dispersione, scegliendola in modo tale che si avvicini il più possibile ai punti del diagramma a dispersione. Ovviamente, è possibile scegliere tra infinite rette diverse. La retta che è rappresentata qui è stata scelta in base ad un criterio particolare, detto “dei minimi quadrati.” Vedremo meglio in seguito cosa questo significa. Per ora ci accontentiamo di riconoscere che la nostra è una buona scelta, per gli scopi presenti.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">seaice</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">year</span>, <span class="va">extent_north</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, se <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> 
<span class="co">#&gt; `geom_smooth()` using formula 'y ~ x'</span></code></pre></div>
<div class="inline-figure"><img src="39_intro_reglin_files/figure-html/unnamed-chunk-6-1.png" width="90%" style="display: block; margin: auto;"></div>
</div>
</div>
<div id="interpretazione-dei-coefficienti-a-e-b" class="section level2" number="1.2">
<h2>
<span class="header-section-number">1.2</span> Interpretazione dei coefficienti <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span><a class="anchor" aria-label="anchor" href="#interpretazione-dei-coefficienti-a-e-b"><i class="fas fa-link"></i></a>
</h2>
<p>La retta che abbiamo disegnato nella figura precedente rappresenta la risposta alla nostra domanda di ricerca: l’estensione del ghiaccio marino artico sta diminuendo nel tempo.</p>
<p>Anziché considerare questa risposta unicamente dal punto di vista grafico, proviamo a descrivere la retta disegnata nella figura in maniera quantitativa, con dei numeri. Per fare questo, dobbiamo innanzitutto ricordare qual è l’equazione di una retta:</p>
<p><span class="math display">\[\begin{equation}
y = a + b \times x
\end{equation}\]</span></p>
<p>Prima di calcolare i coefficienti <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> della retta di regressione, rimaneggiamo i nostri dati. In particolare, rinominiamo le variabili e indicizziamo gli anni da 1 a 39. Nel caso presente, vogliamo sapere se l’estensione del ghiaccio marino artico dall’inizio alla fine del periodo temporale considerato, indipendentemente dal fatto che l’anno iniziale sia il 1979 e l’anno finale il 2017. Quindi sottraiamo 1979 dalle modalità della variabile <code>year</code> in modo tale che il primo punto temporale corrisponda a zero.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">seaice</span> <span class="op">&lt;-</span> <span class="va">seaice</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>
    x <span class="op">=</span> <span class="va">year</span> <span class="op">-</span> <span class="fl">1979</span>
  <span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">rename</span><span class="op">(</span>
    y <span class="op">=</span> <span class="va">extent_north</span>
  <span class="op">)</span>
<span class="fu">glimpse</span><span class="op">(</span><span class="va">seaice</span><span class="op">)</span>
<span class="co">#&gt; Rows: 39</span>
<span class="co">#&gt; Columns: 4</span>
<span class="co">#&gt; $ year         &lt;int&gt; 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 19…</span>
<span class="co">#&gt; $ y            &lt;dbl&gt; 12.328, 12.337, 12.127, 12.447, 12.332, 11.910, 11.995, …</span>
<span class="co">#&gt; $ extent_south &lt;dbl&gt; 11.700, 11.230, 11.435, 11.640, 11.389, 11.454, 11.618, …</span>
<span class="co">#&gt; $ x            &lt;dbl&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16…</span></code></pre></div>
<p>Il diagramma a dispersione avrà ora la forma seguente:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">seaice</span> <span class="op">%&gt;%</span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, se <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> 
<span class="co">#&gt; `geom_smooth()` using formula 'y ~ x'</span></code></pre></div>
<div class="inline-figure"><img src="39_intro_reglin_files/figure-html/unnamed-chunk-8-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Per trovare i coefficienti <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> della retta di regressione possiamo usare, ad esempio, la funzione <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code>:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x</span>, data <span class="op">=</span> <span class="va">seaice</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">fm</span><span class="op">)</span>
<span class="co">#&gt; (Intercept)           x </span>
<span class="co">#&gt; 12.50131410 -0.05457389</span></code></pre></div>
<p>L’output della funzione <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> ci dice che <code>a</code> è uguale a 12.501 e che <code>b</code> è uguale a -0.055. Ma che significato (geometrico) hanno questi valori? Ai coefficienti <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> possiamo assegnare la seguente interpretazione:</p>
<ul>
<li><p>il coefficiente <span class="math inline">\(a\)</span> rappresenta il valore della coordinata <span class="math inline">\(y\)</span> (l’estensione del ghiaccio marino artico) della retta di regressione quando la coordinata <span class="math inline">\(x\)</span> vale zero (nel nostro caso, l’anno 1979) – in altre parole, corrisponde al punto dove la retta di regressione interseca l’asse <span class="math inline">\(y\)</span> del sistema di assi cartesiani;</p></li>
<li><p>il coefficiente <span class="math inline">\(b\)</span> ci dice di quanto aumenta la coordinata <span class="math inline">\(y\)</span> della retta di regressione, quando <span class="math inline">\(x\)</span> aumenta di un’unità.</p></li>
</ul>
<p>Quindi, <span class="math inline">\(a\)</span> = 12.501 significa che, nel 1979, l’estensione del ghiaccio marino artico era pari a 12.501 milioni di chilometri quadrati.</p>
<p>Nel nostro caso, il segno di <span class="math inline">\(b\)</span> è negativo; questo significa che l’estensione del ghiaccio marino artico sta diminuendo nel tempo. Il valore -0.055 ci dice che, per ogni anno che passa (nel periodo considerato dal 1979 al 2017), l’estensione del ghiaccio marino artico è diminuita, in media, di -0.055 milioni di chilometri quadrati.</p>
<p>Se guardiamo la figura, infatti, vediamo che, se ci sposiamo da <span class="math inline">\(x = 10\)</span> a <span class="math inline">\(x = 20\)</span> (ovvero, di dieci unità), la coordinata <span class="math inline">\(y\)</span> della retta diminuisce di 10 volte <span class="math inline">\(b\)</span>, ovvero di -0.55 milioni di chilometri quadrati. Questo è indicato nella figura qui sotto.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">dplot</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>
  x1 <span class="op">=</span> <span class="fl">10</span>,
  x2 <span class="op">=</span> <span class="fl">20</span>,
  y1 <span class="op">=</span> <span class="fl">12.50131410</span> <span class="op">+</span> <span class="op">-</span><span class="fl">0.05457389</span> <span class="op">*</span> <span class="fl">10</span>,
  y2 <span class="op">=</span> <span class="fl">12.50131410</span> <span class="op">+</span> <span class="op">-</span><span class="fl">0.05457389</span> <span class="op">*</span> <span class="fl">20</span>
<span class="op">)</span>

<span class="va">seaice</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>color<span class="op">=</span><span class="st">"gray"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, se <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_segment.html">geom_segment</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x2</span>, y <span class="op">=</span> <span class="va">y1</span>, xend <span class="op">=</span> <span class="va">x2</span>, yend <span class="op">=</span> <span class="va">y2</span><span class="op">)</span>,
               arrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/grid/arrow.html">arrow</a></span><span class="op">(</span><span class="op">)</span>, size<span class="op">=</span><span class="fl">1.1</span>, data <span class="op">=</span> <span class="va">dplot</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_segment.html">geom_segment</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x1</span>, y <span class="op">=</span> <span class="va">y1</span>, xend <span class="op">=</span> <span class="va">x2</span>, yend <span class="op">=</span> <span class="va">y1</span><span class="op">)</span>,
               arrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/grid/arrow.html">arrow</a></span><span class="op">(</span><span class="op">)</span>, size<span class="op">=</span><span class="fl">1.1</span>, data <span class="op">=</span> <span class="va">dplot</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="fl">24.0</span>, y <span class="op">=</span> <span class="fl">11.75</span>, label <span class="op">=</span> <span class="st">"b = -0.55"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="fl">15</span>, y <span class="op">=</span> <span class="fl">12.15</span>, label <span class="op">=</span> <span class="st">"delta x = 10.0"</span><span class="op">)</span>
<span class="co">#&gt; `geom_smooth()` using formula 'y ~ x'</span></code></pre></div>
<div class="inline-figure"><img src="39_intro_reglin_files/figure-html/unnamed-chunk-10-1.png" width="90%" style="display: block; margin: auto;"></div>
</div>
<div id="scomposizione-della-y" class="section level2" number="1.3">
<h2>
<span class="header-section-number">1.3</span> Scomposizione della <span class="math inline">\(y\)</span><a class="anchor" aria-label="anchor" href="#scomposizione-della-y"><i class="fas fa-link"></i></a>
</h2>
<p>Uno degli aspetti importanti della regressione lineare è che, in pratica, la retta di regressione scompone ciascun punteggio <span class="math inline">\(y\)</span> in due componenti:</p>
<p><span class="math display">\[\begin{equation}
y = (a + b \times x) + e
\end{equation}\]</span></p>
<p>laddove <span class="math inline">\(\hat{y} = a + b \times x\)</span> è la componente di <span class="math inline">\(y\)</span> che è linearmente predicibile conoscendo <span class="math inline">\(x\)</span>, mentre la componente residua, <span class="math inline">\(e\)</span>, è la componente di <span class="math inline">\(y\)</span> che non è linearmente predicibile conoscendo <span class="math inline">\(x\)</span>.</p>
<p>Nei nostri dati, questi significa quanto segue. Esaminiamo le prime 5 osservazioni del nostro campione:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">seaice</span> <span class="op">%&gt;%</span> 
  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">top_n</span><span class="op">(</span><span class="fl">5</span><span class="op">)</span> 
<span class="co">#&gt; Selecting by y</span>
<span class="co">#&gt;   x      y</span>
<span class="co">#&gt; 1 0 12.328</span>
<span class="co">#&gt; 2 1 12.337</span>
<span class="co">#&gt; 3 3 12.447</span>
<span class="co">#&gt; 4 4 12.332</span>
<span class="co">#&gt; 5 7 12.203</span></code></pre></div>
<p>Aggiungo al data.frame una colonna che rappresenta i valori <span class="math inline">\(y\)</span> predetti dal modello lineare (ovvero, <span class="math inline">\(\hat{y} = a + b \times x\)</span>: le coordinate <span class="math inline">\(y\)</span> della retta di regressione per ciascuna delle osservazioni):</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">seaice</span><span class="op">$</span><span class="va">yhat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">fm</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">fm</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">*</span> <span class="va">seaice</span><span class="op">$</span><span class="va">x</span>
<span class="va">seaice</span> <span class="op">%&gt;%</span> 
  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">yhat</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">top_n</span><span class="op">(</span><span class="fl">5</span><span class="op">)</span> 
<span class="co">#&gt; Selecting by yhat</span>
<span class="co">#&gt;   x      y     yhat</span>
<span class="co">#&gt; 1 0 12.328 12.50131</span>
<span class="co">#&gt; 2 1 12.337 12.44674</span>
<span class="co">#&gt; 3 2 12.127 12.39217</span>
<span class="co">#&gt; 4 3 12.447 12.33759</span>
<span class="co">#&gt; 5 4 12.332 12.28302</span></code></pre></div>
<p>Aggiungo ora al data.frame i residui del modello di regressione. I residui sono definiti come</p>
<p><span class="math display">\[\begin{equation}
e = y - (a + b \times x) = y - \hat{y}
\end{equation}\]</span></p>
<p>ovvero</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">seaice</span><span class="op">$</span><span class="va">e</span> <span class="op">&lt;-</span> <span class="va">seaice</span><span class="op">$</span><span class="va">y</span> <span class="op">-</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">fm</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">fm</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">*</span> <span class="va">seaice</span><span class="op">$</span><span class="va">x</span><span class="op">)</span>
<span class="va">seaice</span> <span class="op">%&gt;%</span> 
  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">yhat</span>, <span class="va">e</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">top_n</span><span class="op">(</span><span class="fl">5</span><span class="op">)</span> 
<span class="co">#&gt; Selecting by e</span>
<span class="co">#&gt;    x      y     yhat         e</span>
<span class="co">#&gt; 1 13 12.110 11.79185 0.3181464</span>
<span class="co">#&gt; 2 15 12.011 11.68271 0.3282942</span>
<span class="co">#&gt; 3 19 11.757 11.46441 0.2925897</span>
<span class="co">#&gt; 4 20 11.691 11.40984 0.2811636</span>
<span class="co">#&gt; 5 22 11.600 11.30069 0.2993114</span></code></pre></div>
<p>Ciò che volevamo dimostrare è che la somma di <span class="math inline">\(\hat{y}\)</span> e dei residui è uguale alla <span class="math inline">\(y\)</span>. Infatti:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">seaice</span><span class="op">$</span><span class="va">sum</span> <span class="op">&lt;-</span> <span class="va">seaice</span><span class="op">$</span><span class="va">yhat</span> <span class="op">+</span> <span class="va">seaice</span><span class="op">$</span><span class="va">e</span>
<span class="va">seaice</span> <span class="op">%&gt;%</span> 
  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">yhat</span>, <span class="va">e</span>, <span class="va">sum</span><span class="op">)</span> <span class="op">%&gt;%</span> 
  <span class="fu">top_n</span><span class="op">(</span><span class="fl">5</span><span class="op">)</span> 
<span class="co">#&gt; Selecting by sum</span>
<span class="co">#&gt;   x      y     yhat           e    sum</span>
<span class="co">#&gt; 1 0 12.328 12.50131 -0.17331410 12.328</span>
<span class="co">#&gt; 2 1 12.337 12.44674 -0.10974022 12.337</span>
<span class="co">#&gt; 3 3 12.447 12.33759  0.10940756 12.447</span>
<span class="co">#&gt; 4 4 12.332 12.28302  0.04898144 12.332</span>
<span class="co">#&gt; 5 7 12.203 12.11930  0.08370310 12.203</span></code></pre></div>
<p>In altre parole, il modello di regressone scompone la <span class="math inline">\(y\)</span> in due componenti: la porzione della <span class="math inline">\(y\)</span> che possiamo prevedere conoscendo <span class="math inline">\(x\)</span> (ovvero, <span class="math inline">\(\hat{y} = a + b \times x\)</span>) e la porzione della <span class="math inline">\(y\)</span> che <em>non</em> possiamo prevedere sulla base di <span class="math inline">\(x\)</span>.</p>
<div id="metodo-di-stima-dei-coefficienti-del-modello-di-regressione" class="section level3" number="1.3.1">
<h3>
<span class="header-section-number">1.3.1</span> Metodo di stima dei coefficienti del modello di regressione<a class="anchor" aria-label="anchor" href="#metodo-di-stima-dei-coefficienti-del-modello-di-regressione"><i class="fas fa-link"></i></a>
</h3>
<p>Come abbiamo fatto a calcolare i coefficienti dei minimi quadrati <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span>? Ci sono tanti metodi; il più comune si chiama “metodo dei minimi quadrati.” Lo esamineremo in seguito. Per i nostri scopi, è poco importante: per ora ci accontentiamo di chiedere ad R di fare i calcoli per noi.</p>
</div>
</div>
<div id="inferenza-sul-modello-di-regressione" class="section level2" number="1.4">
<h2>
<span class="header-section-number">1.4</span> Inferenza sul modello di regressione<a class="anchor" aria-label="anchor" href="#inferenza-sul-modello-di-regressione"><i class="fas fa-link"></i></a>
</h2>
<p>Finora siamo riusciti a descrivere la relazione <em>statistica</em> tra <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> in un campione di osservazioni. Siamo ben consapevoli che, in un altro campione di osservazioni, la relazione <em>statistica</em> tra <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> non sarà identica a quella osservata nel caso del primo campione – dato che i dati saranno diversi. La domanda cruciale dunque diventa la seguente: quanto sono simili i coefficienti dei minimi quadrati calcolati sui dati campionari ai coefficienti di un’ipotetica retta di regressione che, sempre mediante il metodo dei minimi quadrati, descriverebbe la relazione tra tutte le osservazioni <span class="math inline">\(\{x, y\}\)</span> nella popolazione? Ciò che vogliamo è dunque una quantificazione della nostra <em>incertezza</em>: vogliamo sapere quanto dobbiamo fidarci delle stime campionarie come descrizioni dei valori (sconosciuti) della popolazione. Ci sono due possibilità.</p>
<ul>
<li><p>Se le stime di <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> fornite dal particolare campione che abbiamo osservato sono simili ai valori teorici della popolazione, allora i dati del campione ci forniscono informazioni utili per capire quali sono le proprietà della popolazione.</p></li>
<li><p>Se invece le stime campionarie di <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> sono molto diverse dai valori teorici della popolazione, allora i dati del campione non ci aiutano a capire quali sono le proprietà della popolazione.</p></li>
</ul>
<p>Il problema che abbiamo è quello di decidere in quale di queste due situazioni ci troviamo: la prima o la seconda. Questo è il problema dell’<em>inferenza statistica</em> sul modello di regressione.</p>
<p>Il problema dell’inferenza viene affrontato utilizzando gli strumenti della teoria della probabilità per costruire un intervallo di valori. Nell’approccio Bayesiano, tale intervallo di valori si chiama <em>intervallo di credibilità</em>. Se calcoliamo, ad esempio, l’intervallo di credibilità all’89% per il parametro <span class="math inline">\(\beta\)</span> (inclinazione della retta di regressione nella popolazione), interpretiamo tale intervallo di valori nel modo seguente: possiamo dire che “siamo sicuri all’89% che il vero valore di <span class="math inline">\(\beta\)</span> è contenuto nell’intervallo stimato” – laddove per “vero valore di <span class="math inline">\(\beta\)</span>” intendiamo il valore del parametro sconosciuto della popolazione. Se calcoliamo l’intervallo di credibilità, ad un dato livello di certezza, possiamo giungere a una di tre possibili conclusioni.</p>
<ul>
<li>L’intervallo di credibilità non include lo 0 e il suo limite inferiore è positivo: possiamo concludere, con una certezza dell’89%, che c’è una relazione positiva tra <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> nella popolazione;</li>
<li>l’intervallo di credibilità non include lo 0 e il suo limite superiore è negativo: possiamo concludere, con una certezza del’89%, che c’è una relazione negativa tra <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> nella popolazione;</li>
<li>l’intervallo di credibilità include lo 0: con un un livello di certezza dell’89%, non possiamo negare la possibilità che nella popolazione la relazione tra <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> sia nulla – ovvero, non abbiamo sufficienti informazioni per sapere se è positiva o negativa.</li>
</ul>
<p>Ritorniamo ora ai nostri dati e calcoliamo, con un metodo che discuteremo in seguito, l’intervallo di credibilità all’89%. Per ora non ci preoccupiamo della sintassi dei comandi R, né di cosa significano tali istruzioni. Ci preoccupiamo solo di ottenere le stime dei coefficienti della retta di regressione e gli intervalli di credibilità:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">flist</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span>
    <span class="va">y</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,
    <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span><span class="op">*</span><span class="va">x</span>,
    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">a</span>, <span class="va">b</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">2</span><span class="op">)</span>, 
    <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Cauchy.html">dcauchy</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">2</span><span class="op">)</span>
<span class="op">)</span>

<span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">quap</a></span><span class="op">(</span>
  <span class="va">flist</span>, 
  data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>y<span class="op">=</span><span class="va">seaice</span><span class="op">$</span><span class="va">y</span>, x<span class="op">=</span><span class="va">seaice</span><span class="op">$</span><span class="va">x</span><span class="op">)</span>, 
  start <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>a<span class="op">=</span><span class="fl">0</span>, b<span class="op">=</span><span class="fl">0</span>, sigma<span class="op">=</span><span class="fl">0.1</span><span class="op">)</span>
<span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/precis.html">precis</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span>
<span class="co">#&gt;         mean    sd   5.5%  94.5%</span>
<span class="co">#&gt; a     12.487 0.068 12.379 12.595</span>
<span class="co">#&gt; b     -0.054 0.003 -0.059 -0.049</span>
<span class="co">#&gt; sigma  0.215 0.024  0.176  0.254</span></code></pre></div>
<p>L’intervallo di credibilità per <span class="math inline">\(b\)</span> così ottenuto, ovvero [-0.059, -0.049], non include lo zero. Possiamo dunque concludere, con un livello di certezza dell’89%, che nella popolazione c’è una relazione negativa tra <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>. In altre parole, siamo certi, con un livello di certezza dell’89%, che dal 1979 al 2017 l’estensione del ghiaccio marino artico è diminuita.</p>
<p>Se vogliamo, possiamo anche ottenere una stima di <span class="math inline">\(b\)</span> che corrisponde ad un livello di certezza più alto, il che porterà ad un aumento dell’ampiezza dell’interallo di credibilità. Stimiamo dunque l’interallo di credibilità ad un livello di certezza del 99%:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/precis.html">precis</a></span><span class="op">(</span><span class="va">fit</span>, prob<span class="op">=</span><span class="fl">0.99</span><span class="op">)</span>, <span class="fl">3</span><span class="op">)</span>
<span class="co">#&gt;         mean    sd   0.5%  99.5%</span>
<span class="co">#&gt; a     12.487 0.068 12.313 12.661</span>
<span class="co">#&gt; b     -0.054 0.003 -0.062 -0.046</span>
<span class="co">#&gt; sigma  0.215 0.024  0.152  0.277</span></code></pre></div>
<p>Anche in questo caso l’interallo di credibilità non include lo zero per cui, anche se pretendiamo un livello di certazza del 99%, confermiamo la conclusione secondo la quale dal 1979 al 2017 l’estensione del ghiaccio marino artico è diminuita.</p>
<p>Per quel che riguarda <span class="math inline">\(a\)</span>, con un livello di certezza dell’99% possiamo dire che il valore dell’intercetta della retta di regressione nella popolazione è incluso nell’intervallo [12.379, 12.595]. Nel caso presente, ciò ha una semplice interpretazione: significa che la nostra stima dell’esensione del ghiaccio marino artico nell’anno 1979 corrisponde a un valore compreso tra [12.379, 12.595], con un livello di certezza del 99%.</p>
<div id="errore-standard-della-stima" class="section level3" number="1.4.1">
<h3>
<span class="header-section-number">1.4.1</span> Errore standard della stima<a class="anchor" aria-label="anchor" href="#errore-standard-della-stima"><i class="fas fa-link"></i></a>
</h3>
<p>Il parametto <code>sigma</code> nell’output di <code><a href="https://rdrr.io/pkg/rethinking/man/precis.html">precis()</a></code> ci fornisce un altro utile pezzo di informazione: stima quanto sono distanti, in media, le osservazioni dalla retta di regressione <em>nella popolazione</em>. Il valore stimato di <code>sigma</code>, chiamato <em>errore standard della stima</em>, è pari a 0.215, il che significa che il modello di regressione, nel stimare la relazione tra <span class="math inline">\(y\)</span> e <span class="math inline">\(x\)</span> compie un errore medio di 0.215 milioni di chilometri quadrati – questa è la stima della distanza media tra ciascuno dei punti del diagramma a dispersione e la retta di regressione <em>nella popolazione</em>.</p>
</div>
</div>
<div id="una-variabile-indipendente-qualitativa" class="section level2" number="1.5">
<h2>
<span class="header-section-number">1.5</span> Una variabile indipendente qualitativa<a class="anchor" aria-label="anchor" href="#una-variabile-indipendente-qualitativa"><i class="fas fa-link"></i></a>
</h2>
<p>Il modello statistico della regressione bivariato che abbiamo descritto sopra è molto limitato: può solo descrivere la relazione lineare tra due variabili continue. Estendiamolo ora al caso in cui, oltre ad includere un predittore continuo <span class="math inline">\(x\)</span>, il modello di regressione comprende anche una variabile che consente di suddividere le osservazioni del campione in due gruppi.</p>
<p>Per semplicità, simuliamo un insieme di dati che utilizzeremo nella seguente discussione.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span>
<span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">100</span>
<span class="va">x1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>, <span class="fl">4</span>, <span class="fl">1</span><span class="op">)</span>
<span class="va">y1</span> <span class="op">&lt;-</span> <span class="fl">5</span> <span class="op">+</span> <span class="fl">5</span> <span class="op">*</span> <span class="va">x1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>, <span class="fl">0</span>, <span class="fl">2</span><span class="op">)</span>

<span class="va">x2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>, <span class="fl">4</span>, <span class="fl">1</span><span class="op">)</span>
<span class="va">y2</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">3</span> <span class="op">+</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">x2</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>, <span class="fl">0</span>, <span class="fl">2</span><span class="op">)</span>

<span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">y1</span>, <span class="va">y2</span><span class="op">)</span>
<span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">x1</span>, <span class="va">x2</span><span class="op">)</span>
<span class="va">group</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"gr1"</span>, <span class="st">"gr2"</span><span class="op">)</span>, each <span class="op">=</span> <span class="va">n</span><span class="op">)</span>

<span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, <span class="va">group</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">d</span><span class="op">)</span>
<span class="co">#&gt;          x        y group</span>
<span class="co">#&gt; 1 2.792934 19.79372   gr1</span>
<span class="co">#&gt; 2 4.277429 25.43771   gr1</span>
<span class="co">#&gt; 3 5.084441 30.55419   gr1</span>
<span class="co">#&gt; 4 1.654302 12.26656   gr1</span>
<span class="co">#&gt; 5 4.429125 25.49363   gr1</span>
<span class="co">#&gt; 6 4.506056 27.86426   gr1</span></code></pre></div>
<p>Esaminiamo il diagramma a dispersione che indica chiaramente che ci sono due gruppi distinti di osservazioni:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">d</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>color <span class="op">=</span> <span class="va">group</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="39_intro_reglin_files/figure-html/unnamed-chunk-18-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>È ovvio, che nel caso presente, non è sufficiente un modello di regressione che ignora il fatto che i dati appartengono a due gruppi diversi. Infatti, se adattiamo ai dati un’unica retta di regressione, è facile rendersi conto che tale retta si situerà in una posizione molto distante dai dati.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">d</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>color <span class="op">=</span> <span class="va">group</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, se <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> 
<span class="co">#&gt; `geom_smooth()` using formula 'y ~ x'</span></code></pre></div>
<div class="inline-figure"><img src="39_intro_reglin_files/figure-html/unnamed-chunk-19-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Per questi dati è ovviamente più sensato adattare una diversa retta di regressione a ciascun gruppo di osservazioni:</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">d</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, color <span class="op">=</span> <span class="va">group</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>color <span class="op">=</span> <span class="va">group</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, se <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="co">#&gt; `geom_smooth()` using formula 'y ~ x'</span></code></pre></div>
<div class="inline-figure"><img src="39_intro_reglin_files/figure-html/unnamed-chunk-20-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Come possiamo modificare il modello di regressione che abbiamo esaminato in precedenza in modo tale da essere in grado di stimare i coefficienti di regressione delle due rette rappresentate nella figura precedente? Questo problema si risolve nel modo seguente. Crediamo una variabile, chiamata <em>dummy</em>, che ha valore 0 per un gruppo, diciamo <code>gr1</code>, e valore 1 per l’altro gruppo:</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">d</span><span class="op">$</span><span class="va">gr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">group</span> <span class="op">==</span> <span class="st">"gr1"</span>, <span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">d</span><span class="op">)</span>
<span class="co">#&gt;          x        y group gr</span>
<span class="co">#&gt; 1 2.792934 19.79372   gr1  0</span>
<span class="co">#&gt; 2 4.277429 25.43771   gr1  0</span>
<span class="co">#&gt; 3 5.084441 30.55419   gr1  0</span>
<span class="co">#&gt; 4 1.654302 12.26656   gr1  0</span>
<span class="co">#&gt; 5 4.429125 25.49363   gr1  0</span>
<span class="co">#&gt; 6 4.506056 27.86426   gr1  0</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">tail</a></span><span class="op">(</span><span class="va">d</span><span class="op">)</span>
<span class="co">#&gt;            x         y group gr</span>
<span class="co">#&gt; 195 5.656043  9.369576   gr2  1</span>
<span class="co">#&gt; 196 5.809805 10.198400   gr2  1</span>
<span class="co">#&gt; 197 2.824963  3.564125   gr2  1</span>
<span class="co">#&gt; 198 3.633297  5.344260   gr2  1</span>
<span class="co">#&gt; 199 4.353625  5.736537   gr2  1</span>
<span class="co">#&gt; 200 4.319156  3.805334   gr2  1</span></code></pre></div>
<p>Esaminiamo ora il modello di regressione che include tale variabile dummy, che chiameremo <em>D</em>:</p>
<p><span class="math display">\[\begin{equation}
y = \alpha + \beta x + \gamma D + \varepsilon.
\end{equation}\]</span></p>
<p>Quando <span class="math inline">\(D = 0\)</span>:</p>
<p><span class="math display">\[\begin{align}
y &amp;= \alpha + \beta x + \gamma D + \varepsilon,\notag\\
 &amp;= \alpha + \beta x + \gamma \times 0 + \varepsilon,\notag\\
 &amp;= \alpha + \beta x + \varepsilon.\notag
\end{align}\]</span></p>
<p>Quando <span class="math inline">\(D = 1\)</span>:</p>
<p><span class="math display">\[\begin{align}
y &amp;= \alpha + \beta x + \gamma D + \varepsilon,\notag\\
 &amp;= \alpha + \beta x + \gamma \times 1 + \varepsilon,\notag\\
 &amp;= (\alpha + \gamma) + \beta x + \varepsilon.\notag
\end{align}\]</span></p>
<p>Quindi, se assumiamo che le due rette di regressione siano parallele (nella discussione precedente abbiamo previsto un unico valore <span class="math inline">\(\beta\)</span>), i coefficienti del modello avranno la seguente interpretazione:</p>
<ul>
<li>
<span class="math inline">\(\alpha\)</span> = intercetta della retta di regressione per il gruppo codificato con <em>D</em> = 0;</li>
<li>
<span class="math inline">\(\beta\)</span> = pendenza della retta di regressione per il gruppo codificato con <em>D</em> = 0;</li>
<li>
<span class="math inline">\(\gamma\)</span> = differenza tra l’intercetta della retta di regressione per il gruppo codificato con <em>D</em> = 1 e l’intercetta della retta di regressione per il gruppo codificato con <em>D</em> = 0.</li>
</ul>
<div id="interazione" class="section level3" number="1.5.1">
<h3>
<span class="header-section-number">1.5.1</span> Interazione<a class="anchor" aria-label="anchor" href="#interazione"><i class="fas fa-link"></i></a>
</h3>
<p>In generale, però, le due rette di regressione non sono parallele. Per potere rappresentare una tale possibilità, introduciamo nel data.frame <code>d</code> una seconda variabile e la chiamiamo <code>DX</code>. Creaimo <code>DX</code> facendo il prodotto delle variabili <code>D</code> e <code>x</code>:</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">d</span><span class="op">$</span><span class="va">DX</span> <span class="op">&lt;-</span> <span class="va">d</span><span class="op">$</span><span class="va">gr</span> <span class="op">*</span> <span class="va">d</span><span class="op">$</span><span class="va">x</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">d</span><span class="op">)</span>
<span class="co">#&gt;          x        y group gr DX</span>
<span class="co">#&gt; 1 2.792934 19.79372   gr1  0  0</span>
<span class="co">#&gt; 2 4.277429 25.43771   gr1  0  0</span>
<span class="co">#&gt; 3 5.084441 30.55419   gr1  0  0</span>
<span class="co">#&gt; 4 1.654302 12.26656   gr1  0  0</span>
<span class="co">#&gt; 5 4.429125 25.49363   gr1  0  0</span>
<span class="co">#&gt; 6 4.506056 27.86426   gr1  0  0</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">tail</a></span><span class="op">(</span><span class="va">d</span><span class="op">)</span>
<span class="co">#&gt;            x         y group gr       DX</span>
<span class="co">#&gt; 195 5.656043  9.369576   gr2  1 5.656043</span>
<span class="co">#&gt; 196 5.809805 10.198400   gr2  1 5.809805</span>
<span class="co">#&gt; 197 2.824963  3.564125   gr2  1 2.824963</span>
<span class="co">#&gt; 198 3.633297  5.344260   gr2  1 3.633297</span>
<span class="co">#&gt; 199 4.353625  5.736537   gr2  1 4.353625</span>
<span class="co">#&gt; 200 4.319156  3.805334   gr2  1 4.319156</span></code></pre></div>
<p>Si noti che, quando <em>D = 0</em>, allora <em>DX = 0</em>; quando <em>D = 1</em>, allora <em>DX = x</em>.</p>
<p>Riscriviamo il modello di regressione nel modo seguente:</p>
<p><span class="math display">\[\begin{equation}
y = \alpha + \beta x + \gamma D + \zeta DX + \varepsilon.
\end{equation}\]</span></p>
<p>In tali circostanze, quando <span class="math inline">\(D = 0\)</span>, abbiamo che:</p>
<p><span class="math display">\[\begin{align}
y &amp;= \alpha + \beta x + \gamma D + \zeta DX  + \varepsilon,\notag\\
 &amp;= \alpha + \beta x + \gamma \times 0 + \zeta \times 0 + \varepsilon,\notag\\
 &amp;= \alpha + \beta x + \varepsilon.\notag
\end{align}\]</span></p>
<p>Quando <span class="math inline">\(D = 1\)</span> (ricordiamo: in questo caso <span class="math inline">\(DX = x\)</span>):</p>
<p><span class="math display">\[\begin{align}
y &amp;= \alpha + \beta x + \gamma D + \zeta DX + \varepsilon,\notag\\
 &amp;= \alpha + \beta x + \gamma \times 1 + \zeta x + \varepsilon,\notag\\
 &amp;= (\alpha + \gamma) + (\beta + \zeta) x + \varepsilon.\notag
\end{align}\]</span></p>
<p>Ciò significa che i coefficienti del modello di regressione avranno ora la seguente interpretazione:</p>
<ul>
<li>
<span class="math inline">\(\alpha\)</span> = intercetta della retta di regressione per il gruppo codificato con <em>D</em> = 0;</li>
<li>
<span class="math inline">\(\beta\)</span> = pendenza della retta di regressione per il gruppo codificato con <em>D</em> = 0;</li>
<li>
<span class="math inline">\(\gamma\)</span> = differenza tra l’intercetta della retta di regressione per il gruppo codificato con <em>D</em> = 1 e l’intercetta della retta di regressione per il gruppo codificato con <em>D</em> = 0;</li>
<li>
<span class="math inline">\(\zeta\)</span> = differenza tra la pendenza della retta di regressione per il gruppo codificato con <em>D</em> = 1 e la pendenza della retta di regressione per il gruppo codificato con <em>D</em> = 0;</li>
</ul>
<p>Ritorniamo al nostro esempio numerico e calcoliamo i coefficienti del modello di regressione utilizzando l’approccio Bayesiano:</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">flist1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">alist</a></span><span class="op">(</span>
    <span class="va">y</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">mu</span>, <span class="va">sigma</span><span class="op">)</span>,
    <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">a</span> <span class="op">+</span> <span class="va">b</span><span class="op">*</span><span class="va">x</span> <span class="op">+</span> <span class="va">gamma</span><span class="op">*</span><span class="va">d</span> <span class="op">+</span> <span class="va">zeta</span><span class="op">*</span><span class="va">DX</span>,
    <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">a</span>, <span class="va">b</span>, <span class="va">gamma</span>, <span class="va">zeta</span><span class="op">)</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span>, 
    <span class="va">sigma</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">5</span><span class="op">)</span>
<span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/quap.html">quap</a></span><span class="op">(</span>
  <span class="va">flist1</span>, 
  data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>y<span class="op">=</span><span class="va">d</span><span class="op">$</span><span class="va">y</span>, x<span class="op">=</span><span class="va">d</span><span class="op">$</span><span class="va">x</span>, d<span class="op">=</span><span class="va">d</span><span class="op">$</span><span class="va">gr</span>, DX<span class="op">=</span><span class="va">d</span><span class="op">$</span><span class="va">DX</span><span class="op">)</span>, 
  start <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>a<span class="op">=</span><span class="fl">0</span>, b<span class="op">=</span><span class="fl">0</span>, gamma<span class="op">=</span><span class="fl">0</span>, zeta<span class="op">=</span><span class="fl">0</span>, sigma<span class="op">=</span><span class="fl">0.5</span><span class="op">)</span>
  <span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/pkg/rethinking/man/precis.html">precis</a></span><span class="op">(</span><span class="va">fit1</span><span class="op">)</span>
<span class="co">#&gt;            mean        sd       5.5%     94.5%</span>
<span class="co">#&gt; a      5.202783 0.8167093   3.897524  6.508043</span>
<span class="co">#&gt; b      4.967164 0.2057473   4.638340  5.295988</span>
<span class="co">#&gt; gamma -8.569902 1.2250868 -10.527828 -6.611977</span>
<span class="co">#&gt; zeta  -2.881817 0.2970176  -3.356509 -2.407126</span>
<span class="co">#&gt; sigma  2.069882 0.1034130   1.904608  2.235155</span></code></pre></div>
<p>In un tale modello, la prima domanda che dobbiamo porci è se i dati giustificano la conclusione secondo la quale, <em>nella popolazione</em>, le due rette hanno una pendenza diversa. Per rispondere a tale domanda esaminiamo l’intervallo di credibilità del coefficiente associato al termine d’interazione, ovvero del coefficiente <span class="math inline">\(\zeta\)</span>. R ci dice che l’intervallo di credibilità all’89% per il coefficiente <span class="math inline">\(\zeta\)</span> è pari a [-3.36, -2.41]. Dato che tale intervallo non include lo zero, con un livello di certezza dell’89% concludiamo che la retta di regressione del gruppo codificato con <em>D = 1</em> (ovvero <code>gr2</code>) ha una pendenza minore della retta di regressione per il gruppo codificato con <em>D = 0</em> (ovvero <code>gr1</code>).</p>

</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="index.html">Benvenuti</a></div>
<div class="empty"></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#introduzione-alla-regressione-lineare"><span class="header-section-number">1</span> Introduzione alla regressione lineare</a></li>
<li>
<a class="nav-link" href="#regressione-bivariata"><span class="header-section-number">1.1</span> Regressione bivariata</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#scioglimento-ghiaccio-marino"><span class="header-section-number">1.1.1</span> Scioglimento ghiaccio marino</a></li></ul>
</li>
<li><a class="nav-link" href="#interpretazione-dei-coefficienti-a-e-b"><span class="header-section-number">1.2</span> Interpretazione dei coefficienti \(a\) e \(b\)</a></li>
<li>
<a class="nav-link" href="#scomposizione-della-y"><span class="header-section-number">1.3</span> Scomposizione della \(y\)</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#metodo-di-stima-dei-coefficienti-del-modello-di-regressione"><span class="header-section-number">1.3.1</span> Metodo di stima dei coefficienti del modello di regressione</a></li></ul>
</li>
<li>
<a class="nav-link" href="#inferenza-sul-modello-di-regressione"><span class="header-section-number">1.4</span> Inferenza sul modello di regressione</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#errore-standard-della-stima"><span class="header-section-number">1.4.1</span> Errore standard della stima</a></li></ul>
</li>
<li>
<a class="nav-link" href="#una-variabile-indipendente-qualitativa"><span class="header-section-number">1.5</span> Una variabile indipendente qualitativa</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#interazione"><span class="header-section-number">1.5.1</span> Interazione</a></li></ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>PSICOMETRIA</strong>" was written by Corrado Caudek. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
