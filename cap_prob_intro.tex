% !TEX encoding = UTF-8 
% !TeX program = pdflatex
% !TeX spellcheck = italian
\chapter{Che cos'è la probabilità?}
\label{chapter:prob_discreta} 

%\section*{Obiettivi di apprendimento}
%
%Lo studio di questo capitolo dovrebbe insegnare allo studente come:
%\begin{itemize}
%\item 
%  Spiegare il significato dei termini spazio campionario, evento e funzione di probabilità.
%\item 
%  Organizzare uno scenario aleatorio nei termini di un esperimento casuale e di uno spazio campionario.
%\item 
%  Descrivere le proprietà elementari del calcolo delle probabilità.
%\item 
%  Spiegare come si assegnano le probabilità agli eventi.
%\item 
%  Spiegare in termini semplici che cosa significhi il termine variabile aletoria.
%\item 
%  Spiegare che cosa significhi il termine funzione di massa di probabilità.
%\item 
%  Calcolare le probabilità degli eventi sulla base delle informazioni fornite da una  funzione di probabilità.
%\item
%  Capire la notazione usata per fare riferimento ad eventi e probabilità.
%\end{itemize}
%
%\section*{Motivazione}

È normale fare delle congetture rispetto a ciò di cui non siamo sicuri. 
Ma perché facciamo questo? 
Molto spesso perché, anche se sappiamo che le nostre conoscenze sono incomplete, dobbiamo comunque prendere delle decisioni. 
Ad esempio: \enquote{non so se tra qualche ora pioverà; devo o non devo prendere l'ombrello?} 
In maniera simile, anche se uno psicologo non sa in maniera certa quali sono i meccanismi che regolano i fenomeni psicologi, deve comunque decidere tra diverse alternative.
Per esempio, deve fornire un parere, relativamente a chi, tra due genitori, sia più adatto per ottenere l'affidamento del figlio in caso di divorzio, oppure quale sia, in un caso specifico, l'approccio più efficace per il trattamento dei disturbi dell'alimentazione.
Ovviamente la qualità delle congetture varia, così come varia la qualità delle decisioni che prendiamo. 
La teoria delle probabilità ci fornisce gli strumenti per prendere decisioni \enquote{razionali} in condizioni di incertezza, ovvero per formulare le migliori congetture possibili. 

La teoria delle probabilità ci consente di descrivere in maniera quantitativa quei fenomeni che, pur essendo altamente variabili, rivelano comunque una qualche coerenza a lungo termine. 
Il lancio ripetuto di una moneta è uno di questi fenomeni. 
È anche l'esempio tipico che viene usato per introdurre una discussione sulle probabilità. 
Sapere se una moneta sia onesta o meno, o calcolare la probabilità di ottenere testa un certo numero di volte può essere interessante nel mondo delle scommesse, ma nella vita quotidiana non ci capita spesso di lanciare una moneta per prendere una decisione.  
Allora perché ci preoccupiamo di studiare le proprietà statistiche dei lanci di una moneta? 
A questa domanda si può rispondere dicendo che l'esperimento (chiamato \enquote{casuale}) che corrisponde al lancio di una moneta è il surrogato di una molteplicità di eventi che, della vita reale, sono molto importanti. 
Per esempio: qual è la probabilità di successo di un intervento psicologico? 
Qual è la probabilità che un test per l'HIV dia esito positivo in una persona che non ha l'HIV? Qual è la probabilità di essere occupato entro un anno dalla laurea? 
I lanci di una moneta costituiscono una rappresentazione generica di molteplici altri eventi che hanno un grande significato nella nostra vita. 
Questa è la ragione per cui  studiamo le proprietà statistiche dei fenomeni aleatori usando il lancio di una moneta quale esempio generico.

La discussione della teoria della probabilità è certamente l'argomento più impegnativo affrontato in queste dispense. 
Fare uno sforzo di comprensione per chiarire i concetti di base della teoria della probabilità è però necessario per mettersi nelle condizioni di capire le caratteristiche dell'inferenza statistica che verranno discusse in seguito.


\section{Probabilità nel linguaggio naturale}

In un articolo pubblicato su Harward Business Review nel 2018, Mauboussin e Mauboussin ci ricordano come, nel marzo del 1951, l'\emph{Office of National Estimates} della CIA pubblicò un documento che suggeriva che un attacco sovietico alla Jugoslavia nel corso dell'anno fosse una \enquote{seria possibilità}. 
Sherman Kent, un professore di storia a Yale che fu chiamato a Washington, D.C. per dirigere l'\emph{Office of National Estimates}, espresse perplessità sull'esatto significato dell'espressione \enquote{seria possibilità}. 
Lo interpretò nel senso che la probabilità di un attacco era di circa il 65\%. 
Ma quando chiese ai membri del \emph{Board of National Estimates} cosa ne pensassero, gli furono riferite cifre che andavano dal 20\% all'80\%. 
Una gamma così ampia rappresentava chiaramente un problema, poiché le implicazioni politiche di quegli estremi erano nettamente diverse. 
Kent riconobbe che la soluzione di tale problema era quella di usare i numeri per esprimere il nostro grado di certezza, notando mestamente: \enquote{Non abbiamo usato i numeri\dots\, e sembra chiaro che abbiamo abusando delle parole}.

Da allora non è cambiato molto. 
Ancora oggi le persone nel mondo della politica, degli affari e nella vita quotidiana continuano a usare parole vaghe per descrivere i possibili risultati degli eventi.
Perché? 
Phil Tetlock, professore di psicologia all'Università della Pennsylvania, che ha studiato a fondo il fenomeno psicologico della previsione, suggerisce che \enquote{una vaga verbosità conferisce sicurezza}.
Quando usiamo una parola per descrivere la probabilità di un evento incerto, cerchiamo di porci nelle condizioni di non essere smentiti dopo che il risultato dell'evento verrà rivelato. 
Se si verifica l'evento che abbiamo previsto, è facile dire: \enquote{Ti avevo detto che probabilmente sarebbe successo questo.} Se la nostra predizione fallisce, possiamo sempre dire: \enquote{Ho solo detto che probabilmente sarebbe successo.} 
Parole così ambigue non solo consentono all'oratore di evitare di essere smentito, ma consentono anche al destinatario di interpretare il messaggio in modo coerente con le sue nozioni preconcette. 
Ovviamente, da tale ambiguità linguistica deriva una cattiva comunicazione.
%Tale conclusione è stata confermata da un ricerca di Mauboussin e Mauboussin (2018) i quali hanno chiesto a \num{1700} persone di associare una stima numerica della probabilità a 23 parole o frasi comuni che esprimo vari gradi di incertezza (\emph{always}, \emph{possible}, \dots).
%I risultati indicano che alcune espressioni linguistiche sono interpretate in un modo piuttosto restrittivo, altre sono interpretate in senso lato. 
%Ad esempio, la maggior parte delle persone -- ma non tutte -- pensano che \enquote{always} significhi \enquote{100\% delle volte}, ma la stima numerica della probabilità che la maggior parte delle persone attribuisce all'espressione \enquote{real possibility} è molto grande e va dal 20\% all'80\% circa. 
%È dunque chiaro che l'uso dei termini come quelli esaminati da Mauboussin e Mauboussin (2018) nel nostro linguaggio naturale e quotidiano non può che generare confusione.
%Mauboussin e Mauboussin (2018) hanno svolto una ricerca in cui veniva chiesto a \num{1700} persone di associare una stima numerica della probabilità a 23 parole o frasi comuni che esprimo vari gradi di incertezza.
%I risultati sono riportati nella figura~\ref{fig:prob_lang_nat}.
%Salta immediatamente agli occhi la grande varietà delle stime numeriche della probabilità che le persone attribuiscono a determinate parole che esprimono il grado di certezza. 
%Mentre alcune espressioni linguistiche sono interpretate in un modo piuttosto restrittivo, altre sono interpretate in senso lato. 
%Ad esempio, la maggior parte -- ma non tutte -- delle persone pensano che \enquote{always} significhi \enquote{100\% delle volte}, ma l'intervallo di probabilità che la maggior parte delle persone attribuisce all'espressione \enquote{real possibility} è molto grande e va dal 20\% all'80\% circa. 
%In generale, la ricerca di Mauboussin e Mauboussin (2018) mette in luce il fatto che alla parola \enquote{possibile} e alle sue variazioni tende ad essere attribuita un gamma di significati molto ampia.
%È dunque chiaro che l'uso dei termini come quelli esaminati da Mauboussin e Mauboussin (2018) nel nostro linguaggio naturale e quotidiano non può che generare confusione.
%
%\begin{figure}%[h!]
% \centering
%\includegraphics[width=0.3\textwidth]{prob_language_nat}
%\caption{\label{fig:prob_lang_nat}Risultati dello studio di Mauboussin e Mauboussin (2018).}
% \end{figure}
%
%Mauboussin e Mauboussin (2018) hanno anche scoperto un interessante effetto di genere:  gli uomini e le donne tendono ad assegnare significati diversi alle parole che esprimono incertezza. 
%Come mostra la figura~\ref{fig:prob_lang_nat_sex}, le donne tendono ad associare un maggiore grado di certezza agli eventi descritti da parole e termini ambigui come \enquote{maybe}, \enquote{possibly} e \enquote{might happen}. 
%Questo risultato è coerente con quelli trovati da ricerche precedenti che hanno mostrato come le donne tendono ad usare parole e frasi che esprimono incertezza più spesso degli uomini, anche quando il livello di certezza non differisce tra i due generi.
%
%\begin{figure}%[h!]
% \centering
% \includegraphics[width=0.4\textwidth]{prob_language_nat_sex}
%\caption{\label{fig:prob_lang_nat_sex}Risultati dello studio di Mauboussin e Mauboussin (2018).}
%\end{figure}
È dunque necessario procedere in modo diverso nel linguaggio scientifico.
%In conclusione, anche se sembra chiaro che le persone usano parole ambigue invece di stime precise della probabilità per ridurre il rischio di essere smentite, nel linguaggio scientifico dobbiamo 
Vedremo in questo capitolo come sia possibile assegnare al termine \enquote{probabilità} un significato preciso.
% e come la chiarificazione di questo concetto costituisca il fondamento della teoria della probabilità, ovvero di quella branca della matematica che costituisce uno degli strumenti più potenti a disposizione della ricerca scientifica.



\section{Probabilità nel linguaggio scientifico}

% \subsection{Il gioco di De Méré}

La teoria della probabilità nasce nel 1654. 
Fu infatti in questa data che Antoine Gombaud Cavalier De Méré, un nobile francese, nonché accanito giocatore d'azzardo scrisse una lettera al suo amico Pascal per cercare di comprendere il motivo delle sue continue perdite nel gioco dei dadi.
De Méré descrisse due diverse scommesse: 

\begin{description}
\item[scommessa A] si lancia un dado per 4 volte di seguito e si vince se esce almeno una volta il 6;
\item[scommessa B] si lanciano due dadi per 24 volte di seguito e si vince se esce almeno una volta il doppio 6.
\end{description}
Il cavaliere De Méré pose a Pascal il seguente quesito: le possibilità di vittoria sono maggiori nella scommessa A o nella scommessa B?
Il problema di De Méré divenne un motivo di scambio epistolare tra Pascal e Fermat, i due più grandi matematici del tempo, e viene considerato come la motivazione iniziale dello sviluppo  della teoria della probabilità.

Ma come può essere risolto il problema di De Méré?
Una strategia possibile è quella di seguire l'esempio di De Méré, ovvero, giocare questo gioco molte volte.
Così facendo, De Méré si rese conto che le possibilità di vittoria erano leggermente migliori nel caso della scommessa A.

Utilizzando una simulazione al computer possiamo facilmente giungere a questa stessa conclusione senza perdere tutto il tempo che De Méré ha dedicato a questa materia.
Una simulazione al computer ci consente infatti di ripetere il gioco di De Méré moltissime volte e di annotare il risultato ottenuto ad ogni ripetizione del gioco.
Vedremo in seguito perché, utilizzando un computer, è possibile ottenere un risultato diverso ogni volta che si ripete una certa operazione, in modo tale da rappresentare il grado di casualità che si osserva quando si lancia di un dado.
Per ora ci limitiamo ad esaminare i risultati che vengono prodotti in questo modo e che sono illustrati nella figura~\ref{fig:demere}.

\begin{figure}%[h!]
 \centering
 \includegraphics[width=1\textwidth]{demere}
 \caption{Risultati ottenuti da \num{10000} ripetizioni delle due scommesse di De Méré.}
 \label{fig:demere}
 \end{figure}
 
La figura~\ref{fig:demere} riportata la proporzione di vittorie in funzione del numero di ripetizioni di ciascuna scommessa e rivela che, a lungo termine (ovvero, se consideriamo un grande numero di ripetizioni del gioco di De Méré), la scommessa A risulta più conveniente della scommessa B. 
Nel caso di \num{10000} ripetizioni del gioco di De Méré, la proporzione di vittorie è risultata essere pari a 0.5182 per la scommessa A e pari a 0.4909 per la scommessa B.
Se ripetiamo la stessa simulazione altre \num{10000} volte, otteniamo una proporzione di vittorie uguale a 0.5180 per la scommessa A e a 0.4878 per la scommessa B.

Vedremo in questo capitolo come ciascuna di queste proporzioni possa essere considerata come una \emph{stima empirica} di ciò che chiamiamo \emph{probabilità}.
Le proporzioni descritte sopra vengono sono delle \enquote{stime} poiché approssimano il vero valore della probabilità; infatti, ripetendo la simulazione due volte abbiamo ottenuto dei risultati leggermente diversi.
Ma allora qual è il \enquote{vero} valore della probabilità?
Un modo semplice per rispondere a questa domanda è quello di dire che, utilizzando la procedura descritta sopra, il vero valore della probabilità si otterrebbe se il gioco di De Méré venisse ripetuto infinite volte.
Ma ovviamente, per qualunque applicazione concreta, non abbiamo bisogno di ripetere la simulazione  infinite volte, in quanto un grande numero di ripetizioni ci fornisce un'approssimazione sufficiente.

In conclusione, le considerazioni precedenti ci fanno capire che il concetto di probabilità sia legato a quello di incertezza. 
La probabilità può infatti essere definita come la quantificazione del livello di \enquote{casualità} di un evento, laddove viene detto casuale ciò che non è noto o non può essere predetto con certezza. 


\section{Terminologia}

Come qualsiasi altra branca della matematica, la teoria delle probabilità fa uso di una specifica terminologia i cui concetti di base sono descritti di seguito.
%Per formalizzare il concetto di probabilità, dobbiamo prima introdurre alcuni termini. 
Il calcolo delle probabilità si occupa di un generico \emph{esperimento casuale}.
\begin{defn}
Si dice \emph{esperimento casuale} qualsiasi attività che produce un risultato osservabile. 
L'esecuzione di un esperimento casuale è chiamata \emph{prova} dell'esperimento. 
\end{defn}
Esempi sono: lanciare una moneta, lanciare un dado a 6 facce, provare un nuovo percorso per andare al lavoro per vedere se è più veloce di quello che usiamo di solito, o giocare al gioco di De Méré.
\begin{defn}
Il risultato (o esito) di una prova si indica con $\omega$ ed è detto \emph{evento elementare}.
\end{defn}
Prima che l'esperimento casuale venga eseguito non sappiamo quale esito verrà prodotto; dopo che l'esperimento casuale è stato eseguito, l'esito dell'esperimento si \enquote{cristallizza} nel risultato osservato. 
\begin{defn}
Si dice \emph{spazio campionario} $\Omega$ (probability space) l'insieme di tutti i possibili esiti di un esperimento casuale. 
\end{defn}
Lo spazio campionario può essere finito, infinito o infinito numerabile. 
Eseguire un esperimento casuale significa scegliere in maniera casuale uno dei possibili eventi elementari dello spazio campionario.
\begin{defn}
Si dice \emph{evento composto} (o non-elementare) un sottoinsieme dello spazio campionario, ovvero un insieme che può essere a sua volta scomposto in più eventi elementari.  
\end{defn}
Per esempio, il numero 4 è un evento elementare dello spazio campionario finito $\Omega = \{1, 2, 3, 4, 5, 6\}$ che corrisponde all'esperimento casuale del lancio di un dado. 
L'evento composto $A$ \enquote{il risultato è pari} è $A = \{2, 4, 6\}$. 


%\section{Probabilità e teoria degli insiemi}
%
%La teoria degli insiemi fornisce il fondamento della teoria della probabilità in quanto ci fornisce una serie di strumenti utili per descrivere gli eventi (cioè, i risultati possibili di un esperimento casuale).
%I concetti di \enquote{unione}, \enquote{intersezione} e \enquote{evento complementare} (si veda l'Appendice~\ref{cap:insiemi}) rendono possibile la definizione di nuovi eventi sulla base di eventi che sono già stati definiti, o rendono possibile la descrizione dello stesso evento in modi diversi, alcuni più facili da comprendere di altri.
%Due eventi $A$ e $B$ si dicono \enquote{disgiunti} o \enquote{mutualmente esclusivi} se non possono accadere insieme. 
%Per esempio, gli eventi elementari dello spazio campionario sono eventi disgiunti.
%%Più formalmente diciamo che, se $P(A) > 0$ e $P(B) > 0$, allora $A$ e $B$ sono eventi disgiunti quando $P(A \cap B) = \emptyset$.
%
%\begin{exmp}
%\label{exercise:sampling_space_2dice}
%Si costruisca lo spazio campionario dell'esperimento casuale consistente nell'osservare i punti ottenuti dal lancio di una coppia di dadi a sei facce. 
%\end{exmp}
%\begin{solu}
%Lo spazio campionario $\Omega$ è costituito da tutte le coppie di numeri ($i, j$) per $i, j = 1, \dots, 6$, come indicato nella figura seguente. 
%
%\begin{center}
%{\large
%\noindent
%\epsdice{1}\epsdice{1}\, \epsdice{1}\epsdice{2}\, \epsdice{1}\epsdice{3}\, \epsdice{1}\epsdice{4}\, \epsdice{1}\epsdice{5}\, \epsdice{1}\epsdice{6}\\
%\epsdice{2}\epsdice{1}\, \epsdice{2}\epsdice{2}\, \epsdice{2}\epsdice{3}\, \epsdice{2}\epsdice{4}\, \epsdice{2}\epsdice{5}\, \epsdice{2}\epsdice{6}\\
%\epsdice{3}\epsdice{1}\, \epsdice{3}\epsdice{2}\, \epsdice{3}\epsdice{3}\, \epsdice{3}\epsdice{4}\, \epsdice{3}\epsdice{5}\, \epsdice{3}\epsdice{6}\\
%\epsdice{4}\epsdice{1}\, \epsdice{4}\epsdice{2}\, \epsdice{4}\epsdice{3}\, \epsdice{4}\epsdice{4}\, \epsdice{4}\epsdice{5}\, \epsdice{4}\epsdice{6}\\
%\epsdice{5}\epsdice{1}\, \epsdice{5}\epsdice{2}\, \epsdice{5}\epsdice{3}\, \epsdice{5}\epsdice{4}\, \epsdice{5}\epsdice{5}\, \epsdice{5}\epsdice{6}\\
%\epsdice{6}\epsdice{1}\, \epsdice{6}\epsdice{2}\, \epsdice{6}\epsdice{3}\, \epsdice{6}\epsdice{4}\, \epsdice{6}\epsdice{5}\, \epsdice{6}\epsdice{6}\\
%}
%\end{center}
%In maniera più succinta possiamo scrivere $D^2 = \big\{\epsdice{1}\epsdice{1}, \epsdice{1}\epsdice{2}, \dots, \epsdice{6}\epsdice{6}\big\}$, dove
%\[
%D = \big\{\epsdice{1}, \epsdice{2}, \epsdice{3}, \epsdice{4}, \epsdice{5}, \epsdice{6}\big\}
%\]
%è l'insieme di tutti gli esiti possibili del lancio di un dado. Due lanci come $\epsdice{1}\epsdice{2}$ e $\epsdice{2}\epsdice{1}$ sono considerati eventi distinti per cui lo spazio campionario è costituito da un totale di $6^2=36$ eventi elementari.
%\end{solu}

\section{Le diverse definizioni della probabilità}

Ma, nello specifico, che cos'è la probabilità?
A questa domanda si può rispondere in modi diversi.

\subsection{Una definizione \enquote{ingenua} della probabilità}
\label{sec:def_ing_prob}

Storicamente, la prima definizione della probabilità di un evento è stata quella che richiede di contare il numero di modi nei quali un evento può manifestarsi e di dividere tale numero per il numero totale di eventi dello spazio campionario $\Omega$.
\begin{defn}
\label{def_ing_prob}
Dato uno spazio campionario finito, la definizione ingenua della probabilità dell'evento $A$ è
\begin{align}
P_{\text{ing}} = \frac{|A|}{|\Omega|}
= \frac{\text{numero eventi elementari favorevoli all'evento }A}{\text{numero totale  eventi elementari dello spazio campionario }\Omega}.\notag
\end{align}

\end{defn}
%Tale risulto è sempre sensato, anche quando viene superata la definizione ingenua di proprietà.

La definizione~\ref{def_ing_prob} rende chiaro che il calcolo delle probabilità richiede di contare il numero di modi in cui un evento può realizzarsi.
Per esempio, nell'esercizio~\ref{exercise:sampling_space_2dice} l'evento $A$ = \enquote{la somma dei due dati è 5} si può realizzare in 4 modi diversi:
$
A = \big\{
\epsdice{1}\epsdice{4}, 
\epsdice{2}\epsdice{3}, 
\epsdice{3}\epsdice{2},
\epsdice{4}\epsdice{1}
\big\}
$. 
Contare il numero di modi in cui un evento può realizzarsi può essere semplice,  nel caso di alcuni eventi (come il presente), oppure estremamente complesso, nel caso di altri eventi.
In questo secondo caso, per contare il numero di modi in cui un evento può realizzarsi, al fine di calcolare la probabilità definita come indicato sopra, è necessario fare uso del calcolo combinatorio.
In queste dispense ci accontenteremo di presentare alcune nozioni di base del calcolo combinatorio, ma non entreremo nei dettagli di questo argomento.
%In generale, una strategia utile per trovare la probabilità di un evento è quella di chiedersi: \enquote{è più facile trovare direttamente la probabilità dell'evento, oppure conviene invece calcolare la probabilità dell'evento complementare?}


\subsection{Una definizione \enquote{non ingenua} della probabilità}

Il calcolo combinatorio ci consente di contare il numero di casi nello spazio campionario e di applicare la definizione \enquote{ingenua} di probabilità descritta nella definizione~\ref{sec:def_ing_prob}.
È però facile rendersi conto che tale definizione di probabilità ha un grosso problema: non può essere applicata al caso di uno spazio campionario infinito. 
Dobbiamo dunque trovare una definizione che risolva un tale problema.
Per fare ciò vengono specificate alcune proprietà che vorremmo potere attribuire alla probabilità -- in matematica, tali proprietà sono dette \emph{assiomi} -- per poi definire una funzione di probabilità che soddisfi tali proprietà.
Arriviamo in questo modo alla seguente definizione non ingenua della probabilità.
\begin{defn}
\label{def:assiomi_Kolmogorov}
Uno spazio di probabilità è una terna ($\Omega$, $\mathcal{A}$, $P$), dove $\Omega$ è l'insieme dei risultati possibili di un esperimento casuale, $\mathcal{A}$ è detta $\sigma$-algebra, ovvero un insieme di insiemi (gli eventi) per i quali si può calcolare una probabilità, e $P()$ è una misura di probabilità su $\Omega$, ovvero $P: \Omega \rightarrow [0, 1]$.
\end{defn}
Per la precisione, una $\sigma$-algebra è una famiglia di insiemi tali che
\begin{itemize}
\item $\emptyset \in \mathcal{A}$;
\item se $A \in \mathcal{A}$ allora anche il suo complementare $A^C$ è in $\mathcal{A}$; 
\item unioni numerabili di elementi di $\mathcal{A}$ appartengono ancora ad $\mathcal{A}$.
\end{itemize}
%Ad esempio, nell'esperimento \enquote{lancio di un dado},
%$\Omega = \{1, 2, 3, 4, 5, 6\}$, $\mathcal{A}$ è la $\sigma$-algebra generata dagli eventi elementari di $\Omega$, cioè di fatto, quelli per i quali è possibile calcolare una probabilità.

La funzione di probabilità $P()$ deve soddisfare i seguenti assiomi:
\begin{enumerate}
\item la probabilità $P(\omega)$ soddisfa la disuguaglianza 
\begin{equation}
0 \leq P(\omega) \leq 1;
\end{equation}
\item la probabilità dell'evento certo (ovvero la probabilità dello spazio campionario $\Omega$) è 1:
\begin{equation}
P(\Omega) = \sum_{\omega \in \Omega} P(\omega) = 1;
\label{eq:tot_prob_sample_space}
\end{equation}
\item se $A_1, A_2, \dots, A_k$ sono eventi disgiunti, allora la probabilità che uno di essi si verifichi è pari alla somma delle loro separate probabilità:
\begin{equation}
P(A_1 \text{ o } A_1 \dots \text{ o } A_k) = P(A_1) + P(A_2) +\dots + P(A_k). \label{eq:kolmogorov_3}
\end{equation}
\end{enumerate}
La definizione~\ref{def:assiomi_Kolmogorov} corrisponde al cosiddetto \emph{approccio assiomatico} messo a punto da Kolmogorov intorno al 1930, il quale è alla base della moderna teoria della probabilità. 

Nonostante l'enorme complessità dell'approccio assiomatico alla probabilità, per gli scopi dell'analisi dei dati psicologici le cose che dobbiamo capire sono molto semplici.
I vincoli della $\sigma$-algebra sono necessari per evitare i paradossi che si possono creare quando si manipolano gli insiemi (ad esempio, l'utilizzo dell'\enquote{l'insieme di tutti gli insiemi} tipicamente conduce ad un paradosso).
Questi problemi sono però molto lontani dalle applicazioni della teoria della probabilità all'analisi dei dati psicologici.
Gli psicologi tipicamente effettuano partizioni molto semplici dello spazio campionario: il trattamento ha funzionato oppure no?
Per cui le aporie della teoria degli insiemi a cui la $\sigma$-algebra vuole porre un freno sono problemi che non ci riguardano.

Gli altri aspetti della teoria assiomatica della probabilità, invece, sono molto intuitivi.
I primi due assiomi possono essere interpretati nel modo seguente.
Si assegna il valore 0 all'\enquote{evento impossibile}, ovvero all'esito dell'esperimento casuale che non può verificarsi (ad esempio, il lancio di un dado a sei facce produce 7), e si assegna il valore 1 all'evento certo (ad esempio, il lancio di un dado a sei facce produce un numero compreso tra 1 e 6).
Di conseguenza, la probabilità è un numero nell'intervallo $[0, 1]$.

Il terzo assioma può essere compreso interpretando la probabilità come la frequenza relativa a lungo termine del verificarsi di un evento.
Se due eventi sono incompatibili, allora la frequenza relativa dell'unione di tali eventi è la somma delle due singole frequenze relative.
Lo stesso si vale per la probabilità.


\section{Assegnare le probabilità agli eventi}

È importante capire che l'approccio assiomatico non ci dice come sia possibile assegnare un valore di probabilità a un evento definito in $\Omega$.
A questo proposito esistono due diverse scuole di pensiero.

%Una volta definiti i concetti precedenti è necessario dare un contenuto concreto alla funzione di probabilità, ovvero è necessario specificare una regola che associa  a ciascun evento elementare $\omega \in \Omega$ un valore nell'intervallo $[0, 1]$. 



\subsection{Approccio frequentista}

Una prima possibilità è di definire la nozione di probabilità in termini empirici. 
La probabilità di un evento $A$ può essere concepita come il limite cui tende la  frequenza relativa dell'evento, al tendere all'infinito del numero delle prove effettuate, ossia 
\begin{equation}
P_A = \lim_{n \to \infty} \frac{n_A}{n}.
\end{equation}
Questo è l'approccio che abbiamo utilizzato in precedenza, quando abbiamo discusso il gioco di De Méré.

Tale  definizione assume che l'esperimento possa essere ripetuto più volte, idealmente infinite volte, sotto le medesime condizioni, e corrisponde alla definizione \emph{frequentista} di probabilità.
Per l'approccio frequentista, dire che la probabilità di ottenere testa è 0.5 significa affermare che l'evento \enquote{testa} verrebbe ottenuto nel 50\% dei casi, se ripetessimo tantissime volte l'esperimento casuale del lancio di una moneta.

Se non abbiamo a disposizione informazioni empiriche a proposito del verificarsi di un evento possiamo attribuire le probabilità agli eventi usando la nostra conoscenza della situazione. 
Tale approccio è seguito dalla definizione \emph{classica} di probabilità in base alla quale la  probabilità di un evento è il rapporto tra il numero di casi favorevoli e quelli possibili, supposto che tutti gli eventi siano equiprobabili, ossia 
\begin{equation}
P_A = \frac{n_A}{n},
\end{equation}
dove $n$ è il numero di casi possibili e $n_A$ è il numero di casi favorevoli per l'evento $A$. 
L'assunzione di equiprobabilità degli eventi elementari ha senso soprattutto nel caso dei giochi d'azzardo. 

\begin{exmp}
In base all'approccio frequentista, la probabilità è il limite a cui tende una frequenza relativa empirica al crescere del numero di ripetizioni dell'esperimento casuale.
È molto facile utilizzare \R\, per calcolare una tale probabilità.
Per esempio, se vogliamo calcolare la probabilità di ottenere 3 nel lancio di un dado equilibrato, possiamo eseguire la seguente simulazione.
\begin{lstlisting}
n <- 1e5
x <- sample(1:6, n, replace = TRUE)
x_01 <- ifelse(x == 3, 1, 0)
mean(x_01)
#> [1] 0.166824
\end{lstlisting}
Il risultato è ovviamente molto simile a $1/6$.
\end{exmp}


\subsection{Approccio Bayesiano}

%\subsection{Probabilità come grado di fiducia}
%\label{sec:prob_fiducia_def}
%
%%La definizione assiomatica della probabilità pone dei vincoli alle proprietà dei numeri che possiamo utilizzare per quantificare la probabilità, ma non ci dice che cosa quei numeri significano.
%La definizione \enquote{soggettivista} della probabilità supera alcune difficoltà delle precedenti definizioni della probabilità.
%Esistono infatti eventi per i quali non è possibile calcolare la frequenza, quelli che si verificano una volta soltanto.
%Ma che cos'è la probabilità, nel caso degli eventi unici, se non può essere una frequenza relativa?
%%\begin{defn}
%%La probabilità è la misura del grado di fiducia che un evento si verifichi.
%%\end{defn}
%Secondo la definizione \enquote{soggettivista},
%% della probabilità fornisce dunque un'interpretazione al valore della probabilità che viene assegnato agli eventi: 
%la probabilità quantifica il grado di fiducia che un soggetto ha rispetto al verificarsi dell'evento considerato, sia esso unico o ripetibile.

Esistono però degli eventi per i quali non è possibile calcolare una frequenza relativa, ovvero quelli che si verificano una volta soltanto.
Che cos'è allora la probabilità in questi casi?
In base all'approccio Bayesiano la probabilità è una misura del grado di plausibilità di una proposizione. 
Questa definizione è applicabile a qualsiasi evento. 
Ciò consente di assegnare una probabilità anche a proposizioni quali \enquote{il candidato $A$ vincerà le elezioni} oppure \enquote{l'accusato è innocente}, anche se non è possibile ripetere più volte un'elezione o un evento criminoso.

Per assegnare le probabilità agli eventi, nell'approccio Bayesiano si utilizzano considerazioni \enquote{soggettive} che derivano dalle informazioni di cui il soggetto è in possesso.
Il teorema di Bayes consente di aggiustare, alla luce dei dati osservati, tali  credenze \enquote{a priori} per arrivare alla probabilità a posteriori.  
Quindi, tramite l'approccio Bayesiano, si usa una stima del grado di plausibilità di una proposizione prima dell'osservazione dei dati, al fine di associare un valore numerico al grado di plausibilità di quella stessa proposizione successivamente all'osservazione dei dati.
Questo processo di \enquote{aggiornamento Bayesiano} corrisponde all'inferenza statistica e verrà discusso in dettaglio nella parte~\ref{part:bayesian_inference} delle dispense.


\section{Proprietà elementari della probabilità}

Indipendentemente da come decidiamo di interpretare la probabilità (in termini frequentisti o Bayesiani), alla probabilità possono essere assegnate le seguenti proprietà.
%Consideriamo ora alcune relazioni elementari relative al calcolo delle probabilità. 
\begin{enumerate}[label=(\alph*)]
\item La probabilità dell'evento impossibile è zero:
\begin{equation}
P(\emptyset) = 1 - P(\Omega) = 0.
\end{equation}
\item Se consideriamo due eventi $A$ e $B$ tali che $A \subseteq B$, cioè che $A$ è contenuto o coincidente con $B$, da ciò segue che 
\begin{equation}
 P(A) \leq P(B). 
\end{equation}
\item Se $A^c = \Omega \textbackslash A$ è il complementare dell'evento $A$, allora 
\begin{equation}
P(A^c) = 1 - P(A).
\label{eqprobcomp}
\end{equation}
\item Dati $n$ eventi $A_i$ per $i= 1, \cdots, n$, gli eventi si dicono \emph{indipendenti} se risulta
\begin{equation}
P(A_i \cap A_j \cap \cdots \cap A_k) = P(A_i) P(A_j) \cdots P(A_k).
\label{eq_indipendence}
\end{equation}
\item Se due eventi $A$ e $B$ non sono disgiunti, allora  quando sommiamo le loro probabilità dobbiamo evitare che la loro parte comune $A \cap B$ venga contata due volte. 
Dati due eventi non necessariamente disgiunti, dunque, la probabilità dell'unione è pari alla somma delle singole probabilità dei due eventi meno la probabilità dell'intersezione:
\begin{equation}
P(A \text{ o } B) = P(A \cup B) = P(A) + P(B) - P(A \cap B).
\label{eq:probunione}
\end{equation}
\end{enumerate}

\begin{exmp}
Nel 2012, a 97 deputati al Parlamento di Londra è stato chiesto: \enquote{Se lanci una moneta due volte, qual è la probabilità di ottenere due volte testa?} La maggioranza, 60 su 97, non ha saputo dare la risposta corretta. Come possiamo dare a questo problema una risposta migliore di quella fornita da questi politici?
\end{exmp}
\begin{solu}
In base alla regola (d) elencata sopra, la risposta corretta è $0.5 \times 0.5 = 0.25$.
\end{solu}

\begin{exmp}
Un'urna contiene $30$ palline: $10$ bianche numerate da $1$ a $10$, $10$ rosse e $10$ gialle numerate allo stesso modo. 
Qual è la probabilità che, estraendo una pallina a caso, venga estratta una pallina gialla o una pallina pari? 
\end{exmp}
\begin{solu}
Il  numero  totale  di  palline  è  $30$.  La  probabilità  che  venga  estratta  una gialla è $P(G) = \frac{10}{30} = \frac{1}{3}$. 
Le palline con numero pari sono $5$ per ogni colore, quindi $15$. 
La probabilità che venga estratto un numero pari è $P(P) = \frac{15}{30} = \frac{1}{2}$. 
Gli eventi sono compatibili: i casi favorevoli a entrambi gli eventi (pallina gialla e pari) sono $5$. 
La probabilità dell'evento cercato è dunque  $P(\text{gialla} \cup \text{pari}) = \frac{1}{3} + \frac{1}{2} - \frac{5}{30} = \frac{2}{3}$.
\end{solu}


%\section{Come si assegnano le probabilità agli eventi?}
%
%Ora che sappiamo cos'è una probabilità, chiediamoci come sia possibile assegnare un valore di probabilità a ciascun evento definito in $\Omega$.
%Una possibilità è di definire la nozione di  probabilità in termini empirici. 
%La probabilità di un evento $A$ può essere concepita come il limite  cui  tende  la  frequenza  relativa dell'evento, al tendere all'infinito del numero delle prove effettuate, ossia 
%\begin{equation}
%P_A = \lim_{n \to \infty} \frac{n_A}{n}.
%\end{equation}
%Tale  definizione  assume che l'esperimento possa essere ripetuto più volte, idealmente infinite volte, sotto le medesime condizioni, e corrisponde alla definizione \emph{frequentista} di probabilità.
%
%Se non abbiamo a disposizione informazioni empiriche a proposito del verificarsi di un evento possiamo attribuire le probabilità agli eventi usando la nostra conoscenza della situazione. 
%Tale approccio è seguito dalla definizione \emph{classica} di probabilità in base alla quale la  probabilità  di  un  evento è il  rapporto  tra  il  numero  di  casi favorevoli e quelli possibili, supposto che tutti gli eventi siano equiprobabili, ossia 
%\begin{equation}
%P_A = \frac{n_A}{n},
%\end{equation}
%dove $n$ è il numero di casi possibili e $n_A$ è il numero di casi favorevoli per l'evento $A$. 
%L'assunzione di equiprobabilità degli eventi elementari ha senso soprattutto nel caso dei giochi d'azzardo. 
% 
%Un'ultima, più moderna, concezione della probabilità è quella \emph{bayesiana}.
%Nell'approccio bayesiano si utilizzano considerazioni `soggettive' per assegnare le probabilità agli eventi.  
%Nell'approccio bayesiano ci si chiede quale sia il grado di fiducia che si ha nei confronti del verificarsi di un certo evento, se si è in possesso di certe informazioni.
%Il teorema di Bayes consente in seguito, alla luce dei dati osservati, di aggiustare le nostre credenze `a priori' per arrivare alla probabilità a posteriori.  
%Quindi, tramite tale approccio, si usa una stima del grado di credibilità di una data ipotesi prima dell'osservazione dei dati, al fine di associare un valore numerico al grado di credibilità di quella stessa ipotesi successivamente all'osservazione dei dati.


\section{Variabili aleatorie}

Il concetto di \enquote{variabile aleatoria} è estremamente utile per estendere la nostra capacità di quantificare l'incertezza e di riassumere i risultati di un esperimento casuale.
Le variabili aleatorie sono un concetto fondamentale di tutta la teoria statistica; è quindi cruciale capire quale sia il loro significano.
%È inoltre necessario sapere come tali variabili possano essere manipolate algebricamente. 
Iniziamo con una definizione.
\begin{defn}
Una variabile aleatoria è una funzione sullo spazio campionario $\Omega$ che associa ad ogni evento elementare $\omega_i$ un unico numero $X(\omega_i) = x_i$, ovvero $X: \Omega \rightarrow \Re$.
\end{defn}
Il dominio della variabile aleatoria $X$ (che è una funzione) è dato dai punti dello spazio campionario $\Omega$.
%\[
%X: \Omega \rightarrow \Re.
%\]
Ad ogni evento elementare $\omega_i$ attribuiamo il numero $X(\omega_i)$, ovvero il valore che la variabile aleatoria assume sul risultato $\omega_i$ dell'esperimento casuale.
L'attributo \enquote{aleatoria} si riferisce al fatto che la variabile considerata trae origine da un esperimento di cui non siamo in grado di prevedere l'esito con certezza. 

Mediante una variabile aleatoria trasformiamo lo spazio campionario $\Omega$, che in genere è complesso, in uno spazio campionario più semplice formato da un insieme di numeri. 
Il maggior vantaggio di questa sostituzione è che molte variabili aleatorie, definite su spazi campionari anche molto diversi tra loro, danno luogo ad una stessa \enquote{distribuzione} di probabilità sull'asse reale. 
Le variabili aleatorie si indicano con le lettere maiuscole ed i valori da esse assunti con le lettere minuscole.  

%Il valore $x_i$ è una determinazione della variabile aleatoria $X$.
%L'idea intuitiva è semplice: chiamiamo variabile aleatoria ogni grandezza su cui non possiamo fare previsioni certe. 
%Infatti, l'attributo `aleatoria' si riferisce al fatto che la variabile a cui ci riferiamo trae origine da un esperimento di cui non siamo in grado di prevedere l'esito con certezza. 

Ci sono due classi di variabili aleatorie: variabili aleatorie discrete e variabili aleatorie continue.
Consideriamo innanzitutto il caso delle variabili aleatorie discrete.

\begin{defn}
Una variabile aleatoria $X$ viene detta discreta se può assumere un insieme discreto (finito o numerabile) di numeri reali.
\end{defn}
Se $X$ è una variabile aleatoria discreta allora l'insieme dei possibili valori $x$, tali per cui $P(X = x) > 0$, viene detto \enquote{supporto} di $X$.

Alcuni esempi di variabili aleatorie discrete sono i seguenti: 
 il numero di intrusioni di pensieri, immagini, impulsi indesiderabili in un paziente OCD, 
il voto all'esame di Psicometria,
la durata di vita di un individuo,
il numero dei punti che si osservano nel lancio di due dadi e
 il guadagno (la perdita) che un giocatore realizzerà in $n$ partite.
Si noti che, in tutti questi casi, la variabile aleatoria considerata viene rappresentata mediante un numero.

\subsection{A cosa servono le variabili aleatorie?}

Facendo riferimento agli esempi elencati sopra, possiamo chiederci perché questi numeri vengono considerati come \enquote{aleatori}.
È ovvio che noi non conosciamo, ad esempio, il voto di Psicometria di Mario Rossi prima del momento in cui Mario Rossi avrà fatto l'esame.
Le variabili aleatorie si pongono il seguente problema: come possiamo descrivere le nostre opinioni rispetto al voto (possibile) di Mario Rossi, prima che lui abbia fatto l'esame.
Prima dell'esame, il voto di Psicometria di Mario Rossi si può solo descrivere facendo riferimento ad un insieme di valori possibili.
Inoltre, molto spesso, possiamo anche dire che tali valori possibili non sono tutti egualmente verosimili: ci aspettiamo di osservare più spesso alcuni di questi valori rispetto agli altri.
Le proprietà delle variabili aleatorie ci consentono di sistematizzare questo tipo di opinioni.
Ovviamente, una volta che Mario Rossi avrà fatto l'esame, questa materia non avrà più alcuna componente aleatoria.


\subsection{Funzione di massa di probabilità}

Per entrare nel merito di questa discussione, chiediamoci ora come sia possibile associare delle probabilità ai valori che vengono assunti dalle variabili aleatorie.
Ad esempio, qual è la probabilità che Mario Rossi ottenga 29 all'esame?
Ci occuperemo qui del caso delle variabili aleatorie discrete.


Alle variabili aleatorie discrete vengono assegnale le probabilità mediante le cosiddette \enquote{distribuzioni di probabilità}. 
Una distribuzione di probabilità è un modello matematico che collega ciascun valore di una variabile aleatoria discreta alla probabilità di osservare un tale valore in un esperimento casuale.
%L'esito di una misura, per esempio, può essere considerato una variabile aleatoria, poiché tale valore può assumere valori differenti all'interno della popolazione.  
In pratica, ad ognuno dei valori che possono essere assunti da una variabile aleatoria discreta viene associata una determinata probabilità. 
La funzione che associa ad ogni valore della variabile aleatoria una probabilità corrispondente si chiama \enquote{distribuzione di probabilità} oppure \enquote{legge di probabilità}.

Una descrizione intuitiva del concetto di distribuzione di probabilità può essere formulata nei  termini seguenti.
Possiamo pensare alla probabilità come ad una quantità positiva che viene \enquote{distribuita} sull'insieme dei valori della variabile aleatoria. 
Tale \enquote{distribuzione} (suddivisione, spartizione) viene scalata in maniera tale che ciascun elemento di essa corrisponda ad una proporzione del totale, nel senso che il valore totale della distribuzione è sempre pari a 1.  
Una distribuzione di probabilità non è dunque altro che un modo per suddividere la nostra certezza (cioè 1) tra i valori che la variabile aleatoria può assumere.
In modo più formale, possiamo dire quanto segue.
\begin{defn}
Se $X$ è una variabile aleatoria discreta, una distribuzione di probabilità può essere rappresentata mediante una funzione di massa di probabilità che associa a ciascuno dei valori $x$ che la variabile aleatoria $X$ può assumere la corrispondente probabilità $P_{\pi}(X=x)$. 
\end{defn}
In maniera più semplice, una distribuzione di (massa) di probabilità è formata dall'elenco di tutti i valori possibili di una variabile aleatoria discreta e dalle probabilità loro associate.
Si noti che $P_{\pi}(X=x)$ è un numero positivo se il valore $x$ è compreso nel supporto di $X$, altrimenti vale 0.

Se $A$ è un sottoinsieme della variabile aleatoria $X$, allora denotiamo con $P_{\pi}(A)$ la probabilità assegnata ad $A$ dalla distribuzione $P_{\pi}$.
Mediante una distribuzione di probabilità $P_{\pi}$ è possibile determinare la probabilità di ciascun sottoinsieme $A \subset X$ come
\begin{equation}
P_{\pi}(A) = \sum_{x \in A} P_{\pi}(x).
\end{equation}
Qui non facciamo altro che applicare il terzo assioma di Kolmogorov -- si veda l'eq.~\eqref{eq:kolmogorov_3}.

\begin{exmp}
\label{exercise:prob_distr_2dice}
Consideriamo nuovamente lo spazio campionario $\Omega$ dell'esercizio~\ref{exercise:sampling_space_2dice} e definiamo la variabile aleatoria $S(\omega)$ come la somma dei puntini che si ottengono dal lancio di due dadi. 
Per esempio, $S\big(\epsdice{6}\epsdice{3}\big) = 6+3=9$. 
Iniziamo a chiederci qual è la probabilità dell'evento $S = 7$.

Per risolvere tale problema iniziamo a considerare il fatto che l'evento $S = 7$ si verifica in corrispondenza di sei punti elementari dello spazio campionario $\Omega$: 
$\epsdice{1}\epsdice{6}$, $\epsdice{2}\epsdice{5}$, $\epsdice{3}\epsdice{4}$, $\epsdice{4}\epsdice{3}$, $\epsdice{5}\epsdice{2}$, $\epsdice{6}\epsdice{1}$. 
% Sappiamo inoltre che gli eventi elementari di $\Omega$ sono equiprobabili.
Dunque,
\[
P(S = 7) = P\big(\epsdice{1}\epsdice{6}\big) + P\big(\epsdice{2}\epsdice{5}\big) + P\big(\epsdice{3}\epsdice{4}\big) + P\big(\epsdice{4}\epsdice{3}\big) + P\big(\epsdice{5}\epsdice{2}\big) + P\big(\epsdice{6}\epsdice{1}\big). 
\]
Se possiamo assumere che i due dadi sono bilanciati, allora ciascun evento elementare dello spazio campionario ha probabilità $\frac{1}{36}$ e la probabilità cercata diventa $\frac{1}{6}$. 
È facile estendere il ragionamento fatto sopra a tutti i valori che $S$ può assumere.
In questo modo giungiamo alla funzione di massa di probabilità $P_0$ riportata nella prima riga della tabella~\ref{tab:massa_prob_due_dadi_on_tr}. 
\begin{table}[h!]
\caption{Distribuzione di massa di probabilità per la somma dei punti prodotti dal lancio di due dadi bilanciati ($P_0$) e di due dadi truccati ($P_1$).}
\centering
\begin{tabular}{cccccccccccc}
\toprule
s & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 \\
\midrule
$P_0(S = s)$ & $\frac{1}{36}$ & $\frac{2}{36}$ & $\frac{3}{36}$ & $\frac{4}{36}$ & $\frac{5}{36}$ & $\frac{6}{36}$ & $\frac{5}{36}$ & $\frac{4}{36}$ & $\frac{3}{36}$ & $\frac{2}{36}$ & $\frac{1}{36}$ \\[5pt]
$P_1(S = s)$ & $\frac{4}{64}$ & $\frac{4}{64}$ & $\frac{5}{64}$ & $\frac{6}{64}$ & $\frac{7}{64}$ & $\frac{12}{64}$ & $\frac{7}{64}$ & $\frac{6}{64}$ & $\frac{5}{64}$ & $\frac{4}{64}$ & $\frac{4}{64}$ \\
\bottomrule
\end{tabular}
\label{tab:massa_prob_due_dadi_on_tr}
\end{table}%

Per considerare un caso più generale, poniamoci ora il problema di trovare la funzione di massa di probabilità di $S$ nel caso di due dadi truccati aventi la seguente distribuzione di probabilità:
\begin{align}
P\big(\epsdice{1}\big) &= P\big(\epsdice{6}\big) = \frac{1}{4};\notag\\
P\big(\epsdice{2}\big) &= P\big(\epsdice{3}\big) = P\big(\epsdice{4}\big) = P\big(\epsdice{5}\big) = \frac{1}{8}\notag.
\label{eq:loaded_dice}
\end{align}
%Nel caso di due dadi onesti, la variabile aleatoria $S$ assume i valore 2 nel caso di un unico punto dello spazio campionario, $\epsdice{1}\epsdice{1}$. 
%Dunque $P(S = 2) = \frac{1}{36}$. 
%$S$ assume valore 3 in corrispondenza di due punti dello spazio campionario: $\epsdice{1}\epsdice{2}$ e $\epsdice{2}\epsdice{1}$. 
%Dunque, $P(S = 3) = \frac{2}{36}$, e così via. 
%La distribuzione di massa di probabilità della variabile aleatoria $S$ è quella indicata come $P_0$ nella tabella~\ref{tab:massa_prob_due_dadi_on_tr}. 
Nel caso dei due dadi truccati, la probabilità dell'evento elementare $\epsdice{1}\epsdice{1}$ è $\frac{1}{4}\frac{1}{4}$. 
Dunque, $P(S=2) = \frac{4}{64}$. 
La probabilità dell'evento elementare $\epsdice{1}\epsdice{2}$ è $\frac{1}{4}\frac{1}{8}$. 
Tale valore è uguale alla probabilità dell'evento elementare $\epsdice{2}\epsdice{1}$. 
Dunque, la probabilità che $S$ sia uguale a 3 è $\frac{1}{4}\frac{1}{8} + \frac{1}{8}\frac{1}{4} = \frac{4}{64}$, e  così via. 
Svolgendo i calcoli per tutti i possibili valori di $S$ otteniamo la funzione di massa di probabilità $P_1$ riportata nella seconda riga della tabella~\ref{tab:massa_prob_due_dadi_on_tr}. 

Si noti che, a partire dalla funzione di massa di probabilità di $S$, è possibile calcolare la probabilità di altri eventi. 
Per esempio, possiamo dire che l'evento $S > 10$ ha una probabilità minore nel caso dei dadi bilanciati, $P_0(S > 10) = \frac{3}{36} = \frac{1}{12}$, rispetto al caso dei dadi truccati considerati in precedenza, $P_1(S > 10) = \frac{8}{64} = \frac{1}{8}$.

\end{exmp}


\section{Notazione}

Qui sotto è riportata la notazione che verrà usata per fare riferimento ad eventi e probabilità, nel caso discreto e continuo, in maniera tale che queste convenzioni siano elencate tutte in un posto solo. 
\begin{itemize}
\item Gli eventi sono denotati da lettere maiuscole, es. $A$, $B$, $C$.
\item Una variabile aleatoria è denotata da una lettera maiuscola, ad esempio $X$, e assume valori denotati dalla stessa lettera minuscola, ad esempio $x$. 
\item La connessione tra eventi e valori viene espressa nei termini seguenti: ``$X = x$'' significa che l'evento $X$ assume il valore $x$.
\item La probabilità di un evento è denotata con $P(A)$.
\item Una variabile aleatoria discreta ha una funzione di massa di probabilità denotata con $p(x)$. 
La relazione tra $P$ e $p$ è che $P(X=x) = p(x)$.
\end{itemize}


\section*{Conclusioni}

In questo capitolo abbiamo visto come si costruisce lo spazio campionario di un esperimento casuale, quali sono le proprietà di base della probabilità e come si assegnano le probabilità agli eventi definiti sopra uno spazio campionario discreto.
Abbiamo anche introdotto le nozioni di \enquote{variabile aleatoria} e di \enquote{funzione di massa di probabilità}. 
Le procedure di analisi dei dati psicologici che discuteremo in seguito faranno un grande uso di questi concetti e della notazione qui introdotta.



%%%-----------------------------------------------------------------------------
%\section*{Problemi}
%%%-----------------------------------------------------------------------------
%
%\addcontentsline{toc}{section}{Problemi}
%
%%--------------------------------------------------------------------
%
%\begin{prob}
%Sia $X$ la somma dei puntini ottenuti nel lancio di due dadi. Qual è la probabilità che $X$ assuma un valore maggiore di 10?
%\label{ex:rocco_7}
%\end{prob}
%
%%--------------------------------------------------------------------
%
%\begin{prob}
%Sia $X$ la somma dei puntini ottenuti nel lancio di 4 dadi. Qual è la probabilità che $X$ assuma un valore  di almeno 23?
%\label{ex:rocco_8}
%\end{prob}
%
%%---------------------------------------------------------------------
%
%\begin{prob}
%\label{ex:dadidisgiunti}
%Si consideri l'esperimento consistente nel lancio di due dadi onesti. $A$: ``esce un 1 o un 2 nel primo lancio;'' $B$: ``i due lanci producono  un punteggio totale uguale a 10.''
%Gli eventi $A$ e $B$ sono disgiunti?
%\end{prob}
%
%%---------------------------------------------------------------------
%
%\begin{prob}
%\label{ex:dadidisgiunti2}
%Per l'esperimento casuale descritto nell'esercizio~\ref{ex:dadidisgiunti}, si calcoli la probabilità $P(A \cup B)$.
%\end{prob}
%
%
%%---------------------------------------------------------------------
%\begin{prob}
%\label{prob_siletti4}
%Un esperimento consiste nel lanciare insieme due dadi a sei facce. Dopo aver determinato lo spazio degli eventi elementari, calcolare la probabilità dei seguenti eventi: (1) $A$ = ``nei due lanci le facce superiori sono uguali,'' (2) $B$ = ``nei due lanci le facce superiori hanno somma cinque,'' (3) $C$ = ``il numero riportato su una faccia è il doppio dell'altra.''
%\end{prob}
%
%%---------------------------------------------------------------------
%
%\begin{prob}
%\label{es_siletti5}
%Un dado regolare viene lanciato tre volte. Determinare:
%(1) la probabilità che i numeri ottenuti siano pari;
%(2) la probabilità che la somma dei numeri ottenuti sia cinque.
%\end{prob}
%
%%----------------------------------------------------------------------
%
%\begin{prob}
%\label{ex:cityeye}
%In un campione di pazienti che soffrono di un disturbo d'ansia generalizzato il 75\% manifesta palpitazioni (P), il 40\% tremori (T) e il 25\%  sia sia palpitazioni sia tremori. Una paziente è scelto a caso.  Qual è la probabilità che manifesti palpitazioni o tremori? Che non manifesti né palpitazioni né tremori?
%\end{prob}
%
%%----------------------------------------------------------------------
%
%\begin{prob}
%\label{ex:falk_keldig}
%Una moneta onesta viene lanciata due volte. Sapendo che il primo lancio ha prodotto testa, si trovi la probabilità che l'esito testa venga trovato in entrambi i lanci.
%\end{prob}
%
%%----------------------------------------------------------------------
%\begin{prob}
%\label{es_insonnia}
%Un gruppo di pazienti affetti da disturbo da uso di sostanze è costituito da $24$
%   femmine e $26$ maschi.  Tra questi, $12$ femmine e $18$
%   maschi soffrono d'insonnia.  Un paziente viene scelto a caso. (a) Qual \`e la probabilit\`a che soffra d'insonnia?   Se sappiamo che il paziente selezionato \`e una femmina, qual \`e la probabilit\`a che soffra d'insonnia?
%\end{prob}
%
%%---------------------------------------------------------------------
%
%\begin{prob}
%\label{es_siletti6}
%Nel lancio di un dado sia $A$ l'evento ``esce un numero dispari,'' $B$ l'evento ``esce un numero pari.'' (1)  Gli eventi $A$ e $B$ sono incompatibili? (2)  Gli eventi $A$ e $B$ sono complementari? (3)  Gli eventi $A$ e $B$ sono indipendenti?
%\end{prob}
%
%%----------------------------------------------------------------------
%\begin{prob}
%\label{ex:riganti_1.1}
%Da un mazzo di 52 carte se ne sceglie una a caso. Quanto vale la probabilità di estrarre una figura o una carta di fiori? E quella di estrarre una figura e un fiori?
%\end{prob}
%
%
%%----------------------------------------------------------------------
%\begin{prob}
%\label{es_siletti7}
%Siano $A$ e $B$ due eventi in $\mathcal{S}$ tali che $P(A) = 0.5$ e $P(A \cup B) = 0.6$. Determinare P(B) nel caso in cui:
%(1) $A$ e $B$ sono eventi incompatibili.
%(2) $A$ e $B$ sono eventi indipendenti.
%(3) $P(A|B) = 0.4$.
%\end{prob}
%
%%----------------------------------------------------------------------
%\begin{prob}
%\label{ex:dadisomma3}
%Si consideri l'esperimento casuale corrispondente al lancio di due dadi onesti.
%(a) Qual \`e la probabilit\`a che la somma dei due lanci sia $3$?
%(b) Sapendo che il primo lancio produce $1$, qual \`e la probabilit\`a che la somma  dei due lanci sia $3$?
%\end{prob}
%
%%----------------------------------------------------------------------
%\begin{prob}
%\label{ex:cond2}
%In un gruppo di pazienti clinicamente depressi, il 60\% manifesta disturbi d'umore, il 40\% manifesta  difficoltà nella concentrazione e il 30\%  sia disturbi d'umore sia difficoltà nella concentrazione. Sapendo che un paziente scelto a caso manifesta disturbi d'umore, qual è la probabilità che manifesti anche difficoltà nella concentrazione?
%\end{prob}
%
%
%%----------------------------------------------------------------------
%\begin{prob}
%\label{ex:pokerind1}
%Una carta viene estratta a caso da un mazzo da poker. Sia $A$ l'evento ``fiori'' e $B$ l'evento ``asso.'' I due eventi $A$ e $B$ sono indipendenti?
%\end{prob}
%
%%--------------------------------------------------------------------
%\begin{prob}
%\label{ex:incomp}
%Siano $A$ e $B$ due eventi dello spazio campionario $\mathcal{S}$ tali che $P(A)$ =
%0.7 e $P(A \cup B)$ = 0.8. Si determini $P(B)$ nei seguenti casi: $A$ e $B$ sono incompatibili, $A$ e $B$ sono indipendenti.
%\end{prob}
%
%
%% sommatorie %%%%%%%%%%%
%
%%------------------------------------------------------------------
%\begin{prob}
%\label{prob:sum_1}
%Si valuti $\sum_{r=1}^4 r^2$.
%\end{prob}
%
%
%%------------------------------------------------------------------
%\begin{prob}
%\label{prob:sum_2}
%Si valuti $\sum_{n=2}^5 n^2$.
%\end{prob}
%
%
%%------------------------------------------------------------------
%\begin{prob}
%\label{prob:sum_3}
%Si valuti $\sum_{k=0}^5 2^k$.
%\end{prob}
%
%%------------------------------------------------------------------
%\begin{prob}
%\label{prob:sum_4}
%Si valuti $\sum_{r=1}^6 \frac{1}{2}r(r+1)$.
%\end{prob}
%
%%------------------------------------------------------------------
%\begin{prob}
%\label{prob:sum_5}
%Si valuti $\sum_{r=1}^4 (-1)^r$.
%\end{prob}
%
%%------------------------------------------------------------------
%\begin{prob}
%\label{prob:sum_6}
%Si valuti $\sum_{k=1}^3 (-\frac{1}{k})^2$.
%\end{prob}
%
%%------------------------------------------------------------------
%\begin{prob}
%\label{prob:sum_7}
%Si valuti $\sum_{k=1}^4 3k$.
%\end{prob}
%
%%------------------------------------------------------------------
%\begin{prob}
%\label{prob:sum_8}
%Si valuti $\sum_{k=1}^4 (k+2)$.
%\end{prob}
%
%%------------------------------------------------------------------
%\begin{prob}
%\label{prob:sum_9}
%Si valuti $\sum_{k=1}^3 (k+k^2)$.
%\end{prob}
%
%%------------------------------------------------------------------
%\begin{prob}
%\label{prob:sum_10}
%Sia $x = \{7, 4, 1\}$. Si valuti $\sum_{i=1}^3 (x_i - 4)$.
%\end{prob}
%
%%------------------------------------------------------------------
%\begin{prob}
%\label{prob:sum_11}
%Sia $x = \{7, 4, 1\}$. Si valuti $\sum_{i=1}^3 x_i - 4$.
%\end{prob}
