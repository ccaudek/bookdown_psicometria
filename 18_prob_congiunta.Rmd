# Probabilità congiunta {#chapter:distr_congiunta}

```{r, include = FALSE}
source("_common.R")
knitr::opts_chunk$set(fig.align="center")
```

Finora abbiamo considerato unicamente le leggi di singole variabile
aleatorie. Tuttavia, in psicologia e nella vita quotidiana, siamo spesso
interessati a studiare problemi di probabilità legati al valore
congiunto di due o più variabili aleatorie. Ad esempio, potremmo
misurare il QI dei bambini e il loro peso alla nascita, o l'altezza e il
peso delle giraffe, o il livello di inquinamento atmosferico e il tasso
di malattie respiratorie nelle città, o il numero di amici di Facebook e
l'età. Che relazione tra le variabili ci possiamo aspettare in ciascuno
di questi esempi? Perché?

Per capire la relazione che sussiste tra due variabili aleatorie è
necessario calcolare gli indici di *covarianza* e *correlazione*. Per
fare ciò è necessario utilizzare la funzione di probabilità congiunta.
L'obiettivo di questo capitolo è quello di chiarire cosa si intende per
funzione di probabilità congiunta di due variabili casuali $X$ e $Y$.
Esamineremo qui in dettaglio il caso discreto.

## Funzione di probabilità congiunta

Dopo aver trattato delle distribuzioni di probabilità di una variabile
aleatoria, che associa ad ogni evento elementare dello spazio
campionario uno ed un solo numero reale, è naturale estendere questo
concetto al caso di due o più dimensioni. Iniziamo a descrivere il caso
discreto con un esempio. Consideriamo qui l'esperimento casuale
corrispondente al lancio di tre monete equilibrate. Lo spazio
campionario di tale esperimento casuale è
$$\Omega = \{TTT, TTC, TCT, CTT, CCT, CTC, TCC, CCC\}.$$ Dato che i tre
lanci sono tra loro indipendenti, non c'è ragione di aspettarsi che uno
degli otto risultati possibili dell'esperimento sia più probabile degli
altri, dunque possiamo associare a ciascuno degli otto eventi elementari
dello spazio campionario la stessa probabilità, ovvero 1/8.

Su tale spazio campionario consideriamo le variabili aleatorie
$X \in \{0, 1, 2, 3\}$, che conta il numero delle teste nei tre lanci, e
$Y \in \{0, 1\}$, che conta il numero delle teste al primo lancio.
Indicando con T = 'testa' e C = 'croce', si ottiene dunque la situazione
riportata nella tabella successiva.

::: {#tab:tre-monete-distr-cong-1}
       $\omega$       $X$   $Y$   $P(\omega)$
  ------------------ ----- ----- -------------
   $\omega_1$ = TTT    3     1        1/8
   $\omega_2$ = TTC    2     1        1/8
   $\omega_3$ = TCT    2     1        1/8
   $\omega_4$ = CTT    2     0        1/8
   $\omega_5$ = CCT    1     0        1/8
   $\omega_6$ = CTC    1     0        1/8
   $\omega_7$ = TCC    1     1        1/8
   $\omega_8$ = CCC    0     0        1/8

  : Spazio campionario dell'esperimento consistente nel lancio di tre
  monete equilibrate su cui sono state definite le variabili aleatorie
  $X$ e $Y$.
:::

Ci poniamo il problema di associare un livello di probabilità ad ogni
coppia $(x, y)$ definita su $\Omega$. La coppia $(X = 0, Y = 0)$ si
realizza in corrispondenza di un solo evento elementare, ovvero CCC;
avrà dunque una probabilità pari a $Pr(X=0, Y=0) = Pr(CCC) = 1/8$. Nel
caso della coppia $(X = 1, Y = 0)$ ci sono due eventi elementari che
danno luogo al risultato considerato, ovvero, CCT e CTC; la probabilità
$Pr(X=1, Y=0)$ sarà dunque data dall'unione delle probabilità dei due
eventi elementari corrispondenti, cioé
$Pr(X=1, Y=0) = Pr(CCT \:\cup\: CTC) = 1/8 + 1/8 = 1/4$. Riportiamo qui
sotto i calcoli svolti per tutti i possibili valori di $X$ e $Y$.
$$
\begin{aligned}
P(X = 0, Y = 0) &= P(\omega_8 = CCC) = 1/8; \notag\\
P(X = 1, Y = 0) &= P(\omega_5 = CCT) + P(\omega_6 = CTC) = 2/8; \notag\\
P(X = 1, Y = 1) &= P(\omega_7 = TCC) = 1/8; \notag\\
P(X = 2, Y = 0) &= P(\omega_4 = CTT) = 1/8; \notag\\
P(X = 2, Y = 1) &= P(\omega_3 = TCT) + P(\omega_2 = TTC) = 2/8; \notag\\
P(X = 3, Y = 1) &= P(\omega_1 = TTT) = 1/8; \notag
\end{aligned}
$$ 

Le probabilità così trovate possono essere riportate nella
tabella seguente.

::: {#tab:tre-monete-distr-cong}
   $x\y$                   0     1   
  --------------------- ----- ----- 
            0            1/8    0   
            1            2/8   1/8  
            2            1/8   2/8  
            3             0    1/8  

  : Distribuzione di probabilità congiunta per i risultati
  dell'esperimento consistente nel lancio di tre monete equilibrate.
:::

La tabella qui sopra ci fornisce il risultato che cercavamo, ovvero la distribuzione di probabilità congiunta delle variabili aleatorie $X$ = "numero di realizzazioni con il risultato testa nei tre lanci" e $Y$ = "numero di realizzazioni con il risultato testa nel primo lancio" per l'esperimento casuale considerato.
Una generica funzione di probabilità congiunta bivariata può essere
rappresentata come qui indicato.

In generale, possiamo dire che, dato uno spazio campionario discreto
$\Omega$, è possibile associare ad ogni evento elementare $\omega_i$
dello spazio campionario una coppia di numeri reali $(x, y)$, essendo
$x = X(\omega)$ e $y = Y(\omega)$, il che ci conduce alla seguente
definizione.

La funzione che associa ad ogni coppia $(x, y)$ un livello di
probabilità prende il nome di funzione di probabilità congiunta:
$$P(x, y) = P(X = x, Y = y).$$
Il termine "congiunta" deriva dal fatto che questa probabilità è legata
al verificarsi di una coppia di valori, il primo associato alla
variabile aleatoria $X$ ed il secondo alla variabile aleatoria $Y$. Nel
caso di due sole variabili, si parla di distribuzione bivariata, mentre
nel caso di più variabili si parla di distribuzione multivariata.

### Proprietà

Una distribuzione di massa di probabilità congiunta bivariata deve
soddisfare due proprietà:

1.  $0 \leq p(x_i, y_j) \leq 1$;

2.  la probabilità totale deve essere uguale a $1.0$. Tale proprietà può
    essere espressa nel modo seguente
    $$\sum_{i} \sum_{j} p(x_i, y_j) = 1.0.$$

### Eventi

Si noti che dalla probabilità congiunta possiamo calcolare la
probabilità di qualsiasi evento definito in base alle variabili
aleatorie $X$ e $Y$. Per capire come questo possa essere fatto,
consideriamo nuovamente l'esperimento discusso sopra.

```{exercise}
Per la distribuzione di massa di probabilità congiunta riportata nella
tabella precedente si trovi la probabilità dell'evento $X+Y \leq 1$.
```

```{solution}
Per trovare la probabilità richiesta dobbiamo semplicemente sommare le
probabilità associate a tutte le coppie $(x,y)$ che soddisfano la
conzione $X+Y \leq 1$. Ovvero, 
$$
\begin{aligned}
P_{XY}(X+Y \leq 1) = &P_{XY}(0, 0) + P_{XY}(1, 0)= 3/8.\notag
\end{aligned}
$$
```

### Funzioni di probabilità marginali

Data la funzione di probabilità congiunta $p(x, y)$ è possibile pervenire alla costruzione della funzione di probabilità della singola variabile aleatoria, $X$ o $Y$: 
$$
p_X(x) = P(X = x) = \sum_y p(x,y)
$$
$$
p_Y(y) = P(Y = y) = \sum_x p(x,y)
$$ 
che prendono, rispettivamente, il nome di funzione di probabilità marginale di $X$ funzione di probabilità marginale di $Y$. Si noti che $P_X$ e $P_Y$ sono normalizzate: 
$$
\sum_x P_X(x) = 1.0, \quad \sum_y P_Y(y) = 1.0.
$$

Per l'esperimento casuale consistente nel lancio di tre monete equilibrate, si calcolino le probabilità marginali di $X$ e $Y$.

Nell'ultima colonna a destra e nell'ultima riga in basso della tabella seguente sono riportate le distribuzioni di probabilità marginali di $X$ e $Y$. $P_X$ si ottiene sommando su ciascuna riga fissata la colonna $j$, $P_X(X = j) = \sum_y p_{xy}(x = j, y)$. $P_Y$ si trova sommando su ciascuna colonna fissata la riga $i,$ $P_Y (Y = i) = \sum_x p_{xy}(x, y = i)$. Si noti che:
$$
\sum_x P_X(x) = 1, \quad \sum_y P_Y(y) = 1.
$$

::: {#default}
   $x\y$                 0     1    $p(x)$
  --------------------- ----- ----- --------
            0            1/8    0     1/8
            1            2/8   1/8    3/8
            2            1/8   2/8    3/8
            3             0    1/8    1/8
         $p(y)$          4/8   4/8    1.0

  : Distribuzione di probabilità congiunta $p(x,y)$ per i risultati
  dell'esperimento consistente nel lancio di tre monete equilibrate e
  probabilità marginali $p(x)$ e $p(y)$.
:::


### Indipendenza stocastica

Ora abbiamo tutti gli strumenti per potere dare una definizione
statistica precisa al concetto di indipendenza. La definizione proposta
sarà necessariamente coerente con la definizione di indipendenza che
abbiamo usato fino ad ora. Ma, espressa in questi nuovi termini, potrà
essere utilizzata in indagini probabilistiche e statistiche più
complesse. Ricordiamo che gli eventi $A$ e $B$ si dicono indipendenti se
$P (A \cap B)\, = P(A) P(B)$. Diciamo quindi che $X$ e $Y$ sono
indipendenti se qualsiasi evento definito da $X$ è indipendente da
qualsiasi evento definito da $Y$. La definizione formale che garantisce
che ciò accada è la seguente.

Le variabili aleatorie distribuite congiuntamente $X$ e $Y$ sono
indipendenti se la loro distribuzione congiunta è il prodotto delle
distribuzioni marginali: $$P(X, Y)\, = P_X(x)P_Y(y).$$

Nel caso discreto, dunque, l'indipendenza implica che la probabilità
riportata in ciascuna cella della tabella di probabilità congiunta deve
essere uguale al prodotto delle probabilità marginali di riga e di
colonna: $$p(x_i, y_i)\, = p_X(x_i) p_Y(y_i).\notag$$

```{exercise}
Per la situazione rappresentata nella tabella qui sopra le variabili aleatorie $X$ e $Y$ sono indipendenti?
```

```{solution}
Nella tabellale variabili aleatorie $X$ e $Y$ non sono indipendenti: le probabilità congiunte non sono ricavabili dal prodotto delle marginali. Per esempio, nessuna delle probabilità marginali è uguale a $0$ per cui nessuno dei valori dentro la tabella (probabilità congiunte) che risulta essere uguale a $0$ può essere il prodotto delle probabilità marginali.
```

## Conclusioni {#conclusioni .unnumbered}

La funzione di probabilità congiunta tiene simultaneamente conto del
comportamento di due variabili aleatorie $X$ e $Y$ e di come esse si
influenzano reciprocamente. In particolare, si osserva che se le due
variabili non si influenzano, cioè se sono statisticamente indipendenti,
allora la distribuzione di massa di probabilità congiunta si ottiene
come prodotto delle funzioni di probabilità marginali di $X$ e $Y$:
$P_{X, Y}(x, y) = P_X(x) P_Y(y)$.
