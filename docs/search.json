[{"path":"index.html","id":"benvenuti","chapter":"Benvenuti","heading":"Benvenuti","text":"Data Science per psicologi contiene il materiale delle lezioni dell’insegnamento di Psicometria B000286 (.. 2020/2021) rivolto agli studenti del primo anno del Corso di Laurea Scienze e Tecniche Psicologiche dell’Università degli Studi di Firenze.","code":""},{"path":"conoscenza-dichiarativa-e-imperativa.html","id":"conoscenza-dichiarativa-e-imperativa","chapter":"Capitolo 1 Conoscenza dichiarativa e imperativa","heading":"Capitolo 1 Conoscenza dichiarativa e imperativa","text":"La conoscenza dichiarativa consiste di una semplice enunciazione di fatti: per esempio “\\(y\\) è la radice quadrata di \\(x\\) se e solo se \\(y \\times y = x\\).”\nLa conoscenza imperativa fornisce invece le istruzioni necessarie per risolvere un problema; è un po’ come una ricetta di cucina.\nL’esempio proposto da (guttag2016introduction?) è il metodo di Erone di Alessandria per trovare la radice quadrata di un numero:Prova con un numero \\(g\\).Se \\(g \\times g\\) è abbastanza vicino \\(x\\), allora \\(g\\) è una buona approssimazione della radice quadrata di \\(x\\).Altrimenti una approssimazione migliore si ottiene come\n\\[\ng_{\\text{nuovo}} = \\frac{g_{\\text{vecchio}} + \\frac{x}{g_{\\text{vecchio}}}}{2}\n\\]\nProviamo. Supponiamo di volere trovare la radice quadrata di \\(x = 16\\). Iniziamo con una proposta piuttosto lontana dalla soluzione corretta, per esempio \\(y = 3\\). Innalzando 3 al quadrato vediamo che siamo piuttosto lontanti dal valore desiderato. Proviamo dunque usare la procedura di Erone di Alessandria e, partendo da 3 otteniamo il valore di 4.166667. Al quadrato diventa 17.36111. Non va ancora bene ma è meglio di prima. Applichiamo nuovamente la procedura di Erone di Alessandria e otteniamo 4.003333. Al quadrato diventa 16.02668, non male. Se facciamo ancora un’iterazione otteniamo 4.000001 e potremmo fermarci qui. Quindi, abbiamo applicato la procedura di Erone di Alessandria tre volte e abbiamo ottenuto un’approssimazione della radice quadrata che, per tutti gli scopi pratici, è sufficiente.questo esempio, la conoscenza dichiarativa ci fornisce la definizione di radice quadrata. Questo è quelcosa che dobbiamo sapere, altrimenti non sappiamo neppure di cosa stiamo parlando. Ma tale conoscenza dichiarativa non ci aiuta nessun modo trovare la radice quadrata di un numero. Sappiamo che caratteristiche deve avere la soluzione, ma non sappiamo come trovarla. La conoscenza imperativa, invece, ci fornisce un metodo per trovare la soluzione che cerchiamo.Una volta chiarita la distinzione tra conoscenze dichiarative e imperative vi dico che questo insegnamento, oltre fornire conoscenze dichiarative, si focalizzerà sulle conoscenze imperative necessarie per risolvere alcuni problemi di analisi di dati psicologici. altre parole, vi mostrerò come alcuni problemi di analisi di dati psicologici possano essere risolti pratica.Le conoscenze dichiarative non saranno dunque sufficienti per risolvere problemi che gli studenti troveranno ’esame (altre parole, non sarà sufficiente avere imparato memoria dei concetti). Saranno invece necessarie conoscenze imperative (altre parole, sarà necessario avere sviluppato la capacità di “sapere fare”). Le conoscenze imperative che verranno sviluppate questo insegnamento sono quelle della Data science, ovvero si pongono ’intersezione tra statistica (ovvero, richiedono la capacità di comprendere teoremi statistici) e informatica (ovvero, richiedono la capacità di sapere utilizzare un software).","code":""},{"path":"conoscenza-dichiarativa-e-imperativa.html","id":"la-psicologia-e-la-data-science","chapter":"Capitolo 1 Conoscenza dichiarativa e imperativa","heading":"1.1 La psicologia e la Data Science","text":"Sembra sensato spendere due parole su un tema che è importante per gli studenti: quello indicato dal titolo di questa sezione.\nÈ ovvio che agli studenti di psicologia la statistica non piace.\nSe piacesse, forse studierebbero Data Science e non psicologia; ma non lo fanno.\nDi conseguenza, gli studenti di psicologia si chiedono: ``perché dobbiamo perdere tanto tempo studiare queste cose quando realtà quello che ci interessa è tutt’altro?’’\nQuesta è una bella domanda.\nPer cercare di rispondere questa domanda introduco qui un importante concetto statistico, il paradosso di Simpson.Consideriamo un fenomeno sociale che ha suscitato un enorme interesse tempi recenti: la brutalità della polizia e le diseguaglianze razziali messe evidenza dalle uccisioni da parte della polizia statunitense.\nPer affrontare questo tema, esaminiamo l’analisi statistica descritta un articolo di Ross et al. (2020).\nLa logica di tale analisi statistica può essere descritta nel modo seguente.\nImmaginiamo due gruppi di individui: Montechi e Capuleti.\nIl 10% dei Montechi e il 20% dei Capuleti commette crimini violenti (ovvero, sono dei criminali).\nun anno, il 14% dei Montechi viene ucciso dalla polizia contro il 26% dei Capuleti.\nCome si fa capire se c’è un pregiudizio verso uno dei due gruppi?Cesario et al. (2019) sostengono che è necessario dividere la frequenza relativa di uccisioni da parte della polizia per la percentuale di criminali ciascun gruppo.\nQuindi, secondo questa logica, il tasso di uccisioni da parte della polizia è di 14/10 = 1.4% per Capuleti e di 26/20 = 1.3% per Montechi.\nQuesto indica una discriminazione contro Capuleti e ci fornisce la risposta alla nostra domanda.\nMa le cose stanno effettivamente così?Forse .\nSe decomponiamo il numero di uccisioni da parte della polizia ciascuna delle modalità della variabile criminalità (ovvero, criminali vs. non criminali), scopriamo che, per Capuleti, 14 morti possono essere suddivisi 5 morti di criminali e 9 morti di non criminali.\nPer Montechi, 26 morti si suddividono 10 morti di criminali e 16 morti di non criminali.\nQuindi, criminali Capuleti vengono uccisi dalla polizia ad un tasso del 5/10 = 50% e criminali Montechi vengono uccisi ad un tasso del 10/20 = 50% – lo stesso tasso nei due gruppi.\nMa non criminali Capuleti vengono uccisi dalla polizia ad un tasso del 9/90 = 10%, mentre non criminali Montechi vengono uccisi ad un tasso del 16/80 = 20%.Ciò significa che criminali di entrambi gruppi hanno la stessa probabilità di essere uccisi dalla polizia, ma non criminali Montechi hanno due volte la probabilità di essere uccisi dalla polizia dei non criminali Capuleti.\nQuesto indica un’enorme discriminazione contro Montechi!\nEppure, l’analisi precedente aveva prodotto il risultato opposto.Lasciando perdere Shakespeare, Ross et al. (2020) hanno dimostrato che questo è esattamente ciò che sta succedendo con dati reali sulle sparatorie della polizia negli Stati Uniti: neri disarmati negli Stati Uniti vengono uccisi tassi molto più alti rispetto ai bianchi disarmati, sebbene tassi siano simili nei due gruppi quando si considerano solo le sparatorie con individui armati; se tuttavia si riassumono dati considerando solo la frequenza totale dei morti scalata per il tasso di criminalità questo fatto viene oscurato.\nL’articolo di Ross et al. (2020) ci fa vedere come sia necessario stare molto attenti con l’uso della statistica, specialmente quando gli errori statistici possono avere un impatto enorme sulla percezione pubblica – e, nella psicologia, sulla pratica dello psicologo.\nLe analisi statistiche precedenti sono un esempio di ciò che viene chiamato il paradosso di Simpson, ovvero il fatto che, alle volte, quando si riassumono dati un modo apparentemente ragionevole, si finisce per giungere ad una conclusione del tutto sbagliata.\nIl paradosso di Simpson illustra il fatto che non è facile neppure affrontare il semplice problema di riassumere dati, figurarsi poi fare delle inferenze!\nQueste considerazioni ci fanno capire che, senza un certo livello di consapevolezza metodologica, lo psicologo (e non solo), quando ha che fare con dei dati empirici, si espone al rischio di fare errori gravissimi.","code":""},{"path":"conoscenza-dichiarativa-e-imperativa.html","id":"la-descrizione-delle-differnze-individuali","chapter":"Capitolo 1 Conoscenza dichiarativa e imperativa","heading":"1.2 La descrizione delle differnze individuali","text":"Ma c’è un’altra ragione ancora più semplice che dovrebbe farci capire perché la Data Science è così importante per la psicologia.\nInfatti, ben pensarci, la psicologia è una disciplina intrinsecamente statistica, se per statistica intendiamo quella disciplina che studia la variazione delle caratteristiche degli individui nella popolazione.\nLa psicologia studia gli individui ed è proprio la variabilità inter- e intra-individuale ciò che vogliamo descrivere e, certi casi, predire.\nquesto senso, la psicologia è molto diversa dall’ingegneria, per esempio.\nLe proprietà di un determinato ponte, sotto certe condizioni, sono molto simili quelle di un altro ponte, sotto le medesime condizioni. Quindi, per un ingegnere la statistica è poco importante: le proprietà dei materiali sono unicamente dipendenti dalla loro composizione e restano costanti. Ma lo stesso non si può dire degli individui: ogni individuo è unico e cambia nel tempo. E le variazioni tra gli individui, e di un individuo nel tempo, sono l’oggetto di studio proprio della psicologia: è dunque chiaro che problemi che la psicologia si pone sono molto diversi da quelli affrontati, per esempio, dagli ingegneri.\nQuesta è la ragione per cui abbiamo tanto bisogno della Data Science psicologia: perché la Data Science ci consente di descrivere la variazione e il cambiamento.\nE queste sono appunto le caratteristiche di base dei fenomeni psicologici.Sono sicuro che, leggendo queste righe, molti studenti sarà venuta mente la seguente domanda: perché non chiediamo qualche esperto di fare il “lavoro sporco” (ovvero le analisi statistiche) per noi, mentre noi (psicologi) ci occupiamo solo di ciò che ci interessa, ovvero dei problemi psicologici slegati dai dettagli “tecnici” della Data Science?\nLa risposta questa domanda è che non è possibile progettare uno studio psicologico sensato senza avere almeno una comprensione rudimentale della Data Science.\nNon possono ignorare le tematiche della Data Science né ricercatori psicologia né coloro che svolgono la professione di psicologo al di fuori dell’Università e dei centri di ricerca.\nInfatti, anche professionisti di fuori dall’università non possono fare meno di leggere la letteratura psicologica più recente: il continuo aggiornamento delle conoscenze è infatti richiesto dalla deontologia della professione. Ma è necessario conoscere un bel po’ di Data Science per potere fare questo! Per rendersi conto di quanto ciò sia vero basta aprire caso una rivista specialistica di psicologia: gli articoli che riportano risultati delle ricerche psicologiche sono zeppi di analisi statistiche e di modelli formali.\nE la comprensione della letteratura psicologica è il requisito minimo del bagaglio professionale dello psicologo.Le considerazioni precedenti cercano di chiarire il seguente punto: la Data Science non è qualcosa da studiare malincuore, un singolo insegnamento universitario, per poi poterla tranquillamente dimenticare. Nel bene e nel male, gli psicologi usano strumenti della Data Science tantissimi ambiti della loro attività professionale: particolare quando costruiscono, somministrano e interpretano test psicometrici.\nÈ dunque chiaro che possedere delle solide basi di Data Science è un tassello imprescindibile del bagaglio professionale dello psicologo.","code":""},{"path":"conoscenza-dichiarativa-e-imperativa.html","id":"come-studiare","chapter":"Capitolo 1 Conoscenza dichiarativa e imperativa","heading":"1.3 Come studiare","text":"Alcuni degli argomenti trattati richiedono delle conoscenze pregresse, soprattutto di tipo matematico. Tali conoscenze sono state aggiunte delle appendici di queste dispense. La lettura di tale materiale è consigliata tutti, sia chi sta studiando gli argomenti proposti per la prima volta, sia chi deve ripassare per colmare eventuali lacune pregresse.Il giusto metodo di studio per prepararsi ’esame di Psicometria è quello di seguire attivamente le lezioni, assimilare concetti via via che essi vengono presentati e verificare autonomia le procedure presentate lezione. Incoraggio gli studenti farmi domande (nelle modalità consentite dalla situazione presente) per chiarire ciò che non è stato capito appieno. Incoraggio inoltre gli studenti prendere parte alle esercitazioni organizzate dai Peer Tutor, utilizzare forum attivi su Moodle e, soprattutto, svolgere gli esercizi proposti su Moodle. problemi forniti su Moodle rappresentano il livello di difficoltà richiesto per superare l’esame e consentono allo studente di comprendere se le competenze sviluppate fino quel punto sono sufficienti rispetto alle richieste dell’esame.La prima fase dello studio, che è sicuramente individuale, è quella cui è necessario acquisire le conoscenze dichiarative relative ai problemi che saranno presentati ’esame. La seconda fase di studio, che può essere facilitata da scambi con altri e da incontri di gruppo, porta ad acquisire conoscenze imperative: è necessario capire come usare un software (R) per applicare concetti statistici alla specifica situazione del problema che si vuole risolvere. Anche se inizialmente potete pensare il contrario, questo insegnamento lo sforzo necessario per acquisire le conoscenze dichiarative è spesso molto maggiore di quello richiesto per acquisire le conoscenze imperative. Tuttavia, le due non sono separate: il saper fare molto spesso ci aiuta capire.","code":""},{"path":"conoscenza-dichiarativa-e-imperativa.html","id":"sviluppare-un-metodo-di-studio-efficace","chapter":"Capitolo 1 Conoscenza dichiarativa e imperativa","heading":"1.4 Sviluppare un metodo di studio efficace","text":"Sebbene non si possano riassumere le intuizioni di tutto l’insegnamento di Psicometria poche parole, è possibile descrivere il tipo di atteggiamento mentale che è utile per affrontare con profitto lo studio dei materiali di questo insegnamento. Avendo insegnato Psicometria molte volte passato, ho notato nel corso degli anni che gli studenti con l’atteggiamento mentale che descriverò qui sotto generalmente ottengono ottimi risultati. Alcuni studenti sviluppano naturalmente questo approccio allo studio, ma altri hanno bisogno di fare uno sforzo per maturarlo. Fornisco qui sotto una breve descrizione del “metodo di studio” che, nella mia esperienza, si dimostra il più efficace per affrontare le richieste di questo insegnamento.È importante dedicare un tempo sufficiente allo studio del materiale di base, anche se questo materiale risulta apparentemente facile. È necessario assicurasi di averlo capirlo veramente. È molto utile individuare le lacune nella propria comprensione del materiale di studio, per poi colmarle. La lettura di presentazioni diverse dello stesso materiale (libri o articoli diversi) facilita la comprensione.Gli errori che facciamo sono nostri migliori maestri. Istintivamente cerchiamo di dimenticarci subito dei nostri errori. Ma il miglior modo di imparare è apprendere dagli errori che commettiamo. questo senso, una soluzione corretta è meno interessante di una non corretta. Quando commettiamo un errore questo ci fornisce un’informazione importante: ci fa capire qual è il materiale di studio sul quale dobbiamo ritornare e che dobbiamo capire meglio.C’è ovviamente un aspetto “psicologico” nello studio. Quando un esercizio o problema ci sembra incomprensibile, forse la cosa migliore da fare è dire: “mi arrendo,” “non ho idea di cosa fare.” Questo ci rilassa: ci siamo già arresi, quindi non abbiamo nient’altro da perdere, non dobbiamo più preoccuparci. Ma non dobbiamo fermarci qui. Dopo un po’, riprendiamo il mano il problema, ma consideriamo una sua versione più semplice. volte è utile suddividere il problema parti più piccole, ognuna delle quali può essere più facile da risolvere. Fa una grande differenza affrontare il problema con tranquillità. Alle volte succede che, per trovare la soluzione ad un problema, dobbiamo soltanto “adottare un punto di vista diverso.” Ma per fare questo dobbiamo essere rilassati. La pressione che ci poniamo quando diciamo “voglio risolvere questo problema il prima possile” non ci aiuta. Perché, sotto pressione, possiamo solo agire maniera automatica, ovvero applicare qualcosa che sappiamo già fare. Ma se dobbiamo scoprire qualcosa di nuovo, la pressione è un impedimento.È utile farsi da soli delle domande sugli argomenti trattati, senza limitarsi cercare di risolvere gli esercizi che io vi darò. Procedendo questo modo lo studente può focalizzarsi sugli aspetti che trova meno chiari, ovvero può dedicare più tempo ciò che richiede più tempo: gli aspetti che per lui sono meno chiari. Questo è qualcosa che nessun altro può fare al posto vostro.Non aspettatevi di capire tutto la prima volta che incontrate un argomento nuovo. È utile farsi una nota mentalmente delle lacune nella vostra comprensione e tornare su di esse per carcare di colmarle. L’atteggiamento naturale, quando non capiamo dettagli di qualcosa, è quello di pensare: “non importa, ho capito maniera approssimativa questo punto, non devo preoccuparmi del resto.” Ma realtà non è vero: se la nostra comprensione è superficiale, quando il problema verrà presentato una nuova forma, non riusciremo risolverlo. Per cui dubbi che ci vengono quando studiamo qualcosa sono il nostro alleato più prezioso: ci dicono esattamente quali sono gli aspetti che dobbiamo approfondire per potere migliorare la nostra preparazione.È utile sviluppare una visione d’insieme degli argomenti trattati, capire l’obiettivo generale che si vuole raggiungere e avere chiaro il contributo che vari pezzi di informazione forniscono al raggiungimento di tale obiettivo. Questa organizzazione mentale del materiale di studio facilita la comprensione. È estremamente utile creare degli schemi di ciò che si sta studiando. Non aspettate che sia io fornirvi un riepilogo puntato di ciò che dovete imparare: sviluppate da soli tali schemi e tali riassunti.Tutti noi dobbiamo sviluppare l’arte di trovare le informazioni, non solo nel caso di questo insegnamento. Quando vi trovate di fronte qualcosa che non capite, o ottenete un oscuro messaggio di errore, ricordatevi: “Google friend.”","code":""},{"path":"introduzione.html","id":"introduzione","chapter":"Introduzione","heading":"Introduzione","text":"questa sezione del libro saranno presentate le caratteristiche di base e la filosofia dell’ambiente R, passando poi illustrare le strutture dati e le principali strutture di controllo. Verranno introdotte alcune funzioni utili per la gestione dei dati e verranno forniti rudimenti per realizzare semplici funzioni. Verranno introdotti tipi di file editabili RStudio (script, markdown, …). Nello specifico, dopo aver accennato alcune caratteristiche del sistema tidyverse, verranno illustrate le principali funzionalità dell’IDE RStudio e dei pacchetti dplyr e ggplot2.","code":""},{"path":"chapter-pacchetti.html","id":"chapter-pacchetti","chapter":"Capitolo 2 Pacchetti","heading":"Capitolo 2 Pacchetti","text":"Riporto qui tutti pacchetti R che verranno usati queste dispense.","code":"\nsuppressPackageStartupMessages(library(\"here\"))\nsuppressPackageStartupMessages(library(\"tidyverse\"))\nsuppressPackageStartupMessages(library(\"ggpubr\"))\nsuppressPackageStartupMessages(library(\"ggExtra\"))\nsuppressPackageStartupMessages(library(\"car\"))\nsuppressPackageStartupMessages(library(\"cowplot\"))\nsuppressPackageStartupMessages(library(\"tidybayes\"))\nsuppressPackageStartupMessages(library(\"datasauRus\"))\nsuppressPackageStartupMessages(library(\"RColorBrewer\"))\nsuppressPackageStartupMessages(library(\"rio\"))\nsuppressPackageStartupMessages(library(\"papaja\"))\nlibrary(\"patchwork\")\n#> \n#> Attaching package: 'patchwork'\n#> The following object is masked from 'package:cowplot':\n#> \n#>     align_plots\nsuppressPackageStartupMessages(library(\"rethinking\"))\nset.seed(12345)\nsessionInfo()\n#> R version 3.6.3 (2020-02-29)\n#> Platform: x86_64-apple-darwin15.6.0 (64-bit)\n#> Running under: macOS Mojave 10.14.6\n#> \n#> Matrix products: default\n#> BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib\n#> LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib\n#> \n#> locale:\n#> [1] it_IT.UTF-8/it_IT.UTF-8/it_IT.UTF-8/C/it_IT.UTF-8/it_IT.UTF-8\n#> \n#> attached base packages:\n#> [1] parallel  stats     graphics  grDevices utils     datasets  methods   base     \n#> \n#> other attached packages:\n#>  [1] rethinking_2.01      dagitty_0.3-1        rstan_2.21.2         StanHeaders_2.21.0-7\n#>  [5] patchwork_1.1.1      rio_0.5.26           RColorBrewer_1.1-2   datasauRus_0.1.4    \n#>  [9] tidybayes_2.3.1      cowplot_1.1.1        car_3.0-10           carData_3.0-4       \n#> [13] ggExtra_0.9          ggpubr_0.4.0         papaja_0.1.0.9997    tinylabels_0.2.1    \n#> [17] bayesplot_1.8.0      forcats_0.5.1        stringr_1.4.0        dplyr_1.0.5         \n#> [21] purrr_0.3.4          readr_1.4.0          tidyr_1.1.3          tibble_3.1.1        \n#> [25] ggplot2_3.3.3        tidyverse_1.3.1      here_1.0.1          \n#> \n#> loaded via a namespace (and not attached):\n#>   [1] colorspace_2.0-0     ggsignif_0.6.1       ellipsis_0.3.1       ggridges_0.5.3      \n#>   [5] rprojroot_2.0.2      fs_1.5.0             rstudioapi_0.13      farver_2.1.0        \n#>   [9] svUnit_1.0.6         mvtnorm_1.1-1        fansi_0.4.2          lubridate_1.7.10    \n#>  [13] xml2_1.3.2           codetools_0.2-18     downlit_0.2.1        knitr_1.33          \n#>  [17] jsonlite_1.7.2       broom_0.7.6          dbplyr_2.1.1         ggdist_2.4.0        \n#>  [21] latex2exp_0.5.0      shiny_1.6.0          compiler_3.6.3       httr_1.4.2          \n#>  [25] backports_1.2.1      assertthat_0.2.1     fastmap_1.1.0        cli_2.4.0           \n#>  [29] later_1.2.0          prettyunits_1.1.1    htmltools_0.5.1.1    tools_3.6.3         \n#>  [33] coda_0.19-4          gtable_0.3.0         glue_1.4.2           rappdirs_0.3.3      \n#>  [37] V8_3.4.1             Rcpp_1.0.6           cellranger_1.1.0     jquerylib_0.1.3     \n#>  [41] vctrs_0.3.7          xfun_0.22            ps_1.6.0             openxlsx_4.2.3      \n#>  [45] rvest_1.0.0          mime_0.10            miniUI_0.1.1.1       lifecycle_1.0.0     \n#>  [49] rstatix_0.7.0        MASS_7.3-53.1        scales_1.1.1         hms_1.0.0           \n#>  [53] promises_1.2.0.1     inline_0.3.17        yaml_2.2.1           curl_4.3            \n#>  [57] gridExtra_2.3        loo_2.4.1            sass_0.3.1           stringi_1.5.3       \n#>  [61] boot_1.3-27          pkgbuild_1.2.0       zip_2.1.1            shape_1.4.5         \n#>  [65] matrixStats_0.58.0   rlang_0.4.10         pkgconfig_2.0.3      distributional_0.2.2\n#>  [69] evaluate_0.14        lattice_0.20-41      processx_3.5.1       tidyselect_1.1.0    \n#>  [73] plyr_1.8.6           magrittr_2.0.1       bookdown_0.22        R6_2.5.0            \n#>  [77] generics_0.1.0       DBI_1.1.1            pillar_1.6.0         haven_2.4.1         \n#>  [81] foreign_0.8-75       withr_2.4.2          abind_1.4-5          modelr_0.1.8        \n#>  [85] crayon_1.4.1         arrayhelpers_1.1-0   utf8_1.2.1           rmarkdown_2.7       \n#>  [89] grid_3.6.3           readxl_1.3.1         data.table_1.14.0    callr_3.7.0         \n#>  [93] reprex_2.0.0         digest_0.6.27        xtable_1.8-4         httpuv_1.6.0        \n#>  [97] stats4_3.6.3         RcppParallel_5.1.2   munsell_0.5.0        bslib_0.2.4"},{"path":"chapter-install-r.html","id":"chapter-install-r","chapter":"Capitolo 3 Per cominciare","heading":"Capitolo 3 Per cominciare","text":"Al fine di utilizzare R è necessario eseguire le seguenti tre operazioni\nnell’ordine dato:Installare R;Installare RStudio;Installare R-Packages (se necessario).Vedremo qui come installare R e RStudio.","code":""},{"path":"chapter-install-r.html","id":"installare-r-e-rstudio","chapter":"Capitolo 3 Per cominciare","heading":"3.1 Installare R e RStudio","text":"R è disponibile gratuitamente ed è scaricabile dal sito\nhttp://www.rproject.org/. Dalla pagina principale del sito\nr-project.org andiamo sulla sezione Download e scegliamo un server \npiacimento per scaricare il software d’installazione. Una volta\nscaricato l’installer, lo installiamo come un qualsiasi software,\ncliccando due volte sul file d’istallazione. Esistono versioni di R  per\ntutti più diffusi sistemi operativi (Windows, Mac OS X e Linux).Il R Core Development Team lavora continuamente per migliorare le\nprestazioni di R, per correggere errori e per consentire l’uso di   con\nnuove tecnologie. Di conseguenza, periodicamente vengono rilasciate\nnuove versioni di R. Informazioni questo proposito sono fornite sulla\npagina web https://www.r-project.org/. Per installare una nuova\nversione di R si segue la stessa procedura che è stata seguita per la\nprima installazione.Insieme al software si possono scaricare dal sito principale sia manuali d’uso che numerose dispense per approfondire diversi aspetti di R. particolare, nel sito http://cran.r-project.org/-docs.html si possono trovare anche numerose dispense italiano (sezione “languages”).Dopo avere installato R è opportuno installare anche RStudio. RStudio si\npuò scaricare da https://www.rstudio.com/. Anche RStudio è disponibile\nper tutti più diffusi sistemi operativi.","code":""},{"path":"chapter-install-r.html","id":"utilizzare-rstudio-per-semplificare-il-lavoro","chapter":"Capitolo 3 Per cominciare","heading":"3.2 Utilizzare RStudio per semplificare il lavoro","text":"Possiamo pensare ad R come al motore di un automobile e RStudio come\nal cruscotto di un automobile. Più precisamente, R è un linguaggio di\nprogrammazione che esegue calcoli mentre RStudio è un ambiente di\nsviluppo integrato (IDE) che fornisce un’interfaccia grafica aggiungendo\nuna serie di strumenti che facilitano la fase di sviluppo e di\nesecuzione del codice. Utilizzeremo dunque R mediante RStudio. altre\nparole,non apriteaprite inveceL’ambiente di lavoro di RStudio è costituito da quattro finestre: la finestra del codice (scrivere-eseguire script), la finestra della console (riga di comando -\noutput), la finestra degli oggetti (elenco oggetti-cronologia dei\ncomandi) e la finestra dei pacchetti-dei grafici-dell’aiuto linea.La console di RStudio.","code":""},{"path":"chapter-install-r.html","id":"eseguire-il-codice","chapter":"Capitolo 3 Per cominciare","heading":"3.3 Eseguire il codice","text":"Mediante il menu tendina di RStudio, scegliendo il percorsooppurel’utente può aprire nella finestra del codice (alto destra) un R Notebook o un R script dove inserire le istruzioni da eseguire.un R script, un blocco di codice viene eseguito selezionando un\ninsieme di righe di istruzioni e digitando la sequenza di tasti\nCommand + Invio sul Mac, oppure Control + Invio su Windows. \nun R Notebook, un blocco di codice viene eseguito schiacciando il\nbottone con l’icona \\(\\color{red}\\blacktriangleright\\) (“Run current\nchunk”) posizionata destra rispetto al codice.","code":"File > New File > R NotebookFile > New File > R Script"},{"path":"chapter-sintassi.html","id":"chapter-sintassi","chapter":"Capitolo 4 Sintassi di base","heading":"Capitolo 4 Sintassi di base","text":"R è un linguaggio di programmazione orientato ’analisi dei dati, il\ncalcolo e la visualizzazione grafica. È disponibile su Internet una\nvasta gamma di materiali utile per avvicinarsi ’ambiente R e aiutare\nl’utente nell’apprendimento di questo software statistico. Cercheremo\nqui di fornire alcune indicazioni e una breve descrizione delle risorse\ndi base di R.Aggiungo qui sotto alcune considerazioni che ho preso, pari pari, da un testo che tratta di un altro linguaggio di programmazione, ma che si applicano perfettamente anche al caso nostro.Come ogni linguaggio, per parlare R è necessario seguire un insieme di regole. Come tutti linguaggi di programmazione, queste regole sono del tutto inflessibili e inderogabili. R, un enunciato o è sintatticamente corretto o è incomprensibile ’interprete, che lo segnalerà ’utente. Questo aspetto non è esattamente amichevole per chi non è abituato ai linguaggi di programmazione, e si trova così costretto ad una precisione di scrittura decisamente poco “analogica.” Tuttavia, ci sono due aspetti positivi nello scrivere codice, interrelati tra loro. Il primo è lo sforzo analitico necessario, che allena ad un’analisi precisa del problema che si vuole risolvere modo da poterlo formalizzare linguisticamente. Il secondo concerne una forma di autoconsapevolezza specifica: salvo “bachi” nel linguaggio (rarissimi sebbene possibili), il mantra del programmatore è “Se qualcosa non ti funziona, è colpa tua” (testo adattato da Andrea Valle).chi preferisce un approccio più “giocoso” posso suggerire il seguente link.","code":""},{"path":"chapter-sintassi.html","id":"utilizzare-la-console-r-come-calcolatrice","chapter":"Capitolo 4 Sintassi di base","heading":"4.1 Utilizzare la console R come calcolatrice","text":"La console di RStudio contiene un cursore rappresentato dal simbolo “>”\n(linea di comando) dove si possono inserire comandi e le funzioni –\nrealtà è sempre meglio utilizzare un R Notebook anziché la console,\nma per ora esaminiamo il funzionamento di quest’ultima.La console di RStudio può essere utilizzata come semplice calcolatrice.\ncomandi elementari consistono di espressioni o di assegnazioni. Le\noperazioni aritmetiche vengono eseguite mediante simboli “standard:” +,\n*, -, /, sqrt(), log(), exp(), …comandi sono separati da un carattere di nuova linea (si immette un\ncarattere di nuova linea digitando il tasto Invio). Se un comando non\nè completo alla fine della linea, R darà un prompt differente che per\ndefault è il carattere + sulla linea seguente e continuerà leggere\nl’input finché il comando non è sintatticamente completo. Ad esempio,R è un ambiente interattivo, ossia comandi producono una risposta immediata. Se scriviamo 2 + 2 e premiamo il tasto di invio, comparirà nella riga successiva il risultato:Il risultato è preceduto da [1], il che significa che il risultato dell’operazione che abbiamo appena eseguito è il primo valore di questa linea. Alcune funzioni ritornano più di un singolo numero e, quel caso, l’informazione fornita da R è più utile. Per esempio, l’istruzione 100:130 ritorna \\(31\\) valori, ovvero numeri da \\(100\\) \\(130\\):questo caso, sul mio computer, [24] indica che il valore \\(123\\) è il ventiquattresimo numero che è stato stampato sulla console – su un altro computer le cose possono essere diverse quanto il risultato, credo, dipende dalla grandezza dello schermo.","code":"\n4 -\n+ \n+ 1\n#> [1] 3\n2 + 2\n#> [1] 4\n100:130\n#>  [1] 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122\n#> [24] 123 124 125 126 127 128 129 130"},{"path":"chapter-sintassi.html","id":"espressioni","chapter":"Capitolo 4 Sintassi di base","heading":"4.2 Espressioni","text":"questo corso, cercheremo di evitare numeri nei nomi R, così come le lettere maiuscole e .. Useremo quindi nomi come: my_data, anova_results, square_root, ecc.Un’espressione R è un enunciato finito e autonomo del linguaggio: una frase conclusa, si potrebbe dire. Si noti che le espressioni R non sono delimitate dal ; come succede alcuni linguaggi di programmazione. L’ordine delle espressioni è l’ordine di esecuzione delle stesse.L’capo non è rilevante per R. Questo permette di utilizzare l’capo per migliorare la leggibilità del codice.","code":""},{"path":"chapter-sintassi.html","id":"oggetti","chapter":"Capitolo 4 Sintassi di base","heading":"4.3 Oggetti","text":"R è un linguaggio di programmazione oggetti, quindi si basa sulla creazione di oggetti e sulla possibilità di salvarli nella memoria del programma. R distingue tra maiuscole e minuscole come la maggior parte dei linguaggi basati su UNIX, quindi e sono nomi diversi e fanno riferimento oggetti diversi.comandi elementari di R consistono espressioni o assegnazioni.Se un’espressione viene fornita come comando, viene valutata, stampata sullo schermo e il valore viene perso, come succedeva alle operazioni aritmetiche che abbiamo presentato sopra discutendo l’uso della console R come calcolatrice.Un’assegnazione crea un oggetto oppure valuta un’espressione e passa il valore un oggetto, ma il risultato non viene stampato automaticamente sullo schermo. Per l’operazione di assegnazione si usa il simbolo <-. Ad esempio, per creare un oggetto che contiene il risultato dell’operazione 2 + 2 procediamo nel modo seguente:L’operazione di assegnazione (<-) copia il contenuto dell’operando destro (detto r-value) nell’operando sinistro detto (l-value). Il valore dell’espressione assegnazione è r-value. Nell’esempio precedente, res_sum (l-value) assume il valore di \\(4\\).","code":"\nres_sum <- 2 + 2\nres_sum\n#> [1] 4"},{"path":"chapter-sintassi.html","id":"variabili","chapter":"Capitolo 4 Sintassi di base","heading":"4.4 Variabili","text":"L’oggetto res_sum è una variabile. Una spiegazione di ciò che questo significa è riportata qui sotto.Una variabile è un segnaposto. Tutte le volte che si memorizza un dato lo si assegna ad una variabile. Infatti, se il dato è nella memoria, per potervi accedere, è necessario conoscere il suo indirizzo, la sua “etichetta” (come un grande magazzino cui si va cercare un oggetto base alla sua collocazione). Se il dato è memorizzato ma inaccessibile (come nel caso di un oggetto sperso un magazzino), allora non si può usare ed è soltanto uno spreco di spazio. La teoria delle variabili è un ambito molto complesso nella scienza della computazione. Ad esempio, una aspetto importante può concernere la tipizzazione delle variabili. Nei linguaggi “tipizzati” (ad esempio C), l’utente dichiara che userà quella etichetta (la variabile) per contenere solo ed esclusivamente un certo tipo di oggetto (ad esempio, un numero intero), e la variabile non potrà essere utilizzata per oggetti diversi (ad esempio, una stringa). questo caso, prima di usare una variabile se ne dichiara l’esistenza e se ne specifica il tipo. linguaggi non tipizzati non richiedono ’utente di specificare il tipo, che viene inferito vario modo (ad esempio, funzione dell’assegnazione del valore alla variabile). Alcuni linguaggi (ad esempio Python) non richiedono neppure la dichiarazione della variabile, che viene semplicemente usata. È l’interprete che inferisce che quella stringa è una variabile. La tipizzazione impone vincoli d’uso sulle variabili e maggiore scrittura del codice, ma assicura una chiara organizzazione dei dati. assenza di tipizzazione, si lavora maniera più rapida e snella, ma potenzialmente si può andare incontro situazioni complicate, come quando si cambia il tipo di una variabile “corsa” senza accorgersene (Andrea Valle).R è un linguaggio non tipicizzato, come Python. R non è necessario dichiarare le variabili che si intendono utilizzare, né il loro tipo.","code":""},{"path":"chapter-sintassi.html","id":"r-console","chapter":"Capitolo 4 Sintassi di base","heading":"4.5 R console","text":"La console di RStudio fornisce la possibilità di richiamare e rieseguire\ncomandi. tasti freccia verticale, \\(\\uparrow\\) e \\(\\downarrow\\), sulla\ntastiera possono essere utilizzati per scorrere avanti e indietro \ncomandi già immessi. Appena trovato il comando che interessa, lo si può\nmodificare, ad esempio, con tasti freccia orizzontali, immettendo\nnuovi caratteri o cancellandone altri.Se viene digitato un comando che R non riconosce, sulla console viene visualizzato un messaggio di errore; ad esempio,","code":"3 % 9\nErrore: unexpected input in \"3 % 9\""},{"path":"chapter-sintassi.html","id":"parentesi","chapter":"Capitolo 4 Sintassi di base","heading":"4.6 Parentesi","text":"Le parentesi R (come generale ogni linguaggio di programmazione) assegnano un significato diverso alle porzioni di codice che delimitano.Le parentesi tonde funzionano come nell’algebra. Per esempionon è equivalente aLe due istruzioni precedenti producono risultati diversi perché, se\nla sequenza delle operazioni algebriche non viene specificata dalle\nparentesi, R assegna alle operazioni algebriche il seguente ordine\ndi priorità decrescente: esponenziazione, moltiplicazione /\ndivisione, addizione / sottrazione, confronti logici\n(<, >, <=, >=, ==, !=). È sempre una buona idea rendere esplicito\nl’ordine delle operazioni algebriche che si vuole eseguire mediante\nl’uso delle parentesi tonde.\nLe parentesi tonde vengono anche utilizzate per le funzioni, come\nvedremo nei prossimi paragrafi. Tra le parentesi tonde avremo dunque\nl’oggetto cui vogliamo applicare la funzione e gli argomenti\npassati alla funzione.Le parentesi graffe sono destinate alla programmazione. Un blocco\ntra le parentesi graffe viene letto come un oggetto unico che può\ncontenere una o più istruzioni.Le parentesi graffe sono destinate alla programmazione. Un blocco\ntra le parentesi graffe viene letto come un oggetto unico che può\ncontenere una o più istruzioni.Le parentesi quadre vengono utilizzate per selezionare degli\nelementi, per esempio ’interno di un vettore, o di una matrice, o\ndi un data.frame. L’argomento entro le parentesi quadre può essere\ngenerato da espressioni logiche.Le parentesi quadre vengono utilizzate per selezionare degli\nelementi, per esempio ’interno di un vettore, o di una matrice, o\ndi un data.frame. L’argomento entro le parentesi quadre può essere\ngenerato da espressioni logiche.","code":"\n2 + 3 * 4\n#> [1] 14\n(2 + 3) * 4\n#> [1] 20"},{"path":"chapter-sintassi.html","id":"i-nomi-degli-oggetti","chapter":"Capitolo 4 Sintassi di base","heading":"4.7 I nomi degli oggetti","text":"Le entità create e manipolate da R si chiamano ‘oggetti.’ Tali oggetti\npossono essere variabili (come nell’esempio che abbiamo visto sopra), array di numeri, caratteri, stringhe, funzioni, o più generale strutture costruite partire da tali\ncomponenti. Durante una sessione di R gli oggetti sono creati e\nmemorizzati attraverso opportuni nomi.nomi possono contenere un qualunque carattere alfanumerico e come\ncarattere speciale il trattino basso (_) o il punto. R fornisce \nseguenti vincoli per nomi degli oggetti: nomi degli oggetti non\npossono mai iniziare con un carattere numerico e non possono contenere \nseguenti simboli: $, @, !, ^, +, -, /, *. È buona\npratica usare nomi come ratio_of_sums. È fortemente sconsigliato\nutilizzare nei nomi degli oggetti caratteri accentati o, ancora peggio,\napostrofi. Per questa ragione è sensato creare nomi degli oggetti\nutilizzando la lingua inglese. È anche bene che nomi degli oggetti non\ncoincidano con nomi di funzioni. Ricordo nuovamente che R è case sensitive, cioè\ne sono due simboli diversi e identificano due oggetti\ndifferenti.questo corso cercheremo di evitare numeri nei nomi degli oggetti R, così come le lettere maiuscole e il punto. Useremo quindi nomi come: my_data, regression_results, square_root, ecc.","code":""},{"path":"chapter-sintassi.html","id":"permanenza-dei-dati-e-rimozione-di-oggetti","chapter":"Capitolo 4 Sintassi di base","heading":"4.7.1 Permanenza dei dati e rimozione di oggetti","text":"Gli oggetti vengono salvati nello “spazio di lavoro” (workspace). Il\ncomando ls() può essere utilizzato per visualizzare nomi degli\noggetti che sono quel momento memorizzati R.Per eliminare oggetti dallo spazio di lavoro è disponibile la funzione\nrm(); ad esempiocancella tutti gli oggetti indicati entro parentesi. Per eliminare tutti\ngli oggetti presenti nello spazio di lavoro si può utilizzare la\nseguente istruzione:","code":"\nrm(x, y, z, ink, junk, temp, foo, bar)\nrm(list = ls())"},{"path":"chapter-sintassi.html","id":"chiudere-r","chapter":"Capitolo 4 Sintassi di base","heading":"4.8 Chiudere R","text":"Quando si chiude RStudio il programma ci chiederà se si desidera salvare\nl’area di lavoro sul computer. Tale operazione è da evitare quanto\ngli oggetti così salvati andranno ad interferire con gli oggetti creati\nun lavoro futuro. Si consiglia dunque di rispondere negativamente \nquesta domanda.RStudio, selezionare Preferences dal menu tendina e, \nR General Workspace, deselezionare l’opzione\nRestore .RData workspace start- e scegliere l’opzione\nNever nella finestra di dialogo Save workspace \n.RData exit.RStudio, selezionare Preferences dal menu tendina e, \nR General Workspace, deselezionare l’opzione\nRestore .RData workspace start- e scegliere l’opzione\nNever nella finestra di dialogo Save workspace \n.RData exit.R, selezionare Preferences dal menu tendina e, Startup,\nselezionare l’opzione corrispondenza dell’item\nSave workspace exit R.R, selezionare Preferences dal menu tendina e, Startup,\nselezionare l’opzione corrispondenza dell’item\nSave workspace exit R.","code":""},{"path":"chapter-sintassi.html","id":"creare-ed-eseguire-uno-script-r-con-un-editore","chapter":"Capitolo 4 Sintassi di base","heading":"4.9 Creare ed eseguire uno script R con un editore","text":"È molto più facile interagire con R manipolando uno script con un\neditore piuttosto che inserendo direttamente le istruzioni nella\nconsole. R fornisce il Text Editor dove è possibile inserire il codice\n(File \\(\\\\) New Script). Per salvare il file basta utilizzare l’apposito\nmenù tendina (estensione .R). Tale file potrà poi essere riaperto ed\nutilizzato un momento successivo.L’editore comunica con R nel modo seguente: dopo avere selezionato la\nporzione di codice che si vuole eseguire, si digita un’apposita sequenza\ndi tasti (Command + Enter su Mac OS X e ctrl + r Windows).\nctrl + r significa premere il tasto ctrl e, tenendolo premuto, premere il tasto r della tastiera.\nCosì facendo, R eseguirà le istruzioni selezionate e l’output verrà\nstampato sulla console. Il Text Editor fornito da R è piuttosto\nprimitivo: è fortemente consigliato utilizzare RStudio.","code":""},{"path":"chapter-sintassi.html","id":"commentare-il-codice","chapter":"Capitolo 4 Sintassi di base","heading":"4.9.1 Commentare il codice","text":"Un “commento” è una parte di codice che l’interprete non tiene considerazione. Quando l’interprete arriva ad un segnalatore di commento salta fino al segnalatore di fine commento e di lì riprende il normale processo esecutivo.commenti sono parole linguaggio naturale (nel nostro caso l’italiano), che permettono agli utilizzatori di capire il flusso logico del codice e chi lo ha scritto di ricordare il perché di determinate istruzioni.R, le parole dopo il simbolo # sono considerate commenti e sono ignorate; ad esempio:","code":"\n# Questo e' un commento"},{"path":"chapter-sintassi.html","id":"cambiare-la-cartella-di-lavoro","chapter":"Capitolo 4 Sintassi di base","heading":"4.10 Cambiare la cartella di lavoro","text":"Quando si inizia una sessione di lavoro, R sceglie una cartella quale\n“working directory.” Sarà tale cartella che andrà cercare gli\nscript definiti dall’utilizzatore e file dei dati. È possibile\ndeterminare quale sia la corrente “working directory” digitando sulla\nconsole di RStudio l’istruzione:Per cambiare la cartella di lavoro (maniera tale che corrisponda alla\ncartella nella quale sono stati salvati dati e gli script da eseguire)\nsi sceglie la voce Set Working Directory sul menù tendina di RStudio\ne si selezione la voce Choose Directory… Nella finestra che compare,\nsi cambia la cartella con quella che si vuole.","code":"\ngetwd()"},{"path":"chapter-sintassi.html","id":"loggetto-base-di-r-il-vettore","chapter":"Capitolo 4 Sintassi di base","heading":"4.11 L’oggetto base di R: il vettore","text":"R opera su strutture di dati; la più semplice di tali strutture è il\nvettore numerico, che consiste un insieme ordinato di numeri; ad\nesempio:Nell’istruzione precedente, c() è una funzione. R gli argomenti\nsono passati alle funzioni inserendoli ’interno delle parentesi\ntonde. Si noti che gli argomenti (questo caso, numeri\n\\(7.0, 10.2, -2.9, 21.4\\)) sono separati virgole. La funzione c() può\nprendere un numero arbitrario di argomenti e genera un vettore\nconcatenando suoi argomenti. L’operatore <- assegna un nome al\nvettore che è stato creato. Nel caso presente, digitando x possiamo\nvisualizzare il vettore che abbiamo creato:Se invece eseguiamo l’istruzionesenza assegnazione, il valore dell’espressione sarà visualizzato nella\nconsole, ma il vettore non potrà essere utilizzato nessun altro modo.","code":"\nx <- c(7.0, 10.2, -2.9, 21.4)\nx\n#> [1]  7.0 10.2 -2.9 21.4\nc(7.0, 10.2, -2.9, 21.4)\n#> [1]  7.0 10.2 -2.9 21.4"},{"path":"chapter-sintassi.html","id":"operazioni-vettorializzate","chapter":"Capitolo 4 Sintassi di base","heading":"4.11.1 Operazioni vettorializzate","text":"Molte operazioni R sono vettorializzate, il che significa che esse\nsono eseguite parallelo determinati oggetti. Ciò consente di\nscrivere codice che sia efficiente, conciso e più facile da leggere\nrispetto al codice che contiene istruzioni non vettorializzate.","code":""},{"path":"chapter-sintassi.html","id":"vettori-aritmetici","chapter":"Capitolo 4 Sintassi di base","heading":"4.11.2 Vettori aritmetici","text":"L’esempio più semplice che illustra come si svolgono le operazioni\nvettorializzate riguarda le operazioni algebriche applicate ai vettori.\nvettori, infatti, possono essere utilizzati espressioni numeriche\nnelle quali le operazioni algebriche vengono eseguite “elemento per\nelemento.”Per illustrare questo concetto, definiamo il vettore die che contiene\npossibili risultati del lancio di un dado:Supponiamo di volere sommare \\(10\\) ciascun elemento del vettore die.\nDato che le operazioni sui vettori sono eseguite elemento per elemento,\nper ottenere questo risultato è sufficiente eseguire l’istruzione:Si noti come la costante \\(10\\) sia stata sommata ciascun elemento del\nvettore. maniera corrispondente, l’istruzionesottrarrà un’unità da ciascuno degli elementi del vettore die.Se l’operazione aritmetica coinvolge due o più vettori, R allinea vettori ed esegue una sequenza di operazioni elemento per elemento. Per esempio, l’istruzionefa sì che due vettori vengano disposti l’uno di fianco ’altro per poi moltiplicare gli elementi corrispondenti: il primo elemento del primo vettore per il primo elemento del secondo vettore e così via. Il vettore risultante avrà la stessa dimensione dei due vettori che sono stati moltiplicati, come indicato qui sotto:\\[\n\\begin{array}{ccccc}\n1 & \\times & 1 & \\& 1 \\\\\n2 & \\times & 2 & \\& 4 \\\\\n3 & \\times & 3 & \\& 9 \\\\\n4 & \\times & 4 & \\& 16 \\\\\n5 & \\times & 5 & \\& 25 \\\\\n6 & \\times & 6 & \\& 36 \\\\\n\\hline\n\\verb+die+ & * & \\verb+die+ & = & \n\\end{array}\n\\]\nOltre agli operatori aritmetici elementari +, -, *, /, e ^ per\nl’elevamento potenza, sono disponibili le più comuni funzioni\nmatematiche: log(), exp(), sin(), cos(), tan(), sqrt(),\nmax(), min() e così via. Altre funzioni di uso comune sono:\nrange() che restituisce un vettore c(min(x), max(x)); sort() che\nrestituisce un vettore ordinato; length(x) che restituisce il numero\ndi elementi di x; sum(x) che dà la somma degli elementi di x,\nmentre prod(x) dà il loro prodotto. Due funzioni statistiche di uso\ncomune sono mean(x), la media aritmetica, e var(x), la varianza.","code":"\ndie <- c(1, 2, 3, 4, 5, 6)\ndie\n#> [1] 1 2 3 4 5 6\ndie + 10\n#> [1] 11 12 13 14 15 16\ndie - 1\n#> [1] 0 1 2 3 4 5\ndie * die\n#> [1]  1  4  9 16 25 36"},{"path":"chapter-sintassi.html","id":"generazione-di-sequenze-regolari","chapter":"Capitolo 4 Sintassi di base","heading":"4.11.3 Generazione di sequenze regolari","text":"R possiede un ampio numero di funzioni per generare sequenze di numeri.\nAd esempio, c(1:10) è il vettore c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10).\nL’espressione c(30:1) può essere utilizzata per generare una sequenza\n’indietro.La funzione seq() genera un vettore che contiene una sequenza regolare\ndi numeri, generata base determinate regole. Può avere 5 argomenti:\nprimi due rappresentano l’inizio () e la fine () della\nsequenza, il terzo specifica l’ampiezza del passo (), il quarto la\nlunghezza della sequenza (length.) e infine il quinto\n(along.), che se utilizzato deve essere l’unico parametro\npresente, è il nome di un vettore, ad esempio x, creando tal modo\nla sequenza 1, 2, …, length(x). Esempi di utilizzo della funzione\nseq() sono seguenti:Altra funzione utilizzata per generare sequenze è rep() che può essere\nutilizzata per replicare un oggetto vari modi. Ad esempio:metterà tre copie di die nell’oggetto die3.","code":"\nseq(from = 1, to = 10)\n#>  [1]  1  2  3  4  5  6  7  8  9 10\nseq(-5, 5, by = 2.5)\n#> [1] -5.0 -2.5  0.0  2.5  5.0\nseq(from = 1, to = 7, length.out = 4)\n#> [1] 1 3 5 7\nseq(along.with = die)\n#> [1] 1 2 3 4 5 6\ndie3 <- rep(die, times = 3)\ndie3\n#>  [1] 1 2 3 4 5 6 1 2 3 4 5 6 1 2 3 4 5 6"},{"path":"chapter-sintassi.html","id":"generazione-di-numeri-casuali","chapter":"Capitolo 4 Sintassi di base","heading":"4.11.4 Generazione di numeri casuali","text":"La funzione sample() è una delle tante funzioni che possono essere\nusate per generare numeri casuali. Per esempio, la seguente istruzione\nsimula dieci lanci di un dado sei facce:Il primo argomento di sample() è il vettore da cui la funzione\nestrarrà degli elementi caso; il secondo argomento specifica che\ndovranno essere effettuate 10 estrazioni casuali; il terzo argomento\nspecifica che le estrazioni sono con rimessa (cioè, lo stesso elemento\npuò essere estratto più di una volta).Scegliere un elemento caso dal vettore \\(\\{1, 2, 3, 4, 5, 6\\}\\) è\nequivalente lanciare un dado e osservare la faccia che si presenta.\nL’istruzione precedente corrisponde dunque alla simulazione di dieci\nlanci di un dado sei facce.","code":"\nroll <- sample(1:6, 10, replace = TRUE)\nroll\n#>  [1] 5 4 5 6 4 6 1 5 5 5"},{"path":"chapter-sintassi.html","id":"vettori-logici","chapter":"Capitolo 4 Sintassi di base","heading":"4.11.5 Vettori logici","text":"Quando si manipolano vettori, talvolta si vogliono trovare gli\nelementi che soddisfano determinate condizioni logiche. Per esempio, \ndieci lanci di un dado, quante volte è uscito \\(5\\)? Per rispondere \nquesta domanda si possono usare gli operatori logici <, > e == per\nle operazioni di “minore di,” “maggiore di” e “uguale .” Se scriviamocreiamo un vettore costituito da elementi TRUE/FALSE quali\nidentificano gli elementi del vettore che soddisfano la condizione\nlogica specificata.Possiamo trattare tale vettore come se fosse costituito da elementi di\nvalore \\(0\\) e \\(1\\). Sommando gli elementi di tale vettore, infatti,\npossiamo contare il numero di “5”:","code":"\nroll == 5\n#>  [1]  TRUE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE\nsum(roll == 5)\n#> [1] 5"},{"path":"chapter-sintassi.html","id":"dati-mancanti","chapter":"Capitolo 4 Sintassi di base","heading":"4.11.6 Dati mancanti","text":"Quando si è presenza di un dato mancante, R assegna il valore\nspeciale NA, che sta per Available. generale, un’operazione\nsu un NA dà come risultato un NA. Nell’uso delle funzioni che\noperano sui dati sarà dunque necessario specificare che, qualunque\noperazione venga effettuata, gli NA devono essere esclusi.","code":""},{"path":"chapter-sintassi.html","id":"vettori-di-caratteri-e-fattori","chapter":"Capitolo 4 Sintassi di base","heading":"4.11.7 Vettori di caratteri e fattori","text":"vettori di caratteri si creano formando una sequenza di caratteri\ndelimitati da doppie virgolette e possono essere concatenati un\nvettore attraverso la funzione c(). Successivamente, si può applicare\nla funzione factor(), che definisce automaticamente le modalità della\nvariabile categoriale. Ad esempio,Talvolta l’ordine dei livelli del fattore non importa, mentre altre\nvolte l’ordine è importante, per esempio, quando una variable\ncategoriale viene rappresentata un grafico. Per specificare l’ordine\ndei livelli del fattore si usa la seguente sintassi:","code":"\nsoc_status <- factor(\n  c(\"low\", \"high\", \"medium\", \"high\", \"low\", \"medium\", \"high\")\n)\nlevels(soc_status)\n#> [1] \"high\"   \"low\"    \"medium\"\nsoc_status <- \n  factor(soc_status, levels = c(\"low\", \"medium\", \"high\"))\nlevels(soc_status)\n#> [1] \"low\"    \"medium\" \"high\""},{"path":"chapter-sintassi.html","id":"funzioni","chapter":"Capitolo 4 Sintassi di base","heading":"4.12 Funzioni","text":"R offre la possibilità di utilizzare un’enorme libreria di funzioni che\npermettono di svolgere operazioni complicate, quali ad esempio, il\ncampionamento casuale. Esaminiamo ora con più attenzione le proprietà\ndelle funzioni di R utilizzando ancora l’esempio del lancio di un dado.\nAbbiamo visto precedenza come il lancio di un dado possa essere\nsimulato da R con la funzione sample(). La funzione sample() prende\ntre argomenti: il nome di un vettore, un numero chiamato size e un\nargomento chiamato replace. La funzione sample() ritorna un numero\ndi elementi del vettore pari size. Ad esempioAssegnando TRUE ’argomento replace specifichiamo che vogliamo un\ncampionamento con rimessa.Se volgiamo eseguire una serie di lanci indipendenti di un dado,\neseguiamo ripetutamente la funzione sample() ponendo size uguale \n1:Come si fa sapere quanti e quali argomenti sono richiesti da una\nfunzione? Tale informazione viene fornita dalla funzione args(). Nel\nnostro casoci informa che il primo argomento è un vettore chiamato x, il secondo\nargomento è chiamato size ed ha il significato descritto sopra, il\nterzo argomento, replace, specifica se il campionamento è eseguito con\no senza reimmissione, e il quarto argomento, prob, assegna delle\nprobabilità agli elementi del vettore. Il significato degli argomenti\nviene spiegato nel file di help della funzione. Si noti che agli ultimi\ndue argomenti sono stati assegnati dei valori, detti di default. Ciò\nsignifica che, se l’utilizzatore non li cambia, verranno usati da . La\nspecificazione replace = FALSE significa che il campionamento viene\neseguito senza reimmissione. Se desideriamo un campionamento con\nreimmissione, basta specificare replace = TRUE (nel caso di una\nsingola estrazione è ovviamente irrilevante). Ad esempio, l’istruzione\nseguente simula risultati di 10 lanci indipendenti di un dado:Infine, prob = NULL specifica che non viene alterata la probabilità di\nestrazione degli elementi del vettore. generale, gli argomenti di una\nfunzione possono essere oggetti come vettori, matrici, altre funzioni,\nparametri o operatori logici.R ha un sistema di help interno formato HTML che si richiama con\nhelp.start(). Per avere informazioni su qualche funzione specifica,\nper esempio la funzione sample(), il comando da utilizzare è\nhelp(sample) oppure ?sample.","code":"\nsample(die, 2, replace = TRUE)\n#> [1] 2 6\nsample(die, 1, replace = TRUE)\n#> [1] 3\nsample(die, 1, replace = TRUE)\n#> [1] 6\nsample(die, 1, replace = TRUE)\n#> [1] 3\nargs(sample)\n#> function (x, size, replace = FALSE, prob = NULL) \n#> NULL\nsample(die, 10, replace = TRUE)\n#>  [1] 5 5 4 5 2 6 4 2 3 1"},{"path":"chapter-sintassi.html","id":"scrivere-proprie-funzioni","chapter":"Capitolo 4 Sintassi di base","heading":"4.12.1 Scrivere proprie funzioni","text":"Abbiamo visto precedenza come sia possibile simulare risultati\nprodotti da dieci lanci di un dado o, maniera equivalente, dal\nsingolo lancio di dieci dadi. Possiamo replicare questo processo\ndigitando ripetutamente le stesse istruzioni nella console. Otterremo\nogni volta risultati diversi perché, ad ogni ripetizione, il generatore\ndi numeri pseudo-casuali di R dipende dal valore ottenuto dal clock\ninterno della macchina. La funzione set.seed() ci permette di\nreplicare esattamente risultati della generazione di numeri casuali.\nPer ottenere questo risultato, basta assegnare al seed un numero\narbitrario, es. set.seed(12345). Tuttavia, questa procedura è\npraticamente difficile da perseguire se il numero di ripetizioni è alto.\ntal caso è vantaggioso scrivere una funzione contenente il codice che\nspecifica il numero di ripetizioni. questo modo, per trovare il\nrisultato cercato basterà chiamare la funzione una sola volta.Le funzioni utilizzate da R sono costituite da tre elementi: il nome, il blocco del\ncodice e una serie di argomenti. Per creare una funzione è necessario\nimmagazzinare R questi tre elementi e function() consente di\nottenere tale risultato usando la sintassi seguente:Una chiamata di funzione è poi eseguita nel seguente modo:Per potere essere utilizzata, una funzione deve essere presente nella\nmemoria di lavoro di R. Le funzioni salvate un file possono essere\nrichiamate utilizzando la funzione source(), ad esempio,\nsource(\"file_funzioni.R\").Consideriamo ora la funzione two_rolls() che ritorna la somma dei\npunti prodotti dal lancio di due dadi non truccati:La funzione two_rolls() inizia con il creare il vettore die che\ncontiene sei elementi: numeri da \\(1\\) \\(6\\). Viene poi utilizzata la\nfunzione sample() con gli gli argomenti, die, size = 2 e\nreplace = TRUE. Tale funzione restituisce il risultato del lancio di\ndue dadi. Il risultato fornito da sample(die, size = 2, replace = TRUE) viene assegnato ’oggetto res. L’oggetto res corrisponde dunque ad un vettore di due elementi.\nL’istruzione sum(res) somma gli elementi del vettore res e\nattribuisce il risultato di questa operazione sum_res. Infine, la\nfunzione return() ritorna il contenuto dell’oggetto sum_res.\nInvocando la funzione two_rolls() si ottiene dunque la somma del\nlancio di due dadi. generale, la funzione two_rolls() produrrà un\nrisultato diverso ogni volta che viene usata:La formattazione del codice mediante l’uso di spazi e rientri non è\nnecessaria ma è altamente raccomandata per minimizzare la probabilità di\ncompiere errori.","code":"\nnome_funzione <- function(arg1, arg2, ...) {\n  espressione1\n  espressione2\n  return(risultato)\n} \nnome_funzione(arg1, arg2, ...)\ntwo_rolls <- function() {\n  die <- 1:6\n  res <- sample(die, size = 2, replace = TRUE)\n  sum_res <- sum(res)\n  return(sum_res)\n}\ntwo_rolls()   \n#> [1] 9\ntwo_rolls()\n#> [1] 11\ntwo_rolls()\n#> [1] 7"},{"path":"chapter-sintassi.html","id":"pacchetti","chapter":"Capitolo 4 Sintassi di base","heading":"4.13 Pacchetti","text":"Le funzioni di R sono organizzate pacchetti, più importanti dei\nquali sono già disponibili quando si accede al programma.","code":""},{"path":"chapter-sintassi.html","id":"istallazione-e-upgrade-dei-pacchetti","chapter":"Capitolo 4 Sintassi di base","heading":"4.13.1 Istallazione e upgrade dei pacchetti","text":"Alcuni pacchetti non sono presenti nella release di base di R. Per\ninstallare un pacchetto non presente è sufficiente scrivere nella\nconsole:Ad esempio,La prima volta che si usa questa funzione durante una sessione di lavoro\nsi dovrà anche selezionare da una lista il sito mirror da cui\nscaricare il pacchetto.Gli autori dei pacchetti periodicamente rilasciano nuove versioni dei\nloro pacchetti che contengono miglioramenti di varia natura. Per\neseguire l’upgrade dei pacchetti ggplot2 e dplyr, ad esempio, si usa\nla seguente istruzione:Per eseguire l’upgrade di tutti pacchetti l’istruzione è","code":"\ninstall.packages(\"nome_pacchetto\")\ninstall.packages(\"ggplot2\")\nupdate.packages(c(\"ggplot2\", \"dplyr\"))\nupdate.packages()"},{"path":"chapter-sintassi.html","id":"caricare-un-pacchetto-in-r","chapter":"Capitolo 4 Sintassi di base","heading":"4.13.2 Caricare un pacchetto in R","text":"L’istallazione dei pacchetti non rende immediatamente disponibili le\nfunzioni essi contenute. L’istallazione di un pacchetto semplicemente\ncopia il codice sul disco rigido della macchina uso. Per potere usare\nle funzioni contenute un pacchetto installato è necessario caricare\nil pacchetto . Ciò si ottiene con il comando:se si vuole caricare il pacchetto ggplot2. questo punto diventa\npossibile usare le funzioni contenute ggplot2. Queste operazioni si\npossono anche eseguire usando dal menu tendina di RStudio.Per sapere quali sono pacchetti già presenti nella release di R con\ncui si sta lavorando, basta scrivere:","code":"\nlibrary(\"ggplot2\")\nlibrary()"},{"path":"chapter-strutture-dati.html","id":"chapter-strutture-dati","chapter":"Capitolo 5 Strutture di dati","heading":"Capitolo 5 Strutture di dati","text":"Solitamente gli psicologi raccolgono grandi quantità di dati. Tali dati\nvengono codificati R ’interno di oggetti aventi proprietà\ndiverse. Intuitivamente, R un oggetto è qualsiasi cosa cui è\npossibile assegnare un valore. dati possono essere di tipo numerico o\nalfanumerico. Di conseguenza, Rdistingue tra oggetti aventi modi\ndiversi. Inoltre, dati possono essere organizzati righe e colonne\nbase diversi tipi di strutture che R chiama classi.","code":""},{"path":"chapter-strutture-dati.html","id":"classi-e-modi-degli-oggetti","chapter":"Capitolo 5 Strutture di dati","heading":"5.1 Classi e modi degli oggetti","text":"Gli oggetti R si distinguono seconda della loro classe (class) e\ndel loro modo (mode). La classe definisce il tipo di oggetto. R,\nvengono utilizzate cinque strutture di dati che corrispondono cinque\nclassi differenti: vector, matrix, array, list e data.frame.\nUn’altra classe di oggetti R è function (ad essa appartengono le\nfunzioni).La classe di appartenenza di un oggetto si stabilisce usando le funzioni\nclass(), oppure .list(), .function(), .logical(), e così\nvia. Queste funzioni restituisco TRUE e FALSE base\n’appartenenza o meno dell’argomento quella determinata classe.Gli oggetti R possono anche essere classificati base al loro ‘modo.’\nmodi ‘atomici’ degli oggetti sono: numeric, complex, character e\nlogical. Per esempio,Nel seguito verranno esaminate le cinque strutture di dati utilizzate da\nR.","code":"\nx <- c(4, 9)\nmode(x)\n#> [1] \"numeric\"\ncards <- c(\"9 of clubs\", \"10 of hearts\", \"jack of hearts\") \nmode(cards)\n#> [1] \"character\""},{"path":"chapter-strutture-dati.html","id":"vettori","chapter":"Capitolo 5 Strutture di dati","heading":"5.2 Vettori","text":"vettori sono la classe di oggetto più importante R. Un vettore può\nessere creato usando la funzione c():Le dimensioni di un vettore presente nella memoria di lavoro possono essere trovare con la funzione length(); ad esempio,ci dice che y è un vettore costituito da cinque elementi. La somma, il\nminimo e il massimo degli elementi contenuti un vettore si trovano\ncon le seguenti istruzioni:Mentre ci sono sei ‘tipi’ di vettori ‘atomici’ R, noi ci\nfocalizzeremo sui tipi seguenti: ‘numeric’ (‘integer’: e.g., 5;\n‘double’: e.g., 5.5), ‘character’ (e.g., ‘pippo’) e ‘logical’\n(e.g., TRUE, FALSE). Usiamo la funzione typeof() per determinare\nil ‘tipo’ di un vettore atomico. Tutti gli elementi di un vettore\natomico devono essere dello stesso tipo. La funzione str() rende\nvisibile maniera compatta la struttura interna di un oggetto.","code":"\ny <- c(2, 1, 6, -3, 9)\ny\n#> [1]  2  1  6 -3  9\nlength(y)\n#> [1] 5\nsum(y)\n#> [1] 15\nmin(y)\n#> [1] -3\nmax(y)\n#> [1] 9"},{"path":"chapter-strutture-dati.html","id":"matrici","chapter":"Capitolo 5 Strutture di dati","heading":"5.3 Matrici","text":"Una matrice è una collezione di vettori. Il comando per generare una\nmatrice è matrix():Il primo argomento è il vettore cui elementi andranno disporsi\n’interno della matrice. È poi necessario specificare le dimensioni\ndella matrice e il modo cui R dovrà riempire la matrice. Date le\ndimensioni del vettore, la specificazione del numero di righe (secondo\nargomento) è sufficiente per determinare le dimensioni della matrice.\nL’argomento byrow = FALSE è il default. tal caso, R riempie la\nmatrice per colonne. Se vogliamo che R riempia la matrice per righe,\nusiamo byrow = TRUE:Le dimensioni di una matrice presente nella memoria di lavoro possono\nessere trovare con la funzione dim(); ad esempio,ci dice che Y è una matrice con quattro righe e cinque colonne.","code":"\nX <- matrix(1:20, nrow = 4, byrow = FALSE)\nX\n#>      [,1] [,2] [,3] [,4] [,5]\n#> [1,]    1    5    9   13   17\n#> [2,]    2    6   10   14   18\n#> [3,]    3    7   11   15   19\n#> [4,]    4    8   12   16   20\nY <- matrix(1:20, nrow = 4, byrow = TRUE)\nY\n#>      [,1] [,2] [,3] [,4] [,5]\n#> [1,]    1    2    3    4    5\n#> [2,]    6    7    8    9   10\n#> [3,]   11   12   13   14   15\n#> [4,]   16   17   18   19   20\ndim(Y)\n#> [1] 4 5"},{"path":"chapter-strutture-dati.html","id":"array","chapter":"Capitolo 5 Strutture di dati","heading":"5.4 Array","text":"Un array è una collezione di matrici (si veda la\nFigura 1.1). Per costruire un array con la\nfunzione array() è necessario specificare un vettore come primo\nargomento e un vettore di dimensioni, chiamato dim, quale secondo\nargomento:Un sottoinsieme di questi dati può essere selezionato, per esempio, nel\nmodo seguente:","code":"\nar <- array(\n  c(11:14, 21:24, 31:34), \n  dim = c(2, 2, 3)\n)\nar[, , 3]\n#>      [,1] [,2]\n#> [1,]   31   33\n#> [2,]   32   34"},{"path":"chapter-strutture-dati.html","id":"operazioni-aritmetiche-su-vettori-matrici-e-array","chapter":"Capitolo 5 Strutture di dati","heading":"5.5 Operazioni aritmetiche su vettori, matrici e array","text":"","code":""},{"path":"chapter-strutture-dati.html","id":"operazioni-aritmetiche-su-vettori","chapter":"Capitolo 5 Strutture di dati","heading":"5.5.1 Operazioni aritmetiche su vettori","text":"vettori e le matrici (o gli array) possono essere utilizzati \nespressioni aritmetiche. Il risultato è un vettore o una matrice (o un\narray) formato dalle operazioni fatte elemento per elemento sui vettori\no sulle matrici. Ad esempio,restituisce un vettore di dimensioni uguali alle dimensioni di y, \ncui elementi sono dati dalla somma tra ciascuno degli elementi originari\ndi y e la costante “3.”Ovviamente, ad un vettore possono essere applicate tutte le altre\noperazioni algebriche, sempre elemento per elemento. Ad esempio,restituisce un vettore cui elementi sono uguali agli elementi di y\nmoltiplicati per 3.Se sono costituiti dallo stesso numero di elementi, due vettori possono\nessere sommati, sottratti, moltiplicati e divisi, laddove queste\noperazioni algebriche vengono eseguite elemento per elemento. Per\nesempio,","code":"\ny + 3\n#> [1]  5  4  9  0 12\n3 * y\n#> [1]  6  3 18 -9 27\nx <- c(1, 1, 2, 1, 3)\ny <- c(2, 1, 6, 3, 9)\nx + y\n#> [1]  3  2  8  4 12\nx - y\n#> [1] -1  0 -4 -2 -6\nx * y\n#> [1]  2  1 12  3 27\nx / y\n#> [1] 0.5000000 1.0000000 0.3333333 0.3333333 0.3333333"},{"path":"chapter-strutture-dati.html","id":"operazioni-aritmetiche-su-matrici","chapter":"Capitolo 5 Strutture di dati","heading":"5.5.2 Operazioni aritmetiche su matrici","text":"Le operazioni algebriche elemento per elemento si possono estendere al\ncaso delle matrici. Per esempio, se X, Y sono entrambe matrici di\ndimensioni \\(4 \\times 5\\), allora la seguente operazionecrea una matrice D anch’essa di dimensioni \\(4 \\times 5\\) cui elementi\nsono ottenuti dalle operazioni fatte elemento per elemento sulle matrici\ne sugli scalari:","code":"\nM <- 2 * (X + Y) - 3 \nM\n#>      [,1] [,2] [,3] [,4] [,5]\n#> [1,]    1   11   21   31   41\n#> [2,]   13   23   33   43   53\n#> [3,]   25   35   45   55   65\n#> [4,]   37   47   57   67   77"},{"path":"chapter-strutture-dati.html","id":"operazioni-aritmetiche-su-array","chapter":"Capitolo 5 Strutture di dati","heading":"5.5.3 Operazioni aritmetiche su array","text":"Le stesse considerazioni si estendono al caso degli array.","code":""},{"path":"chapter-strutture-dati.html","id":"liste","chapter":"Capitolo 5 Strutture di dati","heading":"5.6 Liste","text":"Le liste assomigliano ai vettori perché raggruppano dati un insieme\nunidimensionale. Tuttavia, le liste non raggruppano elementi individuali\nma bensì oggetti di R, quali vettori e altre liste. Per esempio,Le doppie parentesi quadre identificano l’elemento della lista cui\nvogliamo fare riferimento. Per esempio,","code":"\nlist1 <- list(\"R\", list(TRUE, FALSE), 20:24)\nlist1\n#> [[1]]\n#> [1] \"R\"\n#> \n#> [[2]]\n#> [[2]][[1]]\n#> [1] TRUE\n#> \n#> [[2]][[2]]\n#> [1] FALSE\n#> \n#> \n#> [[3]]\n#> [1] 20 21 22 23 24\nlist1[[3]]\n#> [1] 20 21 22 23 24\nlist1[[3]][2]\n#> [1] 21"},{"path":"chapter-strutture-dati.html","id":"data-frame","chapter":"Capitolo 5 Strutture di dati","heading":"5.7 Data frame","text":"data.frame sono strutture tipo matrice, cui le colonne possono\nessere vettori di tipi differenti. La funzione usata per generare un\ndata frame è data.frame(), che permette di unire più vettori di uguale\nlunghezza come colonne del data frame, ognuno dei quali si riferisce ad\nuna diversa variabile. Ad esempio,L’estrazione di dati da un data.frame può essere effettuata maniera\nsimile quanto avviene per vettori. Ad esempio, per estrarre la\nvariabile value dal data.frame df si può indicare l’indice della\nterza colonna:Dal momento che le colonne sono delle variabili, è possibile estrarle\nanche indicando nome della variabile, scrivendo\nnome_data_frame$nome_variabile:Per fare un esempio, creiamo un data.frame che contenga tutte le informazioni di un mazzo di carte da poker (Grolemund, 2014). tale data.frame, ciascuna riga\ncorrisponde ad una carta – un mazzo da poker ci sono 52 carte,\nperciò il data.frame avrà 52 righe. Il vettore face indica con una\nstringa di caratteri il valore di ciascuna carta, il vettore suit\nindica il seme e il vettore value indica con un numero intero il\nvalore di ciascuna carta. Quindi, il data.frame avrà 3 colonne.Avendo salvato tutte queste informazioni nell’oggetto deck, possiamo\nstamparle sullo schermo semplicemente digitando il nome dell’oggetto che\nle contiene:Si noti che, schermo, R stampa un numero progressivo che corrisponde\nal numero della riga.","code":"\ndf <- data.frame(\n  face = c(\"ace\", \"two\", \"six\"),\n  suit = c(\"clubs\", \"clubs\", \"clubs\"), \n  value = c(1, 2, 3)\n)\ndf\n#>   face  suit value\n#> 1  ace clubs     1\n#> 2  two clubs     2\n#> 3  six clubs     3\ndf[, 3]\n#> [1] 1 2 3\ndf$value\n#> [1] 1 2 3\ndeck <- data.frame(\n  face = c(\"king\", \"queen\", \"jack\", \"ten\", \"nine\", \"eight\",\n  \"seven\", \"six\", \"five\", \"four\", \"three\", \"two\", \"ace\", \n  \"king\", \"queen\", \"jack\", \"ten\", \"nine\", \"eight\", \"seven\", \n  \"six\", \"five\", \"four\", \"three\", \"two\", \"ace\", \"king\", \n  \"queen\", \"jack\", \"ten\", \"nine\", \"eight\", \"seven\", \"six\", \n  \"five\", \"four\", \"three\", \"two\", \"ace\", \"king\", \"queen\", \n  \"jack\", \"ten\", \"nine\", \"eight\", \"seven\", \"six\", \"five\", \n  \"four\", \"three\", \"two\", \"ace\"), \n  suit = c(\"spades\", \"spades\", \"spades\", \"spades\", \n  \"spades\", \"spades\", \"spades\", \"spades\", \"spades\", \n  \"spades\", \"spades\", \"spades\", \"spades\", \"clubs\", \"clubs\", \n  \"clubs\", \"clubs\", \"clubs\", \"clubs\", \"clubs\", \"clubs\", \n  \"clubs\", \"clubs\", \"clubs\", \"clubs\", \"clubs\", \"diamonds\", \n  \"diamonds\", \"diamonds\", \"diamonds\", \"diamonds\", \n  \"diamonds\", \"diamonds\", \"diamonds\", \"diamonds\", \n  \"diamonds\", \"diamonds\", \"diamonds\", \"diamonds\", \"hearts\", \n  \"hearts\", \"hearts\", \"hearts\", \"hearts\", \"hearts\", \n  \"hearts\", \"hearts\", \"hearts\", \"hearts\", \"hearts\", \n  \"hearts\", \"hearts\"), \n  value = c(13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1)\n)\ndeck\n#>     face     suit value\n#> 1   king   spades    13\n#> 2  queen   spades    12\n#> 3   jack   spades    11\n#> 4    ten   spades    10\n#> 5   nine   spades     9\n#> 6  eight   spades     8\n#> 7  seven   spades     7\n#> 8    six   spades     6\n#> 9   five   spades     5\n#> 10  four   spades     4\n#> 11 three   spades     3\n#> 12   two   spades     2\n#> 13   ace   spades     1\n#> 14  king    clubs    13\n#> 15 queen    clubs    12\n#> 16  jack    clubs    11\n#> 17   ten    clubs    10\n#> 18  nine    clubs     9\n#> 19 eight    clubs     8\n#> 20 seven    clubs     7\n#> 21   six    clubs     6\n#> 22  five    clubs     5\n#> 23  four    clubs     4\n#> 24 three    clubs     3\n#> 25   two    clubs     2\n#> 26   ace    clubs     1\n#> 27  king diamonds    13\n#> 28 queen diamonds    12\n#> 29  jack diamonds    11\n#> 30   ten diamonds    10\n#> 31  nine diamonds     9\n#> 32 eight diamonds     8\n#> 33 seven diamonds     7\n#> 34   six diamonds     6\n#> 35  five diamonds     5\n#> 36  four diamonds     4\n#> 37 three diamonds     3\n#> 38   two diamonds     2\n#> 39   ace diamonds     1\n#> 40  king   hearts    13\n#> 41 queen   hearts    12\n#> 42  jack   hearts    11\n#> 43   ten   hearts    10\n#> 44  nine   hearts     9\n#> 45 eight   hearts     8\n#> 46 seven   hearts     7\n#> 47   six   hearts     6\n#> 48  five   hearts     5\n#> 49  four   hearts     4\n#> 50 three   hearts     3\n#> 51   two   hearts     2\n#> 52   ace   hearts     1"},{"path":"chapter-strutture-dati.html","id":"selezione-di-elementi","chapter":"Capitolo 5 Strutture di dati","heading":"5.8 Selezione di elementi","text":"Una volta creato un data.frame, ad esempio quello che contiene un mazzo\nvirtuale di carte (si veda\nl’esempio \\[exmp:deck_of_cards\\]), è necessario sapere come manipolarlo.\nLa funzione head() mostra le prime sei righe del data.frame:Poniamoci ora il problema di mescolare il mazzo di carte e di estrarre\nalcune carte dal mazzo. Queste operazioni possono essere eseguite usando\nil sistema notazionale di R.Il sistema di notazione di R consente di estrarre singoli elementi\ndagli oggetti definiti da R. Per estrarre un valore da un data.frame,\nper esempio, dobbiamo scrivere il nome del data.frame seguito da una\ncoppia di parentesi quadre:’interno delle parentesi quadre ci sono due indici separati da una\nvirgola. R usa il primo indice per selezionare un sottoinsieme di righe\ndel data.frame e il secondo indice per selezionare un sottoinsieme di\ncolonne. L’indice è il numero d’ordine che etichetta progressivamente ognuno dei valori del vettore. Per esempio,restituisce l’elemento che si trova nella nella nona riga della seconda\ncolonna di deck.R ci sono sei modi diversi per specificare gli indici di un oggetto:\ninteri positivi, interi negativi, zero, spazi vuoti, valori logici e\nnomi. Esaminiamoli qui di seguito.","code":"\nhead(deck)\n#>    face   suit value\n#> 1  king spades    13\n#> 2 queen spades    12\n#> 3  jack spades    11\n#> 4   ten spades    10\n#> 5  nine spades     9\n#> 6 eight spades     8\ndeck[, ]\ndeck[9, 2]\n#> [1] spades\n#> Levels: clubs diamonds hearts spades"},{"path":"chapter-strutture-dati.html","id":"interi-positivi","chapter":"Capitolo 5 Strutture di dati","heading":"5.8.0.1 Interi positivi","text":"Gli indici \\(, j\\) possono essere degli interi positivi che identificano\nl’elemento nella \\(\\)-esima riga e nella \\(j\\)-esima colonna del\ndata.frame. Per l’esempio relativo al mazzo di carte, l’istruzioneritorna il valore nella prima riga e nella prima colonna. Per estrarre\npiù di un valore, usiamo un vettore di interi positivi. Per esempio, la\nprima riga di deck si trova conTale sistema notazionale non si applica solo ai data.frame ma può essere\nusato anche per gli altri oggetti di R.L’indice usato da R inizia da 1. altri linguaggi di programmazione,\nper esempio C, inizia da 0.","code":"\ndeck[1, 1]\n#> [1] king\n#> Levels: ace eight five four jack king nine queen seven six ten three two\ndeck[1, c(1:3)]\n#>   face   suit value\n#> 1 king spades    13"},{"path":"chapter-strutture-dati.html","id":"interi-negativi","chapter":"Capitolo 5 Strutture di dati","heading":"5.8.0.2 Interi negativi","text":"Gli interi negativi fanno l’esatto contrario degli interi positivi: R\nritornerà tutti gli elementi tranne quelli specificati dagli interi\nnegativi. Per esempio, la prima riga del data.frame può essere\nspecificata nel modo seguenteovvero, escludendo tutte le righe seguenti.","code":"\ndeck[-(2:52), 1:3]\n#>   face   suit value\n#> 1 king spades    13"},{"path":"chapter-strutture-dati.html","id":"zero","chapter":"Capitolo 5 Strutture di dati","heading":"5.8.1 Zero","text":"Quando lo zero viene usato come indice, R non ritorna nulla dalla\ndimensione cui lo zero si riferisce. L’istruzioneritorna un data.frame vuoto. Non molto utile.","code":"\ndeck[0, 0]\n#> data frame with 0 columns and 0 rows"},{"path":"chapter-strutture-dati.html","id":"spazio","chapter":"Capitolo 5 Strutture di dati","heading":"5.8.2 Spazio ’ ’","text":"Uno spazio viene usato quale indice per comunicare R di estrarre\ntutti valori quella dimensione. Questo è utile per estrarre intere\ncolonne o intere righe da un data.frame. Per esempio, l’istruzioneritorna la terza riga del data.frame deck.","code":"\ndeck[3, ]\n#>   face   suit value\n#> 3 jack spades    11"},{"path":"chapter-strutture-dati.html","id":"valori-booleani","chapter":"Capitolo 5 Strutture di dati","heading":"5.8.3 Valori booleani","text":"Se viene fornito un vettore di stringhe TRUE, FALSE, R selezionerà\ngli elementi riga o colonna corrispondenti ai valori booleani TRUE\nusati quali indici. Per esempio, l’istruzioneritorna valori delle prime due colonne della terza riga di deck.","code":"\ndeck[3, c(TRUE, TRUE, FALSE)]\n#>   face   suit\n#> 3 jack spades"},{"path":"chapter-strutture-dati.html","id":"nomi","chapter":"Capitolo 5 Strutture di dati","heading":"5.8.4 Nomi","text":"È possibile selezionare gli elementi del data.frame usando loro nomi.\nPer esempio,","code":"\ndeck[1, c(\"face\", \"suit\", \"value\")]\n#>   face   suit value\n#> 1 king spades    13\ndeck[, \"value\"]\n#>  [1] 13 12 11 10  9  8  7  6  5  4  3  2  1 13 12 11 10  9  8  7  6  5  4  3  2  1 13 12 11 10  9\n#> [32]  8  7  6  5  4  3  2  1 13 12 11 10  9  8  7  6  5  4  3  2  1"},{"path":"chapter-strutture-dati.html","id":"giochi-di-carte","chapter":"Capitolo 5 Strutture di dati","heading":"5.9 Giochi di carte","text":"Avendo presentato le nozioni base del sistema di notazione di R,\nutilizziamo tali conoscenze per manipolare il data.frame. L’istruzioneritorna tutte le righe e tutte e le colonne del data.frame deck. Le\nrighe sono identificate dal primo indice, che va da 1 52. Permutare \nmodo casuale l’indice delle righe equivale mescolare il mazzo di\ncarte. Per fare questo, utilizziamo la funzione sample() ponendo replace=FALSE e size\nuguale alla dimensione del vettore che contiene gli indici da 1 52:Utilizzando il vettore random di indici permutati otteniamo il\nrisultato cercato:Possiamo ora scrivere una funzione che include le precedenti istruzioni:Invocando la funzione shuffle() possiamo generare un data.frame che\nrappresenta un mazzo di carte mescolato:Se immaginiamo di distribuire le carte di questo mazzo due giocatori\ndi poker, per il primo giocatore avremo:e per il secondo:","code":"\ndeck[1:52, ]\nrandom <- sample(1:52, size = 52, replace = FALSE)\nrandom\n#>  [1] 45 23 12 37 38 47 31  4 48  9  5 42 24 15 13  2 41 21 34  6 46 32 52 16 49  3 25 22 11  7 35\n#> [32] 33 43 10 28 17 30  8 26  1 14 18 27 44 20 51 40 36 29 39 50 19\ndeck_shuffled <- deck[random, ]\nhead(deck_shuffled)\n#>     face     suit value\n#> 45 eight   hearts     8\n#> 23  four    clubs     4\n#> 12   two   spades     2\n#> 37 three diamonds     3\n#> 38   two diamonds     2\n#> 47   six   hearts     6\nshuffle <- function(cards) {\n  random <- sample(1:52, size = 52, replace = FALSE) \n  return(cards[random, ])\n}\ndeck_shuffled <- shuffle(deck)\ndeck_shuffled[c(1, 3, 5, 7, 9), ]\n#>     face     suit value\n#> 19 eight    clubs     8\n#> 51   two   hearts     2\n#> 11 three   spades     3\n#> 35  five diamonds     5\n#> 23  four    clubs     4\ndeck_shuffled[c(2, 4, 6, 8, 10), ]\n#>     face     suit value\n#> 28 queen diamonds    12\n#> 48  five   hearts     5\n#> 26   ace    clubs     1\n#> 2  queen   spades    12\n#> 42  jack   hearts    11"},{"path":"chapter-strutture-dati.html","id":"variabili-locali","chapter":"Capitolo 5 Strutture di dati","heading":"5.9.1 Variabili locali","text":"Si noti che, nell’esempio precedente, abbiamo passato l’argomento deck\nalla funzione shuffle(), perché questo è il nome del data.frame che\nvolevamo manipolare. Nella definizione della funzione shuffle(), però,\nl’argomento della funzione era chiamato cards. Il nome degli argomenti\nè diverso nei due casi. Allora perché l’istruzione shuffle(deck) non\ndà un messaggio d’errore?La risposta questa domanda è che nelle funzioni le variabili nascono\nquando la funzione entra esecuzione e muoiono al termine\ndell’esecuzione della funzione. Per questa ragione, sono dette ‘locali.’\nLa variabile cards, questo esempio, esiste soltanto ’interno\ndella funzione. Dunque non deve (necessariamente) avere lo stesso nome\ndi un altro oggetto che esiste al di fuori della funzione, nello spazio\ndi lavoro di R (anzi, è meglio se il nome degli oggetti usati\n’interno delle funzioni è diverso da quello degli oggetti che\nesistono fuori dalle funzioni). R sa che l’oggetto deck passato \nshuffle() corrisponde cards ’interno della funzione perché\nassegna il nome cards qualunque oggetto venga passato alla funzione\nshuffle() come primo (e, questo caso, unico) argomento.","code":""},{"path":"chapter-strut-contr.html","id":"chapter-strut-contr","chapter":"Capitolo 6 Strutture di controllo","heading":"Capitolo 6 Strutture di controllo","text":"R il flusso della computazione segue l’ordine di lettura delle espressioni. controlli di flusso sono quei costrutti sintattici che possono modificare quest’ordine di computazione. Ad esempio, un ciclo ripete le istruzioni annidate al suo interno per un certo numero di volte, e quindi procede sequenzialmente da lì avanti, mentre un condizionale valuta una condizione rispetto alla quale il flusso di informazioni si biforca (se è vero / se è falso). Ci limitiamo qui ad introdurre il ciclo .","code":""},{"path":"chapter-strut-contr.html","id":"il-ciclo-for","chapter":"Capitolo 6 Strutture di controllo","heading":"6.1 Il ciclo for","text":"Il ciclo è una struttura di controllo iterativa che determina l’esecuzione di una porzione di codice ripetuta per un certo numero noto di volte. Il linguaggio R usa la seguente sintassi per il ciclo :(indice valori_indice) {\noperazioni\n}il che significa “esegui le operazioni operazioni per diversi valori di indice compresi nel vettore valori_indice.” Per esempio, il seguente ciclo non fa altro che stampare il valore della variabile contatore ciascuna esecuzione del ciclo:Un esempio (leggermente) più complicato è il seguente:Per esempio, quanti numeri pari sono contenuti un vettore? La\nrisposta questa domanda viene fornita dalla funzione\ncountEvenNumbers() che possiamo definire come indicato qui sotto:Nella funzione countEvenNumbers() abbiamo inizializzato la variabile\ncount zero. Prima dell’esecuzione del ciclo , dunque, count\nvale zero. Il ciclo viene eseguito tante volte quanti sono gli\nelementi che costituiscono il vettore x. L’indice dunque assume\nvalori compresi tra 1 e il valore che corrisponde al numero di elementi\ndi x. L’operazione modulo, indicato con %% dà come risultato il\nresto della divisione euclidea del primo numero per il secondo. Per\nesempio, 9 %% 2 dà come risultato \\(1\\) perché questo è il resto della\ndivisione \\(9/2\\). L’operazione modulo dà come risultato \\(0\\) per tutti \nnumeri pari. ciascuna esecuzione del ciclo l’operazione modulo\nviene eseguita, successivamente, su uno degli elementi di x. Se\nl’operazione modulo dà \\(0\\) come risultato, ovvero se il valore\nconsiderato è un numero pari, allora la variabile count viene\nincrementata di un’unità. L’istruzione return() ritorna il\nnumero di valori pari contenuti nel vettore di input alla funzione.\nSi noti che è necessario usare return(): la funzione ritornerà qualunque cosa sia stampato nell’ultima riga della funzione stessa.Facciamo un esempio:","code":"\nfor (i in 1:3) {\n  print(i)\n}\n#> [1] 1\n#> [1] 2\n#> [1] 3\nx_list <- seq(1, 9, by = 2)\nx_list\n#> [1] 1 3 5 7 9\nsum_x <- 0\nfor (x in x_list) {\n  sum_x <- sum_x + x\n  cat(\"L'indice corrente e'\", x, \"\\n\")\n  cat(\"La frequenza cumulata e'\", sum_x, \"\\n\") \n}\n#> L'indice corrente e' 1 \n#> La frequenza cumulata e' 1 \n#> L'indice corrente e' 3 \n#> La frequenza cumulata e' 4 \n#> L'indice corrente e' 5 \n#> La frequenza cumulata e' 9 \n#> L'indice corrente e' 7 \n#> La frequenza cumulata e' 16 \n#> L'indice corrente e' 9 \n#> La frequenza cumulata e' 25\ncountEvenNumbers <- function(x) {\n  count <- 0\n  for (i in 1:length(x)) {\n    if (x[i] %% 2 == 0)  \n      count = count + 1\n  }\n  count\n}\nx <- c(1, 2, 1, 4, 6, 3, 9, 12)\ncountEvenNumbers(x)\n#> [1] 4"},{"path":"chapter-input-output.html","id":"chapter-input-output","chapter":"Capitolo 7 Input/Output","heading":"Capitolo 7 Input/Output","text":"dati raccolti dallo psicologo sono contenuti file aventi formati\ndiversi: solo testo, CSV, Excel, eccetera. R prevede diverse funzioni\ndi importazione dei dati. Esamineremo qui la funzione read.table() per\nl’importazione di dati formato solo testo, ma funzioni analoghe\npossono essere usate per molti altri formati possibili.","code":""},{"path":"chapter-input-output.html","id":"la-funzione-read.table","chapter":"Capitolo 7 Input/Output","heading":"7.1 La funzione read.table()","text":"Ci sono tanti modi per importare un file dal nostro computer. R permette di utilizzare delle funzioni che sono già nella libreria di base, oppure possiamo utilizzare delle funzioni specifiche, seconda del tipo di file da importare, che sono contenute pacchetti aggiuntivi. Per leggere dati da file R è conveniente\npreliminarmente generare un file di dati formato ASCII, disponendoli\ncome si farebbe una matrice di dati, e mettere questo file nella\ncartella di lavoro corrente. Fatto questo, si può utilizzare la funzione\nread.table() presente nella libreria di base per leggere l’intero\ndataset. Se la prima riga del file contiene l’intestazione delle\nvariabili, allora read.table(\"my_file.txt\", header = TRUE)\ninterpreterà la prima riga del file come una riga dove sono contenuti \nnomi delle variabili, assegnando ciascun nome alle variabili del data\nframe:alternativa, si può impiegare la funzione read.csv(), che è adatta\nleggere dati salvati .csv. Utilizzando altre funzioni, si possono\nleggere R  dati contenuti file aventi formati diversi da quelli\nconsiderati qui, quali Excel, SPSS, ecc.","code":"mydata <- read.table(\"my_file.txt\", header = TRUE)"},{"path":"chapter-input-output.html","id":"file-di-dati-forniti-da-r","chapter":"Capitolo 7 Input/Output","heading":"7.2 File di dati forniti da R","text":"R esistono comunque oltre 50 insiemi di dati contenuti nel package\nbase e altri sono disponibili altri packages. Per vedere l’elenco\ndegli insiemi di dati disponibili nel package base basta usare\nl’istruzione data(); per caricare un particolare insieme di dati, ad\nesempio cars, basta utilizzare l’istruzioneNella maggior parte dei casi questo corrisponde caricare un oggetto,\nsolitamente un data.frame dello stesso nome: per l’esempio considerato\nsi avrebbe un data frame di nome cars.","code":"data(cars)"},{"path":"chapter-input-output.html","id":"esportazione-di-un-file","chapter":"Capitolo 7 Input/Output","heading":"7.3 Esportazione di un file","text":"Per esportare un data.frame formato .csv possiamo scrivere il\nseguente codicedove df_esempio è il data.frame da salvare e esempio.csv è il file\nche verrà salvato ’interno della nostra cartellla di lavoro.","code":"write.csv(df_esempio, file = \"esempio.csv\", row.names = FALSE)"},{"path":"chapter-input-output.html","id":"pacchetto-rio","chapter":"Capitolo 7 Input/Output","heading":"7.4 Pacchetto rio","text":"Un’alternativa più semplice è fornita dalle funzioni fornite dal pacchetto rio. Per importare dati da un file qualsiasi formato si usaPer esportare dati un file avente qualsiasi formato si usa invece","code":"\nmy_data_frame <- rio::import(\"my_file.csv\")\nrio::export(my_data_frame, \"my_file.csv\")"},{"path":"chapter-input-output.html","id":"dove-sono-i-miei-file","chapter":"Capitolo 7 Input/Output","heading":"7.5 Dove sono i miei file?","text":"Quello che abbiamo detto finora, proposito dell’importazione ed esportazione dei file, si riferisce file che si trovano nella cartella di lavoro (working directory). Ma non sempre ci troviamo questa situazione, il che è anche una buona cosa, perché se dobbiamo gestire un progetto anche leggermente complesso è sempre una buona idea salvare file che usiamo cartelle diverse. Per esempio, possiamo usare una cartella chiamata psicometria dove salviamo tutto il materiale di questo insegnamento. Nella cartella psicometria ci potrà essere una cartella chiamata scripts dove salveremo gli script con il codice R utilizzato per vari esercizi, e una cartella chiamata data dove possiamo salvare dati. Questa organizzazione minimale ci pone, però, difronte ad un problema: dati che vogliamo caricare R non si trovano più nella cartella dove sono contenuti gli script. Quando importiamo un file di dati dobbiamo dunque specificare il percorso che identifica la posizione sul nostro computer del file che ci interessa.Questo problema può essere risolto due modi: speficicando l’inridizzo del file modo assoluto o relativo. Specificare l’indirizzo di un file modo assoluto ha una serie di limiti. Il più grande è che non sarà possibile utilizzare quell’istruzione su una macchina diversa. Dunque, è molto più conveniente specificare l’indirizzo dei file modo relativo. Ma relativo rispetto cosa? Rispetto alla working directory che definirà l’origine del nostro percorso.Ma è facile immaginare che progetti diversi possano avere diverse working directory. Infatti le cose stanno proprio questo modo: per ciascun progetto dobbiamo specificare una diversa working directory. Per esempio, potremmo avere un progetto relativo ’insegnamento di Psicometria e un progetto relativo alla prova finale.Per organizzaere il lavoro questo modo, si procede come segue. Supponiamo di creare una cartella chiamata psicometria che contiene, al suo interno, le cartelle scripts e data:Queste cartelle conterranno file che ho specificato sopra.Chiudiamo RStudio, se è aperto e lo riapriamo di nuovo. Dal menu selezioniamo File -> New Project... Questo aprirà un altro menu che ci chiederà, tra le altre cose se vogliamo creare un nuovo progetto (New project). Selezioniamo quell’opzione e navighiamo fino alla cartella psicometria e selezioniamo open. Questo creerà un file chiamato psicometria.Rproj nella cartella psicometria.Chiudiamo RStudio. Se vogliamo accedere al progetto “psicometria” dobbiamo cliccare sul file psicometria.Rproj. Questo aprirà RStudio e farà modo che la working directory coincida con la cartalla psicometria. Ogni volta che vogliamo lavorare sui dati del progetto “psicometria” dobbiamo chiudere RStudio (se è già aperto) e riaprirlo cliccando sul file psicometria.Rproj.questo punto possiamo definire l’indirizzo dei file modo relativo – relativo alla cartella psicometria. Per fare questo usiamo le funzionalità del pacchetto . Supponiamo di volere caricare un file di dati che si chiama dati_depressione.txt e si trova nella cartella data contenuta nella cartella psicometria. Per importare questi dati (dopo avere caricato pacchetti rio e ) useremo l’istruzione seguente:altre parole, così facendo specifichiamo il percorso relativo del file dati_depressione.txt. L’istruzione precedente significa che, partendo dalla cartella che coincide con la working directory dobbiamo spostarci nella cartella data e lì dentro troviamo il file chiamato dati_depressione.txt.","code":"psicometria/\n  ├── data\n  ├── scripts\nrio::import(here(\"data\", \"dati_depressione.txt\"))"},{"path":"manipolazione-dei-dati.html","id":"manipolazione-dei-dati","chapter":"Capitolo 8 Manipolazione dei dati","heading":"Capitolo 8 Manipolazione dei dati","text":"","code":""},{"path":"manipolazione-dei-dati.html","id":"motivazione","chapter":"Capitolo 8 Manipolazione dei dati","heading":"8.1 Motivazione","text":"Si chiamano “dati grezzi” quelli che provengono dal mondo circostanze, \ndati raccolti per mezzo degli strumenti usati negli esperimenti, per\nmezzo di interviste, di questionari, ecc. Questi dati (chiamati\ndataset) raramente vengono forniti con una struttura logica precisa.\nPer potere elaborarli mediante dei software dobbiamo prima trasformarli\nmaniera tale che abbiano una struttura logica organizzata. La\nstruttura che solitamente si utilizza è quella tabellare (matrice dei\ndati), ovvero si dispongono dati una tabella nella quale ciascuna\nriga corrisponde ad un’osservazione e ciascuna colonna corrisponde ad\nuna variabile rilevata. R una tale struttura è chiamata data frame.\nIl pacchetto dplyr, che è al momento uno dei pacchetti più famosi e\nutilizzati per la gestione dei dati, offre una serie di funzionalità che\nconsentono di ottenere il risultato descritto precedenza e consente\ninoltre di eseguire le operazioni più comuni di manipolazione dei dati\nmaniera più semplice rispetto quanto succeda quando usiamo le\nfunzioni base di R.","code":""},{"path":"manipolazione-dei-dati.html","id":"trattamento-dei-dati-con-dplyr","chapter":"Capitolo 8 Manipolazione dei dati","heading":"8.2 Trattamento dei dati con dplyr","text":"Il pacchetto dplyr include cinque funzioni base: filter(),\nselect(), mutate(), arrange() e summarise(). queste cinque\nfunzioni di base si aggiungono il pipe %>% che serve concatenare più\noperazioni e group_by che serve per il subsetting. particolare,\nconsiderando una matrice osservazioni per variabili, select() e\nmutate() si occupano di organizzare le variabili, filter() e\narrange() casi, e summarise() gruppi.Per introdurre le funzionalità di base di dplyr, considereremo dati contenuti nel data frame msleep fornito dal pacchetto ggplot2, che elenca le ore di sonno medie per 83 specie di mammiferi (Savage et al., 2007). Carichiamo il pacchetto tidyverse (che contiene ggplot2) e leggiamo nella memoria di lavoro l’oggetto msleep:","code":"\nlibrary(\"tidyverse\")\ndata(msleep)\ndim(msleep)\n#> [1] 83 11"},{"path":"manipolazione-dei-dati.html","id":"operatore-pipe","chapter":"Capitolo 8 Manipolazione dei dati","heading":"8.2.1 Operatore pipe","text":"Prima di presentare le funzionalità di tidyverse, introduciamo l’operatore pipe %>% del pacchetto magrittr – ma ora presente anche base R nella versione |>. L’operatore pipe, %>% o |>, serve concatenare varie funzioni insieme, modo da inserire un’operazione dietro l’altra. Una spiegazione intuitiva dell’operatore pipe è stata fornita un tweet di @andrewheiss. Consideriamo la seguente istruzione pseudo-codice R:Il listato precedente descrive una serie di (pseudo) funzioni concatenate, le quali costituiscono gli argomenti di altre funzioni. Scritto così, il codice è molto difficile da capire. Possiamo però ottenere lo stesso risultato utilizzando l’operatore pipe che facilita la leggibilità del codice:questa seconda versione del (pseudo) codice R si capisce molto meglio ciò che vogliamo fare. Il data.frame viene passato alla funzione wake_up(). La funzione wake_up() ha come argomento l’ora del giorno: time = \"8:00\". Una volta “svegliati” (wake ) dobbiamo scendere dal letto. Quindi l’output di wake_up() viene passato alla funzione get_out_of_bed() la quale ha come argomento side = \"correct\" perché vogliamo scendere dal letto dalla parte giusta. E così via.","code":"\nleave_house(get_dressed(get_out_of_bed(wake_up(me, time = \"8:00\"), side = \"correct\"), pants = TRUE, shirt = TRUE), car = TRUE, bike = FALSE)\nme %>% \n  wake_up(time = \"8:00\") %>% \n  get_out_of_bed(side = \"correct\") %>% \n  get_dressed(pants = TRUE, shirt = TRUE) %>% \n  leave_house(car = TRUE, bike = FALSE)"},{"path":"manipolazione-dei-dati.html","id":"selezionare-le-colonne-del-data.frame-con-select","chapter":"Capitolo 8 Manipolazione dei dati","heading":"8.2.2 Selezionare le colonne del data.frame con select()","text":"Ritorniamo ora ’esempio precedente e supponiamo di volere selezionare le variabili name, vore e sleep_total dal data.frame msleep. Per fare ciò usiamo funzione select() che consente di selezionare un sottoinsieme di variabili un dataset. Usando pipe scriviamo:laddove la sequenza di istruzioni precedenti significa che il data.frame dt è stato passato alla funzione select() contenuta nel pacchetto dplyr.","code":"\ndt <- msleep %>%\n  dplyr::select(name, vore, sleep_total)\ndt\n#> # A tibble: 83 x 3\n#>   name                       vore  sleep_total\n#>   <chr>                      <chr>       <dbl>\n#> 1 Cheetah                    carni        12.1\n#> 2 Owl monkey                 omni         17  \n#> 3 Mountain beaver            herbi        14.4\n#> 4 Greater short-tailed shrew omni         14.9\n#> 5 Cow                        herbi         4  \n#> 6 Three-toed sloth           herbi        14.4\n#> # … with 77 more rows"},{"path":"manipolazione-dei-dati.html","id":"filtrare-le-righe-del-data.frame-con-filter","chapter":"Capitolo 8 Manipolazione dei dati","heading":"8.2.3 Filtrare le righe del data.frame con filter()","text":"La funzione filter() consente di selezionare un sottoinsieme di\nosservazioni un dataset. Per esempio, possiamo selezionare tutte le\nosservazioni nella variabile vore contrassegnate come carni \nquesto modo (ovvero, tutti carnivori):","code":"\ndt %>%\n  dplyr::filter(vore == \"carni\")\n#> # A tibble: 19 x 3\n#>   name                 vore  sleep_total\n#>   <chr>                <chr>       <dbl>\n#> 1 Cheetah              carni        12.1\n#> 2 Northern fur seal    carni         8.7\n#> 3 Dog                  carni        10.1\n#> 4 Long-nosed armadillo carni        17.4\n#> 5 Domestic cat         carni        12.5\n#> 6 Pilot whale          carni         2.7\n#> # … with 13 more rows"},{"path":"manipolazione-dei-dati.html","id":"aggiungere-una-colonna-al-data.frame-con-mutate","chapter":"Capitolo 8 Manipolazione dei dati","heading":"8.2.4 Aggiungere una colonna al data.frame con mutate()","text":"Talvolta vogliamo creare una nuova variabile uno stesso dataset ad\nesempio sommando o dividendo due variabili, oppure calcolandone la\nmedia. questo scopo si usa la funzione mutate(). Per esempio, se\nvogliamo esprimere valori di sleep_total minuti, moltiplichiamo\nper 60:","code":"\ndt %>% \n  mutate(sleep_minutes = sleep_total * 60) %>%\n  dplyr::select(sleep_total, sleep_minutes)\n#> # A tibble: 83 x 2\n#>   sleep_total sleep_minutes\n#>         <dbl>         <dbl>\n#> 1        12.1           726\n#> 2        17            1020\n#> 3        14.4           864\n#> 4        14.9           894\n#> 5         4             240\n#> 6        14.4           864\n#> # … with 77 more rows"},{"path":"manipolazione-dei-dati.html","id":"ordinare-i-dati-con-arrange","chapter":"Capitolo 8 Manipolazione dei dati","heading":"8.2.5 Ordinare i dati con arrange()","text":"La funzione arrange() serve ordinare dati base ai valori di una\no più variabili. Per esempio, possiamo ordinare la variabile\nsleep_total dal valore più alto al più basso questo modo:","code":"\ndt %>% \n  arrange(desc(sleep_total))\n#> # A tibble: 83 x 3\n#>   name                   vore    sleep_total\n#>   <chr>                  <chr>         <dbl>\n#> 1 Little brown bat       insecti        19.9\n#> 2 Big brown bat          insecti        19.7\n#> 3 Thick-tailed opposum   carni          19.4\n#> 4 Giant armadillo        insecti        18.1\n#> 5 North American Opossum omni           18  \n#> 6 Long-nosed armadillo   carni          17.4\n#> # … with 77 more rows"},{"path":"manipolazione-dei-dati.html","id":"raggruppare-i-dati-con-group_by","chapter":"Capitolo 8 Manipolazione dei dati","heading":"8.2.6 Raggruppare i dati con group_by()","text":"La funzione group_by() serve raggruppare insieme valori base \nuna o più variabili. La vedremo uso seguito insieme \nsummarise().","code":""},{"path":"manipolazione-dei-dati.html","id":"sommario-dei-dati-con-summarise","chapter":"Capitolo 8 Manipolazione dei dati","heading":"8.2.7 Sommario dei dati con summarise()","text":"La funzione summarise() collassa il dataset una singola riga dove\nviene riportato il risultato della statistica richiesta. Per esempio, la\nmedia del tempo totale del sonno è","code":"\ndt %>% \n  summarise(\n  m_sleep = mean(sleep_total, na.rm = TRUE)\n  ) %>% \n  unlist()\n#>  m_sleep \n#> 10.43373"},{"path":"manipolazione-dei-dati.html","id":"operazioni-raggruppate","chapter":"Capitolo 8 Manipolazione dei dati","heading":"8.2.8 Operazioni raggruppate","text":"precedenza abbiamo visto come mammiferi considerati dormano, \nmedia, 10.4 ore al giorno. Troviamo ora il sonno medio funzione di\nvore:Si noti che, nel caso di 7 osservazioni, il valore di vore non era\nspecificato. Per tali osservazioni, dunque, la classe di appartenenza è\nNA.","code":"\ndt %>%\n  group_by(vore) %>%\n  summarise(\n    m_sleep = mean(sleep_total, na.rm = TRUE), \n    n = n()\n  )\n#> # A tibble: 5 x 3\n#>   vore    m_sleep     n\n#>   <chr>     <dbl> <int>\n#> 1 carni     10.4     19\n#> 2 herbi      9.51    32\n#> 3 insecti   14.9      5\n#> 4 omni      10.9     20\n#> 5 <NA>      10.2      7"},{"path":"manipolazione-dei-dati.html","id":"dati-categoriali-in-r","chapter":"Capitolo 8 Manipolazione dei dati","heading":"8.3 Dati categoriali in R","text":"Consideriamo una variabile che descrive il genere e include le categorie male, female e non-conforming. R, ci sono due modi per memorizzare queste informazioni. Uno è usare la classe character strings e l’altro è usare la classe factor. Non ci addentrimo qui nelle sottigliezze di questa distinzione, motivata gran parte per le necessità della programmazione con le funzioni di tidyverse. Per gli scopi di questo insegnamento sarà sufficiente codificare le variabili qualitative usando la classe factor. Una volta codificati dati qualitativi utilizzando la classe factor, si pongono spesso due problemi:modificare le etichette dei livelli (modalità) di un fattore,riordinare livelli di un fattore.","code":""},{"path":"manipolazione-dei-dati.html","id":"modificare-le-etichette-dei-livelli-di-un-fattore","chapter":"Capitolo 8 Manipolazione dei dati","heading":"8.3.1 Modificare le etichette dei livelli di un fattore","text":"Esaminiamo l’esempio seguente.Supponiamo di volere che livelli del fattore f_1 abbiano le etichette new_1, new_2, ecc. Per ottenere questo risultato usiamo la funzione recode() di dplyr:","code":"\nf_1 <- c(\"old_3\", \"old_4\", \"old_1\", \"old_1\", \"old_2\")\nf_1 <- factor(f_1)\ny <- 1:5\ndf <- data.frame(f_1, y)\ndf\n#>     f_1 y\n#> 1 old_3 1\n#> 2 old_4 2\n#> 3 old_1 3\n#> 4 old_1 4\n#> 5 old_2 5\ndf <- df %>%\n  mutate(f_1 =\n    dplyr::recode(f_1,\n      \"old_1\" = \"new_poco\",\n      \"old_2\" = \"new_medio\",\n      \"old_3\" = \"new_tanto\",\n      \"old_4\" = \"new_massimo\",\n     )\n   )\ndf\n#>           f_1 y\n#> 1   new_tanto 1\n#> 2 new_massimo 2\n#> 3    new_poco 3\n#> 4    new_poco 4\n#> 5   new_medio 5"},{"path":"manipolazione-dei-dati.html","id":"riordinare-i-livelli-di-un-fattore","chapter":"Capitolo 8 Manipolazione dei dati","heading":"8.3.2 Riordinare i livelli di un fattore","text":"Spesso livelli dei fattori hanno un ordinamento naturale. Tuttavia, l’impostazione predefinita base R è ordinare livelli ordine alfabetico. Quindi, gli utenti devono avere un modo per imporre l’ordine desiderato sulla codifica delle loro variabili qualitative. Ciò può essere ottenuto nel modo seguente.Per approfondire le problematiche della manipolazione di variabili qualitative R, si veda (mcnamara2018wrangling?).","code":"\ndf$f_1 <- factor(df$f_1,\n  levels = c(\n    \"new_poco\", \"new_medio\", \"new_tanto\", \"new_massimo\"\n  )\n)\nsummary(df$f_1)\n#>    new_poco   new_medio   new_tanto new_massimo \n#>           2           1           1           1"},{"path":"manipolazione-dei-dati.html","id":"creare-grafici-con-ggplot2","chapter":"Capitolo 8 Manipolazione dei dati","heading":"8.4 Creare grafici con ggplot2()","text":"Il pacchetto ggplot2() è un potente strumento per rappresentare graficamente dati. Le iniziali del nome, gg, si riferiscono alla “Grammar Graphics,” che è un modo di pensare le figure come una serie di layer stratificati. Originariamente descritta da (wilkinson2012grammar?), la grammatica dei grafici è stata aggiornata e applicata R da Hadley Wickham, il creatore del pacchetto.La funzione da cui si parte per inizializzare un grafico è ggplot(). La funzione ggplot() richiede due argomenti. Il primo è l’oggetto di tipo data.frame che contiene dati da visualizzare – alternativa al primo argomento, un dataframe può essere passato ggplot() mediante l’operatore pipe. Il secondo è una particolare lista che viene generata dalla funzione aes(), la quale determina l’aspetto (aesthetic) del grafico. La funzione aes() richiede necessariamente di specificare “x” e “y,” ovvero nomi delle colonne del data.frame che è stato utilizzato quale primo argomento di ggplot() (o che è stato passato da pipe), le quali rappresentano le variabili da porre rispettivamente sugli assi orizzontale e verticale.La definizione della tipologia di grafico e vari parametri sono poi definiti successivamente, aggiungendo ’oggetto creato da ggplot() tutte le componenti necessarie. Saranno quindi altre funzioni, come geom_bar(), geom_line() o geom_point() occuparsi di aggiungere al livello di base barre, linee, punti, e così via. Infine, tramite altre funzioni, ad esempio labs(), sarà possibile definire dettagli più fini.Gli elementi grafici (bare, punti, segmenti, …) usati da ggplot2 sono chiamati geoms. Mediante queste funzioni è possibile costruire diverse tipologie di grafici:geom_bar(): crea un layer con delle barre;geom_bar(): crea un layer con delle barre;geom_point(): crea un layer con dei punti (diagramma dispersione);geom_point(): crea un layer con dei punti (diagramma dispersione);geom_line(): crea un layer con una linea retta;geom_line(): crea un layer con una linea retta;geom_histogram(): crea un layer con un istogramma;geom_histogram(): crea un layer con un istogramma;geom_boxplot(): crea un layer con un box-plot;geom_boxplot(): crea un layer con un box-plot;geom_errorbar(): crea un layer con barre che rappresentano intervalli di confidenza;geom_errorbar(): crea un layer con barre che rappresentano intervalli di confidenza;geom_hline() e geom_vline() : crea un layer con una linea orizzontale o verticale definita dall’utente.geom_hline() e geom_vline() : crea un layer con una linea orizzontale o verticale definita dall’utente.Un comando generico ha la seguente forma:La prima volta che si usa il pacchetto ggplot2 è necessario installarlo. Per fare questo possiamo installare tidyverse che, oltre caricare ggplot2, carica anche altre utili funzioni per l’analisi dei dati:Per attivare il pacchetto si usa l’istruzione:Ogni volta che si inizia una sessione R è necessario attivare pacchetti che si vogliono usare, ma non è necessario istallarli una nuova volta. Se è necessario specificare il pacchetto nel quale è contenuta la funzione (o il data.frame) che vogliamo utilizzare, usiamo la sintassi package::function(). Per esempio, l’istruzione ggplot2::ggplot() rende esplicito che stiamo usando la funzione ggplot() contenuta nel pacchetto ggplot2.","code":"\nmy_graph <- my_data %>% \n  ggplot(aes(x_var, y_var)) +\n  geom_...()\ninstall.packages(\"tidyverse\")\nlibrary(\"tidyverse\")"},{"path":"manipolazione-dei-dati.html","id":"diagramma-a-dispersione","chapter":"Capitolo 8 Manipolazione dei dati","heading":"8.4.1 Diagramma a dispersione","text":"Consideriamo nuovamenti dati contenuti nel data frame msleep e poniamoci il problema di rappresentare graficamente la relazione tra il numero medio di ore di sonno giornaliero (sleep_total) e il peso dell’animale (bodywt). Usando le impostazioni di default di ggplot2, con le istruzioni seguenti, otteniamo il grafico fornito dalla figura seguente.Coloriamo ora maniera diversa punti che rappresentano animali carnivori, erbivori, ecc.È chiaro, senza fare alcuna analisi statistica, che la relazione tra le due variabili non è lineare. Trasformando maniera logaritmica valori dell’asse \\(x\\) la relazione si linearizza.Infine, aggiustiamo il “tema” del grafico, aggiungiamo le etichette sugli assi e il titolo.","code":"\ndata(msleep)\np <- msleep %>% \n  ggplot(\n    aes(x = bodywt, y = sleep_total)\n  ) +\n  geom_point()\nprint(p)\np <- msleep %>% \n  ggplot(\n    aes(x = bodywt, y = sleep_total, col = vore)\n  ) +\n  geom_point()\nprint(p)\np <- msleep %>% \n  ggplot(\n    aes(x = log(bodywt), y = sleep_total, col = vore)\n  ) +\n  geom_point()\nprint(p)\nmsleep %>% \n  ggplot(\n    aes(x = log(bodywt), y = sleep_total, col = vore)\n  ) +\n  geom_point(size = 2) +\n    theme(legend.title = element_blank()) +\n    labs(\n      x = \"Log Peso Corporeo\",\n      y = \"Totale Ore di Sonno\",\n      title = \"Il sonno in 83 specie di mammiferi\",\n      subtitle = \"Savage e West (2007)\"\n     )"},{"path":"manipolazione-dei-dati.html","id":"istogramma","chapter":"Capitolo 8 Manipolazione dei dati","heading":"8.4.2 Istogramma","text":"Creiamo ora un istogramma che rappresenta la distribuzione del (logaritmo del) peso medio del cervello delle 83 specie di mammiferi considerate da (savage2007quantitative?).L’argomento aes(y=..density..) geom_histogram() produce le frequenze relative. L’opzione di default (senza questo argomento) porta ggplot() rappresentare le frequenze assolute.","code":"\nmsleep %>% \n  ggplot(\n    aes(log(brainwt))\n  ) +\n  geom_histogram(aes(y = ..density..)) +\n  labs(\n    x = \"Log Peso Cervello\",\n    y = \"Frequenza Relativa\"\n  ) +\n  theme(legend.title = element_blank())\n#> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n#> Warning: Removed 27 rows containing non-finite values (stat_bin)."},{"path":"manipolazione-dei-dati.html","id":"scrivere-il-codice-in-r-con-stile","chapter":"Capitolo 8 Manipolazione dei dati","heading":"8.4.3 Scrivere il codice in R con stile","text":"Uno stile di programmazione è un insieme di regole per la gestione dell’indentazione dei blocchi di codice, per la creazione dei nomi dei file e delle variabili e per le convenzioni tipografiche che vengono usate. Scrivere il codice R con stile consente di creare listati più leggibili e semplici da modificare, minimizza la possibilità di errore, e consente correzioni e modifiche più rapide. Vi sono molteplici stili di programmazione che possono essere utilizzati dall’utente, anche se è bene attenersi quelle che sono le convenzioni maggiormente diffuse, allo scopo di favorire la comunicazione. ogni caso, l’importante è di essere coerenti, ovvero di adottare le stesse convenzioni tutte le parti del codice che si scrive. Ad esempio, se si sceglie di usare lo stile snake_case per il nome composto di una variabile (es., personality_trait), non è appropriato usare lo stile lower Camel case per un’altra variabile (es., socialStatus). Dato che questo argomento è stato trattato ampiamente varie sedi, mi limito qui rimandare ad uno stile di programmazione molto popolare, quello proposto da Hadley Wickham, il creatore di tidyverse. Potete trovare maggiori informazioni al seguente link: http://style.tidyverse.org/.","code":""},{"path":"flusso-di-lavoro-riproducibile.html","id":"flusso-di-lavoro-riproducibile","chapter":"Capitolo 9 Flusso di lavoro riproducibile","heading":"Capitolo 9 Flusso di lavoro riproducibile","text":"","code":""},{"path":"flusso-di-lavoro-riproducibile.html","id":"la-crisi-della-riproducibilità","chapter":"Capitolo 9 Flusso di lavoro riproducibile","heading":"9.1 La crisi della riproducibilità","text":"Per il metodo scientifico è essenziale che gli esperimenti siano riproducibili. Vale dire che una persona diversa dallo sperimentatore originale deve essere grado di ottenere gli stessi risultati seguendo lo stesso protocollo sperimentale. (Gilbert Chin)Ma psicologia (e non solo) la riproducibilità è inferiore quanto previsto o desiderato. un famoso studio pubblicato su “Science” un ampio gruppo di ricercatori (Open Science Collaboration others, 2015) è riuscito replicare solo il 40 per cento circa dei risultati di 100 studi di psicologia cognitiva e sociale pubblicati precedenza. risultati di questo studio, e di molti altri pubblicati seguito, sono stati interpretati modi diversi. La preoccupazione sulla riproducibilità della ricerca è stata espressa mediante l’affermare secondo la quale “la maggior parte dei risultati della ricerca sono falsi” (Ioannidis, 2005) oppure mediante l’affermazione secondo cui “dobbiamo apportare modifiche sostanziali al modo cui conduciamo la ricerca” (Cumming, 2014). Alcuni ricercatori sono arrivati definire la presente situazione come una “crisi della riproducibilità dei risultati della ricerca.”Il termine “riproducibilità” (o “replicabilità”) è stato definito vari modi. Consideriamo la definizione fornita da Goodman et al. (2016):la riproducibilità dei metodi “si riferisce al fatto che il ricercatore fornisce dettagli sufficienti sulle procedure e sui dati dello studio modo che le stesse procedure possano … essere replicate esattamente” (pag. 2) con gli stessi dati;la riproducibilità dei metodi “si riferisce al fatto che il ricercatore fornisce dettagli sufficienti sulle procedure e sui dati dello studio modo che le stesse procedure possano … essere replicate esattamente” (pag. 2) con gli stessi dati;la riproducibilità dei risultati “si riferisce ’ottenimento degli stessi risultati dalla conduzione di uno studio indipendente le cui procedure replicano il più esattamente possibile quelle dell’esperimento originale” (pag. 2-3) con dati indipendenti;la riproducibilità dei risultati “si riferisce ’ottenimento degli stessi risultati dalla conduzione di uno studio indipendente le cui procedure replicano il più esattamente possibile quelle dell’esperimento originale” (pag. 2-3) con dati indipendenti;la riproducibilità inferenziale “si riferisce alla possibilità di trarre conclusioni qualitativamente simili da una replica indipendente di uno studio o da una nuova analisi dello studio originale” (pag. 4).la riproducibilità inferenziale “si riferisce alla possibilità di trarre conclusioni qualitativamente simili da una replica indipendente di uno studio o da una nuova analisi dello studio originale” (pag. 4).Per gli scopi presenti, ci focalizzeremo qui sulla riproducibilità dei metodi. Cioè, discuteremo di come R può aiutarci migliorare questo aspetto della riproducibilità. questo capitolo mostreremo come R possa essere utilizzato ’interno di un flusso di lavoro (workflow) riproducibile che integra (1) il codice di analisi dei dati, (2) dati medesimi e (3) il testo della relazione che comunica risultati dello studio. tal fine utilizzeremo due pacchetti R: rmarkdown e knitr. Questi pacchetti consentono di unire il codice R ad un linguaggio di marcatura (o di markup) chiamato Markdown. Il linguaggio di markup Markdown sta diventando sempre più popolare e viene usato, oltre che per creare reports di analisi di dati, anche per creare siti web, blog, libri, articoli accademici, curriculum vitae, slide, tesi di laurea. Per esempio, il presente sito web è stato scritto usando R-markdown.","code":""},{"path":"flusso-di-lavoro-riproducibile.html","id":"r-markdown","chapter":"Capitolo 9 Flusso di lavoro riproducibile","heading":"9.2 R-markdown","text":"Un linguaggio di markup permette di aggiungere mediante marcatori (tag) informazioni sulla struttura e sulla formattazione da applicare ad un documento. Un’introduzione al linguaggio Markdown può essere trovata, per esempio, qui oppure qui.questo capitolo ci focalizzeremo però sugli aspetti più importanti di R-markdown che permette di costruire documenti cui combinare testo formattato (quindi non solo commenti ma anche formule, titoli etc) e istruzioni codice (R e non solo) con corrispettivi output. Informazioni dettagliate su R-markdown sono disponibili qui e qui.Un file R-markdown è composto da tre tipi di oggetti:header formato YAML delimitato da ---,testo formato markdown,blocchi (“chunks”) di codice R, delimitati da ```.","code":""},{"path":"flusso-di-lavoro-riproducibile.html","id":"header","chapter":"Capitolo 9 Flusso di lavoro riproducibile","heading":"9.2.1 Header","text":"L’intestazione di un documento .Rmd (R-markdown) corrisponde al cosiddetto YAML header (un acronimo che significa Yet Another Markup Language). Lo YAML header controlla le caratteristiche generali del documento, incluso il tipo di documento che viene prodotto (un documento HTML che può essere visualizzato su tutti principali browser, un documento Microsoft Word o un PDF se abbiamo installato \\(\\LaTeX\\) sul nostro computer), la dimensione del carattere, lo stile, il titolo, l’autore, ecc.Nello YAML header (differenza del codice R) è necessario rispettare la spaziatura prestabilita delle istruzioni che vengono elencate. Gli elementi principali sono questi:L’argomento output è dove diciamo R-markdown quale tipo di file vogliamo che venga prodotto. Il tipo più flessibile, che non richiede alcuna configurazione, è html_document.","code":"---\ntitle: \"Il titolo\"\nauthor: \"Tu, l'autore\"\noutput: html_document\n---"},{"path":"flusso-di-lavoro-riproducibile.html","id":"testo","chapter":"Capitolo 9 Flusso di lavoro riproducibile","heading":"9.2.2 Testo","text":"Alla conclusione dello YAML header inizia il documento R-markdown. Da questo punto poi possiamo utilizzare testo normale, codice R e sintassi Markdown per controllare cosa viene mostrato e come.","code":""},{"path":"flusso-di-lavoro-riproducibile.html","id":"formattazione","chapter":"Capitolo 9 Flusso di lavoro riproducibile","heading":"Formattazione","text":"È possibile contrassegnare intestazioni, grassetto e corsivo come indicato di seguito.","code":"# Intestazione 1\n## Intestazione 2\n### Intestazione 3\n#### Intestazione 4\n##### Intestazione 5\n###### Intestazione 6\n\nQuesto è un testo normale.\nPossiamo scrivere in **grassetto** il testo usando due asterischi.\nPossiamo scrivere in *corsivo* usando un asterisco.\n\n>Questa è un’**area rientrata**.\n\nQuesta riga invece non è più rientrata."},{"path":"flusso-di-lavoro-riproducibile.html","id":"elenchi","chapter":"Capitolo 9 Flusso di lavoro riproducibile","heading":"Elenchi","text":"Per creare un elenco puntato si utilizza il segno più, il trattino o l’asterisco. Tutte le tre soluzioni portano allo stesso risultato.Un elenco numerato, invece, si crea con un numero seguito da un punto.","code":"- Punto 1 della lista\n- Punto 2 della lista\n- Punto 3 della lista1. Punto 1 della lista\n2. Punto 2 della lista\n3. Punto 3 della lista"},{"path":"flusso-di-lavoro-riproducibile.html","id":"hyperlink","chapter":"Capitolo 9 Flusso di lavoro riproducibile","heading":"Hyperlink","text":"Per inserire un hyperlink ci sono due metodi:specificare solo il percorso <http://rmarkdown.rstudio.com>, http://rmarkdown.rstudio.comcreare un link con [link](http://rmarkdown.rstudio.com)","code":""},{"path":"flusso-di-lavoro-riproducibile.html","id":"immagini","chapter":"Capitolo 9 Flusso di lavoro riproducibile","heading":"Immagini","text":"Per inserire un’immagine la sintassi è molto simile: ![Esempio di immagine inserita un documento R-markdown.](images/hex-rmarkdown.png){width=20%}:Esempio di immagine inserita un documento R-markdown.","code":""},{"path":"flusso-di-lavoro-riproducibile.html","id":"codice-inline","chapter":"Capitolo 9 Flusso di lavoro riproducibile","heading":"Codice inline","text":"Per contrassegnare un’area di testo come codice, markdown utilizza il cosiddetto backtick, noto anche come gravis o accento grave, da non confondere con la virgoletta singola. La marcatura prevede un accento ’inizio e uno alla fine dell’area di testo corrispondente.","code":"Questo è `codice`."},{"path":"flusso-di-lavoro-riproducibile.html","id":"equazioni","chapter":"Capitolo 9 Flusso di lavoro riproducibile","heading":"Equazioni","text":"Equazioni possono essere inserite un documento R-markdown usando la sintassi \\(\\LaTeX\\). Qualsiasi cosa ’interno del segno di dollaro $ viene trattata come un’equazione “inline.” Qualunque cosa ’interno di due segni di dollaro $$ viene trattata come un’equazione sé stante.Per esempio, questa è la formula della distribuzione Normale espressa notazione \\(\\LaTeX\\) e riprodotta ’interno di un documento R-markdown:\\[\nf(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \n  \\exp\\left( -\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^{\\!2}\\,\\right)\n\\]","code":"$$\nf(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \n  \\exp\\left( -\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^{\\!2}\\,\\right)\n$$"},{"path":"flusso-di-lavoro-riproducibile.html","id":"codice-r","chapter":"Capitolo 9 Flusso di lavoro riproducibile","heading":"9.2.3 Codice R","text":"un documento R-markdown istruzioni di codice vengono inserite blocchi delimitati da tre apici ```. Un generico blocco di codice (“chunk”) ha la seguente forma:Ciò consente di valutare il codice ’interno del documento e di produrre un output che verrà stampato nel documento stesso. Possiamo dunque stampare tabelle e figure prodotti direttamente dal codice R. Ciò significa inoltre, che se qualcosa cambia nei dati o nelle analisi dei dati, le tabelle e le figure si aggiorneranno automaticamente.Un chunk R viene valutato proprio come il normale codice R, quindi si applica tutto ciò che abbiamo imparato nei capitoli precedenti. Se il chunk R produce un output, questo output verrà visualizzato nel documento.","code":"```{r}\n## il codice R va qui\n```"},{"path":"flusso-di-lavoro-riproducibile.html","id":"compilare-la-presentazione-r-markdown","chapter":"Capitolo 9 Flusso di lavoro riproducibile","heading":"9.3 Compilare la presentazione R-markdown","text":"Ma dove si trova questo magico documento che include il testo e l’output prodotto dal codice R? Ottima domanda. Siamo stati abituati ai programmi di videoscrittura (come Microsoft Word) che si conformano al cosiddetto stile “WYSIWYG” (See Get) – cioè, si vede come apparirà il documento stampato mentre lo si digita. Questo può avere alcuni vantaggi ma può anche essere molto limitante. R-Markdown, d’altra parte, funziona modo diverso. Ovvero, deve essere “compilato” (knitted) per passare dal file sorgente al documento formattato. RStudio, tale operazione è semplice: c’è un pulsante alto sinistra nel pannello di scripting di un documento .Rmd. È sufficiente selezionare tale pulsante e il nostro documento verrà creato.","code":""},{"path":"flusso-di-lavoro-riproducibile.html","id":"importante","chapter":"Capitolo 9 Flusso di lavoro riproducibile","heading":"Importante","text":"Il codice del documento deve essere completamente autonomo. Ciò significa che tutto ciò che volete che venga eseguito deve essere nel documento, indipendentemente da ciò che è stato già eseguito al di fuori di esso. Ad esempio, è perfettamente legittimo (e anche molto utile) testare il codice R al di fuori del documento Rmd. Tuttavia, quando compiliamo il documento Rmd, tutto ciò che è stato fatto al di fuori del documento Rmd viene dimenticato. Ciò consente di creare un documento autosufficiente che favorisce la riproducibilità dei metodi di analisi dei dati: utilizzando uno specifico documento Rmd con un campione di dati si giunge sempre allo stesso risultato e alla stessa interpretazione. Ciò non è invece vero se si utilizza un software con un interfaccia point--click.","code":""},{"path":"introduzione-1.html","id":"introduzione-1","chapter":"Introduzione","heading":"Introduzione","text":"Le analisi esplorative dei dati e la statistica descrittiva costituiscono la prima fase dell’analisi dei dati psicologici. Ci consentono di capire come dati sono distribuiti. Inoltre, ci aiutano ad individuare outliers ed errori di tabulazione. Sono anche molto utili per studiare le relazioni tra le variabili. Insomma, sono indispensabili per condurre una qualsiasi analisi statistica, dal livello base quello avanzato, modo corretto.Si parla di analisi descrittiva se l’obiettivo è quello di descrivere le caratteristiche di un campione.\nSi parla di analisi esplorativa dei dati (Exploratory Data Analysis o EDA) se l’obiettivo è quello di esplorare dati alla ricerca di nuove informazioni e relazioni tra variabili.\nQuesta distinzione, seppur importante livello teorico, nella pratica è più fumosa perché spesso entrambe le situazioni si verificano contemporaneamente nella stessa indagine statistica e le metodologie di analisi che si utilizzano sono molto simili.Né il calcolo delle statistiche descrittive né l’analisi esplorativa dei dati possono essere condotte senza utilizzare un software. Le descrizioni dei concetti di base della EDA saranno dunque fornite di pari passo alla spiegazione di come le quantità discusse possono essere calcolate pratica utilizzando R.questo breve capitolo introdurremo la terminologia che verrà usata seguito. particolare, verrà chiarito il significato di “variabile statistica” e verrà introdotto il concetto di “matrice dei dati,” ovvero, verrà descritto quell’oggetto statistico che consente di immagazzinare e organizzare le informazioni che sono state raccolte un’indagine psicologica.","code":""},{"path":"terminologia.html","id":"terminologia","chapter":"Capitolo 10 Terminologia","heading":"Capitolo 10 Terminologia","text":"","code":""},{"path":"terminologia.html","id":"metodi-e-procedure-della-psicologia","chapter":"Capitolo 10 Terminologia","heading":"10.1 Metodi e procedure della psicologia","text":"Una teoria psicologica di un qualche aspetto del comportamento umano (o della mente) ha le seguenti proprietà:descrive le caratteristiche del comportamento questione,formula predizioni sulle caratteristiche future del comportamento,è sostenuta da evidenze empiriche,deve essere falsificabile (ovvero, linea di principio, deve\npotere fare delle predizioni su aspetti del fenomeno considerato che\nnon sono ancora noti e che, se venissero indagati, potrebbero\nportare rigettare la teoria, se si dimostrassero incompatibili con\nessa).L’analisi dei dati consente di valutare una teoria psicologica utilizzando seguenti strumenti statistici:la misurazione,l’analisi descrittiva,l’inferenza.Prima di affrontare il primo dei tre ambiti elencati sopra, ovvero quello della misurazione, prenderemo qui esame la terminologia che verrà utilizzata.","code":""},{"path":"terminologia.html","id":"variabili-e-costanti","chapter":"Capitolo 10 Terminologia","heading":"10.2 Variabili e costanti","text":"L’analisi dei dati inizia con l’individuazione delle unità portatrici di\ninformazioni circa il fenomeno di interesse. Si dice popolazione (o\nuniverso) l’insieme \\(\\Omega\\) delle entità capaci di fornire\ninformazioni sul fenomeno oggetto dell’indagine statistica. Possiamo\ndunque scrivere\n\\(\\Omega = \\{\\omega_i\\}_{=1, \\dots, n}= \\{\\omega_1, \\omega_2, \\dots, \\omega_n\\}\\)\noppure \\(\\Omega = \\{\\omega_1, \\omega_2, \\dots \\}\\) nel caso di\npopolazioni finite o infinite, rispettivamente. Gli elementi \\(\\omega_i\\)\ndell’insieme \\(\\Omega\\) sono detti unità statistiche. Un sottoinsieme\ndella popolazione viene chiamato campione. Ciascuna unità statistica\n\\(\\omega_i\\) (abbreviata con u.s.) è portatrice dell’informazione che\nverrà rilevata mediante un’operazione di misurazione.Definiamo variabile statistica la proprietà (o grandezza) che è\noggetto di studio nell’analisi dei dati. Una variabile è una proprietà\ndi un fenomeno che può essere espressa più valori sia numerici sia\ncategoriali. Il termine “variabile” si contrappone al termine “costante”\nche descrive una proprietà invariante di tutte le unità statistiche.Si dice modalità ciascuna delle varianti con cui una variabile\nstatistica può presentarsi. Definiamo insieme delle modalità di una\nvariabile statistica l’insieme \\(M\\) di tutte le possibili espressioni con\ncui la variabile può manifestarsi. Le modalità osservate e facenti parte\ndel campione si chiamano dati (si veda la\nTabella 1.1).Proprietà oggetto di studio, variabile e modalità.","code":""},{"path":"terminologia.html","id":"variabili-indipendenti-e-variabili-dipendenti","chapter":"Capitolo 10 Terminologia","heading":"10.3 Variabili indipendenti e variabili dipendenti","text":"Un primo compito fondamentale qualsiasi analisi statistica è l’identificazione delle variabili dipendenti (\\(Y\\)) e delle variabili indipendenti (\\(X\\)). Le variabili dipendenti sono anche chiamate variabili di esito o di risposta e le variabili indipendenti sono anche chiamate predittori o covariate. Ad esempio, nell’analisi di regressione, che esamineremo seguito, la domanda centrale è quella di capire come \\(Y\\) cambia al variare di \\(X\\). Più precisamente, la domanda che viene posta è: se il valore della variabile indipendente \\(X\\) cambia, qual è la conseguenza per la variabile dipendente \\(Y\\)? parole povere, le variabili indipendenti e dipendenti sono analoghe “cause” ed “effetti,” laddove le virgolette usate qui sottolineano che questa è solo un’analogia e che la determinazione delle cause può avvenire soltanto mediante l’utilizzo di un appropriato disegno sperimentale e di un’adeguata analisi statistica.Se una variabile è una variabile indipendente o dipendente dipende dalla domanda di ricerca. volte può essere difficile decidere quale variabile è dipendente e quale è indipendente, particolare quando siamo specificamente interessati ai rapporti di causa/effetto. Ad esempio, supponiamo di indagare l’associazione tra esercizio fisico e insonnia. Vi sono evidenze che l’esercizio fisico (fatto al momento giusto della giornata) può ridurre l’insonnia. Ma l’insonnia può anche ridurre la capacità di una persona di fare esercizio fisico. questo caso, dunque, non è facile capire quale sia la causa e quale l’effetto, quale sia la variabile dipendente e quale la variabile indipendente. La possibilità di identificare il ruolo delle variabili (dipendente/indipendente) dipende dalla nostra comprensione del fenomeno esame.","code":""},{"path":"terminologia.html","id":"la-matrice-dei-dati","chapter":"Capitolo 10 Terminologia","heading":"10.4 La matrice dei dati","text":"Le realizzazioni delle variabili esaminate una rilevazione statistica\nvengono organizzate una matrice dei dati. Le colonne della matrice\ndei dati contengono gli insiemi dei dati individuali di ciascuna\nvariabile statistica considerata. Ogni riga della matrice contiene tutte\nle informazioni relative alla stessa unità statistica. Una generica\nmatrice dei dati ha l’aspetto seguente: \\[D_{m,n} = \n \\begin{pmatrix}\n  \\omega_1 & a_{1}   & b_{1}   & \\cdots & x_{1} & y_{1}\\\\\n  \\omega_2 & a_{2}   & b_{2}   & \\cdots & x_{2} & y_{2}\\\\\n  \\vdots   & \\vdots  & \\vdots  & \\ddots & \\vdots & \\vdots  \\\\\n \\omega_n  & a_{n}   & b_{n}   & \\cdots & x_{n} & y_{n}\n \\end{pmatrix}\\] dove, nel caso presente, la prima colonna contiene il\nnome delle unità statistiche, la seconda e la terza colonna si\nriferiscono due mutabili statistiche (variabili categoriali; \\(\\) e\n\\(B\\)) e ne presentano le modalità osservate nel campione mentre le ultime\ndue colonne si riferiscono due variabili statistiche (\\(X\\) e \\(Y\\)) e ne\npresentano le modalità osservate nel campione. Generalmente, tra le\nunità statistiche \\(\\omega_i\\) non esiste un ordine progressivo; l’indice\nattribuito alle unità statistiche nella matrice dei dati si riferisce\nsemplicemente alla riga che esse occupano.","code":""},{"path":"chapter-misurazione.html","id":"chapter-misurazione","chapter":"Capitolo 11 La misurazione in psicologia","heading":"Capitolo 11 La misurazione in psicologia","text":"Introduco il problema della misurazione psicologia parlando dell’intelligenza. quanto psicologi, siamo abituati pensare alla misurazione dell’intelligenza, ma anche le persone che non sono psicologi sono ben familiari con la misurazione dell’intelligenza: tra le misurazioni delle caratteristiche psicologiche, infatti, la misurazione dell’intelligenza è forse la più conosciuta.test di intelligenza consistono una serie di problemi di carattere verbale, numerico o simbolico. Come ci si può aspettare, alcune persone riescono risolvere correttamente un numero maggiore di problemi di altre. Possiamo contare il numero di risposte corrette e osservare le differenze individuali nei punteggi calcolati. Scopriamo questo modo che le differenze individuali nell’abilità di risolvere tali problemi risultano sorprendentemente stabili nell’età adulta. Inoltre, diversi test di intelligenza tendono ad essere correlati positivamente: le persone che risolvono un maggior numero di problemi verbali, media, tenderanno anche risolvere correttamente un numero più grande di numerici e simbolici. Esiste quindi una notevole coerenza delle differenze osservate tra le persone, sia nel tempo sia considerando diverse procedure di test e valutazione.Avendo stabilito che ci sono differenze individuali tra le persone, è possibile esaminare le associazioni tra punteggi dei test di intelligenza e altre variabili. Possiamo indagare se le persone con punteggi più alti nei test di intelligenza, rispetto persone che ottengono punteggi più bassi, hanno più successo sul lavoro; se guadagnano di più; se votano modo diverso; o se hanno un’aspettativa di vita più alta. Possiamo esaminare le differenze nei punteggi dei test di intelligenza funzione di variabili come il genere, il gruppo etnico-razziale o lo stato socio-economico. Possiamo fare ricerche sull’associazione tra punteggi dei test di intelligenza e l’efficienza dell’elaborazione neuronale, tempi di reazione o la quantità di materia grigia ’interno della scatola cranica. Tutte queste ricerche sono state condotte e gli psicologi hanno scoperto una vasta gamma di associazioni tra le misure dell’intelligenza e altre variabili. Alcune di queste associazioni sono grandi e stabili, altre sono piccole e difficili da replicare. riferimento ’intelligenza, dunque, gli psicologi hanno condotto un enorme numero di ricerche ponendosi domande diverse. quali condizioni si verificano determinati effetti? Quali variabili mediano o moderano le relazioni tra punteggi dei test di intelligenza e altre variabili? Queste relazioni si mantengono stabili diversi gruppi di persone? Le ricerche sull’intelligenza umana sono un campo continuo sviluppo.Tuttavia, tuttavia una domanda sorge spontanea: test di intelligenza misurano davvero qualcosa e, caso affermativo, che cos’è questo qualcosa? Infatti, dopo un secolo di teoria e ricerca sui punteggi dei test di intelligenza e, generale, sui test psicologici, non sappiamo ancora con precisione cosa effettivamente questi test misurano.\nQueste considerazioni relative ai test di intelligenza ci conducono dunque alla domanda che ha motivato le precedenti considerazioni: cosa significa misurare un attributo psicologico? Questa è una domanda cui è difficile rispondere, una domanda cui è dedicata un’intera area di ricerca, quella della teoria della misurazione psicologica.Non possiamo qui entrare nel merito delle complessità formali della teoria della misurazione psicologica – questo argomento verrà approfondito nei successivi insegnamenti sulla testistica psicologica. Ci limiteremo invece presentare alcune nozioni di base su un tema centrale della teoria della misurazione psicologica: il tema delle scale delle misure psicologiche.","code":""},{"path":"chapter-misurazione.html","id":"le-scale-di-misura","chapter":"Capitolo 11 La misurazione in psicologia","heading":"11.1 Le scale di misura","text":"generale possiamo dire che la teoria della misurazione si occupa dello studio delle relazioni esistenti tra due domini: il “mondo fisico” e il “mondo psicologico.” Secondo la teoria della misurazione, la misurazione è un’attività rappresentativa, cioè è un processo di assegnazione di numeri modo tale da preservare, ’interno del dominio numerico, le relazioni qualitative che sono state osservate nel mondo empirico. La teoria della misurazione ha lo scopo di specificare le condizioni necessarie per la costruzione di una rappresentazione adeguata delle relazioni empiriche ’interno di un sistema numerico. Da una prospettiva formale, le operazioni descritte dalla teoria della misurazione possono essere concettualizzate termini di mappatura tra le relazioni esistenti ’interno di due insiemi (quello empirico e quello numerico). Il risultato di questa attività è chiamato “scala di misurazione.”Una famosa teoria delle scale di misura è stata proposta da Stevens (1946). Stevens ci fa notare che, linea di principio, le variabili psicologiche sono grado di rappresentare (preservare) con diversi gradi di accuratezza le relazioni qualitative che sono state osservate nei fenomeni psicologici. Secondo la teoria di Stevens, possiamo distinguere tra quattro scale di misura: le scale nominali (nominal scales), ordinali (ordinal scales), intervalli (interval scales), di rapporti (ratio scales). Tali scale di misura consentono operazioni aritmetiche diverse, come indicato nella tabella successiva, quanto ciasuna di esse è grado di “catturare” soltanto alcune delle proprietà dei fenomeni psicologici che intende misurare.","code":""},{"path":"chapter-misurazione.html","id":"scala-nominale","chapter":"Capitolo 11 La misurazione in psicologia","heading":"11.1.1 Scala nominale","text":"Il livello di misurazione più semplice è quello della scala nominale. Questa scala di misurazione corrisponde ad una tassonomia. simoboli o numeri che costituiscono questa scala non sono altro che nomi delle categorie che utilizziamo per classificare fenomeni psicologici. base alle misure fornite da una scala nominale, l’unica cosa che siamo grado di dire proposito di una caratteristica psicologica è se essa è uguale o ad un’altra caratteristica psicologica.La scala nominale raggruppa dunque dati categorie qualitative mutuamente esclusive (cioè nessun dato si può collocare più di una categoria).\nEsiste la sola relazione di equivalenza tra le misure delle u.s., cioè\nnella scala nominale gli elementi del campione appartenenti classi\ndiverse sono differenti, mentre tutti quelli della stessa classe sono\ntra loro equivalenti: \\(x_i = x_j\\) oppure \\(x_i \\neq x_j\\).L’unica operazione algebrica che possiamo compiere sulle modalità della scala nominale è quella di contare le u.s. che appartengono ad ogni modalità e contare il numero delle modalità (classi di equivalenza). Dunque la descrizione dei dati avviene tramite le frequenze assolute e le frequenze relative.partire da una scala nominale è possibile costruire altre scale nominali che sono equivalenti alla prima trasformando valori della scala di partenza modo tale\nda cambiare nomi delle modalità, ma lasciando però inalterata la suddivisione u.s. nelle medesime classi di equivalenza. Questo significa che prendendo una variabile misurata su scala nominale e cambiando nomi delle sue categorie otteniamo una nuova variabile esattamente corrispondente alla prima.","code":""},{"path":"chapter-misurazione.html","id":"scala-ordinale","chapter":"Capitolo 11 La misurazione in psicologia","heading":"11.1.2 Scala ordinale","text":"La scala ordinale conserva la proprietà della scala nominale di classificare ciascuna u.s. ’interno di una e una sola categoria, ma alla relazione di equivalenza tra elementi di una stessa classe aggiunge la relazione di ordinamento tra le classi di equivalenza. Essendo basata su una relazione d’ordine, una scala ordinale descrive soltanto l’ordine di rango tra le modalità, ma non ci dà alcuna informazione su quanto una modalità sia più grande di un’altra. Non ci dice, per esempio, se la distanza tra le modalità \\(\\) e \\(b\\) sia uguale, maggiore o minore della distanza tra le modalità \\(b\\) e \\(c\\).","code":""},{"path":"chapter-misurazione.html","id":"esempio","chapter":"Capitolo 11 La misurazione in psicologia","heading":"Esempio","text":"Un esempio classico di scala ordinale è quello della scala Mohs per la\ndeterminazione della durezza dei minerali. Per stabilire la durezza dei\nminerali si usa il criterio empirico della scalfittura. Vengono\nstabiliti livelli di durezza crescente da 1 10 con riferimento dieci\nminerali: talco, gesso, calcite, fluorite, apatite, ortoclasio, quarzo,\ntopazio, corindone e diamante. Un minerale appartenente ad uno di questi\nlivelli se scalfisce quello di livello inferiore ed è scalfito da quello\ndi livello superiore.","code":""},{"path":"chapter-misurazione.html","id":"scala-ad-intervalli","chapter":"Capitolo 11 La misurazione in psicologia","heading":"11.1.3 Scala ad intervalli","text":"La scala ad intervalli include le proprietà di quella nominale e di\nquella ordinale, e più consente di misurare le distanze tra le coppie\ndi u.s. nei termini di un intervallo costante, chiamato unità di\nmisura, cui viene attribuito il valore “1.” La posizione dell’origine\ndella scala, cioè il punto zero, è scelta arbitrariamente, nel senso che\nnon indica l’assenza della quantità che si sta misurando. Avendo uno\nzero arbitrario, questa scala di misura consente valori negativi. Lo\nzero, infatti, non viene attribuito ’u.s. cui la proprietà\nmisurata risulta assente.La scala intervalli equivalenti ci consente di effettuare operazioni\nalgebriche basate sulla differenza tra numeri associati ai diversi\npunti della scala, operazioni algebriche non era possibile eseguire nel\ncaso di misure livello di scala ordinale o nominale. Il limite della\nscala ad intervalli è quello di non consentire il calcolo del rapporto\ntra coppie di misure. Possiamo dire, per esempio, che la distanza tra\n\\(\\) e \\(b\\) è la metà della distanza tra \\(c\\) e \\(d\\). Oppure che la distanza\ntra \\(\\) e \\(b\\) è uguale alla distanza tra \\(c\\) e \\(d\\). Non possiamo dire,\nperò, che \\(\\) possiede la proprietà misurata quantità doppia rispetto\n\\(b\\). Non possiamo cioè stabilire dei rapporti diretti tra le misure\nottenute. Solo per le differenze tra le modalità sono dunque permesse\ntutte le operazioni aritmetiche: le differenze possono essere tra loro\nsommate, elevate potenza oppure divise, determinando così le quantità\nche stanno alla base della statistica inferenziale.Nelle scale ad intervalli equivalenti, l’unità di misura è arbitraria,\novvero può essere cambiata attraverso una dilatazione, operazione che\nconsiste nel moltiplicare tutti valori della scala per una costante\npositiva. Poiché l’aggiunta di una costante non altera le differenze tra\nvalori della scala, è anche ammessa la traslazione, operazione che\nconsiste nel sommare una costante tutti valori della scala. Essendo\nla scala invariate rispetto alla traslazione e alla dilatazione, le\ntrasformazioni ammissibili sono le trasformazioni lineari:\n\\[y' = + , \\quad b > 0.\\]\nL’aspetto che rimane invariante seguito di una trasformazione lineare\nè l’uguaglianza dei rapporti fra intervalli.","code":""},{"path":"chapter-misurazione.html","id":"esempio-1","chapter":"Capitolo 11 La misurazione in psicologia","heading":"Esempio","text":"Esempio di scala ad intervalli è la temperatura misurata gradi\nCelsius o Fahrenheit, ma non Kelvin. Come per la scala nominale, è\npossibile stabilire se due modalità sono uguali o diverse: 30\\(^\\circ\\)C\n\\(\\neq\\) 20\\(^\\circ\\)C. Come per la scala ordinale è possibile mettere due\nmodalità una relazione d’ordine: 30\\(^\\circ\\)C \\(>\\) 20\\(^\\circ\\)C. \naggiunta ai casi precedenti, però, è possibile definire una unità di\nmisura per cui è possibile dire che tra 30\\(^\\circ\\)C e 20\\(^\\circ\\)C c’è\nuna differenza di 30\\(^\\circ\\) - 20\\(^\\circ\\) = 10\\(^\\circ\\)C. valori di\ntemperatura, oltre poter essere ordinati secondo l’intensità del\nfenomeno, godono della proprietà che le differenze tra loro sono\ndirettamente confrontabili e quantificabili.Il limite della scala ad intervalli è quello di non consentire il\ncalcolo del rapporto tra coppie di misure. Ad esempio, una temperatura\ndi 80\\(^\\circ\\)C non è il doppio di una di 40\\(^\\circ\\)C. Se infatti\nesprimiamo le stesse temperature nei termini della scala Fahrenheit,\nallora due valori non saranno rapporto di 1 2 tra loro. Infatti,\n20\\(^\\circ\\)C = 68\\(^\\circ\\)F e 40\\(^\\circ\\)C = 104\\(^\\circ\\)F. Questo significa\nche la relazione “il doppio di” che avevamo individuato precedenza si\napplicava ai numeri della scala centigrada, ma non alla proprietà\nmisurata (cioè la temperatura). La decisione di che scala usare\n(Centigrada vs. Fahrenheit) è arbitraria. Ma questa arbitrarietà non\ndeve influenzare le inferenze che traiamo dai dati. Queste inferenze,\ninfatti, devono dirci qualcosa proposito della realtà empirica e non\npossono nessun modo essere condizionate dalle nostre scelte\narbitrarie che ci portano scegliere la scala Centigrada piuttosto che\nquella Fahrenheit.Consideriamo ora l’aspetto invariante di una trasformazione lineare, ovvero l’uguaglianza dei rapporti fra intervalli. Prendiamo esame, ad esempio, tre temperature:\n\\(20^\\circ C = 68^\\circ F\\),\n\\(15^\\circ C = 59^\\circ F\\),\n\\(10^\\circ C = 50 ^\\circ F\\).È facile rendersi conto del fatto che rapporti fra intervalli restano costanti indipendentemente dall’unità di misura che è stata scelta:\n\\[\n  \\frac{20^\\circ C - 10^\\circ C}{20^\\circ C - 15^\\circ C} =\n  \\frac{68^\\circ F - 50^\\circ F}{68^\\circ F-59^\\circ F} = 2.\n\\]","code":""},{"path":"chapter-misurazione.html","id":"scala-di-rapporti","chapter":"Capitolo 11 La misurazione in psicologia","heading":"11.1.4 Scala di rapporti","text":"Nella scala rapporti equivalenti la posizione dello zero non è\narbitraria, ma corrisponde ’elemento dotato di intensità nulla\nrispetto alla proprietà misurata. Una scala rapporti equivalenti si\ncostruisce associando il numero 0 ’elemento con intensità nulla;\nviene poi scelta un’unità di misura \\(u\\) e, ad ogni elemento, si assegna\nun numero \\(\\) definito come: \\[= \\frac{d}{u}\\] dove \\(d\\) rappresenta la\ndistanza dall’origine. Alle u.s. vengono dunque assegnati dei numeri\ntali per cui le differenze e rapporti tra numeri riflettono le\ndifferenze e rapporti tra le intensità della proprietà misurata.Operazioni aritmetiche sono possibili non solo sulle differenze tra \nvalori della scala (come per la scala intervalli equivalenti), ma\nanche sui valori stessi della scala. L’unica arbitrarietà riguarda\nl’unità di misura che si utilizza. L’unità di misura può cambiare, ma\nqualsiasi unità di misura si scelga, lo zero deve sempre indicare\nl’intensità nulla della proprietà considerata.Le trasformazioni ammissibili questo livello di scala sono dette\ntrasformazioni di similarità: \\[y' = , \\quad b > 0.\\] questo livello\ndi scala, seguito delle trasformazioni ammissibili, rimangono\ninvariati anche rapporti: \\[\\frac{y_i}{y_j} = \\frac{y'_i}{y'_j}.\\]","code":""},{"path":"chapter-misurazione.html","id":"gerarchia-dei-livelli-di-scala-di-misura","chapter":"Capitolo 11 La misurazione in psicologia","heading":"11.2 Gerarchia dei livelli di scala di misura","text":"Stevens (1946) parla di livelli di scala poiché quattro tipi di scala di\nmisura stanno una precisa gerarchia: la scala nominale rappresenta il\nlivello più basso della misurazione, la scala rapporti equivalenti è\ninvece il livello più alto.Passando da un livello di misurazione ad uno più alto aumenta il numero di operazioni aritmetiche che possono essere compiute sui valori della scala, come indicato nella figura seguente.Per ciò che riguarda le trasformazioni ammissibili, più il livello di\nscala è basso, più le funzioni sono generali (sono minori cioè vincoli\nper passare da una rappresentazione numerica ad un’altra equivalente).\nSalendo la gerarchia, la natura delle funzioni di trasformazione si fa\npiù restrittiva.","code":""},{"path":"chapter-misurazione.html","id":"variabili-discrete-o-continue","chapter":"Capitolo 11 La misurazione in psicologia","heading":"11.3 Variabili discrete o continue","text":"Le variabili livello di intervalli e di rapporti possono essere\ndiscrete o continue. Le variabili discrete possono assumere alcuni\nvalori ma non altri. Una volta che l’elenco di valori accettabili è\nstato specificato, non ci sono casi che cadono tra questi valori.\nLe variabili discrete di solito assumono valori interi.Quando una variabile può assumere qualsiasi valore entro un intervallo\nspecificato, allora si dice che la variabile è continua. teoria, ciò\nsignifica che frazioni e decimali possono essere utilizzati per\nraggiungere un livello di precisione qualsiasi. pratica, un certo\npunto dobbiamo arrotondare numeri, rendendo tecnicamente la variabile\ndiscreta. variabili veramente discrete, tuttavia, non è possibile\naumentare piacimento il livello di precisione della misurazione.","code":""},{"path":"chapter-misurazione.html","id":"esempio-2","chapter":"Capitolo 11 La misurazione in psicologia","heading":"Esempio","text":"Il numero di biciclette possedute da una persona è una variabile discreta poiché tale variabile può assumere come modalità solo numeri interi non negativi. Frazioni di bicicletta non hanno senso.","code":""},{"path":"chapter-misurazione.html","id":"alcune-misure-sono-migliori-di-altre","chapter":"Capitolo 11 La misurazione in psicologia","heading":"11.4 Alcune misure sono migliori di altre","text":"psicologia, ciò che vogliamo misurare non è una caratteristica fisica, ma invece è un concetto teorico inosservabile, ovvero un costrutto.Un costrutto rappresenta il risultato di una fondata riflessione scientifica, non è per definizione accessibile ’osservazione diretta, ma viene inferito dall’osservazione di opportuni indicatori (Sartori, 2005).Ad esempio, supponiamo che un docente voglia valutare quanto bene uno studente comprenda la distinzione tra le quattro diverse scale di misura che sono state descritte sopra. Il docente potrebbe predisporre un test costituito da un insieme di domande e potrebbe\ncontare quante domande lo studente risponde correttamente. Questo\ntest, però, può o può non essere una buona misura del costrutto relativo\nalla conoscenza effettiva delle quattro scale di misura. Per esempio, se\nil docente scrive le domande del test modo ambiguo o se usa una\nlinguaggio troppo tecnico che lo studente non conosce, allora \nrisultati del test potrebbero suggerire che lo studente non conosce la\nmateria questione anche se realtà questo non è vero. D’altra\nparte, se il docente prepara un test scelta multipla con risposte\nerrate molto ovvie, allora lo studente può ottenere dei buoni risultati\nal test anche senza essere grado di comprendere adeguatamente le\nproprietà delle quattro scale di misura.generale non è possibile misurare un costrutto senza una certa\nquantità di errore. Poniamoci dunque il problema di determinare che\nmodo una misurazione possa dirsi adeguata.","code":""},{"path":"chapter-misurazione.html","id":"tipologie-di-errori","chapter":"Capitolo 11 La misurazione in psicologia","heading":"11.4.1 Tipologie di errori","text":"L’errore è, per definizione, la differenza tra il valore vero e il\nvalore misurato della grandezza esame. Gli errori sono classificati\ncome sistematici (o determinati) e casuali (o indeterminati). Gli errori\ncasuali sono fluttuazioni, eccesso o difetto rispetto al valore\nreale, delle singole determinazioni e sono dovuti alle molte variabili\nincontrollabili che influenzano ogni misura psicologica. Gli errori\nsistematici, invece, influiscono sulla misurazione sempre nello stesso\nsenso e, solitamente, per una stessa quantità (possono essere additivi o\nproporzionali).Le differenze tra le due tipologie di errori, sistematici e casuali,\nintroducono concetti di accuratezza e di precisione della misura. Una\nmisura viene definita:accurata, quando vi è un accordo tra la misura effettuata ed il\nvalore reale;precisa quando, ripetendo più volte la misura, risultati\nottenuti sono concordanti, cioè differiscono maniera irrilevante\ntra loro.La metafora del tiro bersaglio illustra la relazione tra precisione e accuratezza.Per tenere sotto controllo l’incidenza degli errori, sono stati\nintrodotti psicologia concetti di attendibilità e validità.Uno strumento si dice attendibile quando valuta modo coerente e\nstabile la stessa variabile: risultati ottenuti si mantengono costanti\ndopo ripetute somministrazione ed assenza di variazioni psicologiche\ne fisiche dei soggetti sottoposti al test o cambiamenti dell’ambiente \ncui ha luogo la somministrazione.L’attendibilità di uno strumento, però, non è sufficiente: primo luogo uno\nstrumento di misura deve essere valido, laddove la validità rappresenta\nil grado cui uno strumento misura effettivamente ciò che dovrebbe\nmisurare. genere, si fa riferimento ad almeno quattro tipi di\nvalidità.La validità di costrutto riguarda il grado cui un test misura\nciò per cui è stato costruito. Essa si suddivide : validità\nconvergente e validità divergente. La validità convergente fa\nriferimento alla concordanza tra uno strumento e un altro che misura\nlo stesso costrutto. La validità divergente, al contrario, valuta il\ngrado di discriminazione tra strumenti che misurano costrutti\ndifferenti. Senza validità di costrutto le altre forme di validità\nnon hanno senso.base alla validità di contenuto, un test fornisce una misura\nvalida di un attributo psicologico se il dominio dell’attributo è\nrappresentato maniera adeguata dagli item del test. Un requisito\ndi base della validità di contenuto è la rilevanza e la\nrappresentatività del contenuto degli item riferimento\n’attributo che il test intende misurare.La validità di criterio valuta il grado di concordanza tra \nrisultati dello strumento considerato e risultati ottenuti da\naltri strumenti che misurano lo stesso costrutto, o tra risultati\ndello strumento considerato e un criterio esterno. Nella validità\nconcorrente, costrutto e criterio vengono misurati contestualmente,\nconsentendo un confronto immediato. Nella validità predittiva, il\ncostrutto viene misurato prima e il criterio un momento\nsuccessivo, consentendo la valutazione della capacità dello\nstrumento di predire un evento futuro.Infine, la validità di facciata fa riferimento al grado cui il\ntest appare valido ai soggetti cui esso è diretto. La validità di\nfacciata è importante ambiti particolari, quali ad esempio la\nselezione del personale per una determinata occupazione. questo\ncaso è ovviamente importante che chi si sottopone al test ritenga\nche il test vada misurare quegli aspetti che sono importanti per\nle mansioni lavorative che dovranno essere svolte, piuttosto che\naltre cose. generale, la validità di facciata non è utile, tranne\ncasi particolari.","code":""},{"path":"chapter-misurazione.html","id":"conclusioni","chapter":"Capitolo 11 La misurazione in psicologia","heading":"Conclusioni","text":"Una domanda che uno psicologo spesso si pone è: “sulla base delle\nevidenze osservate, possiamo concludere dicendo che l’intervento\npsicologico è efficace nel trattamento e nella cura del disturbo?” Le\nconsiderazioni svolte questo capitolo dovrebbero farci capire che,\nprima di cercare di rispondere questa domanda con l’analisi statistica\ndei dati, devono essere affrontati problemi della validità e\ndell’attendibilità delle misure (oltre stabilire l’appropriato livello\ndi scala di misura delle osservazioni). L’attendibilità è un\nprerequisito della validità. Se gli errori di misurazione sono troppo\ngrandi, dati sono inutili. Inoltre, uno strumento di misurazione può\nessere preciso ma non valido. La validità e l’attendibilità delle\nmisurazioni sono dunque entrambe necessarie.generale, l’attendibilità e la validità delle misure devono essere\nvalutate per capire se dati raccolti da un ricercatore siano adeguati\n(1) per fornire una risposta alla domanda della ricerca, e (2) per\ngiungere alla conclusione proposta dal ricercatore alla luce dei\nrisultati dell’analisi statistica che è stata eseguita. È chiaro che le\ninformazioni fornite questo capitolo si limitano scalfire la\nsuperficie di questi problemi. concetti qui introdotti, però, devono\nsempre essere tenuti mente e costituiscono il fondamento di quanto\nverrà esposto nei capitoli successivi.","code":""},{"path":"chapter-descript.html","id":"chapter-descript","chapter":"Capitolo 12 Statistica descrittiva","heading":"Capitolo 12 Statistica descrittiva","text":"Nel 1907 Francis Galton, cugino di Charles Darwin, matematico e\nstatistico autodidatta, geografo, esploratore, teorico della\ndattiloscopia (ovvero, dell’uso delle impronte digitali fini\nidentificativi) e dell’eugenetica, scrisse una lettera alla rivista\nscientifica Nature sulla sua visita alla Fat Stock Poultry\nExhibition di Plymouth. Lì vide alcuni membri del pubblico partecipare\nad un gioco il cui scopo era quello di indovinare il peso della carcassa\ndi un grande bue che era appena stato scuoiato. Galton si procurò 787\ndei biglietti che erano stati compilati dal pubblico e considerò il\nvalore medio di 547 kg come la “scelta democratica” dei partecipanti, \nquanto “ogni altra stima era stata giudicata troppo alta o troppo bassa\ndalla maggioranza dei votanti.” Il punto interessante è che il peso\ncorretto di 543 kg si dimostrò essere molto simile alla “scelta\ndemocratica” basata sulle stime dei 787 partecipanti. Galton intitolò la\nsua lettera Nature Vox Populi (voce del popolo), ma questo processo\ndecisionale è ora meglio conosciuto come la “saggezza delle folle”\n(wisdom crowds). Possiamo dire che, nel suo articolo del 1907,\nGalton effettuò quello che ora chiamiamo un riepilogo dei dati, ovvero\ncalcolò un indice sintetico partire da un insieme di dati. questo\ncapitolo esamineremo le tecniche che sono state sviluppate nel secolo\nsuccessivo per riassumere le grandi masse di dati con cui sempre più\nspesso ci dobbiamo confrontare. Vedremo come calcolare e interpretare\ngli indici di posizione e di dispersione, discuteremo le distribuzioni\ndi frequenze e le relazioni tra variabili. Vedremo inoltre quali sono le\ntecniche di visualizzazione che ci consentono di rappresentare questi\nsommari dei dati mediante dei grafici. Ma prima di entrare nei dettagli,\nprendiamoci un momento per capire perché abbiamo bisogno della\nstatistica e, per ciò che stiamo discutendo qui, della statistica descrittiva.Ma generale, che cos’è la statistica? Esistono molti modi per definire la statistica. Fondamentalmente, la statistica è un insieme di tecniche che ci consentono di dare un senso al mondo attraverso dati. Ciò avviene tramite il processo di analisi statistica. L’analisi statistica traduce le domande che abbiamo proposito del mondo modelli matematici, utilizza dati per scegliere modelli matematici che sono apppropriati per descrivere il mondo e, infine, applica tali modelli per trovare una risposta alle domande che ci siamo posti. La statistica consente quindi di collegare le nostre domande proposito del mondo ai dati, di utilizzare dati per trovare le risposte alle domande che ci siamo posti e di valutare l’impatto delle risposte trovate.Inizieremo la nostra discussione sulla Data Science esaminando la statistica descrittiva. Iniziamo con la statistica descrittiva non solo perché è la più facile da capire, ma anche perché essa ci fornisce gli strumenti che devono essere usati per primi un qualsiasi progetto di analisi statistica. Nello specifico, la statistica descrittiva è un insieme di tecniche che possono essere usare per trasformare grandi (o piccole) masse di dati indici sintetici. Tali indici sintecici ci consentono di capire le caratteristiche del mondo che sono riflesse nei dati, mentre ciò non è possibile se esaminiamo direttamente dati grezzi.","code":""},{"path":"chapter-descript.html","id":"riassumere-i-dati","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.1 Riassumere i dati","text":"Quando riassumiamo dati, necessariamente buttiamo via delle informazioni. Ma è una buona idea procedere questo modo? Non sarebbe meglio conservare le informazioni specifiche di ciascun soggetto che partecipa ad un esperimento psicologico, al di là di ciò che viene trasmesso dagli indici riassuntivi della statistica descrittiva? Che\ndire delle informazioni che descrivono come sono stati raccolti dati,\ncome l’ora del giorno o l’umore del partecipante? Tutte queste\ninformazioni vengono perdute quando riassumiamo dati. La risposta alla\ndomanda che ci siamo posti è che, generale, non è una buona idea\nconservare tutti dettagli di ciò che sappiamo. È molto più utile\nriassumere le informazioni perché la semplificazione risultante consente\nprocessi di generalizzazione.un contesto letterario, l’importanza della generalizzazione è stata\nsottolineata da Jorge Luis Borges nel suo racconto “Funes o della\nmemoria,” che descrive un individuo che perde la capacità di\ndimenticare. Borges si concentra sulla relazione tra generalizzazione e\npensiero:Pensare è dimenticare una differenza, generalizzare, astrarre. Nel mondo troppo pieno di Funes, c’erano solo dettagli.Come possiamo ben capire, la vita di Funes non è facile. Se facciamo\nriferimento alla psicologia possiamo dire che gli psicologi hanno\nstudiato lungo l’utilità della generalizzazione per il pensiero. Un\nesempio è fornito dal fenomeno della formazione dei concetti e lo\npsicologo che viene mente questo proposito è sicuramente Eleanor\nRosch, la quale ha studiato principi di base della categorizzazione. \nconcetti ci forniscono uno strumento potente per organizzare le\nconoscenze. Noi siamo grado di riconoscere facilmente diversi\nesemplare di un concetto – per esempio, “gli uccelli” – anche se \nsingoli esemplari che fanno parte di una categoria sono molto diversi\ntra loro (l’aquila, la gallina, il pettirosso). L’uso dei concetti, cioè\nla generalizzazione, è utile perché ci consente di fare previsioni sulle\nproprietà dei singoli esemplari che appartengono ad una categoria, anche\nse non abbiamo mai avuto esperienza diretta con essi – per esempio,\npossiamo fare la predizione che tutti gli uccelli possono volare e\nmangiare vermi, ma non possono guidare un’automobile o parlare \ninglese. Queste previsioni non sono sempre corrette, ma sono utili.Le statistiche descrittive, un certo senso, ci fornisco l’analogo dei\n“prototipi” che, secondo Eleanor Rosch, stanno alla base del processo\npsicologico di creazione dei concetti. Un prototipo è l’esemplare più\nrappresentativo di una categoria. maniera simile, una statistica\ndescrittiva come la media, ad esempio, potrebbe essere intesa come\nl’osservazione “tipica.”La statistica descrittiva ci fornisce gli strumenti per riassumere \ndati che abbiamo disposizione una forma visiva o numerica. Le\nrappresentazioni grafiche più usate della statistica descrittiva sono\ngli istogrammi, diagrammi dispersione o box-plot, e gli indici\nsintetici più comuni sono la media, la mediana, la varianza e la\ndeviazione standard.","code":""},{"path":"chapter-descript.html","id":"distribuzioni-di-frequenze","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.2 Distribuzioni di frequenze","text":"Per introdurre principali strumenti della statistica descrittiva\nconsidereremo qui dati raccolti da Zetsche et al. (2019). Questi autori\nhanno studiato le aspettative negative le quali sono state evidenziate\ncome un meccanismo chiave nel mantenimento e nella reiterazione della\ndepressione. Zetsche et al. (2019) hanno valutato le aspettative di\nindividui depressi circa il loro umore futuro ed si sono chiesti se\nqueste aspettative fossero accurate oppure distorte negativamente.uno degli studi descritti viene esaminato un campione costituito da 30\nsoggetti con almeno un episodio depressivo maggiore e da 37 controlli\nsani. Gli autori hanno misurato il livello depressivo con il Beck\nDepression Inventory (BDI-II). Ma qual è la la gravità della\ndepressione riportata dai soggetti nel campione esaminato da\nZetsche et al. (2019)?Dei 67 soggetti considerati, uno non ha completato il BDI-II e quindi abbiamo disposizione 66 valori del BDI-II.\ndati sono riportati nella tabella [tab:bdi2_values].\nPer semplicità dati sono stati ordinati \nordine crescente. È chiaro che dati grezzi sono di difficile lettura.\nPoniamoci dunque il problema di creare una rappresentazione sintetica e\ncomprensibile di questo insieme di valori.Uno dei modi che ci consentono di effettuare una sintesi dei dati è\nquello di generare una distribuzione di frequenze.\nUna distribuzione di frequenze è un riepilogo del conteggio della\nfrequenza con cui le modalità osservate un insieme di dati si\nverificano un intervallo di valori.Per creare una distribuzione di frequenze possiamo procedere effettuando\nuna partizione delle modalità della variabile di interesse \\(m\\) classi\n(denotate con \\(\\Delta_i\\)) tra loro disgiunte. tale partizione, la\nclasse \\(\\)-esima coincide con un intervallo di valori aperto destra\n\\([a_i, b_i)\\) o aperto sinistra \\((a_i, b_i]\\). Ad ogni classe\n\\(\\Delta_i\\) avente \\(a_i\\) e \\(b_i\\) come limite inferiore e superiore\nassociamo l’ampiezza \\(b_i - a_i\\) (non necessariamente uguale per ogni\nclasse) e il valore centrale \\(\\bar{x}_i\\). La scelta delle classi è\narbitraria, ma è buona norma non definire classi con un numero troppo\npiccolo (< 5) di osservazioni. Poiché ogni elemento dell’insieme\n\\(\\{x_i\\}_{=1}^n\\) appartiene ad una ed una sola classe \\(\\Delta_i\\),\npossiamo calcolare le quantità elencate di seguito.La frequenza assoluta \\(n_i\\) di ciascuna classe, ovvero il numero di osservazioni che ricadono nella classe \\(\\Delta_i\\).\nProprietà: \\(n_1 + n_2 + \\dots + n_m = n\\).La frequenza assoluta \\(n_i\\) di ciascuna classe, ovvero il numero di osservazioni che ricadono nella classe \\(\\Delta_i\\).\nProprietà: \\(n_1 + n_2 + \\dots + n_m = n\\).La frequenza relativa \\(f_i = n_i/n\\) di ciascuna classe. Proprietà: \\(f_1+f_2+\\dots+f_m =1\\).La frequenza relativa \\(f_i = n_i/n\\) di ciascuna classe. Proprietà: \\(f_1+f_2+\\dots+f_m =1\\).La frequenza cumulata \\(N_i\\), ovvero il numero totale delle osservazioni che ricadono nelle classi fino alla \\(\\)-esima compresa: \\(N_i = \\sum_{=1}^m n_i.\\)La frequenza cumulata \\(N_i\\), ovvero il numero totale delle osservazioni che ricadono nelle classi fino alla \\(\\)-esima compresa: \\(N_i = \\sum_{=1}^m n_i.\\)La frequenza cumulata relativa \\(F_i\\), ovvero\n\\(F_i = f_1+f_2+\\dots+f_m = \\frac{N_i}{n} = \\frac{1}{n} \\sum_{=1}^m f_i.\\)La frequenza cumulata relativa \\(F_i\\), ovvero\n\\(F_i = f_1+f_2+\\dots+f_m = \\frac{N_i}{n} = \\frac{1}{n} \\sum_{=1}^m f_i.\\)Calcoliamo ora la distribuzione di frequenza assoluta e la distribuzione di frequenza relativa per valori del BDI-II del campione clinico di Zetsche et al. (2019).\nPer costruire una distribuzione di frequenza è innanzitutto necessario scegliere gli\nintervalli delle classi. Facendo riferimento ai cut-usati per l’interpretazione del BDI-II, definiamo seguenti intervalli aperti destra:depressione minima: [0, 13.5),depressione lieve: [13.5, 19.5),depressione moderata: [19.5, 28.5),depressione severa: [28.5, 63).La distribuzione di frequenza della variabile bdi2 è riportata nella\ntabella seguente. Questa distribuzione di frequenza ci aiuta capire meglio cosa sta succedendo. Se consideriamo la frequenza relativa, ad esempio, possiamo notare che ci sono due valori maggiormente ricorrenti e tali valori corrispondono alle due classi più estreme. Questo ha senso nel caso presente, quanto il campione esaminato da Zetsche et al. (2019) includeva due gruppi di\nsoggetti: soggetti sani (con valori BDI-II bassi) e soggetti depressi\n(con valori BDI-II alti). una distribuzione di frequenza tali valori\ntipici vanno sotto il nome di mode della distribuzione.","code":""},{"path":"chapter-descript.html","id":"esercizio-con-r","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.2.1 Esercizio con R","text":"Poniamoci ora il problema di costruire la tabella precedente partendo dai dati grezzi messi disposizione da Zetsche et al. (2019).\nLeggiamo dati assumendo che il file data.mood.csv si trovi nella cartella data contenuta nella working directory.C’è un solo valore di depressione per ciascun soggetto ma tale valore viene ripetuto tante volte quante volte sono le righe del data.frame associate ad ogni soggetto (ciascuna riga corrispondente ad una prova diversa). È dunque necessario trasformare il data.frame modo tale da avere un’unica riga per ciascun soggetto, ovvero un unico valore BDI-II per soggetto.Ci sono dunque 66 soggetti quali hanno ottenuto valori sulla scala del BDI-II stampati di seguito (li presento ordinati dal più piccolo al più grande).Calcolo ora le frequenze assolute per seguenti intervalli aperti destra: [0, 13.5), [13.5, 19.5), [19.5, 28.5), [28.5, 63). Esaminando dati, possiamo notare che 36 soggetti cadono nella prima classe. È però necessario eseguire quest’operazione di conteggio utilizzando R.Uno dei modi possibili per calcolare le frequenze assolute è quello di usare la funzione cut(). Mediante tal funzione è possibile dividere il campo di variazione (ovvero, la differenza tra il valore massimo di una distribuzione ed il valore minimo) di una variabile continua x intervalli e codificare ciascun valore x nei termini dell’intervallo cui appartiene. Tale risultato si ottiene nel modo seguente.Possiamo ora usare la funzione table() la quale ritorna un elenco che associa la frequenza assoluta ciascuna modalità della variabile input – ovvero, la distribuzione di frequenza assoluta.Per ottenere la distribuzione di frequenza relativa è sufficiente dividere ciascuna frequenza assoluta per il numero totale di osservazioni:questo modo abbiamo ottenuto le distribuzioni di frequenza assoluta e relativa per valori del BDI-II dei soggetti di Zetsche et al. (2019):","code":"\ndf <- read.csv(\n  here(\"data\", \"data.mood.csv\"), \n  header=TRUE\n) \nbysubj <- df %>% \n  group_by(esm_id) %>% \n  summarise(\n    bdi = mean(bdi)\n  ) %>% \n  na.omit()\nsort(bysubj$bdi)\n#>  [1]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  2  2  2  2  3  3\n#> [32]  3  5  7  9 12 19 22 22 24 25 25 26 26 26 27 27 28 28 30 30 30 31 31 33 33 34 35 35 35 36 39\n#> [63] 41 43 43 44\nbysubj$bdi_level <- cut(\n  bysubj$bdi,\n  breaks = c(0, 13.5, 19.5, 28.5, 63),\n  include.lowest = TRUE,\n  labels = c(\n    \"minimal\", \"mild\", \"moderate\", \"severe\"\n  )\n)\n\nbysubj$bdi_level\n#>  [1] moderate severe   severe   moderate severe   severe   severe   severe   moderate severe  \n#> [11] moderate mild     severe   minimal  minimal  minimal  severe   moderate minimal  minimal \n#> [21] minimal  minimal  minimal  moderate minimal  minimal  minimal  minimal  minimal  minimal \n#> [31] minimal  severe   minimal  minimal  severe   minimal  moderate minimal  minimal  minimal \n#> [41] severe   minimal  minimal  severe   severe   moderate severe   severe   minimal  moderate\n#> [51] minimal  moderate severe   moderate moderate minimal  minimal  minimal  minimal  minimal \n#> [61] minimal  minimal  minimal  minimal  minimal  minimal \n#> Levels: minimal mild moderate severe\ntable(bysubj$bdi_level)\n#> \n#>  minimal     mild moderate   severe \n#>       36        1       12       17\ntable(bysubj$bdi_level) / sum(table(bysubj$bdi_level))\n#> \n#>    minimal       mild   moderate     severe \n#> 0.54545455 0.01515152 0.18181818 0.25757576"},{"path":"chapter-descript.html","id":"osservazione","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.2.2 Osservazione","text":"una sezione successiva di questo capitolo discuteremo principi che, secondo Edward Tufte, devono guidare la Data Science. Parlando delle rappresentazioni grafiche dei dati, Edward Tufte ci dice che la prima cosa da fare è “mostrare dati.” Questa può sembrare una tautologia, considerato che questo è lo scopo della statistica descrittiva: trasformare dati attraverso vari indici riassuntivi o rappresentazioni grafiche, modo tale da renderli comprensibili. Tuttavia, spesso le tecniche statistiche vengono usate per nascondere e non per mostrare dati.L’uso delle frequenze relative offre un chiaro esempio di questo. Di questi tempi capita spesso di incontrare, sulla stampa, notizie proposito un nuovo farmaco che, una prova clinica, ha mostrato risultati incoraggianti che suggeriscono la sua efficacia come possibile trattamento del COVID-19. Alle volte risultati della sperimentazione clinica sono riportati nei termini di una frequenza relativa. Ad esempio, potremmo leggere che l’uso del farmaco ha portato ad una riduzione del 21% dei ricoveri o dei decessi. Sembra tanto. Ma è necessario guardare dati! Ovvero, molto spesso, quello che non viene riportato dai comunicati stampa. Infatti, una riduzione del 21% può corrispondere ad un cambiamento dal 5% al 4%. E una riduzione del 44% può corrispondere ad una differenza di 10 contro 18, o di 5 contro 9, o di 15 contro 27. altri termini, una proporzione, anche grande, può corrispondere ad una differenza assoluta piuttosto piccola: un piccolo passo avanti, ma non ad un balzo! Per questa ragione, per capire cosa dati significano, è necessario guardare dati da diversi punti di vista, utilizzando diverse statistiche descrittive, senza limitarci alla statistica descrittiva che racconta la storia che piace di più. Perché la scelta della statistica descrittiva da utilizzare per riassumere dati dipende dagli scopi di chi esegue l’analisi statisica: il nostro scopo è quelloi di capire se il farmaco funziona; lo scopo delle compagnie farmaceutiche è quello di vendere il farmaco. Sono obiettivi molto diversi.","code":""},{"path":"chapter-descript.html","id":"istogramma-1","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.3 Istogramma","text":"dati che sono stati sintetizzati una distribuzione di frequenze\npossono essere rappresentati graficamente un istogramma.\nUn istogramma si costruisce riportando sulle ascisse limiti delle\nclassi \\(\\Delta_i\\) e sulle ordinate valori della funzione costante \ntratti\n\\[\\varphi_n(x)= \\frac{f_i}{b_i-a_i}, \\quad x\\\\Delta_i,\\, =1, \\dots, m\\]\nche misura la densità della frequenza relativa della variabile \\(X\\)\nnella classe \\(\\Delta_i\\), ovvero il rapporto fra la frequenza relativa\n\\(f_i\\) e l’ampiezza (\\(b_i - a_i\\)) della classe. questo modo il\nrettangolo dell’istogramma associato alla classe \\(\\Delta_i\\) avrà un’area\nproporzionale alla frequenza relativa \\(f_i\\). Si noti che l’area totale\ndell’istogramma delle frequenze relative è data della somma delle aree\ndei singoli rettangoli e quindi vale 1.0.","code":""},{"path":"chapter-descript.html","id":"esercizio-con-r-1","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.3.1 Esercizio con R","text":"Poniamoci il problema di costruire un istogramma per dati del BDI-II.\nNell’istogramma viene rappresentata la frequenza relativa delle classi: l’area di ogni barra dell’istogramma è proporzionale alla frequenza relativa della classe che la barra rappresenta.\nCome si trova l’altezza delle barre dell’istogramma? Per la classe [0, 13.5), ad esempio, la frequenza relativa è 36/66. Tale valore corrisponde ’area del rettangolo. Dato che la base del rettangolo è 13.5, l’altezza sarà 36/66 / 13.5, ovvero 0.0404. E così via per le altre barre dell’istogramma.Una rappresentazione grafica dell’istogramma delle frequenze relative si può ottenere con R utilizzando le funzioni di ggplot2. Il pacchetto ggplot2 è un potente strumento per rappresentare graficamente dati. Le iniziali del nome, gg, si riferiscono alla ‘’Grammar Graphics’’, che è un modo di pensare le figure come una serie di layer stratificati. Originariamente descritta da Leland Wilkinson, la grammatica dei grafici è stata aggiornata e applicata R da Hadley Wickham, il creatore del pacchetto. Per chiarezza, precisiamo che la funzione ggplot() utilizza intervalli aperti destra.\nFigura 12.1: Istogramma per valori BDI-II riportati da Zetsche et al. (2019).\nCon quattro intervalli individuati dai cut-del BDI-II otteniamo la\nrappresentazione riportata nella figura 12.1. Nel caso della prima barra dell’istogramma sinistra, l’ampiezza dell’intervallo è pari 13.5 e\nl’area della barra (ovvero, la frequenza relativa) è uguale 36/66.\nDunque l’altezza della barra è uguale (36 / 66) / 13.5 = 0.040. Lo\nstesso procedimento si applica per il calcolo dell’altezza degli altri\nrettangoli.Anche se nel caso presente è sensato usare ampiezze diverse per gli intervalli delle classi, generale gli istogrammi si costruiscono utilizzando intervalli riportati sulle ascisse con un’ampiezza uguale.\nQuesto è il caso dell’istogramma seguente il quale è stato generato partire dagli stessi dati.\nFigura 12.2: Una rappresentazione più comune per l’istogramma dei valori BDI-II di Zetsche et al. (2019) nella quale gli intervalli delle classi hanno ampiezze uguali.\n","code":"\np1 <- bysubj %>%\n  ggplot(aes(x = bdi)) +\n  geom_histogram(\n    aes(y = ..density..),\n    breaks = c(0, 13.5, 19.5, 28.5, 44.1) # il valore BDI-II massimo è 44\n  ) +\n  scale_x_continuous(breaks=c(0, 13.5, 19.5, 28.5, 44.1)) +\n  labs(\n    x = \"BDI-II\",\n    y = \"Densità di frequenza\"\n  ) +\n  theme_apa()\np1\np2 <- bysubj %>%\n  ggplot(aes(x = bdi)) +\n  geom_histogram(\n    aes(y = ..density..),\n    breaks = seq(0, 44.1, length.out = 7)\n  ) +\n  scale_x_continuous(breaks=c(0.00,  7.35, 14.70, 22.05, 29.40, 36.75, 44.10)) +\n  labs(\n    x = \"BDI-II\",\n    y = \"Densità di frequanza\"\n  ) +\n  theme_apa()\np2"},{"path":"chapter-descript.html","id":"funzione-di-densità-empirica","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.4 Funzione di densità empirica","text":"Il confronto tra le figure 12.1 e 12.2 rende chiaro un limite degli istogrammi. È infatti ovvio che il profilo dell’istogramma è arbitrario: seconda del numero e dei limiti delle classi che vengono scelte,\ncambiano sia il numero che la forma delle barre dell’istogramma. Questo rende difficile fornire un’interpretazione alle informazioni fornite da un istogramma.Il problema precedente può essere alleviato utilizzando una\nrappresentazione alternativa della distribuzione di frequenza, ovvero la\nstima della densità della frequenza dei dati (detta anche stima kernel\ndi densità). Un modo semplice per pensare tale rappresentazione, che\ninglese va sotto il nome di density plot, è quello di immaginare un\ngrande campione di dati, modo che diventi possibile definire un\nenorme numero di classi di equivalenza di ampiezza molto piccola, le\nquali non risultino vuote. tali circostanze, la funzione di densità\nempirica non è altro che il profilo lisciato dell’istogramma. La\nstessa idea si applica anche quando il campione è più piccolo.","code":""},{"path":"chapter-descript.html","id":"esercizio-con-r-2","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.4.1 Esercizio con R","text":"Nel caso dei dati del BDI-II otteniamo la reppresentazione fornita dalla figura seguente.\nFigura 12.3: Funzione di densità empirica per valori BDI-II di Zetsche et al. (2019).\nChe interpretazione possiamo attribuire alla funzione di densità empirica rappresentata nella figura 12.3?\nLa interpretiamo come abbiamo fatto con gli istogrammi: l’area sottesa al grafico della funzione di densità empirica un certo intervallo rappresenta la proporzione dei casi della distribuzione che hanno valori compresi nell’intervallo considerato.","code":"\np3 <- bysubj %>% \n  ggplot(aes(x = bdi)) +\n  geom_histogram(\n    aes(y = ..density..), \n    breaks = seq(0, 44.1, length.out = 7)\n  ) +\n  geom_density(\n    aes(x = bdi), \n    adjust = 0.5, \n    size = 0.8, \n    fill = \"steelblue3\", \n    alpha = 0.5\n  ) +\n  labs(\n    x = \"BDI-II\",\n    y = \"Densità di frequenza\"\n  ) +\n  theme_apa()\np3"},{"path":"chapter-descript.html","id":"forma-di-una-distribuzione","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.5 Forma di una distribuzione","text":"generale, la forma di una distribuzione descrive come dati si\ndistribuiscono intorno ai valori centrali. Distinguiamo tra\ndistribuzioni simmetriche e asimmetriche, e tra distribuzioni unimodali\no multimodali. Un’illustrazione grafica è fornita nella\nfigura seguente.\nFigura 12.4: 1: Asimmetria negativa. 2: Asimmetria positiva. 3: Distribuzione unimodale. 4: Distribuzione bimodale.\nNel pannello 1 la distribuzione è unimodadle con asimmetria negativa; nel pannello 2 la distribuzione è unimodadle con asimmetria positiva; nel pannello 3 la distribuzione è simmetrica e unimodale; nel pannello 4 la distribuzione è bimodale.Se consideriamo nuovamente la figura 12.3 possiamo dire che la distribuzione dei valori del BDI-II nel campione considerato da Zetsche et al. (2019) è bimodale.","code":""},{"path":"chapter-descript.html","id":"indici-di-posizione","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.6 Indici di posizione","text":"Nuovamente, se preferite un’introduzione veramente “soft” alla nozione di “tendenza centrale” di una distribuzione statistica, vi rimando nuovamentew al link che ho già suggerito precedenza.","code":""},{"path":"chapter-descript.html","id":"quantili","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.6.1 Quantili","text":"La descrizione della distribuzione dei valori BDI-II di\nZetsche et al. (2019) può essere facilitata dalla determinazione di\nalcuni valori caratteristici che sintetizzano le informazioni contenute\nnella distribuzione di frequenze. Si dicono quantili (o frattili)\nquei valori caratteristici che hanno le seguenti proprietà. quartili\nsono quei valori che ripartiscono dati \\(x_i\\) quattro parti\nugualmente numerose (pari ciascuna al 25% del totale). Il primo\nquartile, \\(q_1\\), lascia alla sua sinistra il 25% del campione pensato\ncome una fila ordinata (destra quindi il 75%). Il secondo quartile\n\\(q_2\\) lascia sinistra il 50% del campione (destra quindi il 50%).\nEsso viene anche chiamato mediana. Il terzo quartile lascia sinistra\nil 75% del campione (destra quindi il 25%). Secondo lo stesso\ncriterio, si dicono decili quantili di ordine \\(p\\) multiplo di 0.10 e\npercentili quantili di ordine \\(p\\) multiplo di 0.01.Come si calcolano quantili? Consideriamo la definizione di quantile\nnon interpolato di ordine \\(p\\) \\((0 < p < 1)\\). Si procede innanzitutto\nordinando dati ordine crescente, \\(\\{x_1, x_2, \\dots, x_n\\}\\). Ci\nsono poi due possibilità. Se il valore \\(np\\) non è intero, sia \\(k\\)\nl’intero tale che \\(k < np < k + 1\\) – ovvero, la parte intera di \\(np\\).\nAllora \\(q_p = x_{k+1}.\\) Se \\(np = k\\) con \\(k\\) intero, allora\n\\(q_p = \\frac{1}{2}(x_{k} + x_{k+1}).\\) Se vogliamo calcolare il primo\nquartile \\(q_1\\), ad esempio, utilizziamo \\(p = 0.25\\). Dovendo calcolare\ngli altri quantili basta sostituire \\(p\\) il valore appropriato[^2].Gli indici di posizione, tra le altre cose, hanno un ruolo importante,\novvero vengono utilizzati per creare una rappresentazione grafica di una\ndistribuzione di valori che è molto popolare e può essere usata \nalternativa ad un istogramma (realtà vedremo poi come possa essere\ncombinata con un istogramma). Tale rappresentazione va sotto il nome di\nbox-plot.Per fare un esempio, consideriamo nove soggetti del campione clinico di Zetsche et al. (2019) che hanno riportato un unico episodio di depressione maggiore. Per tali soggetti valori ordinati del BDI-II (per semplicità li chiameremo \\(x\\)) sono seguenti: 19, 26, 27, 28, 28, 33, 33, 41, 43.\nPer il calcolo del secondo quartile (non interpolato), ovvero per il calcolo della mediana, dobbiamo considerare la quantità \\(np = 9 \\cdot 0.5 = 4.5\\), non intero. Quindi, \\(q_1 = x_{4 + 1} = 27\\).\nPer il calcolo del quantile (non interpolato) di ordine \\(p = 2/3\\) dobbiamo considerare la quantità \\(np = 9 \\cdot 2/3 = 6\\), intero. Quindi, \\(q_{\\frac{2}{3}} = \\frac{1}{2} (x_{6} + x_{7}) = \\frac{1}{2} (33 + 33) = 33\\).","code":""},{"path":"chapter-descript.html","id":"box-plot","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.6.2 Box-plot","text":"Il box-plot (o diagramma scatola) è uno strumento grafico utile al\nfine di ottenere informazioni circa la dispersione e l’eventuale\nsimmetria o asimmetria di una distribuzione. Per costruire un box-plot\nsi rappresenta sul piano cartesiano un rettangolo (cioè la “scatola”) di\naltezza arbitraria la cui base corrisponde alla dist intanza\ninterquartile (IQR = \\(q_{0.75} - q_{0.25}\\)). La linea interna alla\nscatola rappresenta la mediana \\(q_{0.5}\\). Si tracciano poi ai lati della\nscatola due segmenti di retta cui estremi sono detti “valore\nadiacente” inferiore e superiore. Il valore adiacente inferiore è il\nvalore più piccolo tra le osservazioni che risulta maggiore o uguale al\nprimo quartile meno la distanza corrispondente 1.5 volte la distanza\ninterquartile.\nIl valore adiacente superiore è il valore più grande tra le osservazioni che risulta minore o uguale \\(Q_3+1.5\\) IQR. valori esterni ai valori adiacenti (chiamati valori anomali) vengono rappresentati individualmente nel box-plot per meglio evidenziarne la presenza e la posizione.\nFigura 12.5: Box-plot: \\(M\\) è la mediana, \\(\\bar{x}\\) è la media aritmetica e IQR è la distanza interquartile (\\(Q_3 - Q_1\\)).\nConsideriamo ora un caso concreto nel quale viene utilizzato un box-plot.\nNel caso dei dati di Zetsche et al. (2019) ci chiediamo che modo si differenziano le distribuzioni del BDI-II tra due gruppi considerati, ovvero tra il gruppo dei pazienti e il gruppo di controllo.La figura 12.6 fornisce due rappresentazioni grafiche che possono essere utilizzate per rispondere questa domanda.\nFigura 12.6: Due versioni di un violin plot per valori BDI-II di ciascuno dei due gruppi di soggetti esaminati da Zetsche et al. (2019).\nNella figura 12.6 sinistra sono rappresentati dati grezzi: questa è la pratica migliore quando il numero di osservazioni è piccolo. La linea curva che circonda (simmetricamente) le osservazioni è l’istogramma lisciato che abbiamo descritto precedenza. Nella figura 12.6 destra sono rappresentanti gli stessi dati: la funzione di densità empirica è la stessa di prima, ma al suo interno viene collocato un box-plot. Questa seconda rappresentazione è da preferirsi quando ci sono molte osservazioni e non è utile rappresentare singolarmente ciascun dato. Entrambe le rappresentazioni suggeriscono che la distribuzione dei dati è ’incirca simmetrica nel gruppo clinico (codificato come mdd). Il gruppo di controllo (ctl) mostra invece un’asimmetria positiva, con tre osservazioni evidenziate nel boxplot come dei “valori anomali,” dato che si discostano dalla mediana di una quantità maggiore di 1.5 IQR.","code":"\nbysubj <- df %>% \n  group_by(esm_id, group) %>% \n  summarise(\n    bdi = mean(bdi),\n    nr_of_episodes = mean(nr_of_episodes, na.rm = TRUE)\n  ) %>% \n  na.omit()\n#> `summarise()` has grouped output by 'esm_id'. You can override using the `.groups` argument.\n\nbysubj %>% \n  ggplot(aes(x=group, y=bdi)) + \n  geom_boxplot() +\n  labs(\n    x = \"Gruppo\",\n    y = \"BDI-II\"\n  ) +\n  theme_apa()\nlibrary(\"patchwork\")\n\nbysubj <- df %>% \n  group_by(esm_id, group) %>% \n  summarise(\n    bdi = mean(bdi),\n    nr_of_episodes = mean(nr_of_episodes, na.rm = TRUE)\n  ) %>% \n  na.omit()\n#> `summarise()` has grouped output by 'esm_id'. You can override using the `.groups` argument.\n\np1 <- bysubj %>% \n  ggplot(aes(x=group, y=bdi)) + \n  geom_violin(trim=FALSE) +\n  geom_dotplot(binaxis='y', stackdir='center', dotsize=0.7) +\n  labs(\n    x = \"Gruppo\",\n    y = \"BDI-II\"\n    #, caption = \"Fonte: Zetsche, Buerkner, & Renneberg (2020)\"\n  ) \n\np2 <- bysubj %>% \n  ggplot(aes(x=group, y=bdi)) + \n  geom_violin(trim=FALSE) +\n  geom_boxplot(width=0.05) +\n  labs(\n    x = \"Gruppo\",\n    y = \"BDI-II\"\n    #, caption = \"Fonte: Zetsche, Buerkner, & Renneberg (2020)\"\n  ) \n\np1 + p2\n#> `stat_bindot()` using `bins = 30`. Pick better value with `binwidth`."},{"path":"chapter-descript.html","id":"leccellenza-grafica","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.6.3 L’eccellenza grafica","text":"Non c’è un modo “corretto” per rappresentare forma grafica un insieme\ndi dati. Ciascuno dei grafici che abbiamo discusso ha suoi pregi e \nsuoi difetti. Un ricercatore che ha influenzato molto il modo cui\nviene realizzata la visualizzazione dei dati scientifici è Edward Tufte,\nsoprannominato dal New York Times il “Leonardo da Vinci dei dati.”\nSecondo Tufte, “l’eccellenza nella grafica consiste nel comunicare idee\ncomplesse modo chiaro, preciso ed efficiente.” Nella visualizzazione\ndelle informazioni, l’“eccellenza grafica” ha l’obiettivo di comunicare\nal lettore il maggior numero di idee nel minor tempo possibile, con meno\ninchiostro possibile, usando il minor spazio possibile. Secondo\nTufte (2001), le rappresentazioni grafiche dovrebbero:mostrare dati;indurre l’osservatore riflettere sulla sostanza piuttosto che\nsulla progettazione grafica, o qualcos’altro;evitare di distorcere quanto dati stanno comunicando (“integrità\ngrafica”);presentare molte informazioni forma succinta;rivelare la coerenza tra le molte dimensioni dei dati;incoraggiare l’osservatore comparare differenti porzioni di dati;rivelare dati diversi livelli di dettaglio, da una visione ampia\nalla struttura di base;servire ad uno scopo preciso (descrizione, esplorazione, o la\nrisposta qualche domanda);essere fortemente integrate con le descrizioni statistiche e verbali\ndei dati fornite nel testo.base questi principi, la funzione di densità empirica fornisce una\nrappresentazione migliore dei dati di Zetsche et al. (2019) di quanto lo faccia un istogramma. Inoltre, se oltre al grupppo di appartenenza non ci sono altre dimensioni importanti da mettere evidenza, allora la nostra scelta dovrebbe\nricadere sul pannello di sinistra della figura 12.6. Il seguente link fornisce diverse interessanti illustrazioni dei principi elencati sopra.","code":""},{"path":"chapter-descript.html","id":"indici-di-tendenza-centrale","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.7 Indici di tendenza centrale","text":"L’analisi grafica, esaminata precedenza, costituisce la base di\npartenza di qualsivoglia analisi quantitativa dei dati. Tramite\nl’analisi grafica possiamo capire alcune caratteristiche importanti di\nuna distribuzione: per esempio, se è simmetrica o asimmetrica; oppure se\nè unimodale o multimodale. Successivamente, possiamo calcolare degli\nindici numerici che descrivono modo sintetico le caratteristiche di\nbase dei dati esaminati. Tra le misure di tendenza centrale, ovvero tra\ngli indici che forniscono un’idea dei valori attorno ai quali sono\nprevalentemente concentrati dati di un campione, quella più\ncomunemente usata è la media.","code":""},{"path":"chapter-descript.html","id":"media","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.7.1 Media","text":"Tutti conosciamo la media aritmetica di \\(\\{x_1, x_2, \\dots, x_n\\}\\),\novvero il numero reale \\(\\bar{x}\\) definito da\n\\[\\begin{equation}\n\\bar{x}=\\frac{1}{n}\\sum_{=1}^n x_i.\n\\tag{12.1}\n\\end{equation}\\]\nNell’eq. (12.1) abbiamo usato la notazione delle sommatorie\nper descrivere una somma di valori. Questa notazione è molto usata \nstatistica e viene descritta Appendice.La media gode della seguente importante proprietà: la somma degli scarti\ntra ciascuna modalità \\(x_i\\) e la media aritmetica \\(\\bar{x}\\) è nulla,\ncioè\n\\[\n\\sum_{=1}^n (x_i - \\bar{x}) = 0.\\notag\n\\label{eq:diffmeansumzero}\\] Infatti, \\[\\begin{aligned}\n\\sum_{=1}^n (x_i - \\bar{x}) &= \\sum_i x_i - \\sum_i \\bar{x}\\notag\\\\\n&= \\sum_i x_i - n \\bar{x}\\notag\\\\\n&= \\sum_i x_i - \\sum_i x_i = 0.\\notag\\end{aligned}\n\\]Ciò ci consente di pensare alla media come al baricentro della distribuzione.Un’altra proprietà della media è la seguente. La somma dei quadrati\ndegli scarti tra ciascuna modalità \\(x_i\\) e una costante arbitraria\n\\(\\\\Re\\), cioè \\[\\varphi() = \\sum_{=1}^n (x_i - )^2,\\notag\\] è\nminima per \\(= \\bar{x}\\).Il concetto statistico di media ha suscitato molte battute. Per esempio,\nil fatto che, media, ciascuno di noi ha un numero di gambe circa pari\n1.9999999. Oppure, il fatto che, media, ciascuno di noi ha un\ntesticolo. Ma la media ha altri problemi, oltre al fatto di ispirare\nbattute simili alle precedenti. particolare, dobbiamo notare che la\nmedia non è sempre l’indice che meglio rappresenta la tendenza centrale\ndi una distribuzione. particolare, ciò non accade quando la\ndistribuzione è asimmetrica, o presenza di valori anomali (outlier)\n– si veda il pannello di destra della figura 12.6. tali circostanze, la tendenza centrale della distribuzione è meglio rappresentata dalla mediana o dalla media spuntata.","code":""},{"path":"chapter-descript.html","id":"esercizio-con-r-3","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.7.1.1 Esercizio con R","text":"Calcoliamo la media dei valori BDI-II per due gruppi di soggetti di Zetsche et al. (2019).","code":"\nbysubj %>% \n  group_by(group) %>% \n  summarise(\n    avg_bdi = mean(bdi)\n  ) \n#> # A tibble: 2 x 2\n#>   group avg_bdi\n#>   <fct>   <dbl>\n#> 1 ctl      1.69\n#> 2 mdd     30.9"},{"path":"chapter-descript.html","id":"media-spuntata","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.7.2 Media spuntata","text":"La media spuntata \\(\\bar{x}_t\\) (trimmed mean) non è altro che la\nmedia dei dati calcolata considerando solo il 90% (o altra percentuale)\ndei dati centrali. Per calcolare \\(\\bar{x}_t\\) si ordinando dati secondo\nuna sequenza crescente, \\(x_1 \\leq x_2 \\leq x_3 \\leq \\dots \\leq x_n\\), per\npoi eliminare il primo 5% e l’ultimo 5% dei dati della serie così\nordinata. La media spuntata è data dalla media aritmetica dei dati rimanenti.","code":""},{"path":"chapter-descript.html","id":"esercizio-con-r-4","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.7.2.1 Esercizio con R","text":"Calcoliamo la media spuntata dei valori BDI-II per due gruppi di soggetti di Zetsche et al. (2019) escludendo il 10% dei valori più estremi ciascun gruppo.","code":"\nbysubj %>% \n  group_by(group) %>% \n  summarise(\n    avg_trim_bdi = mean(bdi, trim = 0.1)\n  ) \n#> # A tibble: 2 x 2\n#>   group avg_trim_bdi\n#>   <fct>        <dbl>\n#> 1 ctl            1  \n#> 2 mdd           30.6"},{"path":"chapter-descript.html","id":"moda-e-mediana","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.7.3 Moda e mediana","text":"precedenza abbiamo già incontrato altri due popolari indici di\ntendenza centrale: la moda (Mo), ovvero il valore centrale della\nclasse con la frequenza massima (può succedere che una distribuzione\nabbia più mode; tal caso si dice multimodale e questo operatore\nperde il suo significato di indice di tendenza centrale) e la mediana\n\\(\\tilde{x}\\).","code":""},{"path":"chapter-descript.html","id":"esercizio-con-r-5","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.7.3.1 Esercizio con R","text":"Calcoliamo quantili di ordine 0.25, 0.5 e 0.75 dei valori BDI-II per due gruppi di soggetti di Zetsche et al. (2019).","code":"\nbysubj %>% \n  group_by(group) %>% \n  summarise(\n    q25 = quantile(bdi, probs = 0.25),\n    q50 = quantile(bdi, probs = 0.50),\n    q75 = quantile(bdi, probs = 0.75)\n  ) \n#> # A tibble: 2 x 4\n#>   group   q25   q50   q75\n#>   <fct> <dbl> <dbl> <dbl>\n#> 1 ctl       0     1     2\n#> 2 mdd      26    30    35"},{"path":"chapter-descript.html","id":"indici-di-dispersione","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.8 Indici di dispersione","text":"Le medie e gli indici di posizione descritti precedenza forniscono\ndelle sintesi dei dati che mettono evidenza la tendenza centrale\ndelle osservazioni. Tali indici, tuttavia, non considerano un aspetto\nimportante della distribuzione dei dati, ovvero la variabilità dei\nvalori numerici della variabile statistica. È dunque necessario\nsintetizzare la distribuzione di una variabile statistica oltre che con\nle misure di posizione anche tramite l’utilizzo di indicatori che\nvalutino la dispersione delle unità statistice.Anche questo caso, un’introduzione “soft” è fornita nel link.","code":""},{"path":"chapter-descript.html","id":"indici-basati-sullordinamento-dei-dati","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.8.1 Indici basati sull’ordinamento dei dati","text":"È possibile calcolare degli indici di variabilità basati\nsull’ordinamento dei dati. L’indice più ovvio è l’intervallo di\nvariazione, ovvero la distanza tra il valore massimo e il valore minimo\ndi una distribuzione di modalità, mentre precedenza abbiamo già\nincontrato la differenza interquartile. Questi due indici, però, hanno\nil limite di essere calcolati sulla base di due soli valori della\ndistribuzione (\\(x_{\\text{max}}\\) e \\(x_{\\text{mini}}\\), oppure \\(x_{0.25}\\) e\n\\(x_{0.75}\\)). Pertanto non utilizzano tutte le informazioni che sono\ndisponibili. Inoltre, l’intervallo di variazione ha il limite di essere\npesantemente influenzato dalla presenza di valori anomali.","code":""},{"path":"chapter-descript.html","id":"varianza","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.8.2 Varianza","text":"Dati limiti delle statistiche precedenti è più comune misurare la\nvariabilità di una variabile statistica come la dispersione dei dati\nattorno ad un indice di tendenza centrale. Infatt, la misura di variabilità di gran lunga più usata per valutare la variabilità di una variabile statistica è senza dubbio la varianza. La varianza\n\\[\\begin{equation}\ns^2 = \\frac{1}{n} \\sum_{=1}^n (x_i - \\bar{x})^2\n\\tag{12.2}\n\\end{equation}\\]\nè la media dei quadrati degli scarti \\(x_i - \\bar{x}\\) tra ogni valore e la media della distribuzione.\nLa varianza è una misura di dispersione più complessa di quelle esaminate precedenza. È appropriata solo nel caso di distribuzioni simmetriche e, anch’essa, è fortemente influenzata dai valori anomali. Inoltre, è espressa \nun’unità di misura che è il quadrato dell’unità di misura dei dati originari e quindi ad essa non può essere assegnata un’interpretazione intuitiva.","code":""},{"path":"chapter-descript.html","id":"esercizio-con-r-6","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.8.2.1 Esercizio con R","text":"Calcoliamo la varianza dei punteggi BDI-II nei due gruppi di soggetti di Zetsche et al. (2019).","code":"\nbysubj %>% \n  group_by(group) %>% \n  summarise(\n    variance = var(bdi)\n  ) \n#> # A tibble: 2 x 2\n#>   group variance\n#>   <fct>    <dbl>\n#> 1 ctl       8.03\n#> 2 mdd      43.7"},{"path":"chapter-descript.html","id":"deviazione-standard","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.8.3 Deviazione standard","text":"Per le ragioni espresse sopra, la misura più usata della dispersione di una distribuzione di dati è la deviazione standard, ovvero la radice quadrata della varianza. differenza della varianza, dunque, la deviazione standard è espressa nella stessa unità di misura dei dati. Come nel caso della varianza, anche la deviazione standard \\(s\\) dovrebbe essere usata soltanto quando la media è adeguata per misurare il centro della distribuzione, ovvero, nel caso di distribuzioni simmetriche. Come nel caso della media \\(\\bar{x}\\), anche la deviazione standard è fortemente influenzata dai dati anomali (outlier), ovvero dalla presenza di uno o di pochi dati che sono molto più distanti dalla media rispetto agli altri valori della distribuzione. Quando tutte le osservazioni sono uguali, \\(s=0\\), altrimenti \\(s > 0\\).Alla deviazione standard può essere assegnata una semplice interpretazione: la deviazione standard è simile (ma non identica) allo scostamento medio semplice dalla media. La deviazione standard ci dice, dunque, quanto sono distanti, media, le singole osservazioni dal centro della distribuzione.","code":""},{"path":"chapter-descript.html","id":"esercizio-con-r-7","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.8.3.1 Esercizio con R","text":"Calcoliamo la deviazione standard per il BDI-II dei due gruppi di soggetti di Zetsche et al. (2019).","code":"\nbysubj %>% \n  group_by(group) %>% \n  summarise(\n    stdev = sd(bdi)\n  ) \n#> # A tibble: 2 x 2\n#>   group stdev\n#>   <fct> <dbl>\n#> 1 ctl    2.83\n#> 2 mdd    6.61"},{"path":"chapter-descript.html","id":"deviazione-mediana-assoluta","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.8.4 Deviazione mediana assoluta","text":"Una misura robusta della dispersione statistica di un campione è la deviazione mediana assoluta (Median Absolute Deviation, MAD) definita come la mediana del valore assoluto delle deviazioni dei dati dalla mediana, ovvero:\\[\n{\\displaystyle \\operatorname {MAD} =\\operatorname {median} \\left(\\ \\left|X_{}-\\operatorname {median} (X)\\right|\\ \\right)}\n\\]\nNel caso di una distribuzione dei dati unimodale simmetrica di forma campanulare (ovvero, normale), si ha che\\[\n{\\displaystyle \\text{deviazione standard} \\approx 1.4826\\ \\operatorname {MAD} .\\,}\n\\]Pertanto, solitamente software restituiscono il valore MAD moltiplicato per una tale costante.","code":""},{"path":"chapter-descript.html","id":"esercizio-con-r-8","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.8.4.1 Esercizio con R","text":"Calcoliamo il valore MAD per il BDI-II dei due gruppi di soggetti di Zetsche et al. (2019).Oppure, per due gruppi:","code":"\n1.4826 * median(abs(bysubj$bdi - median(bysubj$bdi)))\n#> [1] 15.5673\nbysubj %>% \n  group_by(group) %>% \n  summarise(\n    MAD = mad(bdi)\n  ) \n#> # A tibble: 2 x 2\n#>   group   MAD\n#>   <fct> <dbl>\n#> 1 ctl    1.48\n#> 2 mdd    6.67"},{"path":"chapter-descript.html","id":"indici-di-variabilità-relativi","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.8.5 Indici di variabilità relativi","text":"volte può essere interessante effettuare un confronto fra due misure\ndi variabilità di grandezze incommensurabili, ovvero di caratteri\nrilevati mediante differenti unità di misura. questi casi, le misure\ndi variabilità precedentemente descritte si rivelano inadeguate \nquanto dipendono dall’unità di misura adottata. Diventa dunque\nnecessario ricorrere particolari numeri adimensionali detti indici\nrelativi di variabilità. Il più importante di tali indici è il\ncoefficiente di variazione, ovvero il numero puro\n\\[C_v = \\frac{\\sigma}{\\bar{x}}\\] ottenuto dal rapporto tra la deviazione\nstandard e la media dei dati. Un altro indice relativo di variabilità è\nla differenza interquartile rapportata al primo quartile oppure al terzo\nquartile oppure alla mediana, cioè:\n\\[\\frac{x_{0.75} - x_{0.25}}{x_{0.25}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.75}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.50}}.\\notag\\]","code":""},{"path":"chapter-descript.html","id":"le-relazioni-tra-variabili","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.9 Le relazioni tra variabili","text":"Zetsche et al. (2019) hanno misurato il livello di depressione dei\nsoggetti del loro esperimento utilizzando due scale psicometriche: il\nBeck Depression Inventory II (BDI-II) e la Center Epidemiologic\nStudies Depression Scale (CES-D). Il BDI-II è uno strumento self-report\nche valutare la presenza e l’intensità di sintomi depressivi pazienti\nadulti e adolescenti di almeno 13 anni di età con diagnosi psichiatrica\nmentre la CES-D è una scala self-report progettata per misurare \nsintomi depressivi che sono stati vissuti nella settimana precedente\nnella popolazione generale, specialmente quella degli\nadolescenti/giovani adulti. Una domanda ovvia che ci può venire \nmente è: quanto sono simili le misure ottenute mediante queste due\nscale?È chiaro che numeri prodotti dalle scale BDI-II e CES-D non possono\nessere identici, e questo per due motivi: (1) la presenza degli errori\ndi misurazione e (2) l’unità di misura delle due variabili. L’errore di\nmisurazione corrompe sempre, almeno parte, qualunque operazione di\nmisurazione. E questo è vero specialmente psicologia dove\nl’attendibilità degli strumenti di misurazione è minore che altre\ndiscipline (quali la fisica, ad esempio). Il secondo motivo per cui \nvalori delle scale BDI-II e CES-D non possono essere uguali è che\nl’unità di misura delle due scale è arbitraria. Infatti, qual è l’unità\ndi misura della depressione? Chi può dirlo! Ma, al di là delle\ndifferenze derivanti dall’errore di misurazione e dalla differente unità\ndi misura, ci aspettiamo che, se le due scale misurano entrambe lo\nstesso costrutto, allora valori prodotti dalle due scale dovranno\nessere tra loro linearmente associati. Per capire cosa si intende con\n“associazione lineare” iniziamo guardare dati. Per fare questo\nutilizziamo una rappresentazione grafica che va sotto il nome di\ndiagramma dispersione.","code":""},{"path":"chapter-descript.html","id":"diagramma-a-dispersione-1","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.9.1 Diagramma a dispersione","text":"Il diagramma di dispersione è la rappresentazione grafica delle coppie\ndi punti individuati dalle variabili BDI-II e CES-D, e si ottiene\nponendo, ad esempio, valori BDI-II sull’asse delle ascisse e quelli\ndel CES-D sull’asse delle ordinate. tale grafico, fornito dalla\nfigura 12.7, cascun punto corrisponde ad un\nindividuo del quale, nel caso presente, conosciamo il livello di\ndepressione misurato dalle due scale psicometriche.\n\n\n\n\nFigura 12.7: Associazione tra le variabili BDI-II e CES-D nello studio di Zetsche et al. (2019). rosso sono rappresentate le osservazioni del gruppo di controllo; blu quelle dei pazienti.\nDalla figura 12.7 possiamo vedere che dati mostrano\nuna certa tendenza disporsi attorno ad una retta – nel gergo\nstatistico, questo fatto viene espresso dicendo che punteggi CES-D\ntendono ad essere linearmente associati ai punteggi BDI-II. È ovvio,\ntuttavia, che tale relazione lineare è lungi dall’essere perfetta – se\nfosse perfetta, tutti punti del diagramma dispersione si\ndisporrebbero esattamente lungo una retta.Il problema che ci poniamo è quello di trovare un indice numerico che\ndescriva di quanto la nube di punti si discosta da una perfetta\nrelazione lineare tra le due variabili. Per risolvere tale problema\ndobbiamo specificare un indice statistico che descriva la direzione e la\nforza della relazione lineare tra le due variabili. Ci sono vari indici\nstatistici che possiamo utilizzare questo scopo.","code":"\nbysubj <- df %>% \n  group_by(esm_id, group) %>% \n  summarise(\n    bdi = mean(bdi),\n    cesd = mean(cesd_sum)\n  ) %>% \n  na.omit() %>% \n  ungroup()\n#> `summarise()` has grouped output by 'esm_id'. You can override using the `.groups` argument.\nm_cesd <- mean(bysubj$cesd)\nm_bdi <- mean(bysubj$bdi)\nFONT_SIZE <- 10\n\np <- bysubj %>%\n  ggplot(\n    aes(x=bdi, y=cesd, color=group)) +\n  geom_point(size=1) +\n  geom_hline(yintercept= m_cesd, linetype=\"dashed\", color = \"gray\") +\n  geom_vline(xintercept = m_bdi, linetype=\"dashed\", color = \"gray\") +\n  geom_text(x=-1, y=16, label=\"I\", color = \"gray\", size=FONT_SIZE) +\n  geom_text(x=0, y=46, label=\"IV\", color = \"gray\", size=FONT_SIZE) +\n  geom_text(x=18, y=46, label=\"III\", color = \"gray\", size=FONT_SIZE) +\n  geom_text(x=18, y=16, label=\"II\", color = \"gray\", size=FONT_SIZE) +\n  labs(\n    x = \"BDI-II\",\n    y = \"CESD\"\n  ) +\n  theme_apa() +\n  theme(legend.position=\"none\") \np"},{"path":"chapter-descript.html","id":"covarianza","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.9.2 Covarianza","text":"Iniziamo considerare il più importante di tali indici, chiamato\ncovarianza. realtà la definizione di questo indice non ci\nsorprenderà più di tanto quanto, una forma solo apparentemente\ndiversa, l’abbiamo già incontrato precedenza. Ci ricordiamo infatti\nche la varianza di una generica variabile \\(X\\) è definita come la media\ndegli scarti quadratici di ciascuna osservazione dalla media:\n\\[\\begin{equation}\nS_{XX} = \\frac{1}{n} \\sum_{=1}^n(X_i - \\bar{X}) (X_i - \\bar{X}).\n\\tag{12.3}\n\\end{equation}\\]\nInfatti, la varianza viene talvolta descritta come la “covarianza di una\nvariabile con sé stessa.”Adesso facciamo un passo ulteriore. Invece di valutare la dispersione di\nuna sola variabile, chiediamoci come due variabili \\(X\\) e \\(Y\\) “variano\ninsieme” (co-variano). È facile capire come una risposta tale domanda\npossa essere fornita da una semplice trasformazione della formula\nprecedente che diventa:\n\\[\\begin{equation}\nS_{XY} = \\frac{1}{n} \\sum_{=1}^n(X_i - \\bar{X}) (Y_i - \\bar{Y}).\n\\tag{12.4}\n\\end{equation}\\]\nL’eq. (12.4) ci fornisce dunque la definizione della covarianza.Per capire il significato dell’eq. (12.4), supponiamo di dividere il grafico della figura 12.7 quattro quadranti definiti da una retta verticale passante per la media dei valori BDI-II e da una\nretta orizzontale passante per la media dei valori CES-D. Numeriamo \nquadranti partendo da quello basso sinistra e muovendoci senso\nantiorario.Se prevalgono punti nel e III quadrante, allora la nuvola di punti\navrà un andamento crescente (per cui valori bassi di \\(X\\) tendono ad\nassociarsi valori bassi di \\(Y\\) e valori elevati di \\(X\\) tendono ad\nassociarsi valori elevati di \\(Y\\)) e la covarianza segno positivo. Mentre\nse prevalgono punti nel II e IV quadrante la nuvola di punti avrà un\nandamento decrescente (per cui valori bassi di \\(X\\) tendono ad\nassociarsi valori elevati di \\(Y\\) e valori elevati di \\(X\\) tendono ad\nassociarsi valori bassi di \\(Y\\)) e la covarianza segno negativo. Dunque,\nil segno della covarianza ci informa sulla direzione della relazione\nlineare tra due variabili: l’associazione lineare si dice positiva se la\ncovarianza è positiva, negativa se la covarianza è negativa.Il segno della covarianza ci informa sulla direzione della relazione, ma\ninvece il valore assoluto della covarianza ci dice ben poco. Esso,\ninfatti, dipende dall’unità di misura delle variabili. Nel caso presente\nquesto concetto è difficile da comprendere, dato che le due variabili \nesame non hanno un’unità di misura (ovvero, hanno un’unità di misura\narbitraria e priva di significato). Ma quest’idea diventa chiara se\npensiamo alla relazione lineare tra l’altezza e il peso delle persone,\nad esempio. La covarianza tra queste due quantità è certamente positiva,\nma il valore assoluto della covarianza diventa più grande se l’altezza\nviene misurata millimetri e il peso grammi, e diventa più piccolo\nl’altezza viene misurata metri e il peso chilogrammi. Dunque, il\nvalore della covarianza cambia al mutare dell’unità di misura delle\nvariabili anche se l’associazione tra le variabili resta costante.","code":""},{"path":"chapter-descript.html","id":"correlazione","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.9.3 Correlazione","text":"Dato che il valore assoluto della covarianza è di difficile\ninterpretazione – pratica, non viene mai interpretato – è\nnecessario trasformare la covarianza modo tale da renderla immune\nalle trasformazioni dell’unità di misura delle variabili. Questa\noperazione si dice standardizzazione e corrisponde alla divisione\ndella covarianza per le deviazioni standard (\\(s_X\\), \\(s_Y\\)) delle due\nvariabili:\\[\\begin{equation}\nr_{XY} = \\frac{S_{XY}}{s_X s_Y}.\n\\tag{12.5}\n\\end{equation}\\]\nLa quantià che si ottiene questo modo viene chiamata correlazione di Bravais-Pearson (dal nome degli autori che, indipendentemente l’uno dall’altro, la hanno introdotta).Il coefficiente di correlazione ha le seguenti proprietà:ha lo stesso segno della covarianza, dato che si ottiene dividendo\nla covarianza per due numeri positivi;è un numero puro, cioè non dipende dall’unità di misura delle\nvariabili;assume valori compresi tra -1 e +1.Ad esso possiamo assegnare la seguente interpretazione:\\(r_{XY} = -1\\) \\(\\rightarrow\\) perfetta relazione negativa: tutti \npunti si trovano esattamente su una retta con pendenza negativa (dal\nquadrante alto sinistra al quadrante basso destra);\\(r_{XY} = +1\\) \\(\\rightarrow\\) perfetta relazione positiva: tutti \npunti si trovano esattamente su una retta con pendenza positiva (dal\nquadrante basso sinistra al quadrante alto destra);\\(-1 < r_{XY} < +1\\) \\(\\rightarrow\\) presenza di una relazione lineare\ndi intensità diversa;\\(r_{XY} = 0\\) \\(\\rightarrow\\) assenza di relazione lineare tra \\(X\\) e\n\\(Y\\).Per dati della figura 12.7, la covarianza è 207.426. Il segno positivo della covarianza ci dice che tra le due variabili c’è\nun’associazione lineare positiva. Per capire qual è l’intensità della\nrelazione lineare tra le due variabili calcoliamo la correlazione.\nEssendo le deviazioni standard del BDI-II e del CES-D rispettavamente\nuguali 15.37 e 14.93, la correlazione diventa uguale \n\\(\\frac{207.426}{15.38 \\cdot 14.93} = 0.904.\\) Tale valore è prossimo \n1.0, il che vuol dire che punti del diagramma dispersione non si\ndiscostano troppo da una retta con una pendenza positiva.","code":""},{"path":"chapter-descript.html","id":"correlazione-e-causazione","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.10 Correlazione e causazione","text":"Facendo riferimento nuovamente alla figura 12.7, possiamo dire che, molte applicazioni (ma non nel caso presente!) l’asse \\(x\\) rappresenta una\nquantità nota come variabile indipendente e l’interesse si concentra\nsulla sua influenza sulla variabile dipendente tracciata sull’asse\n\\(y\\). Ciò presuppone però che sia nota la direzione cui l’influenza\ncausale potrebbe risiedere. È importante tenere bene mente che la\ncorrelazione è soltanto un indice descrittivo della relazione lineare\ntra due variabili e nessun caso può essere usata per inferire\nalcunché sulle relazioni causali che legano le variabili. È ben nota\nl’espressione: “correlazione non significa causazione.”Di opinione diversa era invece Karl Pearson (1911), il quale ha\naffermato:Quanto spesso, quando è stato osservato un nuovo fenomeno,\nsentiamo che viene posta la domanda: ‘qual è la sua causa?’ Questa è\nuna domanda cui potrebbe essere assolutamente impossibile rispondere.\nInvece, può essere più facile rispondere alla domanda: ‘che misura\naltri fenomeni sono associati con esso?’ Dalla risposta questa\nseconda domanda possono risultare molte preziose conoscenze.Che alla seconda domanda posta da Pearson sia facile rispondere è indubbio. Che\nla nostra comprensione di un fenomeno possa aumentare sulla base delle\ninformazioni fornite unicamente dalle correlazioni, invece, è molto dubbio e quasi\ncertamente falso.","code":""},{"path":"chapter-descript.html","id":"usi-della-correlazione","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.10.1 Usi della correlazione","text":"Anche se non può essere usata per studiare le relazioni causali, la\ncorrelazione viene usata per molti altri scopi tra quali, per esempio,\nquello di misurare la validità concorrente di un test psiologico. Se\nun test psicologico misura effettivamente ciò che ci si aspetta che\nmisuri (nel caso dell’esempio presente, la depressione), allora dovremo\naspettarci che fornisca una correlazione alta con risultati di altri\ntest che misurano lo stesso costrutto – come nel caso dei dati di\n(Zetsche et al., 2019). Un’altra proprietà desiderabile di un test\npsicometrico è la validità divergente: risultati di test\npsicometrici che misurano costrutti diversi dovrebbero essere poco\nassociati tra loro. altre parole, questo secondo caso dovremmo\naspettarci che la correlazione sia bassa.","code":""},{"path":"chapter-descript.html","id":"correlazione-di-spearman","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.10.2 Correlazione di Spearman","text":"Una misura alternativa della relazione lineare tra due variabili è\nfornita dal coefficiente di correlazione di Spearman e dipende soltanto\ndalla relazione d’ordine dei dati, non dagli specifici valori dei dati.\nTale misura di associazione è appropriata quando, del fenomeno esame,\ngli psicologi sono stati grado di misurare soltanto le relazioni\nd’ordine tra le diverse modalità della risposta dei soggetti, non\nl’intensità della risposta. Le variabili psicologiche che hanno questa\nproprietà si dicono ordinali. Nel caso di variabili ordinali, non è\npossibile sintetizzare dati mediante le statistiche descrittive che\nabbiamo introdotto questo capitolo, quali ad esempio la media e la\nvarianza, ma è invece solo possibile riassumere dati mediante una\ndistribuzione di frequenze per le varie modalità della risposta.","code":""},{"path":"chapter-descript.html","id":"correlazione-nulla","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.10.3 Correlazione nulla","text":"Un ultimo aspetto da mettere evidenza proposito della correlazione\nriguarda il fatto che la correlazione descrive la direzione e\nl’intensità della relazione lineare tra due variabili. Relazioni non\nlineari tra le variabili, anche sono molto forti, non vengono catturate\ndalla correlazione. È importante rendersi conto che una correlazione\npari zero non significa che non c’è relazione tra le due variabili, ma\nsolo che tra esse non c’è una relazione lineare. Un esempio di questo\nfatto è fornito dalla figura 12.8.\nFigura 12.8: Due insiemi di dati (fittizi) per quali coefficienti di correlazione di Pearson sono entrambi 0. Ma questo non significa che non vi sia alcuna relazione tra le variabili.\n","code":"\nlibrary(\"datasauRus\")\nslant <- ggplot(datasaurus_dozen_wide, aes(x=slant_down_x,y=slant_down_y),   colour=dataset) \n# loads slant-pattern dataset of datasauRus package into data frame slant\nslant <- slant + \n  geom_point() # as a scatter type geom\nslant <- slant + \n  theme_void() # eliminates unwanted axis labels\nslant <- slant + \n  theme(legend.position = \"none\", \n        panel.border = element_rect(colour = \"black\", fill=NA, size = 1),\n        plot.margin = margin(0,2,0,2), aspect.ratio = 1) \n# removes legend, adds a border, adds margin space below, and specifies \n# required aspect ratio\n\ndino <- ggplot(datasaurus_dozen_wide, aes(x=dino_x,y=dino_y), colour=dataset) +\n  geom_point() \n# loads dino-figure dataset of datasauRus package into data \n#frame dino as a scatter type geom\ndino <- dino +theme_void() # eliminates unwanted axis labels\ndino <- dino + \n  theme(legend.position = \"none\", \n        panel.border =  element_rect(colour = \"black\", fill=NA, size = 1),\n        plot.margin = margin(0,2,0,2), aspect.ratio = 1) \n# removes legend, adds a border, adds margin space below, specifies \n# required aspect ratio\n\nslant + dino"},{"path":"chapter-descript.html","id":"conclusioni-1","chapter":"Capitolo 12 Statistica descrittiva","heading":"Conclusioni","text":"La prima fase dell’analisi dei dati è sicuramente quella che ci porta \nriassumere dati mediante gli strumenti della statistica descrittiva.\nCi sono diverse domande che vengono affrontate questa fase: qual è la\ndistribuzione delle variabili di interesse? Quali relazioni coppie si\npossono osservare nel campione? Ci sono delle osservazioni ‘anomale,’\novvero estremamente discrepanti rispetto alle altre, sia quando si\nesaminano le statistiche descrittive univariate (ovvero, quelle che\nriguardano le caratteristiche di una variabile presa singolarmente), sia\nquando vengono esaminate le statistiche bivariate (ovvero, le\nstatistiche che descrivono l’associazione tra le variabili)? È\nimportante avere ben chiare le idee su questi punti prima di procedere\ncon qualsiasi procedura statistica di tipo inferenziale. Per rispondere\nalle domande che abbiamo elencato sopra, ed ad altre simili, è molto\nutile procedere con delle rappresentazioni grafiche dei dati. Dovrebbe\nessere chiaro che, quando disponiamo di grandi moli di dati (come è\nsempre il caso psicologia), per fare questo è necessario usare un\nsoftware statistico.","code":""},{"path":"chapter-descript.html","id":"esercizi","chapter":"Capitolo 12 Statistica descrittiva","heading":"12.11 Esercizi","text":"Scarica gli esercizi:Download 14_descr_exercises.RmdGuarda le risposte solo dopo avere provato rispondere tutte le domande:Download 14_descr_answers.Rmd","code":""},{"path":"introduzione-2.html","id":"introduzione-2","chapter":"Introduzione","heading":"Introduzione","text":"L’idea centrale che esploreremo questo libro è: dati alcuni dati, come è possibile utilizzare il teorema di Bayes per quantificare l’incertezza delle nostre credenze riguardo di una questione di interesse scientifico. Prima di entrare nei dettagli della teoria sottostante e delle sue applicazioni, è necessario maturare una certa familiarità con seguenti argomenti: concetti di base alla base della teoria della probabilità, il concetto di variabili casuali, le distribuzioni di probabilità e il concetto di verosimiglianza. Qui di seguito verranno trattati questi argomenti.","code":""},{"path":"il-calcolo-delle-probabilità.html","id":"il-calcolo-delle-probabilità","chapter":"Capitolo 13 Il calcolo delle probabilità","heading":"Capitolo 13 Il calcolo delle probabilità","text":"È normale fare delle congetture rispetto ciò di cui non siamo sicuri.\nMa perché facciamo questo? Molto spesso perché, anche se sappiamo che le\nnostre conoscenze sono incomplete, dobbiamo comunque prendere delle\ndecisioni. Ad esempio: “non se tra qualche ora pioverà; devo o non\ndevo prendere l’ombrello?” maniera simile, anche se uno psicologo non\nsa maniera certa quali sono meccanismi che regolano fenomeni\npsicologi, deve comunque decidere tra diverse alternative. Per esempio,\ndeve fornire un parere, relativamente chi, tra due genitori, sia più\nadatto per ottenere l’affidamento del figlio caso di divorzio, oppure\nquale sia, un caso specifico, l’approccio più efficace per il\ntrattamento dei disturbi dell’alimentazione. Ovviamente la qualità delle\ncongetture varia, così come varia la qualità delle decisioni che\nprendiamo. La teoria delle probabilità ci fornisce gli strumenti per\nprendere decisioni “razionali” condizioni di incertezza, ovvero per\nformulare le migliori congetture possibili.La teoria delle probabilità ci consente di descrivere maniera\nquantitativa quei fenomeni che, pur essendo altamente variabili,\nrivelano comunque una qualche coerenza lungo termine. Il lancio\nripetuto di una moneta è uno di questi fenomeni. È anche l’esempio\ntipico che viene usato per introdurre una discussione sulle probabilità.\nSapere se una moneta sia onesta o meno, o calcolare la probabilità di\nottenere testa un certo numero di volte può essere interessante nel\nmondo delle scommesse, ma nella vita quotidiana non ci capita spesso di\nlanciare una moneta per prendere una decisione. Allora perché ci\npreoccupiamo di studiare le proprietà statistiche dei lanci di una\nmoneta? questa domanda si può rispondere dicendo che l’esperimento\n(chiamato “casuale”) che corrisponde al lancio di una moneta è il\nsurrogato di una molteplicità di eventi che, della vita reale, sono\nmolto importanti. Per esempio: qual è la probabilità di successo di un\nintervento psicologico? Qual è la probabilità che un test per l’HIV dia\nesito positivo una persona che non ha l’HIV? Qual è la probabilità di\nessere occupato entro un anno dalla laurea? lanci di una moneta\ncostituiscono una rappresentazione generica di molteplici altri eventi\nche hanno un grande significato nella nostra vita. Questa è la ragione\nper cui studiamo le proprietà statistiche dei fenomeni aleatori usando\nil lancio di una moneta quale esempio generico.La discussione della teoria della probabilità è certamente l’argomento\npiù impegnativo affrontato queste dispense. Fare uno sforzo di\ncomprensione per chiarire concetti di base della teoria della\nprobabilità è però necessario per mettersi nelle condizioni di capire le\ncaratteristiche dell’inferenza statistica che verranno discusse \nseguito.","code":""},{"path":"il-calcolo-delle-probabilità.html","id":"probabilità-nel-linguaggio-naturale","chapter":"Capitolo 13 Il calcolo delle probabilità","heading":"13.1 Probabilità nel linguaggio naturale","text":"un articolo pubblicato su Harward Business Review nel 2018,\nMauboussin e Mauboussin ci ricordano come, nel marzo del 1951, l’Office\nNational Estimates della CIA pubblicò un documento che suggeriva che\nun attacco sovietico alla Jugoslavia nel corso dell’anno fosse una\n“seria possibilità.” Sherman Kent, un professore di storia Yale che fu\nchiamato Washington, D.C. per dirigere l’Office National\nEstimates, espresse perplessità sull’esatto significato\ndell’espressione “seria possibilità.” Lo interpretò nel senso che la\nprobabilità di un attacco era di circa il 65%. Ma quando chiese ai\nmembri del Board National Estimates cosa ne pensassero, gli furono\nriferite cifre che andavano dal 20% ’80%. Una gamma così ampia\nrappresentava chiaramente un problema, poiché le implicazioni politiche\ndi quegli estremi erano nettamente diverse. Kent riconobbe che la\nsoluzione di tale problema era quella di usare numeri per esprimere il\nnostro grado di certezza, notando mestamente:Non abbiamo usato numeri… e sembra chiaro che abbiamo abusando delle parole.Da allora non è cambiato molto. Ancora oggi le persone nel mondo della\npolitica, degli affari e nella vita quotidiana continuano usare parole\nvaghe per descrivere possibili risultati degli eventi. Perché? Phil\nTetlock, professore di psicologia ’Università della Pennsylvania, che\nha studiato fondo il fenomeno psicologico della previsione, suggerisce\nche “una vaga verbosità conferisce sicurezza.” Quando usiamo una parola\nper descrivere la probabilità di un evento incerto, cerchiamo di porci\nnelle condizioni di non essere smentiti dopo che il risultato\ndell’evento verrà rivelato. Se si verifica l’evento che abbiamo\nprevisto, è facile dire: “Ti avevo detto che probabilmente sarebbe\nsuccesso questo.” Se la nostra predizione fallisce, possiamo sempre\ndire: “Ho solo detto che probabilmente sarebbe successo.” Parole così\nambigue non solo consentono ’oratore di evitare di essere smentito,\nma consentono anche al destinatario di interpretare il messaggio modo\ncoerente con le sue nozioni preconcette. Ovviamente, da tale ambiguità\nlinguistica deriva una cattiva comunicazione. È dunque necessario\nprocedere modo diverso nel linguaggio scientifico. Vedremo questo\ncapitolo come sia possibile assegnare al termine “probabilità” un\nsignificato preciso.","code":""},{"path":"il-calcolo-delle-probabilità.html","id":"probabilità-nel-linguaggio-scientifico","chapter":"Capitolo 13 Il calcolo delle probabilità","heading":"13.2 Probabilità nel linguaggio scientifico","text":"La teoria della probabilità nasce nel 1654. Fu infatti questa data\nche Antoine Gombaud Cavalier De Méré, un nobile francese, nonché\naccanito giocatore d’azzardo scrisse una lettera al suo amico Pascal per\ncercare di comprendere il motivo delle sue continue perdite nel gioco\ndei dadi. De Méré descrisse due diverse scommesse:scommessa Asi lancia un dado per 4 volte di seguito e si vince se esce almeno\nuna volta il 6;\nsi lancia un dado per 4 volte di seguito e si vince se esce almeno\nuna volta il 6;scommessa Bsi lanciano due dadi per 24 volte di seguito e si vince se esce\nalmeno una volta il doppio 6.\nsi lanciano due dadi per 24 volte di seguito e si vince se esce\nalmeno una volta il doppio 6.Il cavaliere De Méré pose Pascal il seguente quesito: le possibilità\ndi vittoria sono maggiori nella scommessa o nella scommessa B? Il\nproblema di De Méré divenne un motivo di scambio epistolare tra Pascal e\nFermat, due più grandi matematici del tempo, e viene considerato come\nla motivazione iniziale dello sviluppo della teoria della probabilità.Ma come può essere risolto il problema di De Méré? Una strategia\npossibile è quella di seguire l’esempio di De Méré, ovvero, giocare\nquesto gioco molte volte. Così facendo, De Méré si rese conto che le\npossibilità di vittoria erano leggermente migliori nel caso della\nscommessa .Utilizzando una simulazione al computer possiamo facilmente giungere \nquesta stessa conclusione senza perdere tutto il tempo che De Méré ha\ndedicato questa materia. Una simulazione al computer ci consente\ninfatti di ripetere il gioco di De Méré moltissime volte e di annotare\nil risultato ottenuto ad ogni ripetizione del gioco. Vedremo seguito\nperché, utilizzando un computer, è possibile ottenere un risultato\ndiverso ogni volta che si ripete una certa operazione, modo tale da\nrappresentare il grado di casualità che si osserva quando si lancia di\nun dado. Per ora ci limitiamo ad esaminare risultati che vengono\nprodotti questo modo e che sono illustrati nella\nfigura 13.1.\nFigura 13.1: Risultati ottenuti da 10000 ripetizioni delle due scommesse di De Méré.\nLa figura 13.1 riportata la proporzione di vittorie funzione\ndel numero di ripetizioni di ciascuna scommessa e rivela che, lungo\ntermine (ovvero, se consideriamo un grande numero di ripetizioni del\ngioco di De Méré), la scommessa risulta più conveniente della\nscommessa B. Nel caso di 10000 ripetizioni del gioco di De Méré, la\nproporzione di vittorie è risultata essere pari 0.5182 per la\nscommessa e pari 0.4909 per la scommessa B. Se ripetiamo la stessa\nsimulazione altre 10000 volte, otteniamo una proporzione di vittorie\nuguale 0.5180 per la scommessa e 0.4878 per la scommessa B.Vedremo questo capitolo come ciascuna di queste proporzioni possa\nessere considerata come una stima empirica di ciò che chiamiamo\nprobabilità. Le proporzioni descritte sopra vengono sono delle “stime”\npoiché approssimano il vero valore della probabilità; infatti, ripetendo\nla simulazione due volte abbiamo ottenuto dei risultati leggermente\ndiversi. Ma allora qual è il “vero” valore della probabilità? Un modo\nsemplice per rispondere questa domanda è quello di dire che,\nutilizzando la procedura descritta sopra, il vero valore della\nprobabilità si otterrebbe se il gioco di De Méré venisse ripetuto\ninfinite volte. Ma ovviamente, per qualunque applicazione concreta, non\nabbiamo bisogno di ripetere la simulazione infinite volte, quanto un\ngrande numero di ripetizioni ci fornisce un’approssimazione sufficiente.conclusione, le considerazioni precedenti ci fanno capire che il\nconcetto di probabilità sia legato quello di incertezza. La\nprobabilità può infatti essere definita come la quantificazione del\nlivello di “casualità” di un evento, laddove viene detto casuale ciò che\nnon è noto o non può essere predetto con certezza.","code":"\n# Game A: Throw a fair die at most four times, and win if you get a six.\nexperiment_a <- function(){\n  rolls <- sample(1:6, size = 4, replace = TRUE)\n  condition <- sum(rolls == 6) > 0\n  return(condition)\n}\n\n# Game B: Throw two fair dice at most twenty-four times, and win if you get a double-six.\nexperiment_b <- function(){\n  first.die <- sample(1:6, size = 24, replace = TRUE)\n  second.die <- sample(1:6, size = 24, replace = TRUE)\n  condition <- sum((first.die == second.die) & (first.die == 6)) > 0\n  return(condition)\n}\n\n# number of replications\nnrep <- 1e4\n# Play game A nrep times. We get a vector of nrep elements. Eeach element of \n# of the simsA vector is the outcome obtained by playing game A once: TRUE if\n# the output is a win, FALSE if the output of the game is a loss. Remember than\n# TRUE = 1 and FALSE = 0.\nsims_a <- replicate(nrep, experiment_a())\n# The proportion of wins in game A \nprop_wins_a <- sum(sims_a)/length(sims_a)\nprop_wins_a\n#> [1] 0.5193\n# To plot the results, we compute the \nnwins_a <- cumsum(sims_a)\nntrials <- 1:nrep\n\nsims_b <- replicate(nrep, experiment_b())\nprop_wins_b <- sum(sims_b)/length(sims_b) \nprop_wins_b\n#> [1] 0.493\n\nnwins_b <- cumsum(sims_b)\n\nd <- data.frame(\n  n = c(ntrials, ntrials), \n  pwin = c(nwins_a/ntrials, nwins_b/ntrials),\n  game = rep(c(\"Scommessa A\", \"Scommessa B\"), each = nrep)\n)\n\nd %>% \n  ggplot(\n    aes(x = n, y = pwin, col = game)\n  ) +\n  geom_point(alpha = 0.4) +\n  geom_line() +\n  scale_x_log10(breaks = c(1, 3, 10, 50, 200, 1000, 3000,  10000)) +\n  theme(legend.title = element_blank()) +\n  labs(\n    x=\"Numero di ripetizioni del gioco di De Méré\", \n    y=\"Proporzione di vincite\") +\n  scale_color_manual(values = c(\"gray80\", \"skyblue\")) +\n  theme(legend.position = \"bottom\")"},{"path":"il-calcolo-delle-probabilità.html","id":"terminologia-1","chapter":"Capitolo 13 Il calcolo delle probabilità","heading":"13.3 Terminologia","text":"Come qualsiasi altra branca della matematica, la teoria delle\nprobabilità fa uso di una specifica terminologia cui concetti di base\nsono descritti di seguito.Il calcolo delle probabilità si occupa di un generico esperimento casuale. Si dice esperimento casuale qualsiasi attività che produce un risultato osservabile. L’esecuzione di un esperimento casuale è chiamata prova dell’esperimento. Esempi sono: lanciare una moneta, lanciare un dado 6 facce, provare un nuovo percorso per andare al lavoro per vedere se è più veloce di quello che usiamo di solito, o giocare al gioco di De Méré.Il risultato (o esito) di una prova si indica con \\(\\omega\\) ed è detto evento elementare.Prima che l’esperimento casuale venga eseguito non sappiamo quale esito verrà prodotto; dopo che l’esperimento casuale è stato eseguito, l’esito dell’esperimento si “cristallizza” nel risultato osservato.Si dice spazio campionario \\(\\Omega\\) (probability space) l’insieme di tutti possibili esiti di un esperimento casuale. Lo spazio campionario può essere finito, infinito o infinito numerabile. Eseguire un esperimento casuale significa scegliere maniera casuale uno dei possibili eventi elementari dello spazio campionario.Si dice evento composto (o non-elementare) un sottoinsieme dello spazio campionario, ovvero un insieme che può essere sua volta scomposto più eventi elementari. Per esempio, il numero 4 è un evento elementare dello spazio campionario finito \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\) che corrisponde ’esperimento casuale del lancio di un dado. L’evento composto \\(\\) “il risultato è pari” è \\(= \\{2, 4, 6\\}\\).","code":""},{"path":"il-calcolo-delle-probabilità.html","id":"le-diverse-definizioni-della-probabilità","chapter":"Capitolo 13 Il calcolo delle probabilità","heading":"13.4 Le diverse definizioni della probabilità","text":"Ma, nello specifico, che cos’è la probabilità? questa domanda si può rispondere modi diversi.","code":""},{"path":"il-calcolo-delle-probabilità.html","id":"una-definizione-ingenua-della-probabilità","chapter":"Capitolo 13 Il calcolo delle probabilità","heading":"13.4.1 Una definizione ingenua della probabilità","text":"Storicamente, la prima definizione della probabilità di un evento è\nstata quella che richiede di contare il numero di modi nei quali un\nevento può manifestarsi e di dividere tale numero per il numero totale\ndi eventi dello spazio campionario \\(\\Omega\\).La definizione 13.1 rende chiaro che il calcolo delle probabilità richiede di contare il numero di modi cui un evento può realizzarsi.\nPer esempio, nell’esperimento casuale corrispondente al lancio di due dadi equilibrati, l’evento \\(\\) = “la somma dei due dati è 5” si può realizzare 4 modi diversi: \\(= \\{ (1, 4), (2, 3), (3, 2), (4, 1) \\}\\).\nContare il numero di modi cui un evento può realizzarsi può essere semplice, nel caso di alcuni eventi (come il presente), oppure estremamente complesso, nel caso di altri eventi. questo secondo caso, per contare il numero di modi cui un evento può realizzarsi, al fine di calcolare la probabilità definita come indicato sopra, è necessario fare uso del calcolo combinatorio. queste dispense ci accontenteremo di presentare alcune nozioni di base del calcolo combinatorio, ma non entreremo nei dettagli di questo argomento.","code":""},{"path":"il-calcolo-delle-probabilità.html","id":"una-definizione-non-ingenua-della-probabilità","chapter":"Capitolo 13 Il calcolo delle probabilità","heading":"13.4.2 Una definizione non ingenua della probabilità","text":"Il calcolo combinatorio ci consente di contare il numero di casi nello spazio campionario e di applicare la definizione “ingenua” di probabilità descritta nella\ndefinizione 13.1. È però facile rendersi conto che tale definizione di probabilità ha un grosso problema: non può essere applicata al caso di uno spazio campionario infinito. Dobbiamo dunque trovare una definizione che risolva un tale problema.L’attuale nozione matematica di probabilità ha impiegato diverse centinaia di anni per cristallizzarsi. Non cerca di rispondere difficili domande filosofiche come “Che cos’è la casualità?” “Da dove viene?” “Qual è il significato della probabilità nel mondo reale?” ecc., ma ci offre un modello matematico che si rivela estremamente efficace nella modellazione dei fenomeni del mondo reale.Nella maggior parte dei trattamenti matematici contemporanei della probabilità, la nozione di base è quella uno spazio di probabilità, che è un modello matematico di un esperimento casuale. Esempi di un esperimento casuale sono tre lanci successivi di una moneta equilibrata o la scelta di un punto casuale un quadrato di area unitaria.Uno spazio di probabilità è una tripla (\\(\\Omega\\), \\(\\mathcal{F}\\), \\(P\\)). La prima componente viene chiamata spazio campionario ed è un insieme costituito da tutti possibili risultati dell’esperimento casuale. Ogni elemento \\(\\omega \\\\Omega\\) è chiamato evento elementare. Per l’esempio dei tre lanci di una moneta, lo spazio campionario consiste di tutte le possibili sequenze di tre lettere costituite da H (testa) e T (croce): \\(\\Omega\\) = {HHH, HHT, …, TTT}. Per l’esempio della scelta di un punto casuale un quadrato, lo spazio campionario è costituito da tutti punti contenuti nell’area del quadrato.La seconda componente \\(\\mathcal{F}\\) di uno spazio di probabilità è un insieme di sottoinsiemi di \\(\\Omega\\). Ogni insieme \\(E \\\\mathcal{F}\\) è chiamata evento. Un esempio concreto di evento nell’esperimento dei tre lanci di una moneta è “numero dispari di risultati croce,” ovvero \\(E = {HHT, HTH, THH, TTT}\\). Nell’esempio della scelta di un punto casuale un quadrato, tutte le figure geometriche ’interno del quadrato sono degli eventi.L’ultimo componente \\(P\\) di uno spazio di probabilità è una funzione che\nassegna un numero reale \\(P(E)\\), chiamato probabilità di \\(E\\), ogni\nevento \\(E \\\\mathcal{F}\\). Nell’esempio dei tre lanci di una moneta, consideriamo tutti gli eventi elementari egualmente probabili, e la probabilità di un evento \\(E\\) è definita come il rapporto tra il numero degli eventi elementari \\(E\\) e il numero degli eventi elementari nello spazio campionario. Nell’esempio della scelta di un punto casuale un quadrato, la probabilità dell’evento \\(E\\) che corrisponde ad una qualche figura geometrica inscritta nel quadrato è data dal rapporto tra l’area di tale figura geometrica e l’area totale del quadrato.La tripla (\\(\\Omega\\), \\(\\mathcal{F}\\), \\(P\\)) deve soddisfare seguenti assiomi, che\nfurono presentati per la prima volta questa forma da Kolmogorov negli anni ’30:\\(P(E) ≥ 0\\) per ciascun \\(E \\\\mathcal{F}\\).\\(P(\\Omega) = 1\\) (l’esperimento produce sempre qualche risultato).\\(P\\) se \\(E_1, E_2, \\dots\\) è una sequenza di eventi mutuamente disgiunti, ne segue che\n\\[\nP\\left(\\bigcup\\limits_{=1}^{\\infty} E_i \\right) = \\sum_{=1}^\\infty P(E_i)\n\\]Gli assiomi (1) e (2) sono molto intuitivi, così come l’additività nel caso di un numero finito di eventi. L’additività numerabile non può essere supportata dall’intuizione, ma è uno strumento fondamentale nella teoria della probabilità e della statistica.La precedente definizione di uno spazio di probabilità corrisponde al cosiddetto approccio assiomatico messo punto da Kolmogorov intorno al 1930, il quale è alla base della moderna teoria della probabilità. Gli assiomi di Kolmogorov sono necessari per evitare paradossi che si possono creare quando si manipolano gli insiemi – ad esempio, l’utilizzo dell’“l’insieme di tutti gli insiemi” tipicamente conduce ad un paradosso.","code":""},{"path":"il-calcolo-delle-probabilità.html","id":"assegnare-le-probabilità-agli-eventi","chapter":"Capitolo 13 Il calcolo delle probabilità","heading":"13.5 Assegnare le probabilità agli eventi","text":"È importante capire che l’approccio assiomatico non ci dice però come sia possibile assegnare un valore di probabilità un evento \\(E \\\\Omega\\). questo proposito esistono due diverse scuole di pensiero.","code":""},{"path":"il-calcolo-delle-probabilità.html","id":"approccio-frequentista","chapter":"Capitolo 13 Il calcolo delle probabilità","heading":"13.5.1 Approccio frequentista","text":"Una prima possibilità è di definire la nozione di probabilità termini\nempirici. La probabilità di un evento \\(\\) può essere concepita come il\nlimite cui tende la frequenza relativa dell’evento, al tendere\n’infinito del numero delle prove effettuate, ossia\n\\[\\begin{equation}\nP_A = \\lim_{n \\\\infty} \\frac{n_A}{n}.\n\\end{equation}\\]\nQuesto è l’approccio che abbiamo utilizzato precedenza, quando abbiamo discusso il gioco di De Méré.Tale definizione assume che l’esperimento possa essere ripetuto più\nvolte, idealmente infinite volte, sotto le medesime condizioni, e\ncorrisponde alla definizione frequentista di probabilità. Per\nl’approccio frequentista, dire che la probabilità di ottenere testa è\n0.5 significa affermare che l’evento “testa” verrebbe ottenuto nel 50%\ndei casi, se ripetessimo tantissime volte l’esperimento casuale del\nlancio di una moneta.Se non abbiamo disposizione informazioni empiriche proposito del\nverificarsi di un evento possiamo attribuire le probabilità agli eventi\nusando la nostra conoscenza della situazione. Tale approccio è seguito\ndalla definizione classica di probabilità base alla quale la\nprobabilità di un evento è il rapporto tra il numero di casi favorevoli\ne quelli possibili, supposto che tutti gli eventi siano equiprobabili,\nossia\n\\[\nP_A = \\frac{n_A}{n},\n\\]\ndove \\(n\\) è il numero di casi possibili e \\(n_A\\) è il numero di casi favorevoli per l’evento \\(\\). L’assunzione di equiprobabilità degli eventi elementari ha senso soprattutto nel caso dei giochi d’azzardo.base ’approccio frequentista, la probabilità è il limite cui\ntende una frequenza relativa empirica al crescere del numero di\nripetizioni dell’esperimento casuale. È molto facile utilizzare   per\ncalcolare una tale probabilità. Per esempio, se vogliamo calcolare la\nprobabilità di ottenere 3 nel lancio di un dado equilibrato, possiamo\neseguire la seguente simulazione.Il risultato è ovviamente molto simile \\(1/6\\).","code":"\nn <- 1e5\nx <- sample(1:6, n, replace = TRUE)\nx_01 <- ifelse(x == 3, 1, 0)\nmean(x_01)\n#> [1] 0.1676"},{"path":"il-calcolo-delle-probabilità.html","id":"approccio-bayesiano","chapter":"Capitolo 13 Il calcolo delle probabilità","heading":"13.5.2 Approccio Bayesiano","text":"Esistono però degli eventi per quali non è possibile calcolare una frequenza relativa, ovvero quelli che si verificano una volta soltanto. Che cos’è allora la probabilità questi casi? base ’approccio Bayesiano la probabilità è una misura del grado di plausibilità di una proposizione. Questa definizione è applicabile qualsiasi evento. Ciò consente di assegnare una probabilità anche proposizioni quali “il candidato \\(\\) vincerà le elezioni” oppure “l’accusato è innocente,” anche se non è possibile ripetere più volte un’elezione o un evento criminoso.Per assegnare le probabilità agli eventi, nell’approccio Bayesiano si\nutilizzano considerazioni “soggettive” che derivano dalle informazioni\ndi cui il soggetto è possesso. Il teorema di Bayes consente di\naggiustare, alla luce dei dati osservati, tali credenze “priori” per\narrivare alla probabilità posteriori. Quindi, tramite l’approccio\nBayesiano, si usa una stima del grado di plausibilità di una\nproposizione prima dell’osservazione dei dati, al fine di associare un\nvalore numerico al grado di plausibilità di quella stessa proposizione\nsuccessivamente ’osservazione dei dati. Questo processo di\n“aggiornamento Bayesiano” corrisponde ’inferenza statistica e verrà\ndiscusso dettaglio nel seguito delle dispense.","code":""},{"path":"il-calcolo-delle-probabilità.html","id":"proprietà-elementari-della-probabilità","chapter":"Capitolo 13 Il calcolo delle probabilità","heading":"13.6 Proprietà elementari della probabilità","text":"Indipendentemente da come decidiamo di interpretare la probabilità (\ntermini frequentisti o Bayesiani), alla probabilità possono essere\nassegnate le seguenti proprietà.La probabilità dell’evento impossibile è zero:\n\\[P(\\emptyset) = 1 - P(\\Omega) = 0.\\]La probabilità dell’evento impossibile è zero:\n\\[P(\\emptyset) = 1 - P(\\Omega) = 0.\\]Se consideriamo due eventi \\(\\) e \\(B\\) tali che \\(\\subseteq B\\), cioè\nche \\(\\) è contenuto o coincidente con \\(B\\), da ciò segue che\n\\[P() \\leq P(B).\\]Se consideriamo due eventi \\(\\) e \\(B\\) tali che \\(\\subseteq B\\), cioè\nche \\(\\) è contenuto o coincidente con \\(B\\), da ciò segue che\n\\[P() \\leq P(B).\\]Se \\(^c\\) è il complementare dell’evento \\(\\), allora\n\\[P(^c) = 1 - P().\\]Se \\(^c\\) è il complementare dell’evento \\(\\), allora\n\\[P(^c) = 1 - P().\\]Dati \\(n\\) eventi \\(A_i\\) per \\(= 1, \\cdots, n\\), gli eventi si dicono\nindipendenti se risulta\n\\[P(A_i \\cap A_j \\cap \\cdots \\cap A_k) = P(A_i) P(A_j) \\cdots P(A_k).\\]Dati \\(n\\) eventi \\(A_i\\) per \\(= 1, \\cdots, n\\), gli eventi si dicono\nindipendenti se risulta\n\\[P(A_i \\cap A_j \\cap \\cdots \\cap A_k) = P(A_i) P(A_j) \\cdots P(A_k).\\]Se due eventi \\(\\) e \\(B\\) non sono disgiunti, allora quando sommiamo\nle loro probabilità dobbiamo evitare che la loro parte comune\n\\(\\cap B\\) venga contata due volte. Dati due eventi non\nnecessariamente disgiunti, dunque, la probabilità dell’unione è pari\nalla somma delle singole probabilità dei due eventi meno la\nprobabilità dell’intersezione:\n\\[\\begin{equation}\nP(\\text{ o } B) = P(\\cup B) = P() + P(B) - P(\\cap B).\n\\tag{13.1}\n\\end{equation}\\]Se due eventi \\(\\) e \\(B\\) non sono disgiunti, allora quando sommiamo\nle loro probabilità dobbiamo evitare che la loro parte comune\n\\(\\cap B\\) venga contata due volte. Dati due eventi non\nnecessariamente disgiunti, dunque, la probabilità dell’unione è pari\nalla somma delle singole probabilità dei due eventi meno la\nprobabilità dell’intersezione:\n\\[\\begin{equation}\nP(\\text{ o } B) = P(\\cup B) = P() + P(B) - P(\\cap B).\n\\tag{13.1}\n\\end{equation}\\]","code":""},{"path":"il-calcolo-delle-probabilità.html","id":"variabili-aleatorie","chapter":"Capitolo 13 Il calcolo delle probabilità","heading":"13.7 Variabili aleatorie","text":"Tutte le nozioni che abbiamo discusso precedenza sono necessarie per potere definire il concetto di “variabile aleatoria.” Le variabili aleatorie sono un concetto fondamentale della teoria statistica e delle sue applicazioni. Infatti, le variabili aleatorie sono lo strumento che usiamo per valutare, per esempio, l’efficacia di un intervento psicologico. Un intervento psicologico, infatti, può essere concepito come un “esperimento casuale” e le variabili aleatorie ci consentono di riassumere risultati di un esperimento casuale e di quantificare il grado di certezza che possiamo assegnare ’esito osservato, nel contesto di tutti gli esiti possibili che, linea di principio, sarebbe stato possibile osservare. Il significato di “variabile aleatoria” è semplice; meno semplice è capire come manipolare le variabili aleatorie. Ma iniziamo con una definizione.Il dominio della variabile aleatoria \\(X\\) (che è una funzione) è dato dai\npunti dello spazio campionario \\(\\Omega\\). Ad ogni evento elementare\n\\(\\omega_i\\) attribuiamo il numero \\(X(\\omega_i)\\), ovvero il valore che la\nvariabile aleatoria assume sul risultato \\(\\omega_i\\) dell’esperimento\ncasuale. L’attributo “aleatoria” si riferisce al fatto che la variabile\nconsiderata trae origine da un esperimento casuale di cui non siamo grado di\nprevedere l’esito con certezza.Mediante una variabile aleatoria trasformiamo lo spazio campionario\n\\(\\Omega\\), che genere è complesso, uno spazio campionario più\nsemplice formato da un insieme di numeri. Il maggior vantaggio di questa\nsostituzione è che molte variabili aleatorie, definite su spazi\ncampionari anche molto diversi tra loro, danno luogo ad una stessa\n“distribuzione” di probabilità sull’asse reale. Le variabili aleatorie\nsi indicano con le lettere maiuscole ed valori da esse assunti con le\nlettere minuscole.Ci sono due classi di variabili aleatorie: variabili aleatorie discrete\ne variabili aleatorie continue. Consideriamo innanzitutto il caso delle\nvariabili aleatorie discrete.Se \\(X\\) è una variabile aleatoria discreta allora l’insieme dei possibili\nvalori \\(x\\), tali per cui \\(P(X = x) > 0\\), viene detto “supporto” di \\(X\\).Alcuni esempi di variabili aleatorie discrete sono seguenti: il numero\ndi intrusioni di pensieri, immagini, impulsi indesiderabili un\npaziente OCD, il voto ’esame di Psicometria, la durata di vita di un\nindividuo, il numero dei punti che si osservano nel lancio di due dadi e\nil guadagno (la perdita) che un giocatore realizzerà \\(n\\) partite. Si\nnoti che, tutti questi casi, la variabile aleatoria considerata viene\nrappresentata mediante un numero.","code":""},{"path":"il-calcolo-delle-probabilità.html","id":"a-cosa-servono-le-variabili-aleatorie","chapter":"Capitolo 13 Il calcolo delle probabilità","heading":"13.7.1 A cosa servono le variabili aleatorie?","text":"Facendo riferimento agli esempi elencati sopra, possiamo chiederci\nperché questi numeri vengono considerati come “aleatori.” È ovvio che\nnoi non conosciamo, ad esempio, il voto di Psicometria di Mario Rossi\nprima del momento cui Mario Rossi avrà fatto l’esame. Le variabili\naleatorie si pongono il seguente problema: come possiamo descrivere le\nnostre opinioni rispetto al voto (possibile) di Mario Rossi, prima che\nlui abbia fatto l’esame. Prima dell’esame, il voto di Psicometria di\nMario Rossi si può solo descrivere facendo riferimento ad un insieme di\nvalori possibili. Inoltre, molto spesso, possiamo anche dire che tali\nvalori possibili non sono tutti egualmente verosimili: ci aspettiamo di\nosservare più spesso alcuni di questi valori rispetto agli altri. Le\nproprietà delle variabili aleatorie ci consentono di sistematizzare\nquesto tipo di opinioni. Ovviamente, una volta che Mario Rossi avrà\nfatto l’esame, questa materia non avrà più alcuna componente aleatoria.","code":""},{"path":"il-calcolo-delle-probabilità.html","id":"funzione-di-massa-di-probabilità","chapter":"Capitolo 13 Il calcolo delle probabilità","heading":"13.7.2 Funzione di massa di probabilità","text":"Per entrare nel merito di questa discussione, chiediamoci ora come sia\npossibile associare delle probabilità ai valori che vengono assunti\ndalle variabili aleatorie. Ad esempio, qual è la probabilità che Mario\nRossi ottenga 29 ’esame? Ci occuperemo qui del caso delle variabili\naleatorie discrete.Alle variabili aleatorie discrete vengono assegnale le probabilità\nmediante le cosiddette “distribuzioni di probabilità.” Una distribuzione\ndi probabilità è un modello matematico che collega ciascun valore di una\nvariabile aleatoria discreta alla probabilità di osservare un tale\nvalore un esperimento casuale. pratica, ad ognuno dei valori che\npossono essere assunti da una variabile aleatoria discreta viene\nassociata una determinata probabilità. La funzione che associa ad ogni\nvalore della variabile aleatoria una probabilità corrispondente si\nchiama “distribuzione di probabilità” oppure “legge di probabilità.”Una descrizione intuitiva del concetto di distribuzione di probabilità\npuò essere formulata nei termini seguenti. Possiamo pensare alla\nprobabilità come ad una quantità positiva che viene “distribuita”\nsull’insieme dei valori della variabile aleatoria. Tale “distribuzione”\n(suddivisione, spartizione) viene scalata maniera tale che ciascun\nelemento di essa corrisponda ad una proporzione del totale, nel senso\nche il valore totale della distribuzione è sempre pari 1. Una\ndistribuzione di probabilità non è dunque altro che un modo per\nsuddividere la nostra certezza (cioè 1) tra valori che la variabile\naleatoria può assumere. modo più formale, possiamo dire quanto segue.maniera più semplice, una distribuzione di (massa) di probabilità è\nformata dall’elenco di tutti valori possibili di una variabile\naleatoria discreta e dalle probabilità loro associate. Si noti che\n\\(P_{\\pi}(X=x)\\) è un numero positivo se il valore \\(x\\) è compreso nel\nsupporto di \\(X\\), altrimenti vale 0.Se \\(\\) è un sottoinsieme della variabile aleatoria \\(X\\), allora denotiamo\ncon \\(P_{\\pi}()\\) la probabilità assegnata ad \\(\\) dalla distribuzione\n\\(P_{\\pi}\\). Mediante una distribuzione di probabilità \\(P_{\\pi}\\) è\npossibile determinare la probabilità di ciascun sottoinsieme\n\\(\\subset X\\) come \\[P_{\\pi}() = \\sum_{x \\} P_{\\pi}(x).\\] Qui non\nfacciamo altro che applicare il terzo assioma di Kolmogorov. Soluzione.  Per risolvere tale problema iniziamo considerare il fatto che l’evento \\(S = 7\\) si verifica corrispondenza di sei punti elementari dello spazio campionario \\(\\Omega\\): {(1, 6), (2, 5), (3, 4), (4, 3), (2, 5), (6, 1)}. Dunque,\n\\[\\begin{equation}\nP(S = 7) = P\\{(1, 6)\\} + P\\{(2, 5)\\} + P\\{(3, 4)\\} + P\\{(4, 3)\\} + P\\{(2, 5)\\} + P\\{(6, 1)\\}.\n\\end{equation}\\]\nSe possiamo assumere che due dadi sono bilanciati, allora ciascun evento elementare dello spazio campionario ha probabilità \\(\\frac{1}{36}\\) e la probabilità cercata diventa \\(\\frac{1}{6}\\). È facile estendere il ragionamento fatto sopra tutti valori che \\(S\\) può assumere. questo modo giungiamo alla funzione di massa di probabilità \\(P_0\\) riportata nella prima riga della tabella seguente.Distribuzione di massa di probabilità per la somma dei punti\nprodotti dal lancio di due dadi bilanciati (\\(P_0\\)) e di due dadi\ntruccati (\\(P_1\\)).Per considerare un caso più generale, poniamoci ora il problema di\ntrovare la funzione di massa di probabilità di \\(S\\) nel caso di due dadi\ntruccati aventi la seguente distribuzione di probabilità:\n\\[\n\\begin{aligned}\nP(\\{1\\}) = P(\\{6\\}) &= \\frac{1}{4};\\notag\\\\\nP(\\{2\\}) = P(\\{3\\}) = P(\\{4\\}) = P(\\{5\\}) = \\frac{1}{8}\\notag.\n\\label{eq:loaded_dice}\n\\end{aligned}\n\\]\nNel caso dei due dadi truccati, la probabilità dell’evento elementare (1, 1) è 1/4 1/4. Dunque, P(S = 2) = 4/64. La probabilità dell’evento elementare (1, 2) è 1/4 1/8. Tale valore è uguale alla probabilità dell’evento elementare (2, 1). La probabilità che S sia uguale 3 è 1/4 1/8 + 1/8 1/4 = 4/64, e così via. Svolgendo calcoli per tutti possibili valori di S otteniamo la funzione di massa di probabilità \\(P_1\\) riportata nella seconda riga della tabella precedente.","code":""},{"path":"il-calcolo-delle-probabilità.html","id":"notazione","chapter":"Capitolo 13 Il calcolo delle probabilità","heading":"13.8 Notazione","text":"Qui sotto è riportata la notazione che verrà usata per fare riferimento\nad eventi e probabilità, nel caso discreto e continuo, maniera tale\nche queste convenzioni siano elencate tutte un posto solo.Gli eventi sono denotati da lettere maiuscole, es. \\(\\), \\(B\\), \\(C\\).Una variabile aleatoria è denotata da una lettera maiuscola, ad\nesempio \\(X\\), e assume valori denotati dalla stessa lettera\nminuscola, ad esempio \\(x\\).La connessione tra eventi e valori viene espressa nei termini\nseguenti: “\\(X = x\\)” significa che l’evento \\(X\\) assume il valore \\(x\\).La probabilità di un evento è denotata con \\(P()\\).Una variabile aleatoria discreta ha una funzione di massa di\nprobabilità denotata con \\(p(x)\\). La relazione tra \\(P\\) e \\(p\\) è che\n\\(P(X=x) = p(x)\\).","code":""},{"path":"il-calcolo-delle-probabilità.html","id":"conclusioni-2","chapter":"Capitolo 13 Il calcolo delle probabilità","heading":"Conclusioni","text":"questo capitolo abbiamo visto come si costruisce lo spazio\ncampionario di un esperimento casuale, quali sono le proprietà di base\ndella probabilità e come si assegnano le probabilità agli eventi\ndefiniti sopra uno spazio campionario discreto. Abbiamo anche introdotto\nle nozioni di “variabile aleatoria” e di “funzione di massa di\nprobabilità.” Le procedure di analisi dei dati psicologici che\ndiscuteremo seguito faranno un grande uso di questi concetti e della\nnotazione qui introdotta.","code":""},{"path":"chapter-prob-cond.html","id":"chapter-prob-cond","chapter":"Capitolo 14 Probabilità condizionata","heading":"Capitolo 14 Probabilità condizionata","text":"L’attribuzione di una probabilità ad un evento è sempre condizionata\ndalle conoscenze che abbiamo disposizione. Per un determinato stato di\nconoscenze, attribuiamo ad un dato evento una certa probabilità di\nverificarsi; ma se il nostro stato di conoscenze cambia, allora cambierà\nanche la probabilità che attribuiamo ’evento questione. Per\nesempio, posiamo chiederci quale sia probabilità che Mario Rossi superi\nl’esame di Psicometria nel primo appello del presente anno accademico.\nassenza di altre informazioni, la migliore stima di tale probabilità\nè data dalla proporzione di studenti che hanno superato l’esame di\nPsicometria nel corrispondente appello dei passati anni accademici. Ma\nse sappiamo che Mario Rossi è particolarmente portato per le materie\nquantitative, ha un’ottima preparazione di base e ha studiato molto,\nallora la probabilità sarà sicuramente più alta.","code":""},{"path":"chapter-prob-cond.html","id":"probabilità-condizionata-su-altri-eventi","chapter":"Capitolo 14 Probabilità condizionata","heading":"14.1 Probabilità condizionata su altri eventi","text":"La probabilità condizionata è una componente essenziale del ragionamento\nscientifico dato che chiarisce come sia possibile incorporare le\nevidenze disponibili, maniera logica e coerente, nella nostra\nconoscenza del mondo. Infatti, si può pensare che tutte le probabilità\nsiano probabilità condizionate, anche se l’evento condizionante non è\nsempre esplicitamente menzionato. Consideriamo il seguente problema.Esercizio.\nLo screening per la diagnosi precoce del tumore mammario si avvale di\ntest che sono accurati al 90%, nel senso che il 90% delle donne con\ncancro e il 90% delle donne senza cancro saranno classificate\ncorrettamente. Supponiamo che l’1% delle donne sottoposte allo screening\nabbia effettivamente il cancro al seno. Ci chiediamo: qual è la\nprobabilità che una donna scelta casualmente abbia una mammografia\npositiva e, se ce l’ha, qual è la probabilità che abbia davvero il\ncancro?Soluzione.\nPer risolvere questo problema, supponiamo che il test questione venga\nsomministrato ad un grande campione di donne, diciamo 1000 donne. Di\nqueste 1000 donne, 10 (ovvero, l’1%) hanno il cancro al seno. Per queste\n10 donne, il test darà un risultato positivo 9 casi (ovvero, nel 90%\ndei casi). Per le rimanenti 990 donne che non hanno il cancro al seno,\nil test darà un risultato positivo 99 casi (se la probabilità di un\nvero positivo è del 90%, la probabilità di un falso positivo è del 10%).\nQuesta situazione è rappresentata nella figura 14.1.\nMettendo insieme questi due risultati, vediamo che il test dà un risultato positivo per 9 donne che hanno effettivamente il cancro al seno e per 99 donne che non ce l’hanno, per un totale di 108 risultati positivi. Dunque, la probabilità di ottenere un risultato positivo al test è \\(\\frac{108}{1000}\\) = 11%. Ma delle 108\ndonne che hanno ottenuto un risultato positivo al test, solo 9 hanno il\ncancro al seno. Dunque, la probabilità di avere il cancro, dato un\nrisultato positivo al test, è pari \\(\\frac{9}{108}\\) = 8%.\nFigura 14.1: Rappresentazione ad albero che riporta le frequenze attese dei risultati di una mammografia un campione di 1,000 donne\nNell’esercizio precedente, la probabilità dell’evento “ottenere un risultato positivo al test” è una probabilità non condizionata, mentre la probabilità dell’evento “avere il cancro al seno, dato che il test ha dato un risultato positivo” è una probabilità condizionata. termini generali, la probabilità condizionata \\(P(\\mid B)\\) rappresenta la probabilità che si verifichi l’evento \\(\\) sapendo che si è verificato\nl’evento \\(B\\); oppure: la probabilità di \\(\\) una prova valida solo se\nsi verifica anche \\(B\\). Ciò ci conduce alla seguente definizione.alcuni casi può essere conveniente leggere al contrario la\nformula 14.1 e utilizzarla per calcolare la probabilità\ndell’intersezione di due eventi. Per esempio se conosciamo la\nprobabilità dell’evento \\(B\\) e la probabilità condizionata di \\(\\) su \\(B\\),\notteniamo\n\\[\\begin{equation}\nP(\\cap B) = P(B)P(\\mid B),\n\\tag{14.2}\n\\end{equation}\\]\nmentre se conosciamo la probabilità dell’evento \\(\\) e la probabilità condizionata di \\(B\\) su \\(\\), otteniamo \\(P(\\cap B) = P()P(B \\mid )\\).Esercizio.\nDa un mazzo di 52 carte (13 carte per ciascuno dei 4 semi) ne viene\nestratta 1 modo casuale. Qual è la probabilità che esca una figura di\ncuori? Sapendo che la carta estratta ha il seme di cuori, qual è la\nprobabilità che il valore numerico della carta sia 7, 8 o 9?Soluzione.\nCi sono 13 carte di cuori, dunque la risposta alla prima domanda è 1/4.\nPer rispondere alla seconda domanda consideriamo solo le 13 carte di\ncuori; la probabilità cercata è dunque 3/13.","code":""},{"path":"chapter-prob-cond.html","id":"la-fallacia-del-pubblico-ministero","chapter":"Capitolo 14 Probabilità condizionata","heading":"14.2 La fallacia del pubblico ministero","text":"Un errore comune che si commette è quello di credere che \\(P(\\mid B)\\)\nsia uguale \\(P(B \\mid )\\). Tale fallacia ha particolare risalto \nambito forense tanto che è conosciuta con il nome di “fallacia del\nprocuratore” (prosecutor’s fallacy). essa, una piccola probabilità\ndell’evidenza, data l’innocenza, viene erroneamente interpretata come la\nprobabilità dell’innocenza, data l’evidenza.Consideriamo il caso di un esame del DNA. Un esperto forense potrebbe\naffermare, ad esempio, che “se l’imputato è innocente, c’è solo una\npossibilità su un miliardo che vi sia una corrispondenza tra il suo DNA\ne il DNA trovato sulla scena del crimine.” Ma talvolta questa\nprobabilità è erroneamente interpretata come avesse il seguente\nsignificato: “date le prove del DNA, c’è solo una possibilità su un\nmiliardo che l’imputato sia innocente.”Le considerazioni precedenti risultano più chiare se facciamo nuovamente\nriferimento ’esercizio sul tumore mammario descritto sopra. tale esercizio abbiamo visto come la probabilità di cancro dato un risultato positivo al test sia uguale 0.08. Tale probabilità è molto diversa dalla probabilità di un risultato\npositivo al test data la presenza del cancro. Infatti, questa seconda\nprobabilità è uguale 0.90 ed è descritta nel problema come una delle\ncaratteristiche del test questione.","code":""},{"path":"chapter-prob-cond.html","id":"legge-della-probabilità-composta","chapter":"Capitolo 14 Probabilità condizionata","heading":"14.3 Legge della probabilità composta","text":"Il teorema della probabilità composta deriva dal concetto di probabilità\ncondizionata per cui la probabilità che si verifichino due eventi \\(A_i\\)\ne \\(A_j\\) è pari alla probabilità di uno dei due eventi moltiplicato con\nla probabilità dell’altro evento condizionato al verificarsi del primo.L’equazione (14.2) si estende al caso di \\(n\\) eventi \\(A_1, \\dots, A_n\\) nella forma seguente:\n\\[\\begin{equation}\n\\begin{split}\nP(A_1 \\cap A_2 \\cap \\dots\\cap A_n) = {}& P(A_1)P(A_2 \\mid A_1)P(A_3 \\mid A_1 \\cap A_2) \\dots\\\\\n & P(A_n \\mid A_1 \\cap A_2 \\cap \\dots \\cap A_{n-1})\n\\end{split}\n\\tag{14.3}\n\\end{equation}\\]\nla quale esprime forma generale la legge della probabilità composta.Esercizio.\nDa un’urna contenente 6 palline bianche e 4 nere si estrae una pallina\nper volta, senza reintrodurla nell’urna. Indichiamo con \\(B_i\\) l’evento:\n“esce una pallina bianca alla \\(\\)-esima estrazione” e con \\(N_i\\)\nl’estrazione di una pallina nera. L’evento: “escono due palline bianche\nnelle prime due estrazioni” è rappresentato dalla intersezione\n\\(\\{B_1 \\cap B_2\\}\\) e la sua probabilità vale, per la (14.2)\n\\[\nP(B_1 \\cap B_2) = P(B_1)P(B_2 \\mid B_1).\n\\]\n\\(P(B_1)\\) vale 6/10, perché nella prima estrazione \\(\\Omega\\) è costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilità condizionata \\(P(B_2 \\mid B_1)\\) vale 5/9, perché nella seconda estrazione, se è verificato l’evento \\(B_1\\), lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava\npertanto:\n\\[\n  P(B_1 \\cap B_2) = \\frac{6}{10} \\cdot \\frac{5}{9} = \\frac{1}{3}.\n\\]\nmodo analogo si ha che\n\\[\nP(N_1 \\cap N_2) = P(N_1)P(N_2 \\mid N_1) = \\frac{4}{10} \\cdot \\frac{3}{9} = \\frac{4}{30}.\n\\]Se l’esperimento consiste nell’estrazione successiva di 3 palline, la\nprobabilità che queste siano tutte bianche vale, per\nla (14.3):\n\\[\nP(B_1 \\cap B_2 \\cap B_3)=P(B_1)P(B_2 \\mid B_1)P(B_3 \\mid B_1 \\cap B_2),\n\\]\ndove la probabilità \\(P(B_3 \\mid B_1 \\cap B_2)\\) si calcola supponendo che\nsi sia verificato l’evento condizionante \\(\\{B_1 \\cap B_2\\}\\). Lo spazio\ncampionario per questa probabilità condizionata è costituito da 4\npalline bianche e 4 nere, per cui \\(P(B_3 \\mid B_1 \\cap B_2) = 1/2\\) e\nquindi:\n\\[\nP (B_1 \\cap B_2 \\cap B_3) = \\frac{6}{10}\\cdot\\frac{5}{9} \\cdot\\frac{4}{8}  = \\frac{1}{6}.\n\\]La probabilità dell’estrazione di tre palline nere è invece:\n\\[\n\\begin{aligned}\nP(N_1 \\cap N_2 \\cap N_3) &= P(N_1)P(N_2 \\mid N_1)P(N_3 \\mid N_1 \\cap N_2)\\notag\\\\ \n&= \\frac{4}{10} \\cdot \\frac{3}{9} \\cdot \\frac{2}{8} = \\frac{1}{30}.\\notag\n\\end{aligned}\n\\]","code":""},{"path":"chapter-prob-cond.html","id":"lindipendendenza-stocastica","chapter":"Capitolo 14 Probabilità condizionata","heading":"14.4 L’indipendendenza stocastica","text":"Un concetto molto importante per le applicazioni statistiche della\nprobabilità è quello dell’indipendenza stocastica. La\ndefinizione (14.1) esprime il concetto intuitivo di indipendenza\ndi un evento da un altro, nel senso che il verificarsi di \\(\\) non\ninfluisce sulla probabilità del verificarsi di \\(B\\), ovvero non la\ncondiziona. Infatti, per la definizione (14.1) di probabilità condizionata, si ha che, se \\(\\) e \\(B\\) sono due eventi indipendenti, risulta:\n\\[\nP(\\mid B) = \\frac{P()P(B)}{P(B)} = P().\\notag\n\\]\nPossiamo dunque dire che due eventi \\(\\) e \\(B\\) sono indipendenti se\n\\[\n\\begin{split}\nP(\\mid B) &= P(), \\\\\nP(B \\mid ) &= P(B).\n\\end{split}\n\\]Esercizio.\nNel lancio di due dadi non truccati, si considerino gli eventi:\n= {esce un 1 o un 2 nel primo lancio} e B = {il punteggio\ntotale è 8}. Gli eventi e B sono indipendenti?Soluzione.\nRappresentiamo qui sotto lo spazio campionario dell’esperimento casuale.\nFigura 14.2: Rappresentazione dello spazio campionario dei risultati dell’esperimento casuale corrispondente al lancio di due dadi bilanciati. Sono evidenziati gli eventi elementari che costituiscono l’evento : esce un 1 o un 2 nel primo lancio.\nGli eventi e B non sono statisticamente indipendenti. Infatti, le\nloro probabilità valgono P() = 12/36 e P(B) = 5/36 e la probabilità\ndella loro intersezione è\n\\[\nP(\\cap B) = 1/36 = 3/108 \\neq P()P(B) = 5/108.\n\\]\n Si noti che il concetto di indipendenza è del tutto differente da quello\ndi incompatibilità. Due eventi e B incompatibili (per quali si\nha \\(\\cap B = \\emptyset\\)) sono statisticamente dipendenti, poiché il\nverificarsi dell’uno esclude il verificarsi dell’altro:\n\\(P(\\cap B)=0 \\neq P()P(B)\\).Si noti inoltre che, se due eventi con probabilità non nulla sono statisticamente indipendenti, la legge delle probabilità totali espressa dalla (13.1) si modifica nella relazione seguente:\\[\\begin{equation}\nP(\\cup B) = P() + P(B) - P()P(B).\n\\end{equation}\\]","code":""},{"path":"chapter-prob-cond.html","id":"conclusioni-3","chapter":"Capitolo 14 Probabilità condizionata","heading":"Conclusioni","text":"La probabilità condizionata è importante perché ci fornisce uno\nstrumento per precisare il concetto di indipendenza statistica. Una\ndelle più importanti domande delle analisi statistiche è infatti quella\nche si chiede se due variabili siano o meno associate. questo\ncapitolo abbiamo discusso il concetto di indipendenza (come contrapposto\nal concetto di associazione); nel capitolo Statistica descrittiva abbiamo descritto poi uno dei modi possibili che ci consentono di quantificare l’associazione tra due variabili. seguito vedremo come sia possibile fare inferenza sull’associazione tra variabili – ovvero, come stabilire il livello di\nfiducia nel verificarsi dell’evento esaminato nel campione un\ncontesto più ampio, cioè quello della popolazione.","code":""},{"path":"chapter-teo-bayes.html","id":"chapter-teo-bayes","chapter":"Capitolo 15 Il teorema di Bayes","heading":"Capitolo 15 Il teorema di Bayes","text":"Il teorema di Bayes ha un ruolo centrale nella statistica Bayesiana,\nanche se viene utilizzato anche dall’approccio frequentista. Prima di\nesaminare il teorema di Bayes introdurremo una sua componente, ovvero il\nteorema della probabilità totale.","code":""},{"path":"chapter-teo-bayes.html","id":"il-teorema-della-probabilità-totale","chapter":"Capitolo 15 Il teorema di Bayes","heading":"15.1 Il teorema della probabilità totale","text":"Il teorema della probabilità totale fa uso della legge della probabilità\ncomposta (14.3) per calcolare le probabilità di casi più\ncomplessi di quelli considerati fino ad ora. La notazione sembra\ncomplessa, ma l’idea sottostante è semplice. Discutiamo qui il teorema\ndella probabilità totale considerando il caso di una partizione dello\nspazio campionario tre sottoinsiemi. È facile estendere tale\nsituazione al caso di una partizione un qualunque numero di\nsottoinsiemi.Il teorema della probabilità totale afferma che, se l’evento \\(E\\) è\ncostituito da tutti gli eventi elementari \\(E \\cap A_1\\), \\(E \\cap A_2\\)\ne \\(E \\cap A_3\\), allora la probabilità \\(P(E)\\) è data dalla somma delle\nprobabilità di queti tre eventi. Ciò è illustrato nella figura seguente.Esercizio.Si considerino tre urne, ciascuna delle quali contiene 100 palline:Urna 1: 75 palline rosse e 25 palline blu,Urna 2: 60 palline rosse e 40 palline blu,Urna 3: 45 palline rosse e 55 palline blu.Una pallina viene estratta caso da un’urna anch’essa scelta caso.\nQual è la probabilità che la pallina estratta sia di colore rosso?Soluzione.\nSia \\(R\\) l’evento “la pallina estratta è rossa” e sia \\(U_i\\) l’evento che\ncorrisponde alla scelta dell’\\(\\)-esima urna. Sappiamo che\n\\[\nP(R \\mid U_1) = 0.75, \\qquad P(R \\mid U_2) = 0.60, \\qquad P(R \\mid U_3) = 0.45.\n\\]\nGli eventi \\(U_1\\), \\(U_2\\) e \\(U_3\\) costituiscono una partizione dello\nspazio campionario quanto \\(U_1\\), \\(U_2\\) e \\(U_3\\) sono eventi\nmutualmente esclusivi ed esaustivi, \\(P(U_1 \\cup U_2 \\cup U_3) = 1.0\\). \nbase al teorema della probabilità totale, la probabilità di estrarre una\npallina rossa è\n\\[\n\\begin{aligned}\nP(R) &= P(R \\mid U_1)P(U_1)+P(R \\mid U_2)P(U_2)+P(R \\mid U_3)P(U_3)\\notag\\\\\n&= 0.75 \\cdot \\frac{1}{3}+0.60 \\cdot \\frac{1}{3}+0.45 \\cdot \\frac{1}{3} =0.60.\\notag\n\\end{aligned}\n\\]Esercizio.\nConsideriamo un’urna che contiene 5 palline rosse e 2 palline verdi. Due\npalline vengono estratte, una dopo l’altra. Vogliamo sapere la\nprobabilità dell’evento “la seconda pallina estratta è rossa.”Soluzione.\nLo spazio campionario è \\(\\Omega = \\{RR, RV, VR, VV\\}\\). Chiamiamo \\(R_1\\)\nl’evento “la prima pallina estratta è rossa,” \\(V_1\\) l’evento “la prima\npallina estratta è verde,” \\(R_2\\) l’evento “la seconda pallina estratta è\nrossa” e \\(V_2\\) l’evento “la seconda pallina estratta è verde.” Dobbiamo\ntrovare \\(P(R_2)\\) e possiamo risolvere il problema usando il teorema\ndella probabilità\ntotale (15.2):\\[\\begin{equation}\n\\begin{aligned}\nP(R_2) &= P(R_2 \\mid R_1) P(R_1) + P(R_2 \\mid V_1)P(V_1)\\notag\\\\\n&= \\frac{4}{6} \\cdot \\frac{5}{7} + \\frac{5}{6} \\cdot \\frac{2}{7} = \\frac{30}{42} = \\frac{5}{7}.\\notag\n\\end{aligned}\n\\end{equation}\\]\nSe la prima estrazione è quella di una pallina rossa, nell’urna restano\n4 palline rosse e due verdi, dunque, la probabilità che la seconda\nestrazione produca una pallina rossa è uguale 4/6. La probabilità di\nuna pallina rossa nella prima estrazione è 5/7. Se la prima estrazione è\nquella di una pallina verde, nell’urna restano 5 palline rosse e una\npallina verde, dunque, la probabilità che la seconda estrazione produca\nuna pallina rossa è uguale 5/6. La probabilità di una pallina verde\nnella prima estrazione è 2/7.","code":""},{"path":"chapter-teo-bayes.html","id":"il-teorema-della-probabilità-delle-cause","chapter":"Capitolo 15 Il teorema di Bayes","heading":"15.2 Il teorema della probabilità delle cause","text":"Il teorema di Bayes rappresenta uno dei fondamenti della teoria della\nprobabilità e della statistica. Lo presentiamo qui considerando prima un\ncaso specifico per poi descriverlo nella sua forma più generale.Sia \\(\\{A_1, A_2\\}\\) una partizione dello spazio campionario \\(\\Omega\\).\nConsideriamo un terzo evento \\(E \\subset \\Omega\\) con probabilità non\nnulla di cui si conoscono le probabilità condizionate rispetto ad \\(A_1\\)\ne \\(A_2\\), ovvero \\(P(E \\mid A_1)\\) e \\(P(E \\mid A_2)\\). È chiaro per le\nipotesi fatte che se si verifica \\(E\\) deve anche essersi verificato\nalmeno uno degli eventi \\(A_1\\) e \\(A_2\\). Supponendo che si sia verificato\nl’evento \\(E\\), ci chiediamo: qual è la probabilità che si sia verificato\n\\(A_1\\) piuttosto che \\(A_2\\)?Per rispondere alla domanda precedente scriviamo:\n\\[\\begin{equation}\n\\begin{aligned}\nP(A_1 \\mid E) &= \\frac{P(E \\cap A_1)}{P(E)}\\notag\\\\ \n&= \\frac{P(E \\mid A_1)P(A_1)}{P(E)}\\notag.\\end{aligned}\n\\end{equation}\\]\nSapendo che \\(E = (E \\cap A_1) \\cup (E \\cap A_2)\\) e che \\(A_1\\) e \\(A_2\\) sono eventi\ndisgiunti, ovvero \\(A_1 \\cap A_2 = \\emptyset\\), ne segue che possiamo\ncalcolare \\(P(E)\\) utilizzando il teorema della probabilità totale:\n\\[\\begin{equation}\n\\begin{aligned}\nP(E) &= P(E \\cap A_1) + P(E \\cap A_2)\\notag\\\\ \n     &= P(E \\mid A_1)P(A_1) + P(E \\mid A_2)P(A_2).\\notag\n\\end{aligned}\n\\end{equation}\\]\nSostituendo il risultato precedente nella formula della probabilità condizionata \\(P(A_1 \\mid E)\\) otteniamo:\n\\[\\begin{equation}\nP(A_1 \\mid E) = \\frac{P(E \\mid A_1)P(A_1)}{P(E \\mid A_1)P(A_1) + P(E \\mid A_2)P(A_2)}.\n\\tag{15.3}\n\\end{equation}\\]\nLa (15.3) si generalizza facilmente al caso di più di due eventi disgiunti, come indicato di seguito.La formula (15.4) prende il nome di Teorema di Bayes e mostra che\nla conoscenza del verificarsi dell’evento \\(E\\) modifica la probabilità\nche abbiamo attribuito ’evento \\(A_j\\).","code":""},{"path":"chapter-teo-bayes.html","id":"aggiornamento-bayesiano","chapter":"Capitolo 15 Il teorema di Bayes","heading":"15.2.1 Aggiornamento Bayesiano","text":"Consideriamo ora un’altra applicazione del teorema di Bayes che ci fa\ncapire come l’applicazione di questo teorema ci consente di modificare\nuna credenza priori maniera dinamica, via via che nuove evidenze\nvengono raccolta, modo tale da formulare una credenza posteriori la\nquale non è mai definitiva, ma può essere sempre aggiornata base alle\nnuove evidenze disponibili. Questo processo si chiama aggiornamento\nBayesiano.Supponiamo che, per qualche strano errore di produzione, una fabbrica\nproduca due tipi di monete. Il primo tipo di monete ha la caratteristica\nche, quando una moneta viene lanciata, la probabilità di osservare\nl’esito “testa” è 0.6. Per semplicità, sia \\(\\theta\\) la probabilità di\nosservare l’esito “testa.” Per una moneta del primo tipo, dunque,\n\\(\\theta = 0.6\\). Per una moneta del secondo tipo, invece, la probabilità\ndi produrre l’esito “testa” è 0.4. Ovvero, \\(\\theta = 0.4\\).Noi possediamo una moneta, ma non sappiamo se è del primo tipo o del secondo\ntipo. Sappiamo solo che il 75% delle monete sono del primo tipo e il 25%\nsono del secondo tipo. Sulla base di questa conoscenza priori –\novvero sulla base di una conoscenza ottenuta senza avere eseguito\nl’esperimento che consiste nel lanciare la moneta una serie di volte per\nosservare gli esiti prodotti – possiamo dire che la probabilità di una\nprima ipotesi, secondo la quale \\(\\theta = 0.6\\), è 3 volte più grande\ndella probabilità di una seconda ipotesi, secondo la quale\n\\(\\theta = 0.4\\). Senza avere eseguito alcun esperimento casuale con la\nmoneta, questo è quello che sappiamo.Ora immaginiamo di lanciare una moneta due volte e di ottenere il\nrisultato seguente: \\(\\{T, C\\}\\). Quello che ci chiediamo è: sulla base di\nquesta evidenza, come cambiano le probabilità che associamo alle due\nipotesi? altre parole, ci chiediamo qual è la probabilità di ciascuna\nipotesi alla luce dei dati che sono stati osservati: \\(P(H \\mid x)\\),\nladdove \\(x\\) sono dati osservati. Tale probabilità si chiama\nprobabilità posteriori. Inoltre, se confrontiamo le due ipotesi, ci\nchiediamo quale valore assuma il rapporto \\(\\frac{P(H_1 \\mid x)}{P(H_2 \\mid x)}\\).\nTale rapporto ci dice quanto è più probabile \\(H_1\\) rispetto ad \\(H_2\\), alla luce dei dati osservati.\nInfine, ci chiediamo come cambia il rapporto definito sopra, quando osserviamo via via nuovi risultati prodotti dal lancio della moneta.Definiamo il problema maniera più chiara.\nConosciamo le probabilità priori, ovvero \\(P(H_1) = 0.75\\) e \\(P(H_1) = 0.25\\).\nQuello che vogliamo conoscere sono le probabilità posteriori \\(P(H_1 \\mid x)\\) e\n\\(P(H_2 \\mid x)\\).Per trovare le probabilità posteriori applichiamo il teorema di Bayes:\n\\[\nP(H_1 \\mid x) = \\frac{P(x \\mid H_1) P(H_1)}{P(x)} = \n\\frac{P(x \\mid H_1) P(H_1)}{P(x \\mid H_1) P(H_1) + P(x \\mid H_2) P(H_2)}\n\\]\nladdove lo sviluppo del denominatore deriva da un’applicazione del teorema della probabilità totale.\nInoltre,\n\\[\nP(H_2 \\mid x) = \n\\frac{P(x \\mid H_2) P(H_2)}{P(x \\mid H_1) P(H_1) + P(x \\mid H_2) P(H_2)}.\n\\]\nSe consideriamo l’ipotesi \\(H_1\\) = “la probabilità di testa è 0.6,” allora\nla verosimiglianza dei dati \\(\\{T, C\\}\\), ovvero la probabilità di osservare questa specifica sequenza di T e C, è uguale \\(0.6 \\times 0.4 = 0.24.\\)\nDunque, \\(P(x \\mid H_1) = 0.24\\).Se invece consideriamo l’ipotesi \\(H_2\\) = “la probabilità di testa è 0.4,” allora la verosimiglianza dei dati \\(\\{T, C\\}\\) è \\(0.4 \\times 0.6 = 0.24\\), ovvero, \\(P(x \\mid H_2) = 0.24\\).\nbase alle due ipotesi \\(H_1\\) e \\(H_2\\), dunque, dati osservati hanno la\nmedesima plausibilità di essere osservati.\nPer semplicità, calcoliamo anche\n\\[\n\\begin{aligned}\nP(x) &= P(x \\mid H_1) P(H_1) + P(x \\mid H_2) P(H_2) = 0.24 \\cdot 0.75 + 0.24 \\cdot 0.25 = 0.24.\\notag\n\\end{aligned}\n\\]Le probabilità posteriori diventano:\n\\[\n\\begin{aligned}\nP(H_1 \\mid x) &= \\frac{P(x \\mid H_1) P(H_1)}{P(x)} = \\frac{0.24 \\cdot 0.75}{0.24} = 0.75,\\notag\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\nP(H_2 \\mid x) &= \\frac{P(x \\mid H_2) P(H_2)}{P(x)} = \\frac{0.24 \\cdot 0.25}{0.24} = 0.25.\\notag\n\\end{aligned}\n\\]\nPossiamo dunque concludere dicendo che, sulla base dei dati osservati, l’ipotesi \\(H_1\\) ha una probabilità 3 volte maggiore di essere vera dell’ipotesi \\(H_2\\).È tuttavia possibile raccogliere più evidenze e, sulla base di esse, le probabilità posteriori cambieranno.\nSupponiamo di lanciare la moneta una terza volta e di osservare croce.\nnostri dati dunque sono \\(\\{T, C, C\\}\\).Di conseguenza, \\(P(x \\mid H_1) = 0.6 \\cdot 0.4 \\cdot 0.4 = 0.096\\) e \\(P(x \\mid H_2) = 0.4 \\cdot 0.6 \\cdot 0.6 = 0.144\\).\nNe segue che le probabilità posteriori diventano:\n\\[\n\\begin{aligned}\nP(H_1 \\mid x) &= \\frac{P(x \\mid H_1) P(H_1)}{P(x)} = \\frac{0.096 \\cdot 0.75}{0.096 \\cdot 0.75 + 0.144 \\cdot 0.25} = 0.667,\\notag\n\\end{aligned}\n\\]\n\\[\\begin{aligned}\nP(H_2 \\mid x) &= \\frac{P(x \\mid H_2) P(H_2)}{P(x)} = \\frac{0.144 \\cdot 0.25}{0.096 \\cdot 0.75 + 0.144 \\cdot 0.25} = 0.333.\\notag\\end{aligned}\\]\nqueste circostanze, le evidenze che favoriscono \\(H_1\\) nei confronti\ndi \\(H_2\\) sono solo pari ad un fattore di 2.Se otteniamo ancora croce un quarto lancio della moneta, nostri\ndati diventano: \\(\\{T, C, C, C\\}\\).\nRipetendo il ragionamento fatto sopra,\n\\(P(x \\mid H_1) = 0.6 \\cdot 0.4 \\cdot 0.4 \\cdot 0.4 = 0.0384\\) e\n\\(P(x \\mid H_2) = 0.4 \\cdot 0.6 \\cdot 0.6 \\cdot 0.6 = 0.0864\\).Dunque\n\\[\n\\begin{aligned}\nP(H_1 \\mid x) &= \\frac{0.0384 \\cdot 0.75}{0.0384 \\cdot 0.75 + 0.0864 \\cdot 0.25} = 0.571,\\notag\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\nP(H_2 \\mid x) &= \\frac{0.0864 \\cdot 0.25}{0.0384 \\cdot 0.75 + 0.0864 \\cdot 0.25} = 0.429.\\notag\n\\end{aligned}\n\\]\ne le evidenze favore di \\(H_1\\) si riducono 1.33. Se si ottenesse un\naltro esito croce un sesto lancio della moneta, l’ipotesi \\(H2\\)\ndiventerebbe più probabile dell’ipotesi \\(H_1\\).conclusione, questo esercizio ci fa capire come sia possibile aggiornare le nostre credenze sulla base delle evidenze disponibili, ovvero come sia possibile passare da un grado di conoscenza del mondo priori una conoscenza posteriori.\nSe prima di lanciare la moneta ritenevamo che l’ipotesi \\(H_1\\) fosse tre volte più plausibile dell’ipotesi \\(H_2\\), dopo avere osservato uno specifico campione di dati siamo giunti alla conclusione opposta.\nIl processo di aggiornamento Bayesiano, dunque, ci fornisce un metodo per modificare il livello di fiducia una data ipotesi, alla luce di nuove informazioni.","code":""},{"path":"chapter-teo-bayes.html","id":"conclusioni-4","chapter":"Capitolo 15 Il teorema di Bayes","heading":"Conclusioni","text":"Il teorema di Bayes costituisce il fondamento dell’approccio più moderno\ndella statistica, quello appunto detto Bayesiano. Chi usa il teorema di\nBayes non è, solo per questo motivo, “bayesiano.” Ci vuole ben altro. Ci\nvuole un modo diverso per intendere il significato della probabilità e\nun modo diverso per intendere gli obiettivi dell’inferenza statistica.\nL’approccio bayesiano è stato, negli scorsi decenni, un approccio\npiuttosto dogmatico questi temi e, causa di ciò, è stato considerato\nda alcuni come un metodo un po’ troppo lontano dall’atteggiamento\ncritico e non dogmatico che costituisce il fondamento della comunità\nscientifica. anni recenti, questi aspetti più “ruvidi” dell’approccio\nbayesiano sono stati abbandonati e una gran parte della comunità\nscientifica riconosce ’approccio bayesiano il merito di consentire lo\nsviluppo di modelli anche molto complessi senza, d’altra parte,\nrichiedere conoscenze matematiche troppo avanzate ’utente. Per questa\nragione l’approccio bayesiano sta prendendo sempre più piede, anche \npsicologia. Un introduzione questi temi sarà presentata nell’ultima\nparte di queste dispense.","code":""},{"path":"chapter-prob-congiunta.html","id":"chapter-prob-congiunta","chapter":"Capitolo 16 Probabilità congiunta","heading":"Capitolo 16 Probabilità congiunta","text":"Finora abbiamo considerato unicamente le leggi di singole variabile\naleatorie. Tuttavia, psicologia e nella vita quotidiana, siamo spesso\ninteressati studiare problemi di probabilità legati al valore\ncongiunto di due o più variabili aleatorie. Ad esempio, potremmo\nmisurare il QI dei bambini e il loro peso alla nascita, o l’altezza e il\npeso delle giraffe, o il livello di inquinamento atmosferico e il tasso\ndi malattie respiratorie nelle città, o il numero di amici di Facebook e\nl’età. Che relazione tra le variabili ci possiamo aspettare ciascuno\ndi questi esempi? Perché?Per capire la relazione che sussiste tra due variabili aleatorie è\nnecessario calcolare gli indici di covarianza e correlazione. Per\nfare ciò è necessario utilizzare la funzione di probabilità congiunta.\nL’obiettivo di questo capitolo è quello di chiarire cosa si intende per\nfunzione di probabilità congiunta di due variabili casuali \\(X\\) e \\(Y\\).\nEsamineremo qui dettaglio il caso discreto.","code":""},{"path":"chapter-prob-congiunta.html","id":"funzione-di-probabilità-congiunta","chapter":"Capitolo 16 Probabilità congiunta","heading":"16.1 Funzione di probabilità congiunta","text":"Dopo aver trattato delle distribuzioni di probabilità di una variabile\naleatoria, che associa ad ogni evento elementare dello spazio\ncampionario uno ed un solo numero reale, è naturale estendere questo\nconcetto al caso di due o più dimensioni. Iniziamo descrivere il caso\ndiscreto con un esempio. Consideriamo qui l’esperimento casuale\ncorrispondente al lancio di tre monete equilibrate. Lo spazio\ncampionario di tale esperimento casuale è\n\\[\\Omega = \\{TTT, TTC, TCT, CTT, CCT, CTC, TCC, CCC\\}.\\] Dato che tre\nlanci sono tra loro indipendenti, non c’è ragione di aspettarsi che uno\ndegli otto risultati possibili dell’esperimento sia più probabile degli\naltri, dunque possiamo associare ciascuno degli otto eventi elementari\ndello spazio campionario la stessa probabilità, ovvero 1/8.Su tale spazio campionario consideriamo le variabili aleatorie\n\\(X \\\\{0, 1, 2, 3\\}\\), che conta il numero delle teste nei tre lanci, e\n\\(Y \\\\{0, 1\\}\\), che conta il numero delle teste al primo lancio.\nIndicando con T = ‘testa’ e C = ‘croce,’ si ottiene dunque la situazione\nriportata nella tabella successiva.Spazio campionario dell’esperimento consistente nel lancio di tre\nmonete equilibrate su cui sono state definite le variabili aleatorie\n\\(X\\) e \\(Y\\).Ci poniamo il problema di associare un livello di probabilità ad ogni\ncoppia \\((x, y)\\) definita su \\(\\Omega\\). La coppia \\((X = 0, Y = 0)\\) si\nrealizza corrispondenza di un solo evento elementare, ovvero CCC;\navrà dunque una probabilità pari \\(Pr(X=0, Y=0) = Pr(CCC) = 1/8\\). Nel\ncaso della coppia \\((X = 1, Y = 0)\\) ci sono due eventi elementari che\ndanno luogo al risultato considerato, ovvero, CCT e CTC; la probabilità\n\\(Pr(X=1, Y=0)\\) sarà dunque data dall’unione delle probabilità dei due\neventi elementari corrispondenti, cioé\n\\(Pr(X=1, Y=0) = Pr(CCT \\:\\cup\\: CTC) = 1/8 + 1/8 = 1/4\\). Riportiamo qui\nsotto calcoli svolti per tutti possibili valori di \\(X\\) e \\(Y\\).\n\\[\n\\begin{aligned}\nP(X = 0, Y = 0) &= P(\\omega_8 = CCC) = 1/8; \\notag\\\\\nP(X = 1, Y = 0) &= P(\\omega_5 = CCT) + P(\\omega_6 = CTC) = 2/8; \\notag\\\\\nP(X = 1, Y = 1) &= P(\\omega_7 = TCC) = 1/8; \\notag\\\\\nP(X = 2, Y = 0) &= P(\\omega_4 = CTT) = 1/8; \\notag\\\\\nP(X = 2, Y = 1) &= P(\\omega_3 = TCT) + P(\\omega_2 = TTC) = 2/8; \\notag\\\\\nP(X = 3, Y = 1) &= P(\\omega_1 = TTT) = 1/8; \\notag\n\\end{aligned}\n\\]Le probabilità così trovate possono essere riportate nella\ntabella seguente.Distribuzione di probabilità congiunta per risultati\ndell’esperimento consistente nel lancio di tre monete equilibrate.La tabella qui sopra ci fornisce il risultato che cercavamo, ovvero la distribuzione di probabilità congiunta delle variabili aleatorie \\(X\\) = “numero di realizzazioni con il risultato testa nei tre lanci” e \\(Y\\) = “numero di realizzazioni con il risultato testa nel primo lancio” per l’esperimento casuale considerato.\nUna generica funzione di probabilità congiunta bivariata può essere\nrappresentata come qui indicato.generale, possiamo dire che, dato uno spazio campionario discreto\n\\(\\Omega\\), è possibile associare ad ogni evento elementare \\(\\omega_i\\)\ndello spazio campionario una coppia di numeri reali \\((x, y)\\), essendo\n\\(x = X(\\omega)\\) e \\(y = Y(\\omega)\\), il che ci conduce alla seguente\ndefinizione.La funzione che associa ad ogni coppia \\((x, y)\\) un livello di\nprobabilità prende il nome di funzione di probabilità congiunta:\n\\[P(x, y) = P(X = x, Y = y).\\]\nIl termine “congiunta” deriva dal fatto che questa probabilità è legata\nal verificarsi di una coppia di valori, il primo associato alla\nvariabile aleatoria \\(X\\) ed il secondo alla variabile aleatoria \\(Y\\). Nel\ncaso di due sole variabili, si parla di distribuzione bivariata, mentre\nnel caso di più variabili si parla di distribuzione multivariata.","code":""},{"path":"chapter-prob-congiunta.html","id":"proprietà","chapter":"Capitolo 16 Probabilità congiunta","heading":"16.1.1 Proprietà","text":"Una distribuzione di massa di probabilità congiunta bivariata deve\nsoddisfare due proprietà:\\(0 \\leq p(x_i, y_j) \\leq 1\\);\\(0 \\leq p(x_i, y_j) \\leq 1\\);la probabilità totale deve essere uguale \\(1.0\\). Tale proprietà può\nessere espressa nel modo seguente\n\\[\\sum_{} \\sum_{j} p(x_i, y_j) = 1.0.\\]la probabilità totale deve essere uguale \\(1.0\\). Tale proprietà può\nessere espressa nel modo seguente\n\\[\\sum_{} \\sum_{j} p(x_i, y_j) = 1.0.\\]","code":""},{"path":"chapter-prob-congiunta.html","id":"eventi","chapter":"Capitolo 16 Probabilità congiunta","heading":"16.1.2 Eventi","text":"Si noti che dalla probabilità congiunta possiamo calcolare la\nprobabilità di qualsiasi evento definito base alle variabili\naleatorie \\(X\\) e \\(Y\\). Per capire come questo possa essere fatto,\nconsideriamo nuovamente l’esperimento discusso sopra.Esercizio.\nPer la distribuzione di massa di probabilità congiunta riportata nella\ntabella precedente si trovi la probabilità dell’evento \\(X+Y \\leq 1\\).Soluzione.\nPer trovare la probabilità richiesta dobbiamo semplicemente sommare le\nprobabilità associate tutte le coppie \\((x,y)\\) che soddisfano la\ncondizione \\(X+Y \\leq 1\\), ovvero\n\\[\n\\begin{aligned}\nP_{XY}(X+Y \\leq 1) = &P_{XY}(0, 0) + P_{XY}(1, 0)= 3/8.\\notag\n\\end{aligned}\n\\]","code":""},{"path":"chapter-prob-congiunta.html","id":"funzioni-di-probabilità-marginali","chapter":"Capitolo 16 Probabilità congiunta","heading":"16.1.3 Funzioni di probabilità marginali","text":"Data la funzione di probabilità congiunta \\(p(x, y)\\) è possibile pervenire alla costruzione della funzione di probabilità della singola variabile aleatoria, \\(X\\) o \\(Y\\):\n\\[\np_X(x) = P(X = x) = \\sum_y p(x,y)\n\\]\n\\[\np_Y(y) = P(Y = y) = \\sum_x p(x,y)\n\\]\nche prendono, rispettivamente, il nome di funzione di probabilità marginale di \\(X\\) funzione di probabilità marginale di \\(Y\\). Si noti che \\(P_X\\) e \\(P_Y\\) sono normalizzate:\n\\[\n\\sum_x P_X(x) = 1.0, \\quad \\sum_y P_Y(y) = 1.0.\n\\]Per l’esperimento casuale consistente nel lancio di tre monete equilibrate, si calcolino le probabilità marginali di \\(X\\) e \\(Y\\).Nell’ultima colonna destra e nell’ultima riga basso della tabella seguente sono riportate le distribuzioni di probabilità marginali di \\(X\\) e \\(Y\\). \\(P_X\\) si ottiene sommando su ciascuna riga fissata la colonna \\(j\\), \\(P_X(X = j) = \\sum_y p_{xy}(x = j, y)\\). \\(P_Y\\) si trova sommando su ciascuna colonna fissata la riga \\(,\\) \\(P_Y (Y = ) = \\sum_x p_{xy}(x, y = )\\). Si noti che:\n\\[\n\\sum_x P_X(x) = 1, \\quad \\sum_y P_Y(y) = 1.\n\\]Distribuzione di probabilità congiunta \\(p(x,y)\\) per risultati\ndell’esperimento consistente nel lancio di tre monete equilibrate e\nprobabilità marginali \\(p(x)\\) e \\(p(y)\\).","code":""},{"path":"chapter-prob-congiunta.html","id":"indipendenza-stocastica","chapter":"Capitolo 16 Probabilità congiunta","heading":"16.2 Indipendenza stocastica","text":"Ora abbiamo tutti gli strumenti per dare una precisa definizione\nstatistica al concetto di indipendenza. La definizione proposta\nsarà necessariamente coerente con la definizione di indipendenza che\nabbiamo usato fino ad ora. Ma, espressa questi nuovi termini, potrà\nessere utilizzata indagini probabilistiche e statistiche più\ncomplesse. Ricordiamo che gli eventi \\(\\) e \\(B\\) si dicono indipendenti se\n\\(P (\\cap B)\\, = P() P(B)\\). Diciamo quindi che \\(X\\) e \\(Y\\) sono\nindipendenti se qualsiasi evento definito da \\(X\\) è indipendente da\nqualsiasi evento definito da \\(Y\\). La definizione formale che garantisce\nche ciò accada è la seguente.Le variabili aleatorie \\(X\\) e \\(Y\\) sono indipendenti se la loro distribuzione congiunta è il prodotto delle rispettive distribuzioni marginali:\n\\[\nP(X, Y)\\, = P_X(x)P_Y(y).\n\\]Nel caso discreto, dunque, l’indipendenza implica che la probabilità\nriportata ciascuna cella della tabella di probabilità congiunta deve\nessere uguale al prodotto delle probabilità marginali di riga e di\ncolonna: \\[p(x_i, y_i)\\, = p_X(x_i) p_Y(y_i).\\notag\\]Esercizio.\nPer la situazione rappresentata nella tabella qui sopra le variabili aleatorie \\(X\\) e \\(Y\\) sono indipendenti?Soluzione.\nNella tabella le variabili aleatorie \\(X\\) e \\(Y\\) non sono indipendenti: le probabilità congiunte non sono ricavabili dal prodotto delle marginali. Per esempio, nessuna delle probabilità marginali è uguale \\(0\\) per cui nessuno dei valori dentro la tabella (probabilità congiunte) che risulta essere uguale \\(0\\) può essere il prodotto delle probabilità marginali.","code":""},{"path":"chapter-prob-congiunta.html","id":"conclusioni-5","chapter":"Capitolo 16 Probabilità congiunta","heading":"Conclusioni","text":"La funzione di probabilità congiunta tiene simultaneamente conto del\ncomportamento di due variabili aleatorie \\(X\\) e \\(Y\\) e di come esse si\ninfluenzano reciprocamente. particolare, si osserva che se le due\nvariabili non si influenzano, cioè se sono statisticamente indipendenti,\nallora la distribuzione di massa di probabilità congiunta si ottiene\ncome prodotto delle funzioni di probabilità marginali di \\(X\\) e \\(Y\\):\n\\(P_{X, Y}(x, y) = P_X(x) P_Y(y)\\).","code":""},{"path":"la-distribuzione-binomiale.html","id":"la-distribuzione-binomiale","chapter":"Capitolo 17 La distribuzione binomiale","heading":"Capitolo 17 La distribuzione binomiale","text":"Un esperimento casuale che può dare luogo solo due possibili esiti\n(successo, insuccesso) è modellabile con una variabile aleatoria di\nBernoulli. Una sequenza di prove di Bernoulli costituisce un processo\nBernoulliano. Il numero di successi dopo \\(N\\) prove di Bernoulli è dato\nda una variabile aleatoria che segue la legge Binomiale. La\ndistribuzione Binomiale è una delle più importanti distribuzioni di\nprobabilità discrete.","code":""},{"path":"la-distribuzione-binomiale.html","id":"una-prova-bernoulliana","chapter":"Capitolo 17 La distribuzione binomiale","heading":"17.1 Una prova Bernoulliana","text":"Se un esperimento casuale ha solo due esiti possibili, allora le\nrepliche indipendenti di questo esperimento sono chiamate “prove\nBernoulliane” (il lancio di una moneta è il tipico esempio). Viene detta\nvariabile di Bernoulli una variabile aleatoria discreta \\(X = \\{0, 1\\}\\)\ncon la seguente distribuzione di probabilità: \\[f(X; p) =\n  \\begin{cases}\n    p     & \\text{se $X = 1$}, \\\\\n    1 - p & \\text{se $X = 0$},\n  \\end{cases}\\] con \\(0 \\leq p \\leq 1\\). Convenzionalmente l’evento\n\\(\\{X = 1\\}\\) con probabilità \\(p\\) viene chiamato “successo” mentre\nl’evento \\(\\{X = 0\\}\\) con probabilità \\(1-p\\) viene chiamato “fallimento.”\nApplicando l’operatore di valore atteso e di varianza, otteniamo\n\\[\n\\begin{aligned}\n\\mathbb{E}(X) &= 0 \\cdot P(X=0) + 1 \\cdot P(X=1) = p,\\\\\nvar(X) &= (0 - p)^2 \\cdot P(X=0) + (1 - p)^2 \\cdot P(X=1) = p(1-p).\n\\end{aligned}\n\\]\nScriviamo \\(X \\sim \\text{Bern}(p)\\) per indicare che la variabile\naleatoria \\(X\\) ha una distribuzione Bernoulliana di parametro \\(p\\).Nel caso del lancio di una moneta onesta, valori della variabile\naleatoria Bernoulliana sono \\(0\\) e \\(1\\). La distribuzione di massa di\nprobabilità è pari \\(\\frac{1}{2}\\) corrispondenza di entrambi \nvalori. La funzione di distribuzione vale \\(\\frac{1}{2}\\) per \\(X = 0\\) e\n\\(1\\) per \\(X = 1\\).","code":""},{"path":"la-distribuzione-binomiale.html","id":"una-sequenza-di-prove-bernoulliane","chapter":"Capitolo 17 La distribuzione binomiale","heading":"17.2 Una sequenza di prove Bernoulliane","text":"La distribuzione Binomiale è rappresentata dall’elenco di tutti \npossibili numeri di successi \\(X = \\{0, 1, 2, \\dots n\\}\\) che possono\nessere osservati \\(n\\) prove Bernoulliane indipendenti di probabilità\n\\(p\\), ciascuno dei quali è associata la relativa probabilità. Esempi di\nuna distribuzione Binomiale sono risultati di una serie di lanci di\nuna stessa moneta o di una serie di estrazioni da un’urna (con\nreintroduzione). La distribuzione Binomiale di parametri \\(n\\) e \\(p\\) è \nrealtà una famiglia di distribuzioni: al variare dei parametri \\(p\\) e \\(n\\)\nvariano le probabilità.La probabilità di ottenere \\(k\\) successi e \\(n-k\\) fallimenti \\(n\\) prove\nBernoulliane è data dalla formula di Bernoulli:\n\\[\n\\begin{aligned}\nP(X=k) &= \\binom{n}{k}  p^{k} (1-p)^{n-k} \\notag \\\\\n&= \\frac{n!}{k!(n-k)!} p^{k} (1-p)^{n-k}, \n\\label{eq:binomial_distribution}\n\\end{aligned}\n\\] dove \\(n\\) = numero di\nprove Bernoulliane, \\(p\\) = probabilità di successo ciascuna prova e\n\\(k\\) = numero di successi.Dimostrazione. Proof. Indichiamo con \\(S\\) il successo e con \\(F\\) il fallimento di\nciascuna prova. Una sequenza di \\(n\\) prove Bernoulliane darà come esito\nuna sequenza di \\(n\\) fra \\(S\\) e \\(F\\). Ad esempio, una sequenza che contiene\n\\(k\\) successi è la seguente:\n\\[\\overbrace{SS\\dots S}^\\text{$k$ volte} \\overbrace{FF\\dots F}^\\text{$n-k$ volte}\\]\nEssendo \\(p\\) la probabilità di \\(S\\) e \\(q = 1-p\\) la probabilità di \\(F\\), la\nprobabilità di ottenere la specifica sequenza riportata sopra è\n\\[\\overbrace{pp\\dots p}^\\text{$k$ volte} \\overbrace{qq\\dots q}^\\text{$n-k$ volte} = p^k \\cdot q^{n-k}.\\]\nÈ immediato notare che una qualsiasi altra sequenza contenente\nesattamente \\(k\\) successi avrà sempre come probabilità\n\\(p^k \\cdot q^{n-k}\\): il prodotto infatti resta costante anche se cambia\nl’ordine dei fattori.Dobbiamo ora chiederci come si possa determinare il numero di sequenze\nche contengono esattamente \\(k\\) successi \\(n\\) prove. La risposta tale\ndomanda ci viene fornita dal coefficiente Binomiale\n\\[\\binom{n}{k} = \\frac{n!}{k!(n-k)!}.\\]Perché il coefficiente Binomiale è la risposta alla domanda che ci siamo\nposti? Per capire perché, facciamo riferimento al triangolo di Tartaglia\n(1499-1557), detto anche triangolo di Pascal. Il triangolo di Tartaglia\nè una tabella forma di triangolo composta da numeri naturali. Le prime\ncinque righe del triangolo di Tartaglia sono riportate qui sotto:Vediamo come si costruisce il triangolo di Tartaglia. Consideriamo una\nsequenza di quattro lanci di una moneta. Il primo lancio può produrre\nzero successi (esito “croce,” 0) o un successo (esito “testa,” 1), come\nindicato qui sotto nella riga indicizzata con \\(n = 1\\).Come indicato nella riga \\(n = 2\\), due lanci possiamo ottenere 0\n(ovvero, croce nel primo lancio e croce nel secondo lancio, \\(\\{00\\}\\)), 1\n(ovvero, croce nel primo lancio e testa nel secondo lancio, oppure testa\nnel primo lancio e croce nel secondo lancio \\(\\{01, 10\\}\\) – si noti che\nun successo due lanci si può ottenere due modi diversi) – oppure\n2 successi (ovvero, testa nel primo lancio e testa nel secondo lancio,\n\\(\\{11\\}\\)). La riga \\(n = 3\\) riporta il numero di sequenze che producono\n0, 1, 2 e 3 successi tre lanci; e così via. Ciò che è importante\nnotare è che ogni numero del triangolo di Tartaglia è un particolare\ncoefficiente binomiale.Possiamo dunque concludere che il coefficiente binomiale fornisce la\nrisposta alla domanda: “quanti modi diversi si possono ottenere \\(k\\)\nsuccessi una sequenza di \\(n\\) prove Bernoulliane?” Se ora combiniamo \ndue risultati che abbiamo descritto sopra (ovvero, “come si calcola la\nprobabilità di una specifica sequenza di teste e croci?” e “quanti\nmodi diversi si possono ottenere \\(k\\) successi \\(n\\) prove?”), giungiamo\nalla formula della distributione binomiale.Esempio. Utilizzando l’equazione della distributione binomiale., troviamo la probabilità di \\(k=2\\)\nsuccessi \\(n=4\\) prove con \\(p=0.2\\):\n\\[\n\\begin{aligned}\nP(X=2) &= \\frac{4!}{2!(4-2)!} 0.2^{2} (1-0.2)^{4-2} \\notag  \\\\\n &= \\frac{4 \\cdot 3 \\cdot 2 \\cdot 1}{(2 \\cdot 1)(2 \\cdot 1)}\n0.2^{2} 0.8^{2} = 0.1536. \\notag\n\\end{aligned}\n\\]\nRipetendo calcoli per valori \\(k = 0, \\dots, 4\\) otteniamo:Lo stesso risultato si ottiene utilizzandoEsempio. Lanciando \\(5\\) volte una moneta onesta, qual è la probabilità che esca\ntesta almeno tre volte?Usando dbinom(3, 5, 0.5) + dbinom(4, 5, 0.5) + dbinom(5, 5, 0.5)\notteniamo 0.5. Alternativamente, possiamo trovare la probabilità\ndell’evento complementare quello definito dalla funzione di\nripartizione calcolata mediante pbinom(), ovvero\n1 - pbinom(2, 5, 0.5) = 0.5.","code":"\ndbinom(0:4, 4, 0.2)\n#> [1] 0.4096 0.4096 0.1536 0.0256 0.0016"},{"path":"la-distribuzione-binomiale.html","id":"media-e-deviazione-standard-della-distribuzione-binomiale","chapter":"Capitolo 17 La distribuzione binomiale","heading":"17.3 Media e deviazione standard della distribuzione Binomiale","text":"La media (numero atteso di successi \\(n\\) prove) e la deviazione\nstandard di una distribuzione Binomiale sono molto semplici:\n\\[\n\\begin{aligned}\n\\mu &= np,  \\notag \\\\\n \\sigma &= \\sqrt{np(1-p)}.\\notag\n \\end{aligned}\n \\]Dimostrazione. Proof. Essendo \\(X\\) la somma di \\(n\\) prove Bernoulliane indipendenti\n\\(X_i\\), è facile vedere che\n\\[\n\\begin{aligned}\n\\mathbb{E}(X) &= \\Ev \\left( \\sum_{=1}^n X_i \\right) = \\sum_{=1}^n \\Ev(X_i) = np, \\\\\nvar(X) &= \\var \\left( \\sum_{=1}^n X_i \\right) = \\sum_{=1}^n \\var(X_i) = n p (1-p).\n\\end{aligned}\n\\]Esempio. Si trovi il valore atteso e la varianza del lancio di quattro monete con\nprobabilità di successo pari \\(p=0.2\\).Il valore atteso è \\(\\mu = np = 4 \\cdot 0.2 = 0.8.\\) Ciò significa che, se\nl’esperimento aleatorio venisse ripetuto infinite volte allora l’esito\ntesta verrebbe osservato un numero medio di volte pari \\(0.8\\). La\nvarianza è \\(n p (1-p) = 4 \\cdot(1 - 0.2) = 0.8\\). L’eguaglianza di \\(\\mu\\)\ne \\(\\sigma\\) è solo una peculiarità di questo esempio.","code":""},{"path":"la-distribuzione-binomiale.html","id":"conclusioni-6","chapter":"Capitolo 17 La distribuzione binomiale","heading":"Conclusioni","text":"Una variabile aleatoria bernoulliana è la più semplice delle variabili aleatorie. Di\nconseguenza, la distribuzione binomiale è la più\nsemplice delle distribuzioni di massa di probabilità. Per questa ragione la distribuzione binomiale viene discussa prima di presentare casi più complessi, perché ci\nfornisce un esempio paradigmatico del tipo di problemi che richiedono,\nper essere risolti, procedure matematicamente più complesse \nsituazioni diverse. L’aspetto matematico, tuttavia, è secondario per \nnostri scopi. tutti casi, è più semplice usare un software per\nsvolgere calcoli, piuttosto che fare una lunga serie di somme\nutilizzando le Tavole delle funzioni di ripartizione di varie\ndistribuzioni di probabilità. Ciò che è cruciale è capire il significato\ndei concetti e come si può utilizzare un software per eseguire \ncalcoli. Nel caso presente, calcoli sono molto semplici e si possono\nanche eseguire mano. seguito vedremo che l’uso di un software sarà\nsempre richiesto.","code":""},{"path":"funzioni-di-densità-di-probabilità.html","id":"funzioni-di-densità-di-probabilità","chapter":"Capitolo 18 Funzioni di densità di probabilità","heading":"Capitolo 18 Funzioni di densità di probabilità","text":"precedenza abbiamo esaminato la distribuzione di massa di probabilità\ndi una variabile aleatoria discreta, ovvero la distribuzione Binomiale.\nPrenderemo ora esame le densità di probabilità di alcune variabili\naleatorie continue. La più importante di esse è la distribuzione\nNormale. realtà vedremo che non c’è solo una distribuzione Normale,\nma ce ne sono molte. Tali distribuzioni sono anche dette Gaussiane \nonore di Carl Friedrich Gauss (uno dei più grandi matematici della\nstoria il quale, tra le altre cose, scoprì l’utilità di tale funzione di\ndensità per descrivere gli errori delle osservazioni astronomiche).\nAdolphe Quetelet, il padre delle scienze sociali quantitative, fu il\nprimo ad applicare tale densità alle misurazioni dell’uomo. Karl Pearson\nusò per primo il termine “distribuzione Normale” anche se ammise che\nquesta espressione “ha lo svantaggio di indurre le persone credere che\ntutte le altre distribuzioni di frequenza siano un senso o nell’altro\nanormali.”","code":""},{"path":"funzioni-di-densità-di-probabilità.html","id":"distribuzione-normale","chapter":"Capitolo 18 Funzioni di densità di probabilità","heading":"18.1 Distribuzione Normale","text":"Chi preferisce un approccio grafico, può consultare il link. Dopo le vignette, per introdurre le distribuzioni normali, considereremo un esempio\nproposto da (McElreath, 2020).Supponiamo che vi siano mille persone tutte allineate su una linea di partenza. Quando viene dato un segnale, ciascuna persona lancia una moneta e fa un passo una\ndirezione oppure nella direzione opposta seconda che sia uscita testa\no croce. Supponiamo che la lunghezza di ciascun passo vari da 0 1\nmetro. Ciascuna persona lancia la moneta 16 volte e dunque fa 16\npassi.Alla conclusione di queste passeggiate aleatorie (random walk), non\npossiamo sapere dove si troverà ciascuna delle persone considerate, ma\npossiamo conoscere con certezza le caratteristiche della distribuzione\ndelle mille distanze dall’origine. Per esempio, possiamo predire la\nproporzione di persone che si saranno spostate avanti oppure indietro.\nOppure, possiamo predire la proporzione di persone che si troveranno ad\nuna certa distanza dalla linea di partenza (es., 1.5 m).Queste predizioni sono possibili perché le distanze create questo\nmodo si distribuiscono secondo la legge Normale. È facile simulare\nquesto processo usando R. risultati della simulazione sono riportati qui di seguito.Questa simulazione mostra che qualunque processo nel quale viene sommato\nun certo numero di valori casuali, tutti provenienti dalla medesima\ndistribuzione, converge ad una distribuzione Normale. Non importa quale\nsia la forma della distribuzione soggiacente. Può essere uniforme, come\nnell’esempio presente, o qualunque altra cosa. La forma della\ndistribuzione soggiacente determina la velocità con cui si realizza la\nconvergenza alla Normale. alcuni casi la convergenza è lenta; \naltri casi, come nell’esempio presente, la convergenza è molto rapida.La distribuzione Normale è importante, primo luogo, perché molti\nfenomeni naturali hanno approssimativamente le caratteristiche descritte\ndall’esempio precedente. secondo luogo, è importante perché molti\nmodelli statistici assumono che il fenomeno aleatorio di interesse abbia\nuna distribuzione Normale. Da un punto di vista formale, una variabile\naleatoria continua \\(X\\) si dice Normale se la sua funzione di densità è\n\\[\nf(x; \\mu, \\sigma) = {1 \\{\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(x- \\mu)^2}{2 \\sigma^2} \\right\\},\n\\]\ndove \\(\\mu \\\\Real\\) e \\(\\sigma > 0\\) sono due\nparametri. La curva di Gauss è unimodale e simmetrica con una\ncaratteristica forma campana e con il punto di massima densità \ncorrispondenza di \\(\\mu\\). Il significato dei parametri \\(\\mu\\) e \\(\\sigma\\)\nche appaiono nella distribuzione Normale viene chiarito dalla\ndimostrazione che\n\\[\n\\mathbb{E}(X) = \\mu, \\qquad var(X) = \\sigma^2.\n\\]","code":"\nset.seed(4)\npos <- \n  replicate(100, runif(16, -1, 1)) %>%        # here's the simulation\n  as_tibble() %>%                             # for data manipulation, we'll make this a tibble\n  rbind(0, .) %>%                             # here we add a row of zeros above the simulation results\n  mutate(step = 0:16) %>%                     # this adds a step index\n  gather(key, value, -step) %>%               # here we convert the data to the long format\n  mutate(person = rep(1:100, each = 17)) %>%  # this adds a person id index\n  # the next two lines allow us to make cumulative sums within each person\n  group_by(person) %>%\n  mutate(position = cumsum(value)) %>%\n  ungroup()  # ungrouping allows for further data manipulation\n#> Warning: The `x` argument of `as_tibble.matrix()` must have unique column names if `.name_repair` is omitted as of tibble 2.0.0.\n#> Using compatibility `.name_repair`.\n\nggplot(data = pos, \n       aes(x = step, y = position, group = person)) +\n  geom_vline(xintercept = c(4, 8, 16), linetype = 2) +\n  geom_line(aes(color = person < 2, alpha  = person < 2)) +\n  scale_color_manual(values = c(\"skyblue4\", \"black\")) +\n  scale_alpha_manual(values = c(1/5, 1)) +\n  scale_x_continuous(\"Numero di passi\", breaks = c(0, 4, 8, 12, 16)) +\n  labs(\n    y = \"Posizione\"\n  )\n  theme(legend.position = \"none\")\n#> List of 1\n#>  $ legend.position: chr \"none\"\n#>  - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n#>  - attr(*, \"complete\")= logi FALSE\n#>  - attr(*, \"validate\")= logi TRUE\n# Figure 4.2.a.\np1 <-\n  pos %>%\n  filter(step == 4) %>%\n  ggplot(aes(x = position)) +\n  geom_line(stat = \"density\", color = \"dodgerblue1\") +\n  labs(title = \"4 steps\")\n\n# Figure 4.2.b.\np2 <-\n  pos %>%\n  filter(step == 8) %>%\n  ggplot(aes(x = position)) +\n  geom_density(color = \"dodgerblue2\", outline.type = \"full\") +\n  labs(title = \"8 steps\")\n\n# this is an intermediary step to get an SD value\nsd <-\n  pos %>%\n  filter(step == 16) %>%\n  summarise(sd = sd(position)) %>% \n  pull(sd)\n\n# Figure 4.2.c.\np3 <-\n  pos %>%\n  filter(step == 16) %>%\n  ggplot(aes(x = position)) +\n  stat_function(fun = dnorm, \n                args = list(mean = 0, sd = sd),\n                linetype = 2) +\n  geom_density(color = \"transparent\", fill = \"dodgerblue3\", alpha = 1/2) +\n  labs(title = \"16 steps\",\n       y = \"density\")\n\nlibrary(\"patchwork\")\n\n# combine the ggplots\n(p1 | p2 | p3) & coord_cartesian(xlim = c(-6, 6))"},{"path":"funzioni-di-densità-di-probabilità.html","id":"concentrazione-della-distribuzione-normale","chapter":"Capitolo 18 Funzioni di densità di probabilità","heading":"18.1.1 Concentrazione della distribuzione Normale","text":"È istruttivo osservare il grado di concentrazione della distribuzione\nNormale attorno alla media:\n\\[\n\\begin{aligned}\nP(\\mu - \\sigma < X < \\mu + \\sigma) &= P (-1 < Z < 1) \\simeq 0.683, \\notag\\\\\nP(\\mu - 2\\sigma < X < \\mu + 2\\sigma) &= P (-2 < Z < 2) \\simeq 0.956, \\notag\\\\\nP(\\mu - 3\\sigma < X < \\mu + 3\\sigma) &= P (-3 < Z < 3) \\simeq 0.997. \\notag\n\\end{aligned}\n\\]\nSi noti come un dato la cui distanza dalla media è superiore 3 volte\nla deviazione standard presenti un carattere di eccezionalità perché\nmeno del 0.3% dei dati della distribuzione Normale presentano questa\ncaratteristica.Per indicare la distribuzione Normale si usa la notazione\n\\(\\mathcal{N}(\\mu, \\sigma)\\). La distribuzione Normale di parametri\n\\(\\mu = 0\\) e \\(\\sigma = 1\\) viene detta distribuzione Normale standard.\nLa famiglia Normale è l’insieme avente come elementi tutte le\ndistribuzioni Normali con parametri \\(\\mu\\) e \\(\\sigma\\) diversi. Tutte le\ndistribuzioni Normali si ottengono dalla Normale standard mediante una\ntrasformazione lineare: se \\(X \\sim \\mathcal{N}(\\mu_X, \\sigma_X)\\) allora\n\\(Y = + b X \\sim \\mathcal{N}(\\mu_Y = +b \\mu_X, \\sigma_Y = \\left|b\\right|\\sigma_X)\\).","code":""},{"path":"funzioni-di-densità-di-probabilità.html","id":"funzione-di-ripartizione-della-distribuzione-normale","chapter":"Capitolo 18 Funzioni di densità di probabilità","heading":"18.1.2 Funzione di ripartizione della distribuzione Normale","text":"Il valore della funzione di ripartizione di \\(X\\) nel punto \\(x\\) è l’area\nsottesa alla curva di densità \\(f(x)\\) nella semiretta \\((-\\infty, x]\\). Non esiste alcuna funzione elementare per la funzione di ripartizione\\[\nF(x) = \\int_{-\\infty}^x {1 \\{\\sigma\\sqrt{2\\pi} }} \\exp \\left\\{-\\frac{(x- \\mu)^2}{2\\sigma^2} \\right\\} dx, \\notag\n\\]\npertanto le probabilità \\(P(X < x)\\) vengono calcolate mediante\nintegrazione numerica approssimata. valori della funzione di\nripartizione di una variabile aleatoria Normale sono dunque forniti da\nun software (passato venivano forniti dalle tavole riportate sui testi di statistica).Esercizio. Possiamo usare R per calcolare la funzione di ripartizione della Normale e per replicare risultati che abbiamo presentato sopra.\nLa funzione pnorm(q, mean, sd) restituisce la funzione di ripartizione della Normale con media mean e deviazione standard sd, ovvero l’area sottesa alla funzione di densità di una Normale con media mean e deviazione standard sd nell’intervallo \\([-\\infty, q]\\).Per esempio, precedenza abbiamo detto che il 68% circa dell’area sottesa ad una Normale è compresa nell’intervallo \\(\\mu \\pm \\sigma\\). Verifichiamo per la distribuzione del QI:Il 95% dell’area è compresa nell’intervallo \\(\\mu \\pm 1.96 \\cdot\\sigma\\):Quasi tutta la distribuzione è compresa nell’intervallo \\(\\mu \\pm 3 \\cdot\\sigma\\):","code":"\npnorm(100+15, 100, 15) - pnorm(100-15, 100, 15)\n#> [1] 0.6826895\npnorm(100+1.96*15, 100, 15) - pnorm(100-1.96*15, 100, 15)\n#> [1] 0.9500042\npnorm(100+3*15, 100, 15) - pnorm(100-3*15, 100, 15)\n#> [1] 0.9973002"},{"path":"funzioni-di-densità-di-probabilità.html","id":"standardizzazione","chapter":"Capitolo 18 Funzioni di densità di probabilità","heading":"18.1.3 Standardizzazione","text":"Per potere utilizzare valori tabulati (ma soprattutto per altri scopi più utili) si ricorre al procedimento di standardizzazione che riconduce una variabile aleatoria distribuita secondo una media \\(\\mu\\) e varianza \\(\\sigma^2\\), ad una variabile\naleatoria con distribuzione “standard,” ovvero di media zero e varianza\npari \\(1\\):\\[\nZ = \\frac{X - \\mu}{\\sigma}.\n\\]L’area sottesa alla curva di densità di \\(X\\) nella semiretta \\((-\\infty, x]\\) è uguale ’area sottesa alla densità Normale standard nella semiretta \\((-\\infty, z]\\), cui\n\\(z = (x -\\mu_X )/\\sigma_X\\) è il punteggio standard di \\(x\\). Per la\nsimmetria della distribuzione, l’area sottesa nella semiretta\n\\([1, \\infty)\\) è uguale ’area sottesa nella semiretta \\((-\\infty, 1]\\) e\nquest’ultima coincide con \\(F(-1)\\). Analogamente, l’area sottesa\nnell’intervallo \\([x_a, x_b]\\), con \\(x_a < x_b\\), è pari \n\\(F(z_b) - F(z_a)\\), dove \\(z_a\\) e \\(z_b\\) sono punteggi standard di \\(x_a\\)\ne \\(x_b\\).Si ha anche il problema inverso rispetto quello del calcolo delle\naree: dato un numero \\(0 \\leq p \\leq 1\\), il problema è quello di\ndeterminare un numero \\(z \\\\Real\\) tale che \\(P(Z < z) = p\\). Il valore\n\\(z\\) cercato è detto quantile di ordine \\(p\\) della Normale standard ed è\ntabulato nelle tavole statistiche o può essere trovato mediante un\nsoftware.Esempio. Supponiamo che l’altezza degli individui adulti segua la distribuzione Normale di media \\(\\mu = 1.7\\) m e deviazione standard \\(\\sigma = 0.1\\) m. Vogliamo sapere la proporzione di individui adulti con un’altezza compresa tra \\(1.7\\) e \\(1.8\\) m.Il problema ci chiede di trovare l’area sottesa alla distribuzione \\(\\mathcal{N}(\\mu = 1.7, \\sigma = 0.1)\\) nell’intervallo \\([1.7, 1.8]\\):La risposta si trova utilizzando la funzione di\nripartizione \\(F(X)\\) della legge \\(\\mathcal{N}(1.7, 0.1)\\) \ncorrispondenza dei due valori forniti dal problema:\n\\(F(X = 1.8) - F(X = 1.7)\\). Utilizzando la seguente istruzioneotteniamo il \\(31.43\\%\\).maniera equivalente, possiamo standardizzare valori che delimitano\nl’intervallo considerato e utilizzare la funzione di ripartizione della\nnormale standardizzata. limiti inferiore e superiore dell’intervallo\nsono\\[\nz_{\\text{inf}} = \\frac{1.7 - 1.7}{0.1} = 0, \\quad z_{\\text{sup}} = \\frac{1.8 - 1.7}{0.1} = 1.0,\n\\]\nquindi otteniamoIl modo più semplice per risolvere questo problema resta comunque quello\ndi rendersi conto che la probabilità richiesta non è altro che la metà\ndell’area sottesa dalle distribuzioni Normali nell’intervallo\n\\([\\mu - \\sigma, \\mu + \\sigma]\\), ovvero \\(0.683/2\\).","code":"\nlibrary(\"gghighlight\")\n\ndf <- data.frame(x = seq(1.4, 2.0, length.out = 100)) %>% \n  mutate(y = dnorm(x, mean=1.7, sd=0.1))\n\nggplot(df, aes(x, y)) + \n  geom_area(fill = \"sky blue\") + \n  gghighlight(x < 1.8 & x > 1.7) +\n  labs(\n    x = \"Altezza\",\n    y = \"Densità\"\n  )\npnorm(1.8, 1.7, 0.1) - pnorm(1.7, 1.7, 0.1)\n#> [1] 0.3413447\npnorm(1.0, 0, 1) - pnorm(0, 0, 1)\n#> [1] 0.3413447"},{"path":"funzioni-di-densità-di-probabilità.html","id":"distribuzione-chi-quadrato","chapter":"Capitolo 18 Funzioni di densità di probabilità","heading":"18.2 Distribuzione Chi-quadrato","text":"La distribuzione con \\(\\chi^2_{~\\nu}\\) descrive la variabile aleatoria\n\\[\nZ_1^2 + Z_2^2 + \\dots + Z_k^2,\n\\]\ndove \\(Z_1, Z_2, \\dots, Z_k\\) sono\nvariabili aleatorie ..d. con distribuzione Normale standard\n\\(\\mathcal{N}(0, 1)\\). La variabile aleatoria chi-quadrato dipende dal\nparametro intero positivo \\(\\nu = k\\) che ne identifica il numero di gradi\ndi libertà. La densità di probabilità di \\(\\chi^2_{~\\nu}\\) è\n\\[\nf(x) = C_{\\nu} x^{\\nu/2-1} \\exp (-x/2), \\qquad \\text{se } x > 0,\n\\]\ndove \\(C_{\\nu}\\) è una costante positiva.La distribuzione di densità \\(\\chi^2_{~\\nu}\\) è asimmetrica.Il valore atteso di una variabile \\(\\chi^2_{~\\nu}\\) è uguale \\(\\nu\\).La varianza di una variabile \\(\\chi^2_{~\\nu}\\) è uguale \\(2\\nu\\).Per \\(k \\rightarrow \\infty\\), la \\(\\chi^2_{~\\nu} \\rightarrow \\mathcal{N}\\).Una caratteristica importante della distribuzione chi-quadrato è la seguente: se \\(X\\) e \\(Y\\) sono due variabili aleatorie chi-quadrato indipendenti con \\(\\nu_1\\) e \\(\\nu_2\\) gradi di libertà, ne segue che \\(X + Y \\sim \\chi^2_m\\), con \\(m = \\nu_1 + \\nu_2\\). Tale principio si estende qualunque numero finito di variabili aleatorie chi-quadrato indipendenti.Esempio. Usiamo R per disegnare la densità chi-quadrato con 3 gradi di libertà. Usiamo due colori per l’area sottesa alla densità così da suddividenderla due parti uguali.","code":"\ndf <- data.frame(x = seq(0, 15.0, length.out = 100)) %>% \n  mutate(y = dchisq(x, 3))\n\nggplot(df, aes(x, y)) + \n  geom_area(fill = \"sky blue\") + \n  gghighlight(x < 3) +\n  labs(\n    x = \"V.a. chi-quadrato con 3 gradi di libertà\",\n    y = \"Densità\"\n  )"},{"path":"funzioni-di-densità-di-probabilità.html","id":"distribuzione-t-di-student","chapter":"Capitolo 18 Funzioni di densità di probabilità","heading":"18.3 Distribuzione \\(t\\) di Student","text":"Se \\(Z \\sim \\mathcal{N}\\) e \\(W \\sim \\chi^2_{~\\nu}\\) sono due variabili aleatorie indipendenti, allora\nil rapporto\n\\[\nT = \\frac{Z}{\\Big( \\frac{W}{\\nu}\\Big)^{\\frac{1}{2}}}\n\\]\ndefinisce la distribuzione \\(t\\) di Student con\n\\(\\nu\\) gradi di libertà.Si usa scrivere \\(T \\sim t_{\\nu}\\). L’andamento della distribuzione \\(t\\) di\nStudent è simile quello della distribuzione Normale, ma ha una\nmaggiore dispersione (ha le code più pesanti di una Normale, ovvero ha\nuna varianza maggiore di 1).La variabile \\(t\\) di Student soddisfa le seguenti proprietà:Per \\(\\nu \\rightarrow \\infty\\), \\(t_{\\nu}\\) tende alla normale standard\n\\(\\mathcal{N}(0, 1)\\).Per \\(\\nu \\rightarrow \\infty\\), \\(t_{\\nu}\\) tende alla normale standard\n\\(\\mathcal{N}(0, 1)\\).La densità della \\(t_{\\nu}\\) è una funzione simmetrica con valore\natteso nullo.La densità della \\(t_{\\nu}\\) è una funzione simmetrica con valore\natteso nullo.Per \\(\\nu > 2\\), la varianza della \\(t_{\\nu}\\) vale \\(\\nu/(\\nu - 2)\\);\npertanto è sempre maggiore di 1 e tende 1 per\n\\(\\nu \\rightarrow \\infty\\).Per \\(\\nu > 2\\), la varianza della \\(t_{\\nu}\\) vale \\(\\nu/(\\nu - 2)\\);\npertanto è sempre maggiore di 1 e tende 1 per\n\\(\\nu \\rightarrow \\infty\\).Esempio. Una rappresentazione di alcune distribuzioni \\(t\\) di Student è fornita nella figura seguente.","code":"\np = seq(-3, 3, length=100)\nplot(p, dnorm(p, 0, 1), ylab=\"density\", type =\"l\", col=4)\nlines(p, dt(p, 2), type =\"l\", col=3)\nlines(p, dt(p, 5), type =\"l\", col=2)\nlines(p, dt(p, 30), col=1) \nlegend(1.5, .4, c(\"N(0,1)\", \"t(2)\",\"t(5)\",\"t(30)\"), lty=c(1,1,1,1),col=c(4,3,2,1))"},{"path":"funzioni-di-densità-di-probabilità.html","id":"distribuzione-beta","chapter":"Capitolo 18 Funzioni di densità di probabilità","heading":"18.4 Distribuzione Beta","text":"La distribuzione Beta è una distribuzione definita nell’intervallo \\[0, 1\\]. La distribuzione Beta ha due parametri, che chiameremo \\(\\) e \\(b\\).\nQuesti due parametri determinano la forma delle distribuzioni Beta\n(proprio come la media e la varianza determinano la forma della\ndistribuzione normale). Seguendo la consueta convenzione, si scrive\n\\(X \\sim Beta(, b)\\) come abbreviazione di “\\(X\\) ha una distribuzione Beta\ndi parametri \\(\\) e \\(b\\).”Se \\(X \\sim Beta(, b)\\), allora la densità di \\(X\\) è\n\\[\nf_X(x) = \\frac{1}{B(, b)} x^{-1} (1-x)^{b-1} \\qquad x \\[0, 1].\n\\]\nladdove \\(B(, b)\\) è conosciuta come la “funzione beta” e corrisponde ad\nuna costante (quanto non dipende da \\(x\\)), il cui scopo è che la\ndensità si integri 1, come deve essere per tutte le funzioni di\ndensità.Esempio. Una rappresentazione di alcune distribuzioni Beta è fornita nella figura seguente.","code":"\np = seq(0,1, length=100)\nplot(p, dbeta(p, 9, 1), ylab=\"density\", type =\"l\", col=5)\nlines(p, dbeta(p, 1, 9), type =\"l\", col=4)\nlines(p, dbeta(p, 1, 1), col=3) \nlines(p, dbeta(p, 3, 7), col=2) \nlines(p, dbeta(p, 5, 5), col=1) \nlegend(0.4,9, c(\"Be(9,1)\",\"Be(1,9)\",\"Be(1,1)\", \"Be(3,7)\", \"Be(5,5)\"),lty=c(1,1,1,1,1),col=c(5,4,3,2,1))"},{"path":"la-funzione-di-verosimiglianza.html","id":"la-funzione-di-verosimiglianza","chapter":"Capitolo 19 La funzione di verosimiglianza","heading":"Capitolo 19 La funzione di verosimiglianza","text":"Per introdurre la funzione di verosimiglianza utilizzeremo un esempio proposto da McElreath (2020) – per una trattazione più formale è possibile consultare il tutorial di Etz (2018). Supponiamo di tenere mano un mappamondo gonfiabile e di chiederci: “qual’è la proporzione della superficie terreste ricoperta d’acqua?” Sembra una domanda cui è difficile rispondere. Ma ci viene mente questa idea brillante: lanciamo aria il mappamondo e, quando lo riprendiamo, osserviamo se la superfice del mappamondo sotto il nostro dito indice destro rappresenta acqua o terra. Possiamo ripetere questa procedura più volte, così da ottenere un campione causale di diverse porzioni della superficie dal mappamondo. Eseguiamo il nostro esperimento lanciando aria il mappamondo nove volte e osserviamo seguenti risultati: , T, , , , T, , T, , dove “” indica acqua e “T” indica terra. questo esempio, McElreath (2020) illustra come sia possibile analizzare questi dati per stimare la proporzione della superficie del globo terrestre che è ricoperta d’acqua. Mediante questo esempio, McElreath (2020) introduce inoltre il concetto di verosimiglianza.","code":""},{"path":"la-funzione-di-verosimiglianza.html","id":"la-narrazione-dei-dati","chapter":"Capitolo 19 La funzione di verosimiglianza","heading":"19.1 La narrazione dei dati","text":"Secondo McElreath (2020) l’analisi Bayesiana può essere descritta come la produzione di una storia che viene raccontata dai dati. Lo scopo di una tale narrazione è quello di chiarire come dati sono stati generati. Per potere formulare la narrazione dei dati è necessario descrivere le caratteristiche del mondo che ha generato il fenomeno di interesse e il processo attraverso il quale abbiamo ottenuti dati. altri termini, la narrazione dei dati corrisponde alla descrizione del processo di campionamento. Per l’esempio del mappamondo possiamo dire quanto segue:la proporzione del pianeta Terra ricoperta d’acqua è \\(p\\);un singolo lancio del mappamondo ha una probabilità \\(p\\) di produrre\nl’osservazione “acqua” ();lanci del mappamondo sono indipendenti (nel senso che il risultato\ndi un lancio non influenza risultati degli altri lanci).una tale narrazione dei dati distinguiamo dati dai parametri. dati sono le frequenze degli eventi \\(\\) (“acqua”) e \\(T\\) (“terra”). La somma delle frequenze di \\(\\) e \\(T\\) è il numero totale dei lanci del mappamondo: \\(N = + T\\).La narrazione di cui ci occupiamo fa riferimento, oltre ai dati, anche al parametro \\(p\\), ovvero alla proporzione di acqua sul globo terrestre. La descrizione di tale parametro rappresenta l’obiettivo dell’inferenza.Anche se il parametro \\(p\\) non può essere direttamente osservato è possibile inferire il suo valore partire dai dati. Avendo specificato ciò che abbiamo stato detto sopra, la narrazione dei dati si trasforma un modello probabilistico – questo caso, abbiamo una sequenza di prove Bernoulliane indipendenti e, dunque, il modello statistico è quello Binomiale. Un tale modello probabilistico è facile da costruire, e vedremo come si fa. Tuttavia, prima di descrivere questo modello probabilistico dettaglio, è utile visualizzare il suo comportamento. Dopo aver visto come questo modello apprende dai dati ci porremo il problema di capire come funziona.","code":""},{"path":"la-funzione-di-verosimiglianza.html","id":"come-impara-un-modello-statistico","chapter":"Capitolo 19 La funzione di verosimiglianza","heading":"19.1.1 Come impara un modello statistico?","text":"Prima di lanciare aria il mappamondo e di ottenere il primo dato, non sappiamo nulla del parametro \\(p\\). Dato che \\(p\\) è una proporzione, suoi valori possibili vanno da 0 1. Se non possediamo alcuna informazione su \\(p\\), allora riteniamo che tutti valori \\(p\\) siano egualmente plausibili. Rappresentiamo dunque la nostra incertezza proposito del parametro \\(p\\) mediante una distribuzione uniforme su tutti valori \\(p\\), come indicato dalla linea tratteggiata nel pannello \\(n = 1\\) della figura 19.1.\nFigura 19.1: Come apprende un modello statistico. Ciascun lancio del mappamondo produce un’osservazione: acqua () o terra (T). La stima del modello statistico della proporzione di acqua sulla superficie terreste è espressa nei termini del grado di plausibilità di ciascun possibile valore \\(p\\) (proporzione di acqua). Le linee e le curve questa figura rappresentano il grado di plausibilità fornito dal modello. ogni diagramma, le plausibilità calcolate base alle informazioni precedenti (curva tratteggiata) vengono aggiornate alla luce dell’ultima osservazione che è stata ottenuta per produrre un nuovo insieme di valori di plausibilità (curva solida).\nLanciamo aria il mappamondo una prima volta e, quando lo riprendiamo, notiamo che sotto il nostro indice destro c’è “acqua.” Dopo avere osservato il risultato del primo lancio, ovvero “,” il modello aggiorna le plausibilità dei valori del parametro \\(p\\) che ora sono rappresentate dalla linea continua nel pannello \\(n = 1\\) della figura 19.1. La plausibilità associata ’evento \\(p = 0\\) è scesa esattamente zero, l’equivalente di “impossibile.” Infatti, avendo osservato almeno un luogo sul mappamondo cui c’è dell’acqua, possiamo dire che l’evento “non c’è acqua” (ovvero \\(p = 0\\)) è impossibile. Allo stesso modo, la plausibilità di \\(p > 0.5\\) è aumentata.\nNon abbiamo ancora evidenze che ci sia terra sul mappamondo, quindi le plausibilità iniziali sono state modificate per essere coerenti con questa informazione: le plausibilità associate \\(p\\) aumentano passando dal valore \\(p = 0\\) valore \\(p = 1\\), maniera coerente con dati che abbiamo. Il punto importante è che le evidenze disponibili fino questo momento vengono incorporata nelle plausibilità attribuite ciascun possibile valore \\(p\\). Il modello implementa questa logica maniera automatica. Non è necessario fornire al modello alcuna istruzione per ottenere questo risultato. La teoria della probabilità svolge tutti \ncalcoli necessari per noi.Lanciamo aria il mappamondo una seconda volta e osserviamo “T.” Consideriamo dunque il pannello n = 2 della figura 19.1. La linea tratteggiata questo\npannello ricopia semplicemente la descrizione del livello di plausibilità di ciascun valore \\(p\\) che era disponibile nel caso di un solo lancio del mappamondo. La linea continua, invece, aggiorna tali valori di plausibilità incorporando l’informazione secondo la quale \ndue lanci abbiamo ottenuto “acqua” una volta e “terra” una volta. Vediamo che ora il valore di plausibilità di \\(p\\) è uguale zero per l’evento \\(p = 0\\); infatti, abbiamo osservato “acqua” nel primo lancio. maniera corrispondente, il valore di plausibilità di \\(p\\) è uguale zero per l’evento \\(p = 1\\) (c’è solo acqua); infatti, abbiamo osservato\n“terra” nel secondo lancio. Avendo osservato “acqua” nel 50% dei casi, il valore più verosimile per \\(p\\) sarà 0.5, come indicato dalla linea continua questo pannello.Nei pannelli rimanenti della figura 19.1 nuovi dati prodotti dai successivi lanci del mappamondo vengono analizzati dal modello, uno alla volta. La curva tratteggiata ciascun pannello corrisponde alla curva solida del pannello precedente, spostandosi da sinistra destra e dall’alto verso il basso. Ogni volta che si ottiene un dato il picco della curva di plausibilità si sposta destra, verso valori più grandi di \\(p\\). Ogni volta si ottiene T ci si sposta nella direzione opposta. L’altezza massima della curva aumenta con ogni campione, il che significa che, ’aumentare della quantità di prove, viene associato un livello di plausibilità maggiore ad un minor numero di valori di \\(p\\). Man mano che viene aggiunta una nuova osservazione, la curva che rappresenta la\nplausibilità dei valori \\(p\\) viene aggiornata maniera coerente con tutte le osservazioni precedenti.","code":""},{"path":"la-funzione-di-verosimiglianza.html","id":"la-funzione-di-verosimiglianza-1","chapter":"Capitolo 19 La funzione di verosimiglianza","heading":"19.2 La funzione di verosimiglianza","text":"Nel caso dell’esempio della figura 19.1, abbiamo visto come il grado di plausibilità che può essere associato ciascun valore di un parametro (nel caso presente, \\(p\\), ovvero la proporzione di acqua sulla superficie terreste) può essere descritto mediante una curva. Una curva è il grafico di una funzione matematica. statistica, tale funzione si chiama verosimiglianza.","code":""},{"path":"la-funzione-di-verosimiglianza.html","id":"la-verosimiglianza-del-modello-binomiale","chapter":"Capitolo 19 La funzione di verosimiglianza","heading":"19.2.1 La verosimiglianza del modello Binomiale","text":"Nel caso dell’esperimento casuale costituito dal lancio del mappamondo, è possibile individuare la funzione di verosimiglianza utilizzando le informazioni fornite dalla narrazione dei dati. Iniziamo elencando tutti possibili eventi che possono essere osservati nel nostro esperimento casuale. Ce ne sono due: acqua (\\(\\)) e terra (\\(T\\)). Non ci sono altri eventi. Il mappamondo non può mai rimanere bloccato sul soffitto, per esempio. Quando osserviamo un campione di eventi \\(\\) e \\(T\\) di lunghezza \\(N\\) (9 nel campione esame qui), la domanda che ci poniamo è: quanto è probabile osservare questo preciso campione (6 volte “acqua” 9 lanci del mappamondo) nell’universo di tutti possibili campioni costituiti da 9 lanci del mappamondo? Potremmo pensare che questa è una domanda \ncui è molto difficile rispondere, ma realtà ciò non è vero. Se\nspecifichiamo le caratteristiche dell’esperimento casuale come abbiamo\nfatto sopra, ovvero: (1) ogni lancio è indipendente dagli altri lanci e\n(2) la probabilità di osservare “acqua” è la stessa ogni lancio,\nallora la teoria della probabilità ci consente di trovare facilmente una\nrisposta alla nostra domanda. Le caratteristiche dell’esperimento\ncasuale che abbiamo descritto sopra specificano le condizioni che\ndefiniscono una variabile aleatoria binomiale. La funzione che stiamo\ncercando, dunque, è la distribuzione binomiale. precedenza abbiamo\ndiscusso tale distribuzione facendo riferimento ’esperimento casuale\nche consisteva nel “lancio di una moneta” una certo numero di volte. Ma\nl’esperimento casuale del lancio di una moneta è strutturalmente\nidentico quello del lancio del mappamondo gonfiabile dato che, nel\nnostro caso, gli unici esiti possibili sono “acqua” e “terra,” lanci\nsono indipendenti gli uni dagli altri e se la probabilità di osservare\n“acqua” rimane costante ciascun lancio. Possiamo dunque usare la\ndistribuzione binomiale per descrivere la probabilità di osservare =\n“numero di volte cui abbiamo osservato acqua” e T = “numero di\nvolte cui abbiamo osservato terra,” quando il nostro mappamondo è\nstato lanciato aria per N = + T volte. Tale probabilità è data\ndalla distribuzione binomiale di parametro \\(p\\):\\[\\begin{equation}\nP(, T \\mid p) = \\frac{(+ T)!}{!T!} p^+ (1-p)^T.\n\\tag{19.1}\n\\end{equation}\\]altre parole, la frequenza degli eventi “numero di volte cui abbiamo osservato acqua” e “numero di volte cui abbiamo osservato terra” segue la distribuzione binomiale nella quale la probabilità di osservare “acqua” ciascun lancio è uguale \\(p\\).","code":""},{"path":"la-funzione-di-verosimiglianza.html","id":"la-verosimiglianza-vista-da-vicino","chapter":"Capitolo 19 La funzione di verosimiglianza","heading":"19.2.2 La verosimiglianza vista da vicino","text":"Ma cosa dobbiamo fare, pratica, per generare le funzioni di verosimiglianza che sono rappresentate nei diversi pannelli della figura 19.1? Iniziamo con una definizione formale.La funzione di verosimiglianza \\(\\mathcal{L}(\\theta \\mid x) = f(x \\mid \\theta), \\theta \\\\Theta,\\) è la funzione di massa o di densità di probabilità dei dati \\(x\\) vista come una funzione del parametro sconosciuto \\(\\theta\\).Spesso per indicare la verosimiglianza si scrive \\(\\mathcal{L}(\\theta)\\) se è chiaro quali valori \\(x\\) ci si riferisce. La verosimiglianza \\(\\mathcal{L}\\) è una curva (generale, una superficie) nello spazio del parametro \\(\\theta\\) (generale, dei parametri \\(\\boldsymbol\\theta\\)) che riflette la plausibilità relativa dei valori \\(\\theta\\) alla luce dei dati osservati. Notiamo un punto importante. La funzione \\(\\mathcal{L}(\\theta \\mid x)\\) non è una funzione di densità. Infatti, essa non racchiude un’area unitaria.Nel caso presente, la funzione di verosimiglianza è descritta dall’eq. (19.1), ovvero, corrisponde alla funzione binomiale con parametro \\(p \\(0, 1)\\) sconosciuto. Nell’esempio che stiamo discutendo, abbiamo osservato “acqua” sei volte nove lanci del mappamondo. Dunque, abbiamo \\(x = 6\\) successi \\(N = 9\\) prove. Per dati del campione considerato, la funzione di verosimiglianza è\\[\\begin{equation}\n\\mathcal{L}(p \\mid x) = \\frac{(6 + 3)!}{6!3!} p^6 + (1-p)^3.\n\\tag{19.2}\n\\end{equation}\\]La definizione precedente ci dice che, tenendo costanti dati, dobbiamo applicare\nl’eq. (19.2) tutti possibili valori \\(p\\).Per esempio, se \\(p = 0.1\\)\\[\n\\mathcal{L}(p \\mid x) = \\frac{(6 + 3)!}{6!3!} 0.1^6 + (1-0.1)^3\n\\]\notteniamo il valore 0.0446. Se \\(p = 0.2\\)\\[\n\\mathcal{L}(p \\mid x) = \\frac{(6 + 3)!}{6!3!} 0.2^6 + (1-0.2)^3\n\\tag{19.3}\n\\]otteniamo 0.1762; e così via.La tabella seguente riportata alcuni valori rappresentativi della funzione di verosimiglianza definita da 6 successi 9 prove Bernoulliane.La figura 19.2 ci fornisce una rappresentazione grafica\ndella funzione di verosimiglianza.\nFigura 19.2: Funzione di verosimiglianza nel caso cui l’esito acqua sia stato osservato 6 volte 9 lanci del mappamondo.\nChe cosa significano valori che abbiamo ottenuto? Per alcuni valori \\(p\\) la funzione di verosimiglianza assume valori bassi; per altri valori la funzione assume valori più grandi. Questi ultimi sono dunque valori di \\(p\\) “più plausibili” e il valore 0.67 è il più plausibile tra tutti. conclusione, la funzione di verosimiglianza ci dice quanto possiamo ritenere “relativamente plausibili” diversi valori del parametro \\(p\\) alla luce dei dati osservati. La figura 19.2, infatti, mostra come la funzione di verosimiglianza assume una forma diversa presenza di campioni diversi di dati: le curve nei diversi pannelli della figura 19.1 sono sempre state ottenute mediante l’eq. (19.1), ma inserendo nella formula informazioni diverse relativamente ai dati: 1 successo 1 prova (abbiamo lanciato il mappamondo una volta e abbiamo osservato “acqua”); 1 successo 2 prove (abbiamo lanciato il mappamondo due volte e abbiamo osservato “acqua” e “terra”); 2 successi 3 prove (abbiamo lanciato il\nmappamondo tre volte e abbiamo osservato “acqua,” “terra” e “acqua”); eccetera.","code":"\nN <- 9\nx <- 6\ntheta <- seq(0, 1, length.out=100)\n\nlike <- choose(N, x) * theta^x * (1 - theta)^(N - x)\n\nplot(theta, like, \n     type='l', xaxt=\"n\", bty = 'l',\n     main=\"Funzione di verosimiglianza\", \n     ylab=expression(L(theta)),\n     xlab=expression('Valori possibili di' ~ theta))\naxis(side=1, at=seq(0, 1, length.out=11))\nsegments(0.67, 0, 0.67, choose(N, x) * 0.67^x * (1 - 0.67)^(N - x), lty=2)"},{"path":"la-funzione-di-verosimiglianza.html","id":"la-stima-di-massima-verosimiglianza","chapter":"Capitolo 19 La funzione di verosimiglianza","heading":"19.2.3 La stima di massima verosimiglianza","text":"La funzione di verosimiglianza rappresenta la “verosimiglianza relativa” dei diversi valori del parametro di interesse. Ma qual è il valore migliore di tutti?questa domanda si può rispondere due modi diversi.La stima di massima verosimiglianza \\(\\hat{\\theta}_{ML}\\) di un parametro \\(\\theta\\) si ottiene massimizzando la funzione di verosimiglianza:\\[\n\\hat{\\theta}_{ML} = \\text{argmax}_{\\theta \\\\Theta} \\mathcal{L}(\\theta).\n\\]\nL’approccio frequentista, diversamente da quello Bayesiano, utilizza la funzione di verosimiglianza quale unico strumento per giungere alla stima del valore più plausibile del parametro sconosciuto \\(p\\) nel caso dell’esempio del mappamondo – generale, possiamo chiamare \\(\\theta\\) il parametro sconosciuto. Il metodo della massima verosimiglianza consiste nel trovare il valore \\(\\theta\\) che più verosimilmente ha generato dati. Tale stima corrisponde al punto di massimo della funzione di verosimiglianza. Nell’esempio presente,\n\\(\\hat{p}_{ML} = 0.6667\\). Nell’esempio che abbiamo discusso, il massimo della funzione di verosimiglianza, ovvero la stima di \\(p\\), si può facilmente ottenere con metodi numerici o grafici.","code":""},{"path":"la-funzione-di-verosimiglianza.html","id":"la-log-verosimiglianza","chapter":"Capitolo 19 La funzione di verosimiglianza","heading":"19.2.4 La log-verosimiglianza","text":"Per motivi algebrici e numerici è conveniente lavorare con il logaritmo della funzione di verosimiglianza, che viene chiamata funzione di log-verosimiglianza,\\[\n\\ell(\\theta) = \\log \\mathcal{L}(\\theta).\\notag\n\\]Poiché il logaritmo è una funzione strettamente crescente (usualmente si considera il\nlogaritmo naturale), allora \\(\\mathcal{L}(\\theta)\\) e \\(\\ell(\\theta)\\) assumono il massimo (o punti di massimo) corrispondenza degli stessi valori di \\(\\theta\\):\\[\n\\hat{\\theta}_{ML} = \\text{argmax}_{\\theta \\\\Theta} \\ell(\\theta).\n\\]\nPer le proprietà del logaritmo, si ha\\[\n\\ell(\\theta) = \\log \\left( \\prod_{= 1}^n f(x \\mid \\theta) \\right) = \\sum_{= 1}^n \\log f(x \\mid \\theta).\n\\]Si noti che non è necessario lavorare con logaritmi, anche se è fortemente consigliato, e questo perché valori della verosimiglianza, cui si moltiplicano valori di probabilità molto piccoli, possono diventare estremamente piccoli (qualcosa come \\(10^{-34}\\)). tali circostanze, non è sorprendente che programmi dei computer mostrino problemi di arrotondamento numerico. Le trasformazioni logaritmiche risolvono questo problema.","code":""},{"path":"la-funzione-di-verosimiglianza.html","id":"derivazione-della-massima-verosimiglianza","chapter":"Capitolo 19 La funzione di verosimiglianza","heading":"19.2.5 Derivazione della massima verosimiglianza","text":"Nell’esempio precedente abbiamo trovato che la stima di massima verosimiglianza di \\(p\\) è uguale alla proporzione di successi campionari. Questo risultato può essere dimostrato come segue. Per \\(N\\) prove Bernoulliane indipendenti, le quali producono \\(x\\) successi e (\\(N-x\\))\ninsuccessi, la funzione nucleo (ovvero, la funzione di verosimiglianza da cui sono state escluse tutte le costanti moltiplicative, dato che esse non hanno alcun effetto su \\(\\hat{p}_{ML}\\)) è\\[\n\\mathcal{L}(p \\mid x) = p^x (1-p)^{N - x}.\\notag\n\\]La funzione nucleo di log-verosimiglianza è\\[\n\\begin{aligned}\n\\ell(p \\mid x) &= \\log \\mathcal{L}(p \\mid x) \\notag\\\\\n          &= \\log \\left( p^x (1-p)^{N - x} \\right) \\notag\\\\\n          &= \\log p^x + \\log \\left( (1-p)^{N - x} \\right) \\notag\\\\\n          &= x \\log p + (N - x) \\log (1-p).\\notag\\end{aligned}\n\\]Per calcolare il massimo della funzione di log-verosimiglianza è necessario differenziare \\(\\ell(p \\mid x)\\) rispetto \\(p\\), porre la derivata zero e risolvere. La derivata di \\(\\ell(p \\mid x)\\) è:\\[\n\\ell'(p \\mid x) = \\frac{x}{p} -\\frac{N-x}{1-p}.\n\\]Ponendo l’equazione uguale zero e risolvendo otteniamo la stima di massima verosimiglianza:\\[\\begin{equation}\n  \\hat{p}_{\\text{ML}} = \\frac{x}{N},\n  \\tag{19.4}\n\\end{equation}\\]ovvero la frequenza relativa dei successi nel campione.","code":""},{"path":"la-funzione-di-verosimiglianza.html","id":"calcolo-numerico","chapter":"Capitolo 19 La funzione di verosimiglianza","heading":"19.2.6 Calcolo numerico","text":"La derivazione formale del risultato secondo il quale la stima di massima verosimiglianza corrisponde alla proporzione di successi nel campione è piuttosto complessa. Lo stesso risultato può essere ottenuto maniera molto più semplice mediante una simulazione svolta R. questo fine, iniziamo con il definire una serie di valori possibili per il parametro incognito \\(p\\):Sappiamo che la funzione di verosimiglianza è la funzione di massa di probabilità espressa funzione del parametro sconosciuto \\(p\\) e assumendo come noti dati. Questo si può esprimere ne modo seguente:Si noti che, nell’istruzione precedente, abbiamo passato alla funzione\ndbinom() dati, ovvero 6 successi 9 prove. Inoltre, abbiamo\npassato alla funzione un vettore che contiene 1000 valori possibili per\nil parametro \\(p\\), da 0 1. Per ciascuno di questi valori di \\(p\\), la\nfunzione dbinom() ci ritorna un valore (cioè l’ordinata della funzione\ndi verosimiglianza), tenendo costanti tutti casi valori dei dati\n(ovvero, 6 successi 9 prove). Un grafico della funzione di\nverosimiglianza è dato da:Nella simulazione, il valore \\(p\\) che massimizza la funzione di verosimiglianza può essere trovato nel modo seguente:Si noti come il valore trovato sia uguale al valore definito dall’eq. (19.4).","code":"\np <- seq(0, 1, length.out=1e3)\nlike <- dbinom(6, 9, p)\nplot(p, like, type='l')\np[which.max(like)]\n#> [1] 0.6666667"},{"path":"la-funzione-di-verosimiglianza.html","id":"la-verosimiglianza-del-modello-normale","chapter":"Capitolo 19 La funzione di verosimiglianza","heading":"19.3 La verosimiglianza del modello Normale","text":"Ora che abbiamo capito come si definisce la funzione verosimiglianza di\nuna Binomiale è relativamente semplice fare un passo ulteriore e\nconsiderare la verosimiglianza del caso di una funzione di densità,\novvero nel caso di una variabile aleatoria continua. Consideriamo qui il\ncaso della Normale. La densità di una distribuzione Normale di parametri\n\\(\\mu\\) e \\(\\sigma\\) è\\[\nf(x \\mid \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left\\{-\\frac{1}{2\\sigma^2}(x-\\mu)^2\\right\\}.\n\\tag{19.5}\n\\]Per un campione ..d. \\(\\mathscr{D}_n = x_1, x_2, \\dots, x_n\\) con\ndensità Normale di parametri \\(\\mu\\) e \\(\\sigma\\), poniamoci il problema di\ntrovare la stima di massima verosimiglianza dei parametri sconosciuti\n\\(\\mu\\) e \\(\\sigma\\). Per semplicità, scriviamo \\(\\theta = \\{\\mu, \\sigma\\}.\\)precedenza abbiamo utilizzato la nozione di probabilità congiunta per\nfare riferimento alla probabilità del verificarsi di un insieme di\neventi. Estendiamo questo ragionamento al caso presente.Consideriamo il campione osservato come un insieme di eventi. Ciascuno di tali eventi è la realizzazione di una variabile aleatoria (possiamo pensarla come l’estrazione casuale di un valore dalla “popolazione” \\(\\mathcal{N}(\\mu, \\sigma)\\)). Tali variabili aleatorie sono mutualmente indipendenti, tutte con la stessa legge distributiva, e la densità congiunta è data da:\\[\n\\begin{aligned}\nf(\\mathscr{D}_n \\mid \\theta) &= f(x_1 \\mid \\theta) \\cdot f(x_2 \\mid \\theta) \\cdot \\dots \\cdot f(x_n \\mid \\theta)\\notag\\\\\n&= \\prod_{=1}^n f(x_i \\mid \\theta),\n\\end{aligned}\n\\]laddove la funzione \\(f(\\cdot)\\) è data dall’eq. (19.5). L’associata funzione di verosimiglianza è dunque:\\[\\begin{equation}\n\\mathcal{L}(\\theta \\mid \\mathscr{D}_n) = \\prod_{=1}^n f(x_i \\mid \\theta).\n\\tag{19.6}\n\\end{equation}\\]L’obiettivo è massimizzare la funzione di verosimiglianza per trovare valori \\(\\theta\\) ottimali. Usando la notazione matematica questo si esprime dicendo che cerchiamo l’argmax dell’eq. (19.6) rispetto \\(\\theta\\), ovvero\\[\n\\hat{\\theta}_{\\text{MLE}} = \\text{argmax}_{\\theta} \\prod_{=1}^n f(x_i \\mid \\theta).\n\\]termini formali, questo problema si risolve calcolando le derivate della funzione rispetto \\(\\theta\\), ponendo le derivate uguali zero e risolvendo. Saltando tutti passaggi algebrici di questo procedimento, per \\(\\mu\\) troviamo che\\[\\begin{equation}\n\\hat{\\mu}_{\\text{MLE}} = \\frac{1}{n} \\sum_{=1}^n x_i\n\\tag{19.7}\n\\end{equation}\\]e per \\(\\sigma\\) abbiamo\\[\\begin{equation}\n\\hat{\\sigma}_{\\text{MLE}} = \\sqrt{\\sum_{=1}^n\\frac{1}{n}(x_i- \\mu)^2}.\n\\tag{19.8}\n\\end{equation}\\]altri termini, la stima di massima verosimiglianza per il parametro \\(\\mu\\) è la media del campione e la stima di massima verosimiglianza per il parametro \\(\\sigma\\) è la deviazione standard del campione.","code":""},{"path":"la-funzione-di-verosimiglianza.html","id":"simulazione","chapter":"Capitolo 19 La funzione di verosimiglianza","heading":"19.3.1 Simulazione","text":"Consideriamo ora un esempio relativo al campione di valori BDI-II dei trenta soggetti del campione clinico descritto da Zetsche et al. (2019), ovveroCi poniamo lo scopo di generare la funzione di verosimiglianza per questi dati. Supponiamo che ricerche precedenti ci dicano che il BDI-II si distribuisce secondo una legge Normale.Ci concentriamo qui sul parametro \\(\\mu\\) della distribuzione Normale. Per semplificare il problema, assumiamo di conoscere \\(\\sigma\\) (lo porremo uguale alla deviazione standard del campione), modo da avere un solo parametro sconosciuto. Il nostro problema è dunque quello di trovare la funzione di verosimiglianza per il parametro \\(\\mu\\), date le 30 osservazioni che abbiamo disposizione.Abbiamo visto sopra che, per una singola osservazione, la funzione di verosimiglianza è la densità Normale espressa funzione dei parametri. Nel caso di un campione di osservazioni \\(\\mathscr{D}_n = (x_1, x_2, \\dots, x_n)\\) dobbiamo utilizzare la funzione\ndi densità congiunta \\(f(\\mathscr{D}_n \\mid \\mu, \\sigma)\\) espressa funzione dei parametri, ovvero \\(\\mathcal{L}(\\mu, \\sigma \\mid \\mathscr{D}_n)\\). Se le 30 osservazioni sono ..d., allora la densità congiunta è data dal prodotto della densità di ciascuna singola osservazione. Per una singola osservazione \\(x_i\\) abbiamo\\[\nf(x_i \\mid \\mu, \\sigma) = \\frac{1}{{\\sigma \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(x_i - \\mu)^2}{2\\sigma^2}}\\right\\},\\notag\n\\]dove il pedice \\(\\) specifica la singola osservazione \\(x_i\\) tra le molteplici osservazioni \\(x\\), e \\(\\mu\\) e \\(\\sigma\\) sono parametri sconosciuti che devono essere determinati. La densità congiunta è dunque\\[\nf(\\mathscr{D}_n \\mid \\mu, \\sigma) = \\, \\prod_{=1}^n f(x_i \\mid \\mu, \\sigma)\\notag\n\\]e, alla luce dei dati osservati, l’associata verosimiglianza diventa\\[\n\\begin{aligned}\n\\mathcal{L}(\\mu, \\sigma \\mid \\mathscr{D}_n) =& \\, \\prod_{=1}^n f(x_i \\mid \\mu, \\sigma) = \\notag\\\\\n& \\frac{1}{{\\sigma \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(26 - \\mu)^2}{2\\sigma^2}}\\right\\} \\times \\notag\\\\\n & \\frac{1}{{\\sigma \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(35 - \\mu)^2}{2\\sigma^2}}\\right\\} \\times  \\notag\\\\\n& \\vdots \\notag\\\\\n & \\frac{1}{{\\sigma \\sqrt {2\\pi}}}\\exp\\left\\{{-\\frac{(22 - \\mu)^2}{2\\sigma^2}}\\right\\}.\n\\end{aligned}\n\\tag{19.9}\n\\]Poniamoci il problema di rappresentare graficamente tale funzione di verosimiglianza per il parametro \\(\\mu\\). Per semplicità, supponiamo che \\(\\sigma\\) sia noto e uguale alla deviazione standard del campione.Avendo un solo parametro sconosciuto da stimare possiamo rappresentare la verosimiglianza con una curva, anziché con una superficie. R, possiamo definire la funzione di log-verosimiglianza nel modo seguente:Si noti che, nella funzione log_likelihood, x è un vettore che, nel caso presente conterrà \\(n = 30\\) valori. Per ciascuno di questi valori, la funzione dnorm() troverà la densità Normale (l’ordinata della funzione) utilizzando il valore \\(\\mu\\) che viene passato log_likelihood e un valore \\(\\sigma\\) sempre uguale, dato che, nell’esempio, questo parametro verrà mantenuto costante. L’argomento log = TRUE specifica che deve essere preso il logaritmo. La funzione dnorm() è un argomento della funzione sum(). Ciò significa che 30 valori così trovati, espressi su scala logaritmica, verranno sommati. Sommare logaritmi è equivalente fare il prodotto dei valori sulla scala originaria.Se applichiamo questa funzione ad un solo valore \\(\\mu\\) otteniamo un singolo valore della\nfunzione di log-verosimiglianza (ovvero, l’ordinata di un singolo punto della funzione rappresentata nella figura (19.9)). Ripeto, tale singolo valore viene trovato utilizzando tutti 30 dati del campione, il valore \\(\\sigma = s\\) che viene tenuto fisso e il singolo valore \\(\\mu\\) che abbiamo passato alla funzione\nlog_likelihood(). Dobbiamo, tuttavia, applicare la funzione tutti possibili valori che \\(\\mu\\) può assumere. Per cui il procedimento che abbiamo descritto per un singolo valore \\(\\mu\\) viene ripetuto tante volte.Nel seguente ciclo () usato nelle istruzioni seguenti viene calcolata la log-verosimiglianza di 100000 possibili valori per il parametro \\(\\mu\\):Il vettore mu contiene 100000 possibili valori del parametro \\(\\mu\\). Tali valori sono stati scelti modo tale da essere compresi nell’intervallo \\(\\bar{x} \\pm s\\).Per ciascuno dei possibili valori del parametro \\(\\mu\\) la funzione log_likelihood() calcola la log-verosimiglianza seguendo la procedura descritta sopra. ’interno del ciclo () 100000 risultati così ottenuti vengono salvati nel vettore ll.Possiamo ora utilizzare valori contenuti nei vettori mu e ll per disegnare il grafico della funzione di log-verosimiglianza del parametro \\(\\mu\\):Dalla figura notiamo che, per questi dati, il massimo della funzione di log-verosimiglianza calcolata per via numerica è pari 30.93. Tale valore è identico alla media dei dati campionari e corrisponde al risultato teorico dell’eq. (19.9).","code":"\nd <- data.frame(x = c(26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, 28, 35, 30, 26, 31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22))\ntrue_sigma <- sd(d$x)\nlog_likelihood <- function(x, mu, sigma=true_sigma) {\n  sum(dnorm(x, mu, sigma, log=TRUE))\n}\nnrep <- 1e5\nmu <- seq(\n  mean(d$x) - sd(d$x), \n  mean(d$x) + sd(d$x), \n  length.out = nrep\n)\n\nll <- rep(NA, nrep)\nfor (i in 1:nrep) {\n  ll[i] <- log_likelihood(d$x, mu[i], true_sigma)\n}\ndata.frame(mu, ll) %>% \nggplot(aes(x=mu, y=ll)) +\n  geom_line() +\n  vline_at(mean(d$x), color=\"red\", linetype=\"dashed\") +\n  labs(\n    y=\"Log-verosimiglianza\",\n    x=c(\"Parametro \\u03BC\")\n  ) "},{"path":"la-funzione-di-verosimiglianza.html","id":"conclusioni-7","chapter":"Capitolo 19 La funzione di verosimiglianza","heading":"Conclusioni","text":"La verosimiglianza viene utilizzata sia nell’inferenza bayesiana che quella frequentista. entrambi paradigmi di inferenza, il suo ruolo è quantificare la forza con la quale dati osservati supportano possibili valori dei parametri sconosciuti.Nella funzione di verosimiglianza dati (osservati) vengono trattati come fissi, mentre valori del parametro (o dei parametri) \\(\\theta\\) vengono variati: la verosimiglianza è una funzione di \\(\\theta\\) per il dato fisso \\(x\\). Pertanto, la funzione di verosimiglianza riassume seguenti elementi: un modello statistico che genera stocasticamente dati (questo capitolo abbiamo esaminato due modelli statistici: quello Binomiale e quello Normale), un intervallo di valori possibili per \\(\\theta\\) e dati osservati \\(x\\).Nella statistica frequentista l’inferenza si basa solo sui dati disposizione e qualunque informazione fornita dalle conoscenze precedenti non viene presa considerazione. Nello specifico, nella statistica frequentista l’inferenza viene condotta massimizzando la\nfunzione di (log) verosimiglianza, condizionatamente ai valori assunti dalle variabili aleatorie campionarie. Nella statistica bayesiana, invece, l’inferenza statistica viene condotta combinando la funzione di verosimiglianza con le distribuzioni priori dei parametri incogniti \\(\\theta\\).La differenza fondamentale tra inferenza bayesiana e frequentista è dunque che frequentisti non ritengono utile descrivere termini probabilistici parametri: parametri dei modelli statistici vengono concepiti come fissi ma sconosciuti. Nell’inferenza bayesiana, invece, parametri sconosciuti sono intesi come delle variabili aleatorie e ciò consente di quantificare termini probabilistici il nostro grado di intertezza relativamente al loro valore.","code":""},{"path":"introduzione-3.html","id":"introduzione-3","chapter":"Introduzione","heading":"Introduzione","text":"La statistica inferenziale è un insieme di tecniche che ci consentono di fare inferenze da un campione ad una specifica popolazione.\naltri termini, l’inferenza statistica può essere descritta come un insieme di operazioni sui dati che producono delle stime e delle affermazioni sul grado di incertezza che il ricercatore attribuisce alle sue previsioni e ai parametri di processi e/o popolazioni.\nInizieremo la nostra discussione definendo alcuni concetti di base.","code":""},{"path":"introduzione-3.html","id":"parametri-e-statistiche","chapter":"Introduzione","heading":"19.4 Parametri e statistiche","text":"statistica, per popolazione si intende un insieme di elementi che\npresenta caratteristiche aleatorie, mentre per campione si intende un\nsottoinsieme della popolazione. Ma cosa corrisponde pratica la\npopolazione? Per uno psicologo la popolazione è un gruppo di individui.\nPer un biologo marino la popolazione è un gruppo di delfini, ad esempio.\nNella maggior parte dei casi, le popolazioni oggetto di interesse per \nricercatori sono insiemi di entità concrete che esistono nel mondo\nreale. Dal punto di vista della statistica, invece, le popolazioni sono\ndelle entità astratte. Infatti, gli statistici operazionalizzano il\nconcetto di “popolazione” nei termini di un oggetto matematico che\nconsente di essere manipolato con facilità. precedenza noi abbiamo\ngià incontrato questi oggetti matematici: sono le distribuzioni di\nprobabilità.L’idea è semplice. Supponiamo di occuparci del quoziente di\nintelligenza, QI. Abbiamo detto che, per uno psicologo, la popolazione\ndi interesse solitamente è un gruppo di individui, ciascuno dei quali è\ndotato di uno specifico punteggio del QI. Uno statistico “semplifica”\ntale situazione definendo maniera operativa la popolazione come la\ndistribuzione di densità rappresentata nella\nfigura 19.3. precedenza abbiamo visto infatti\ncome una distribuzione di densità non sia altro che la descrizione\nmatematica della “forma” di un istogramma che rappresenta un numero\nmolto alto di osservazioni.\nFigura 19.3: Grafico della distribuzione dei punteggi del QI nella popolazione.\ntest di intelligenza sono progettati modo che il QI medio sia pari\n100, la deviazione standard dei punteggi QI sia uguale 15 e la\ndistribuzione dei punteggi del QI sia normale. valori riportati sopra\nsono detti parametri quanto descrivono le proprietà dell’intera\npopolazione. Cioè, diciamo che la media della popolazione è \\(\\mu = 100\\)\ne la deviazione standard della popolazione è \\(\\sigma = 15\\). Dal punto di\nvista statistico, dunque, possiamo rappresentare questa ipotetica\npopolazione di valori del QI mediante l’oggetto matematico che\ncorrisponde una particolare distribuzione Normale:\\[\nQI \\sim \\mathcal{N}(\\mu = 100, \\sigma = 15).\n\\]\nSupponiamo ora di eseguire un esperimento nel quale il test di\nintelligenza viene somministrato 100 persone selezionate caso. Tale\ncampione casuale semplice consiste nel seguente insieme di 100 numeri:Tali valori sono stati trovati utilizzando la funzione rnorm() che genera numeri casuali estratti da una distribuzione normale. Nello specifico, abbiamo estratto 100 valori casuali dalla distribuzione normale con media 100 e deviazione standard 15. Se costruiamo un istogramma con dati di un tale campione otteniamo il grafico mostrato nella figura 19.4.\nFigura 19.4: Istogramma della distribuzione dei punteggi del QI un campione di 100 osservazioni.\nCome possiamo vedere, l’istogramma ha approssimativamente la forma corretta, ma è un’approssimazione molto cruda della distribuzione della popolazione mostrata nella figura 19.3. Se calcoliamo la media del campione, otteniamo un numero abbastanza vicino alla media della popolazione di 100, ma non identico: nel campione considerato la media e la deviazione standard sono uguali :Queste statistiche campionarie descrivono le proprietà di uno specifico campione che è stato osservato e, sebbene siano abbastanza simili ai parametri della popolazione, non\nsono uguali ad essi. generale, le statistiche campionarie sono ciò\nche è possibile calcolare partire dai dati osservati sul campione\nmentre parametri della popolazione sono ciò che vorremmo conoscere.","code":"\nlibrary(\"ggfortify\")\nggdistribution(dnorm, seq(60, 140, 0.1), mean = 100, sd = 15) +\n  labs(\n    x = \"Quoziente d'intelligenza\",\n    y = \"Densità di probabilità\"\n  )\nset.seed(123)\niq1 <- rnorm(100, 100, 15)\n# i valori QI sono numeri interi!\niq1 <- round(iq1) \niq1\n#>   [1]  92  97 123 101 102 126 107  81  90  93 118 105 106 102  92 127 107  71 111  93  84  97  85\n#>  [24]  89  91  75 113 102  83 119 106  96 113 113 112 110 108  99  95  94  90  97  81 133 118  83\n#>  [47]  94  93 112  99 104 100  99 121  97 123  77 109 102 103 106  92  95  85  84 105 107 101 114\n#>  [70] 131  93  65 115  89  90 115  96  82 103  98 100 106  94 110  97 105 116 107  95 117 115 108\n#>  [93] 104  91 120  91 133 123  96  85\ndata.frame(iq1) %>% \n  ggplot(aes(x = iq1)) +\n  geom_histogram(aes(y = ..density..)) +\n  labs(\n    x = \"Quoziente d'intelligenza\",\n    y = \"Densità\"\n  )\n#> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\nmean(iq1)\n#> [1] 101.42\nsd(iq1)\n#> [1] 13.66643"},{"path":"introduzione-3.html","id":"la-legge-dei-grandi-numeri","chapter":"Introduzione","heading":"19.5 La legge dei grandi numeri","text":"Nella sezione Parametri e statistiche abbiamo considerato risultati di un esperimento casuale nel quale sono stati osservati valori\nfittizi del QI di un campione di ampiezza \\(n = 100\\). risultati sono\nincoraggianti: la media campionaria di 101.42 ci fornisce\nun’approssimazione ragionevole della media della popolazione\n\\(\\mu = 100\\). molti studi un tale livello di precisione è accettabile,\nma altre situazioni è necessario essere più precisi.Cosa dobbiamo fare se vogliamo che le statistiche campionarie siano più\nvicine ai parametri della popolazione? La risposta è ovvia: dobbiamo\nraccogliere più dati. Supponiamo dunque di condurre un nuovo esperimento\nnel quale misuriamo il QI di 10000 persone. Possiamo simulare \nrisultati di questo esperimento usando R:Nella figura 19.5 è riportato l’istogramma dei valori del QI di\nquesto campione più numeroso. È chiaro che, questo secondo caso,\notteniamo un’approssimazione migliore rispetto al precedente campione\npiù piccolo. Ciò si riflette anche nelle statistiche del campione:Questi valori sono molto vicini ai parametri della popolazione.\nFigura 19.5: Istogramma della distribuzione dei punteggi del QI un campione di 10000 osservazioni.\nIl messaggio, un po’ banale, che ricaviamo questa simulazione è che,\ngeneralmente, campioni di dimensioni maggiori forniscono informazioni\nmigliori. Ho chiamato “banali” risultati di questa simulazione perché\ndovrebbe essere evidente tutti che le cose stanno così. Infatti,\nquesto punto è talmente ovvio che, quando Jacob Bernoulli – uno dei\nfondatori della teoria della probabilità – formalizzò questa idea nel\n1713, commentò il risultato nel modo seguente:Perché anche il più stupido degli uomini, basandosi soltanto sul suo istinto, da solo e senza alcuna istruzione (il che è notevole), è convinto che maggiore è il numero di osservazioni, minore è il pericolo di sbagliare.statistica questa intuizione va sotto il nome di Legge dei grandi\nnumeri. La Legge dei grandi numeri ci dice che la media aritmetica di\nun campione di \\(n\\) osservazioni (termini tecnici: di \\(n\\) variabili\naleatorie \\(X_i\\) indipendenti e identicamente distribuite), ovvero\n\\(\\frac{1}{n}\\sum_{=1}^nX_i\\), per \\(n\\) crescente tende o converge al\nvalore atteso teorico \\(\\mu\\). La Legge dei grandi numeri è uno degli\nstrumenti più importanti della statistica.","code":"\nset.seed(123)\niq2 <- rnorm(n = 10000, mean = 100, sd = 15) \niq2 <- round(iq2) \nhead(iq2)\n#> [1]  92  97 123 101 102 126\nmean(iq2)\n#> [1] 99.9671\nsd(iq2)\n#> [1] 14.9855\ndata.frame(iq2) %>% \n  ggplot(aes(x = iq2)) +\n  geom_histogram(aes(y = ..density..)) +\n  labs(\n    x = \"Quoziente d'intelligenza\",\n    y = \"Densità\"\n  )\n#> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`."},{"path":"distribuzione-campionaria.html","id":"distribuzione-campionaria","chapter":"Capitolo 20 Distribuzione campionaria","heading":"Capitolo 20 Distribuzione campionaria","text":"Il problema che l’inferenza statistica si pone è quello di capire, sulla base di eventi osservati, quale possa essere la popolazione che li ha generati. Ci sono due approcci ’inferenza statistica: quello frequentista e quello Bayesiano. Considereremo qui l’approccio frequentista soltanto per metterne evidenza limiti, menre approfondiremo seguito l’approccio Bayesiano.L’approccio frequentista è basato sull’idea di probabilità come limite cui tende la frequenza relativa, al tendere ’infinito del numero delle prove effettuate. È dunque centrale ’approccio frequentista l’idea di una ripetizione dell’esperimento casuale cui esiti definiscono l’evento di interesse.Per fornire un’intuizione del tipo di metodi statistici di cui fa uso l’approccio frequentista, esamineremo qui un concetto cruciale di tale approccio: quello di distribuzione campionaria.","code":""},{"path":"distribuzione-campionaria.html","id":"distribuzione-campionaria-1","chapter":"Capitolo 20 Distribuzione campionaria","heading":"20.1 Distribuzione campionaria","text":"precedenza abbiamo presentato la Legge dei grandi numeri.La Legge dei grandi numeri è uno strumento molto potente, ma non è sufficiente per rispondere tutte le nostre domande. Tutto ciò che ci offre è una “garanzia lungo termine.” Essa ci garantisce che, lungo termine, le statistiche campionarie saranno corrette – le statistiche\ncampionarie forniranno la risposta esatta se verrà raccolta una quantità\ninfinita di dati. Ma come ha affermato John Maynard Keynes (1923) \neconomia, una garanzia lungo termine è di scarsa utilità nella vita\nreale:Il lungo periodo è una guida fuorviante per ciò che accade ora. Alla\nlunga saremo tutti morti. Gli economisti si sono dati un compito\ntroppo facile, troppo inutile, se nelle stagioni tempestose possono\nsolo dirci che, quando la tempesta sarà passata da un pezzo, l’oceano\nsarà di nuovo piatto.Come economia, così anche psicologia e nella statistica. Non è\nsufficiente sapere che, lungo termine, arriveremo alla risposta\ngiusta. È di scarso conforto sapere che un campione di dati\ninfinitamente grande ci fornisce il valore esatto della media della\npopolazione, quando il campione che possiamo ottenere qualsiasi\nsituazione pratica non può che avere una numerosità modesta.\nNell’attività pratica della ricerca psicologica, quindi, è necessario\nsapere qualcosa di più del comportamento delle statistiche campionarie\n(per esempio, la media) quando esse vengono calcolate partire da un\ncampione di dati molto più piccolo di quello ipotizzato dalla Legge dei\ngrandi numeri. Queste considerazioni portano l’approccio frequentista alla\nformulazione di un nuovo concetto: quello di distribuzione campionaria\n(sampling distribution).","code":""},{"path":"distribuzione-campionaria.html","id":"simulazione-1","chapter":"Capitolo 20 Distribuzione campionaria","heading":"20.1.1 Simulazione","text":"Tenendo mente quanto detto nella sezione precedente, abbandoniamo\nl’idea che nostri campioni siano grado di raggiungere numerosità\ndell’ordine di grandezza delle decine o delle centinaia di migliaia di\nosservazioni. Prendiamo invece esame una situazione più vicina \nquella cui gli psicologi si trovano ad operare. Consideriamo, quale\nesempio, un’ampiezza campionaria di \\(n = 5\\). Come precedenza,\npossiamo simulare questo esperimento casuale R, usando la funzione\nrnorm():Il QI medio questo campione risulta pari 91. Non sorprende che\nquesto risultato sia molto meno accurato rispetto ’esperimento casuale precedente.Immaginiamo ora di replicare l’esperimento; immaginiamo cioè di ripetere nuovamente la procedura descritta sopra: estraiamo un nuovo campione casuale e misuriamo il QI di 5 persone. Ancora una volta utilizziamo R per effettuare la simulazione:quest altro campione casuale il QI medio è 95.6. Procediamo \nquesto modo e simuliamo l’esperimento casuale dieci volte maniera tale da ottenere risultati seguenti.Iniziamo creando una lista di 10 campioni di ampiezza \\(n = 5\\).Trasformiamo la lista un data.frame.Le medie di ciascuno dei 10 campioni di ampiezza \\(n = 5\\) sono:Poniamoci ora il problema di replicare tante volte la procedura che ci porta calcolare la media dei valori del QI di cinque persone prese caso. Per ciascuna replica dell’esperimento casuale salviamo il valore della media campionaria. Così facendo, generiamo tanti valori, ciascuno dei quali corrisponde alla media di un campione casuale di 5 osservazioni. Usando poteri magici di R, possiamo eseguire una tale simulazione mediante le seguenti istruzioni:Nella figura 20.1 sono riportati risultati della simulazione. Come\nillustrato dalla figura, la media dei 5 punteggi del QI è solitamente\ncompresa tra 80 e 120. Ma il risultato più importante di questa\nsimulazione è quello che ci fa capire che, se ripetiamo l’esperimento\ncasuale più e più volte, otteniamo una distribuzione di medie\ncampionarie. Un tale distribuzione ha un nome speciale statistica: si\nchiama distribuzione campionaria della media.\nFigura 20.1: Istogramma della distribuzione delle medie dei punteggi del QI calcolate su 10000 campioni casuali di ampiezza \\(n=5\\).\nLa “distribuzione campionaria” è un importante concetto della statistica\ned è fondamentale per comprendere il comportamento dei piccoli campioni.\nQuando abbiamo eseguito per la prima volta l’esperimento casuale\nrelativo ’estrazione di cinque punteggi IQ dalla popolazione, abbiamo\ntrovato una media campionaria pari 101.42. Quello che impariamo dalla\ndistribuzione campionaria delle medie di campioni di ampiezza \\(n = 5\\) della\nfigura 20.1 è che un tale esperimento casuale è poco\naccurato. Infatti, la distribuzione campionaria della media dei campioni\ndi ampiezza \\(n=5\\) ci fa capire che, se ripetendo un tale esperimento\ncasuale tante volte, otteniamo delle medie campionarie con valori che\npossono essere compresi nell’intervallo tra 80 e 120. altre parole,\nla distribuzione campionaria della media di campioni di ampiezza 5 ci\ndice che il risultato dell’esperimento casuale (ovvero, la media\nosservata un singolo campione) varia di molto tra diversi campioni\nche possono essere estratti dalla popolazione. Di conseguenza, se il\nnostro obiettivo è quello di stimare la media della popolazione, allora\nnon dobbiamo fidarci troppo del risultato ottenuto per caso da un\nsingolo campione di numerosità \\(n\\) = 5. Nella discussione seguente mostreremo come sia possibile utilizzare la stima della distribuzione campionaria per descrivere le proprietà statistiche delle stime (ovvero, il grado di incertezza che è associato alle stime che otteniamo).La distribuzione campionaria può essere solo stimata","code":"\niq3 <- round(rnorm(n = 5, mean = 100, sd = 15))\niq3\n#> [1]  79 104  63 100 109\niq4 <- round(rnorm(n = 5, mean = 100, sd = 15))\niq4\n#> [1] 117  73  96  96  96\nmean(iq4)\n#> [1] 95.6\nset.seed(123)\nsample_list <- list()\nfor (i in 1:10) {\n  sample_list[[i]] <- round(rnorm(5, 100, 15))\n}\nsample_list[[1]]\n#> [1]  92  97 123 101 102\nsample_list[[2]]\n#> [1] 126 107  81  90  93\ndf <- data.frame(matrix(unlist(sample_list), nrow=length(sample_list), byrow=TRUE))\ndf\n#>     X1  X2  X3  X4  X5\n#> 1   92  97 123 101 102\n#> 2  126 107  81  90  93\n#> 3  118 105 106 102  92\n#> 4  127 107  71 111  93\n#> 5   84  97  85  89  91\n#> 6   75 113 102  83 119\n#> 7  106  96 113 113 112\n#> 8  110 108  99  95  94\n#> 9   90  97  81 133 118\n#> 10  83  94  93 112  99\nrowMeans(df)\n#>  [1] 103.0  99.4 104.6 101.8  89.2  98.4 108.0 101.2 103.8  96.2\nn_samples <- 10000\nsample_size <- 5\nsample_means <- rep(NA, n_samples)\n\nfor (i in 1:n_samples) {\n    y <- round(rnorm(5, 100, 15))\n    sample_means[i] <- mean(y)\n}\ndata.frame(sample_means) %>% \n  ggplot(aes(x = sample_means)) +\n  geom_histogram(aes(y = ..density..)) +\n  labs(\n    x = \"Media del quoziente d'intelligenza in campioni di ampiezza n = 5\",\n    y = \"Densità\"\n  )\n#> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`."},{"path":"distribuzione-campionaria.html","id":"distribuzione-campionaria-della-media","chapter":"Capitolo 20 Distribuzione campionaria","heading":"20.2 Distribuzione campionaria della media","text":"Consideriamo ora l’inferenza statistica nel caso della statistica campionaria corrispondente alla media del campione. Denotiamo con \\(\\bar{X}_n\\) la media calcolata su un campione di \\(n\\) osservazioni. Abbiamo detto che, ogni volta che osserviamo un nuovo campione di ampiezza \\(n\\), la statistica \\(\\bar{X}_n\\) assumerà un valore diverso. termini tecnici diciamo che \\(\\bar{X}_n\\) è una variabile aleatoria, ovvero è una variabile che assume un nuovo valore ogni qualvolta l’esperimento casuale viene ripetuto (nel caso presente l’esperimento casuale corrisponde ’estrazione di un campione casuale dalla\npopolazione e al calcolo della media delle osservazioni campionarie). L’insieme dei valori che \\(\\bar{X}_n\\) può assumere tutti campioni casuali di ampiezza \\(n\\) che possono essere estratti dalla popolazione è detto distribuzione campionaria della media.","code":""},{"path":"distribuzione-campionaria.html","id":"valore-atteso-della-media-campionaria","chapter":"Capitolo 20 Distribuzione campionaria","heading":"20.2.1 Valore atteso della media campionaria","text":"Qual è la media (valore atteso) della distribuzione campionaria della\nmedia? È facile mostrare che \\(\\mu_{\\bar{X}_n}\\) coincide con il valore\nmedio \\(\\mu\\) della popolazione da cui campioni di ampiezza \\(n\\) sono\nstati estratti.Dimostrazione. Ponendo \\(\\bar{X}_n = S_n/n\\), dove \\(S_n = X_1 + X_2 + \\dots + X_n\\) è la somma di \\(n\\) variabili aleatorie iid, ne segue che:\n\\[\n\\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} \\mathbb{E}(S_n) = \\frac{1}{n} \\mathbb{E}(X_1 + X_2 + \\dots + X_n ) =  \\frac{1}{n} n \\mu = \\mu.\n\\]","code":""},{"path":"distribuzione-campionaria.html","id":"varianza-della-media-campionaria","chapter":"Capitolo 20 Distribuzione campionaria","heading":"20.2.2 Varianza della media campionaria","text":"Qual è la varianza della distribuzione campionaria della media? Anche \nquesto caso si può facilmente mostrare come la varianza della\ndistribuzione delle medie campionarie è legata alla varianza \\(\\sigma^2\\)\ndella popolazione dalla seguente relazione:\\[\nvar(\\bar{X}_n) = \\frac{\\sigma^2}{n},\n\\tag{20.1}\n\\]\ndove \\(n\\) è la numerosità dei campioni casuali.Prima di presentare la dimostrazione dell’eq. (20.1) è necessario ricordare la seguente proprietà della varianza: se una variabile aleatoria \\(X\\) viene moltiplicata per una costante \\(\\), la varianza della variabile aleatoria \\(aX\\) diventa\n\\[\nvar(X) = ^2 var(X).\n\\]\nPossiamo ora comprendere la dimostrazione seguente.Dimostrazione. \\[\nvar(\\bar{X}_n) = \\frac{1}{n^2} var(S_n) = \\frac{1}{n^2} n \\sigma^2 \n= \\frac{\\sigma^2}{n}.\n\\]due risultati che abbiamo ottenuto sopra sono molto importanti. Il primo ci dice che la media campionaria è uno stimatore corretto (ovvero, non distorto) della media della popolazione. Il secondo quantifica l’errore medio che compiamo usando usiamo la media del campione quale stima della media della popolazione.","code":""},{"path":"distribuzione-campionaria.html","id":"errore-standard","chapter":"Capitolo 20 Distribuzione campionaria","heading":"20.2.3 Errore standard","text":"La radice quadrata della varianza della distribuzione campionaria della\nmedia si chiama errore standard della media campionaria. Questa è una\nquantità molto importante perché ci informa sul livello di incertezza\ndella nostra stima fornendoci un valore che ha la stessa unità di misura\ndelle osservazioni. Se vogliamo stimare la media della popolazione\nutilizzando la media del campione quale stimatore ci possiamo aspettare\ndi compiere un errore medio pari \\(\\frac{\\hat{\\sigma}_n}{\\sqrt{n}},\\)\nladdove \\(\\hat{\\sigma}_n\\) è la deviazione standard del campione\nutilizzata quale stima della deviazione standard della popolazione.","code":""},{"path":"distribuzione-campionaria.html","id":"simulazione-2","chapter":"Capitolo 20 Distribuzione campionaria","heading":"20.2.3.1 Simulazione","text":"Per chiarire le due conclusioni precedenti, utilizziamo nuovamente la simulazione che abbiamo eseguito precedenza, quando abbiamo generato 10000 medie campionarie per campioni di ampiezza \\(n = 5\\) estratti dalla popolazione \\(\\mathcal{N}(\\mu = 100, \\sigma = 15\\)). La distribuzione di tali medie è rappresentata nella figura 20.1. realtà, quella fornita dalla figura 20.1 non è esattamente la distribuzione campionaria delle medie di campioni casuali di ampiezza \\(n=5\\) estratti dalla popolazione \\(\\mathcal{N}(\\mu = 100, \\sigma = 15\\)): la vera distribuzione campionaria della media si otterrebbe estraendo infiniti campioni di ampiezza \\(n = 5\\) dalla popolazione. Tuttavia, avendo disposizione le medie di 10000 campioni, ci possiamo aspettare un risultato empirico non troppo diverso da quello teorico. Verifichiamo dunque le due conclusioni cui siamo giunti sopra.Sappiamo che la media delle 10000 medie di campioni di ampiezza \\(n=5\\) dovrà essere molto simile (anche se non identica, dato che il numero dei campioni è grande, ma non infinito) alla media della popolazione. Infatti, questa simulazione, abbiamo che \\(\\hat{\\mu}_{\\bar{X}_n} =\\) 99.97 contro un valore teorico \\(\\mu=100\\). ’aumentare del numero di campioni estratti \\(\\mu_{\\bar{X}_n}\\) diventa sempre più simile \\(\\mu\\).Calcoliamo ora la deviazione standard (detta errore standard) delle 10000 medie campionarie che abbiamo trovato. Nella simulazione, tale valore è pari 6.663 mentre il valore teorico è \\(\\sigma_{\\bar{X}} = \\frac{\\sigma}{\\sqrt{n}} = \\frac{15}{\\sqrt{5}} = 6.708\\). Possiamo dunque dire che, con 10000 medie campionarie le proprietà della distribuzione campionaria della media vengono approssimate molto bene.Si noti che possiamo attribuire \\(\\sigma_{\\bar{X}}\\) la stessa interpretazione che è possibile fornire, generale, alla deviazione standard. Nel caso di un campione, la deviazione standard \\(\\sigma\\) ci dice di quanto, media, valori osservati sono lontani dalla media. Nel caso della distribuzione campionaria delle medie dei campioni, \\(\\sigma_{\\bar{X}}\\) ci dice quale errore medio compiamo stimando \\(\\mu\\) con \\(\\bar{X}\\). altre parole, ci dice che, se considerassimo tutte le medie \\(\\bar{X}\\) che si possono calcolare sulla base degli infiniti campioni di dimensioni \\(n\\) che possiamo estrarre dalla popolazione, la distanza media tra ciascuna di queste medie e la media della distribuzione (che corrisponde alla media della popolazione) è pari \\(\\sigma_{\\bar{X}}\\). La quantità \\(\\sigma_{\\bar{X}}\\) può dunque essere considerata come una misura di errore nella stima di \\(\\mu\\) mediante \\(\\bar{X}\\).","code":""},{"path":"distribuzione-campionaria.html","id":"distribuzioni-delle-statistiche-campionarie","chapter":"Capitolo 20 Distribuzione campionaria","heading":"20.2.4 Distribuzioni delle statistiche campionarie","text":"Qualunque statistica campionaria ha una sua distribuzione teorica. Consideriamo, ad esempio, il massimo del campione quale statistica campionaria di interesse. Ripetiamo la simulazione che abbiamo descritto sopra calcolando, questa volta, il valore massimo del campione.risultati di questa simulazione sono riportati nella figura 20.2.\nFigura 20.2: Istogramma della distribuzione del QI massimo osservato ciascun campione casuali di ampiezza \\(n=5\\). Per creare la figura sono stati considerati 10000 campioni casuali.\nNon dovrebbe sorprenderci che, prendendo 5 persone caso per poi selezionare la persona con il punteggio QI più alto, otteniamo una distribuzione che, rispetto alla distribuzione della figura 20.2, è traslata verso destra. Nella presente simulazione, la distribuzione del QI massimo di un campione casuale di ampiezza \\(n = 5\\) si situa approssimativamente nell’intervallo compreso tra 90 e 150.","code":"\nset.seed(123)\nn_samples <- 10000\nsample_size <- 5\nsample_max <- rep(NA, n_samples)\n\nfor (i in 1:n_samples) {\n    y <- round(rnorm(5, 100, 15))\n    sample_max[i] <- max(y)\n}\ndata.frame(sample_max) %>% \n  ggplot(aes(x = sample_max)) +\n  geom_histogram(aes(y = ..density..)) +\n  labs(\n    x = \"Valore massimo del QI in campioni di ampiezza n = 5\",\n    y = \"Densità\"\n  )\n#> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`."},{"path":"distribuzione-campionaria.html","id":"sec:tlc","chapter":"Capitolo 20 Distribuzione campionaria","heading":"20.3 Teorema del limite centrale","text":"Chiediamoci ora quale sia la relazione che intercorre tra la distribuzione campionaria della media e l’ampiezza \\(n\\) dei campioni. ciascun pannello della figura 20.3 sono riportati risultati di una simulazione nella quale sono stati generati 10000 campioni di ampiezza \\(n\\) per poi calcolare il QI medio ciascun campione.\nFigura 20.3: Nel primo pannello alto sinistra ciascun campione contiene una sola osservazione, per cui la media del campione è identica al valore del QI di una persona. Di conseguenza, la distribuzione campionaria della media è identica alla distribuzione dei valori del QI nella popolazione. Quando \\(n=2\\) la media di ciascun campione tende ad essere più simile alla media della popolazione di quanto lo sia ciascuna singola osservazione della popolazione. Quindi anche l’ampiezza dell’istogramma (ovvero, la distribuzione campionaria della media) diminuisce, se confrontata con la dispersione della popolazione. Quando giungiamo ad una numerosità campionaria pari \\(n=30\\) vediamo che la maggior parte delle medie campionarie tende ad addensarsi intorno alla media della popolazione.\nGli istogrammi mostrano la distribuzione delle medie così ottenute, cioè ci forniscono una\nrappresentazione grafica della distribuzione campionaria della media al variare dell’ampiezza campionaria \\(n\\). punteggi del QI sono stati ricavati da una distribuzione normale con media 100 e deviazione standard 15 e tale distribuzione viene visualizzata con una linea nera continua ciascun pannello della figura 20.3.Quello che ci chiediamo è come varia la distribuzione campionaria della\nmedia funzione dell’ampiezza del campione. Intuitivamente, conosciamo\ngià parte della risposta. Se abbiamo disposizione solo poche\nosservazioni, è probabile che la media campionaria sia abbastanza\nimprecisa: se ripetiamo l’esperimento casuale del campionamento e\nricalcoliamo la media del campione, otteniamo una risposta molto diversa\nad ogni ripetizione dell’esperimento casuale. Di conseguenza, la\ndistribuzione campionaria della media comprenderà una gamma di valori\nmolto grande. Invece, si ottengono risultati molto simili tra loro se\nripetiamo l’esperimento del campionamento utilizzando campioni di grandi\ndimensioni. questo secondo caso, la distribuzione campionaria\nincluderà una gamma di valori delle medie molto minore che \nprecedenza. Questo andamento si può notare nei pannelli della\nfigura 20.3: l’errore standard della media campionaria diminuisce ’aumentare dell’ampiezza del campione.Ciò che abbiamo descritto finora, tuttavia, riguarda solo un aspetto di\nquello che accade alla distribuzione campionaria di \\(\\bar{X}\\)\n’aumentare di \\(n\\). Gli esempi discussi finora erano relativi al caso\ndi campioni casuali del QI. Poiché punteggi del QI seguono\napprossimativamente una distribuzione normale, abbiamo assunto che anche\nla popolazione abbia una distribuzione normale. Tuttavia, si presentano\nspesso casi cui la distribuzione della popolazione non è normale. \nqueste circostanze, cosa succede alla distribuzione campionaria della\nmedia? La cosa straordinaria è questa: non importa quale sia la forma\ndella distribuzione della popolazione, ’aumentare della dimensione\ncampionaria \\(n\\), la distribuzione di frequenza delle medie campionarie\nsi approssima sempre più alla tipica forma campana di una\ndistribuzione normale.Per farci un’idea di quello che succede, eseguiamo alcune simulazioni usando R.Consideriamo la distribuzione della popolazione rappresentata dall’istogramma riportato nella figura 20.4. Confrontando l’istogramma triangolare con la curva campana tracciata dalla linea nera risulta chiaro che la distribuzione della popolazione non assomiglia affatto una distribuzione normale.\nFigura 20.4: Dimostrazione del Teorema del limite centrale. Consideriamo una popolazione che non segue la distribuzione normale. La distribuzione di tale popolazione è rappresentata dall’istogramma grigio.\nuna prima simulazione, ho estratto 50000 campioni di ampiezza \\(n=2\\) da questa distribuzione e, per ciascuno di essi ho calcolato la media campionaria. Come si può vedere nella figura 20.5, la distribuzione campionaria non è triangolare. Certamente non è Normale, ma assomiglia di più ad una distribuzione campanulare di quanto assomigli alla distribuzione della popolazione raffigurata nella figura 20.4.\nFigura 20.5: Distribuzione campionaria di \\(ar{X}\\) per campioni casuali di ampiezza \\(n=2\\) estratti dalla popolazione rappresentata nella figura 1.7.\nQuando aumento la numerosità del campione \\(n=4\\) la distribuzione campionaria della media si approssima abbastanza bene alla normale, figura 20.6.\nFigura 20.6: Distribuzione campionaria di \\(ar{X}\\) per campioni casuali di ampiezza \\(n=4\\) estratti dalla popolazione rappresentata nella figura 1.7.\nGià con \\(n=8\\) l’approssimazione diventa molto buona, come indicato nella figura 20.7.\nFigura 20.7: Distribuzione campionaria di \\(ar{X}\\) per campioni casuali di ampiezza \\(n=8\\) estratti dalla popolazione rappresentata nella figura 1.7.\naltre parole, se la dimensione del campione non è piccola, allora la distribuzione campionaria della media sarà approssimativamente normale indipendentemente dalla distribuzione della popolazione! Questo comportamento della distribuzione campionaria di \\(\\bar{X}\\) al variare di \\(n\\) viene descritto maniera formale dal Teorema del limite centrale.Il Teorema del limite centrale ci dice che, se vengono selezionati campioni sufficientemente grandi (tipicamente è sufficiente che \\(n > 30\\) purché il carattere osservato non sia troppo asimmetrico), allora la media campionaria \\(\\bar{X}\\) di \\(n\\) variabili aleatorie indipendenti \\(X_1, X_2, \\dots\\) converge distribuzione ad una variabile aleatoria normale di media \\(\\mu\\) e varianza \\(\\sigma^2/n\\).È altresì molto importante notare che, se le variabili di partenza \\(X_1\\), \\(X_2\\), …\\(X_n\\) sono esse stesse Normali, tutte con lo stesso valore atteso \\(\\mu\\) e la stessa varianza \\(\\sigma^2\\), allora il Teoremadel limite centrale è esatto. Ovvero per ogni \\(n\\),\\[\n\\bar{X}_n \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right).\n\\]\nQuesta proprietà discende dal seguente teorema.conclusione, il Teorema del limite centrale ci consente di specificare completamente le proprietà della distribuzione campionaria di \\(\\bar{X}_n\\).Se la popolazione è normale, allora \\(\\bar{X}_n \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right)\\) indipendentemente da \\(n\\).Se la popolazione è normale, allora \\(\\bar{X}_n \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right)\\) indipendentemente da \\(n\\).Se invece la popolazione non è normale, allora la distribuzione di \\(\\bar{X}_n\\) tende \\(\\mathcal{N}\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right)\\) al crescere di \\(n\\).Se invece la popolazione non è normale, allora la distribuzione di \\(\\bar{X}_n\\) tende \\(\\mathcal{N}\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right)\\) al crescere di \\(n\\).Esaminiamo ora un esercizio cui viene applicato il TLC.Supponiamo di misurare un oggetto con una bilancia non molto precisa. Supponiamo inoltre che l’errore di misura \\(E\\) della bilancia si distribuisca maniera Normale con media \\(0\\) e deviazione standard \\(\\sigma = 2\\) grammi. Se l’oggetto considerato ha un peso uguale \\(w\\), il peso osservato \\(X\\) sarà dato dalla somma del suo peso vero e l’errore di misurazione: \\(X = w + E\\). Dato che \\(w\\) è una costante, \\(X\\) seguirà la distribuzione normale con media \\(\\mathbb{E}(X) = \\mathbb{E}(w + E) = w + \\mathbb{E}(E) = w\\) e varianza \\(var(X) = var(w + E) = var(E) = 4\\). Qual è la probabilità di ottenere una misurazione che non differisce di più di un grammo dal peso vero?Dobbiamo trovare la probabilità\\[\n\\begin{aligned}\nP(-1 \\leq X - w \\leq 1)  &= P\\bigg(-\\frac{1}{2} \\leq \\frac{X - w}{\\sigma} \\leq \\frac{1}{2}\\bigg)\\notag\\\\ &= P\\bigg(-\\frac{1}{2} \\leq Z \\leq \\frac{1}{2}\\bigg)\\notag\n\\end{aligned}\n\\]\novveroConsiderando l’evento complementare, possiamo dunque dire che c’è una probabilità maggiore di \\(0.6\\) che la bilancia produca un valore che differisce di almeno un grammo dal peso vero.Chiediamoci ora cosa succede se, invece di accontentarci di una singola misurazione, calcoliamo la media di \\(n = 10\\) misurazioni. questo secondo caso,\\[\n\\begin{aligned}\nP\\left(-1 \\leq \\frac{S_{10}}{10} - w \\leq 1\\right) \n&= P\\bigg(-\\frac{1}{\\sqrt{4/10}} \\leq \\frac{\\frac{S_{10}}{10} - w}{\\sigma/\\sqrt{10}} \\leq \\frac{1}{\\sqrt{4/10}}\\bigg)\\notag\\\\ \n&= P\\bigg(-\\frac{\\sqrt{10}}{2} \\leq Z \\leq \\frac{\\sqrt{10}}{2}\\bigg)\\notag\n\\end{aligned}\n\\]\novveroConsiderando l’evento complementare, possiamo concludere che c’è una probabilità pari solo 0.114 che la media di 10 misurazioni assuma un valore che differisce di più di un grammo dal peso vero. È dunque ovvio che le medie di misurazioni ripetute sono migliori delle singole misure.","code":"\npar(mfrow=c(2, 3))\n\nmu <- 100\nsigma <- 15\nnrep <- 1e5\n\nqi <- rep(NA, nrep)\n\nget_mean <- function(nobs, mu, sigma) {\n  x <- round(rnorm(n = nobs, mean = mu, sd = sigma))\n  mean(x) \n}\n\nymax <- 0.14\n\nnobs <- 1\nqi <- replicate(nrep, get_mean(nobs, mu, sigma))\nhist(qi, freq=FALSE,\n     yaxt='n', \n     ylim=c(0, ymax),\n     xlim = c(40, 160),\n     ylab = \"\", xlab = \"QI\", main = \"n = 1\")\ncurve(dnorm(x, mean=mu, sd=sigma), add=TRUE, yaxt=\"n\")\n\nnobs <- 2\nqi <- replicate(nrep, get_mean(nobs, mu, sigma))\nhist(qi, freq=FALSE,\n     yaxt='n', \n     ylim=c(0, ymax),\n     xlim = c(40, 160),\n     ylab = \"\", xlab = \"QI\", main = \"n = 2\")\ncurve(dnorm(x, mean=mu, sd=sigma), add=TRUE, yaxt=\"n\")\n\nnobs <- 3\nqi <- replicate(nrep, get_mean(nobs, mu, sigma))\nhist(qi, freq=FALSE,\n     yaxt='n', \n     ylim=c(0, ymax),\n     xlim = c(40, 160),\n     ylab = \"\", xlab = \"QI\", main = \"n = 3\")\ncurve(dnorm(x, mean=mu, sd=sigma), add=TRUE, yaxt=\"n\")\n\nnobs <- 5\nqi <- replicate(nrep, get_mean(nobs, mu, sigma))\nhist(qi, freq=FALSE,\n     yaxt='n', \n     ylim=c(0, ymax),\n     xlim = c(40, 160),\n     ylab = \"\", xlab = \"QI\", main = \"n = 5\")\ncurve(dnorm(x, mean=mu, sd=sigma), add=TRUE, yaxt=\"n\")\n\nnobs <- 15\nqi <- replicate(nrep, get_mean(nobs, mu, sigma))\nhist(qi, freq=FALSE,\n     yaxt='n', \n     ylim=c(0, ymax),\n     xlim = c(40, 160),\n     ylab = \"\", xlab = \"QI\", main = \"n = 15\")\ncurve(dnorm(x, mean=mu, sd=sigma), add=TRUE, yaxt=\"n\")\n\nnobs <- 30\nqi <- replicate(nrep, get_mean(nobs, mu, sigma))\nhist(qi, freq=FALSE,\n     yaxt='n', \n     ylim=c(0, ymax),\n     xlim = c(40, 160),\n     ylab = \"\", xlab = \"QI\", main = \"n = 30\")\ncurve(dnorm(x, mean=mu, sd=sigma), add=TRUE, yaxt=\"n\")\n\npar(mfrow=c(1, 1))\n# needed for printing\nwidth <- 6\nheight <- 6\n\n# parameters of the beta\na <- 2\nb <- 1\n\n# mean and standard deviation of the beta\ns <- sqrt(a * b / (a + b)^2 / (a + b + 1))\nm <- a / (a + b)\n\n# define function to draw a plot\nplot_one <- function(n, N = 50000) {\n\n  # generate N random sample means of size n\n  X <- matrix(rbeta(n * N, a, b), n, N)\n  X <- colMeans(X)\n\n  # plot the data\n  hist(\n    X,\n    breaks = seq(0, 1, .025), border = \"white\", freq = FALSE,\n    #col = ifelse(colour, emphColLight, emphGrey),\n    col = \"gray\",\n    xlab = \"Media campionaria\", ylab = \"\", xlim = c(0, 1.2),\n    main = paste(\"n =\", n), axes = FALSE,\n    font.main = 1, ylim = c(0, 5)\n  )\n  #box()\n  axis(1)\n  # axis(2)\n\n  # plot the theoretical distribution\n  lines(x <- seq(0, 1.2, .01), dnorm(x, m, s / sqrt(n)),\n    lwd = 2, col = \"black\", type = \"l\"\n  )\n}\nplot_one(1)\nplot_one(2)\nplot_one(4)\nplot_one(8)\npnorm(0.5, 0, 1) - pnorm(-0.5, 0, 1)\n#> [1] 0.3829249\npnorm(sqrt(10)/2, 0, 1) - pnorm(-sqrt(10)/2, 0, 1)\n#> [1] 0.8861537"},{"path":"distribuzione-campionaria.html","id":"intervalli-di-confidenza","chapter":"Capitolo 20 Distribuzione campionaria","heading":"20.4 Intervalli di confidenza","text":"","code":""},{"path":"distribuzione-campionaria.html","id":"parametri-di-un-modello-statistico","chapter":"Capitolo 20 Distribuzione campionaria","heading":"20.4.1 Parametri di un modello statistico","text":"Nel gergo statistico, parametri sono valori sconosciuti che determinano un modello statistico. Si consideri il modello statistico \\(Y \\sim \\mathcal{N}(\\mu, \\sigma)\\). Il modello statistico precedente ci dice che \\(Y\\) è una v.. distribuita come una normale di parametri \\(\\mu\\) e \\(\\sigma\\). Supponiamo che la \\(Y\\) sia il QI. questo caso è facile capire cosa sono parametri \\(\\mu\\) e \\(\\sigma\\). Quello del QI, infatti, è un caso particolare perché il test di intelligenza Wechsler Adult Intelligence Scale (WAIS) è stato costruito modo tale da produrre dei dati che si distribuiscono un modo noto: il QI segue la distribuzione normale di parametri \\(\\mu = 100\\) e \\(\\sigma = 15\\). generale, però, parametri di un modello statistico sono sconosciuti.","code":""},{"path":"distribuzione-campionaria.html","id":"lincertezza-della-stima","chapter":"Capitolo 20 Distribuzione campionaria","heading":"20.4.2 L’incertezza della stima","text":"Dato che parametri sono, genere, sconosciuti, è necessario stimarli. Non è sufficiente, però, ottenere una stima puntuale di un parametro. È anche necessario quantificare l’incertezza della stima. L’incertezza della stima viene descritta dall’approccio frequentista nei termini di un intervallo di confidenza. L’intervallo di confidenza si costruisce mediante l’errore standard.L’errore standard è la deviazione standard stimata della stima di un parametro e quantifica il grado della nostra incertezza sulla quantità di interesse. Chiariamo questa idea facendo riferimento alla la figura 20.1. Tale figura riporta la distribuzione di un grande numero di medie campionarie, laddove la media di ciascun campione può essere considerata come una stima della media \\(\\mu\\) della popolazione. La deviazione standard di queste stime, chiamata errore standard, ci fornisce una misura dell’incertezza della nostra stima. altre parole, quantifica la variabilità dei valori delle stime del parametro \\(\\mu\\) che sono calcolate sulla base di campioni diversi. Come abbiamo visto nella simulazione del TLC, l’errore standard ha la proprietà di diminuire ’aumentare della dimensione del campione.L’errore standard viene utilizzato per calcolare l’intervallo di confidenza. L’intervallo di confidenza rappresenta un intervallo di valori di un parametro o quantità di interesse che sono approssimativamente coerenti con dati, data la distribuzione campionaria presunta. ’intervallo di confidenza possiamo dunque assegnare la seguente interpretazione. Supponiamo che il modello statistico sia corretto e supponiamo di ripetere tante volte il processo di campionamento. Se per ogni campione estratto dalla popolazione calcoliamo una stima del parametro, allora gli intervalli di confidenza del 50% e del 95% includeranno il vero valore del parametro il 50% e il 95% delle volte.Sotto l’ipotesi che la distribuzione campionaria segua la distribuzione normale, per campioni di grandi dimensioni l’intervallo di confidenza al 95% si costruisce nel modo seguente:\n\\[\n\\text{stima del parametro} \\pm 2 \\text{ errori standard.}\n\\]\nDalla distribuzione normale sappiamo che una stima del parametro \\(\\pm\\) 1 errore standard corrisponde ad un intervallo del 68% e una stima del parametro \\(\\pm\\) \\(\\frac{2}{3}\\) di un errore standard corrisponde ad un intervallo del 50%. Un intervallo del 50% è particolarmente facile da interpretare dato che il vero valore del parametro ha la stessa probabilità di essere incluso o escluso dall’intervallo. Un intervallo del 95% basato sulla distribuzione normale è circa tre volte più ampio di un intervallo del 50%.","code":""},{"path":"distribuzione-campionaria.html","id":"conclusioni-8","chapter":"Capitolo 20 Distribuzione campionaria","heading":"Conclusioni","text":"risultati precedenti consentono le seguenti conclusioni. Se \\(X_1, \\dots, X_n\\) è un insieme di variabili aleatorie ..d., tutte con media \\(\\mu\\) e varianza \\(\\sigma^2\\), allora\n\\[\n\\mathbb{E}(\\bar{X}) = \\mu, \\quad var(\\bar{X}) = \\frac{\\sigma^2}{n}.\n\\]\nSe le \\(X_i\\) seguono la distribuzione normale, ne segue che \\(\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma/\\sqrt{n})\\), quanto qualunque combinazione lineare di variabili aleatorie Normali è ancora una variabile aleatoria Normale. Invece, se le \\(X_i\\) non seguono la distribuzione normale, il Teorema del limite centrale ci consente comunque di dire che \\(\\bar{X}\\) tende \\(\\mathcal{N}(\\mu, \\sigma/\\sqrt{n})\\) al crescere di \\(n\\). risultati precedenti sono estremamente importanti perché specificano completamente la distribuzione della media campionaria e vengono utilizzati dall’approccio frequentista per l’inferenza sulla media di una popolazione.","code":""},{"path":"significatività-statistica.html","id":"significatività-statistica","chapter":"Capitolo 21 Significatività statistica","heading":"Capitolo 21 Significatività statistica","text":"Una regola decisionale comunemente usata, ma che la comunità statistica\nfortemente sconsiglia, è quella di considerare un risultato come stabile\no reale se è “statisticamente significativo” e di considerare \nrisultati “non significativi” come rumorosi e da trattare con\nscetticismo. Per motivi discussi questo capitolo, è preferibile non\nconcentrarsi sulla significatività statistica, ma il concetto è\nabbastanza importante nella statistica applicata da meritare di essere\ntrattato qui.La significatività statistica è convenzionalmente definita come un\n\\(p\\)-valore inferiore 0.05, relativo qualche ipotesi nulla o valore\npre-specificato che indicherebbe l’assenza di effetto, come discusso di\nseguito nel contesto del test di ipotesi. Facendo riferimento al\nprecedente esempio del QI, usando un linguaggio un po’ approssimativo\n(ma sostanzialmente corretto) possiamo dire che vengono etichettate come\n“statisticamente significative” le medie di quei campioni che risultano\ndistanti di almeno due errori standard da un qualche valore atteso (per\nesempio, 100); altrimenti le medie dei campioni vengono dette “non\nstatisticamente significative.”Parlando più generale, una stima si dice “non statisticamente\nsignificativa” se il suo valore osservato può essere ragionevolmente\nspiegato con una semplice variazione casuale.Facciamo un primo esempio che illustra, senza spiegare dettagli, il ragionamento frequentista che porta alla conclusione secondo la quale un risultato è, oppure non è, “statisticamente significativo.”Supponiamo di credere che una moneta sia equilibrata. La lanciamo 20 volte e\nosserviamo 8 volte testa e 12 volte croce, con una proporzione osservata di eventi “testa” \\(p= 0.4\\). L’ipotesi nulla è che la moneta sia equilibrata, ovvero \\(\\pi= 0.5\\). Ovviamente, il campione di 8 volte testa e 12 volte croce è solo uno dei possibili campioni che è possibile ottenere lanciando una moneta per 20 volte. Dobbiamo dunque sapere di come variano, media, risultati ottenuti da campioni diversi. Tale variabilità va sotto il nome di “errore standard” (ovvero, rappresenta la deviazione standard della statistica questione nell’universo dei campioni). L’errore standard di una proporzione si calcola come \\(\\sqrt{\\frac{p (1-p)}{n}}\\). Utilizzando questa formula, calcoliamo il seguente intervallo: la stima della statistica (nel nostro caso \\(p\\) = 0.4) \\(\\pm\\) due errori standard:\\[\n0.4 \\pm 2 \\times 0.11.\n\\]La statistica osservata dista meno di due errori standard dall’ipotesi\nnulla del 50%. Di conseguenza, diciamo che il risultato non è “significativamente” diverso dal caso (ovvero, è troppo simile al risultato predetto dall’ipotesi nulla).","code":""},{"path":"significatività-statistica.html","id":"un-esempio-motivante","chapter":"Capitolo 21 Significatività statistica","heading":"21.1 Un esempio motivante","text":"Per introdurre maggiore dettaglio il concetto di significatività statistica consideriamo una ricerca svolta da Mehr et al. (2016). La ricerca di Mehr et al. (2016)\nriguarda la musica. L’ascolto musicale è presente tutte le fasi della\nvita e anche nell’infanzia. Tra le altre cose, la musica può trasmettere\ninformazioni relative ’appartenenza sociale – pensiamo alle canzoni\npopolari, ad esempio. Mehr et al. (2016) si sono chiesti se la musica sia\ncapace di trasmettere messaggi di tipo sociale anche bambini molto\npiccoli. Nello specifico, Mehr et al. (2016) si sono chiesti se bambini di\n5 mesi mostrino una preferenza per individui sconosciuti che cantano una\ncanzone loro familiare, rispetto ad altri individui sconosciuti che\ncantano una canzone simile, con le stesse parole e lo stesso ritmo, ma\ncon una diversa melodia. Mehr et al. (2016) hanno scoperto che, effetti,\nle cose stanno veramente così, ma solo quando, nella fase di\nfamiliarizzazione, la canzone test veniva cantata dai genitori, ma non\nquando nella fase di familiarizzazione la stessa canzone veniva cantata\nda un estraneo. Secondo gli autori, questo mostra che il significato\nsociale è l’elemento cruciale della preferenza dei bambini, non\nsemplicemente la familiarità con la canzone.","code":""},{"path":"significatività-statistica.html","id":"la-domanda-della-ricerca","chapter":"Capitolo 21 Significatività statistica","heading":"21.1.1 La domanda della ricerca","text":"La domanda che Mehr et al. (2016) si sono posti si chiama domanda della\nricerca. psicologia, le domande della ricerca sono delle ipotesi che\nriguardano costrutti psicologici. L’ascolto della musica certamente ha\nche fare con la psicologia e il significato che attribuiamo\n’ascolto della musica è certamente un fenomeno psicologico. Per cui\nla domanda che Mehr et al. (2016) si sono posti è certamente una domanda\nlegittima nel contesto della ricerca psicologica.psicologia, le ipotesi della ricerca sono delle proposizioni che\ndescrivono le proprietà dei fenomeni psicologici. Tali proposizioni\npossono essere vere oppure false. Alcune volte le ipotesi della ricerca\nsono espresse termini po’ vaghi – nel caso presente, per esempio, ci\npossono essere idee diverse proposito di ciò che è musicale e di ciò\nche non lo è – ultima analisi le ipotesi della ricerca vengono\nvalutate base alla loro utilità: si dimostrano utili solo se\ncontribuiscono ad aggiungere qualcosa di importante rispetto ciò che\ngià sappiamo rispetto al fenomeno psicologico considerato.","code":""},{"path":"significatività-statistica.html","id":"le-ipotesi-statistiche","chapter":"Capitolo 21 Significatività statistica","heading":"21.1.2 Le ipotesi statistiche","text":"Quello che dobbiamo notare è che non è possibile verificare direttamente\nle ipotesi della ricerca. Le ipotesi della ricerca sono delle\nproposizioni relative alle caratteristiche o al funzionamento dei\nfenomeni psicologici. Tuttavia, generale, le ipotesi psicologiche non\nsono abbastanza precise da poter essere valutate direttamente. Quello\nche ricercatori possono fare, invece, è valutare delle ipotesi\nstatistiche. Le ipotesi statistiche non coincidono con l’ipotesi della\nricerca ma hanno il vantaggio di potere essere espresse termini\nprobabilistici.Nell’esperimento di Mehr et al. (2016), due settimane dopo la fase di\nfamiliarizzazione con la canzone test, bambini che facevano parte\ndell’esperimento venivano esaminati laboratorio. Ad essi venivano\nmostrate due video-registrazioni. Una registrazione presentava un\nestraneo che cantava la canzone test; l’altra registrazione presentava\nun secondo individuo non conosciuto dai bambini che cantava una canzone\nsimile alla prima, ma non familiare ai bambini. ricercatori hanno\nmisurato tempi di fissazione dello sguardo dei bambini nei confronti\ndi ciascuna delle due video-registrazioni. Nel primo esperimento, la\nvariabile dipendente era uguale alla media, calcolata su 32 casi, della\nproporzione del tempo di fissazione rivolta al video “familiare”\nrispetto al tempo di fissazione totale (ovvero la somma del tempo di\nfissazione del video “familiare” e del tempo di fissazione del video\n“non familiare”).Dato che non è possibile valutare direttamente la domanda della ricerca\nè necessario stabilire una connessione tra l’ipotesi della ricerca e\nl’ipotesi statistica. Nel caso presente possiamo pensare tre\npossibilità.Se bambini non hanno alcuna preferenza nei confronti di uno dei\ndue tipi di video-registrazione, allora la media delle proporzioni\ndei tempi di fissazione di tutti bambini possibili (ovvero, nella\npopolazione) sarà uguale \\(\\mu = 0.5\\), perché, media, tempi di\nfissazione per le due video-registazioni saranno uguali.Se bambini non hanno alcuna preferenza nei confronti di uno dei\ndue tipi di video-registrazione, allora la media delle proporzioni\ndei tempi di fissazione di tutti bambini possibili (ovvero, nella\npopolazione) sarà uguale \\(\\mu = 0.5\\), perché, media, tempi di\nfissazione per le due video-registazioni saranno uguali.Se Mehr et al. (2016) hanno ragione, allora bambini preferiranno\nguardare il video con la canzone familiare piuttosto che il video\ncon la canzone non familiare. Questa situazione si traduce\nnell’ipotesi statistica \\(\\mu > 0.5\\) (con \\(\\mu = 0.5\\) che rappresenta\nil livello del caso).Se Mehr et al. (2016) hanno ragione, allora bambini preferiranno\nguardare il video con la canzone familiare piuttosto che il video\ncon la canzone non familiare. Questa situazione si traduce\nnell’ipotesi statistica \\(\\mu > 0.5\\) (con \\(\\mu = 0.5\\) che rappresenta\nil livello del caso).Una terza possibilità è che bambini siano maggiormente attratti da\nuna melodia non familiare – questo è il contrario di ciò che\npropongono gli autori della ricerca. Tale possibilità si traduce\nnell’ipotesi statistica \\(\\mu < 0.5\\).Una terza possibilità è che bambini siano maggiormente attratti da\nuna melodia non familiare – questo è il contrario di ciò che\npropongono gli autori della ricerca. Tale possibilità si traduce\nnell’ipotesi statistica \\(\\mu < 0.5\\).Le tre ipotesi precedenti sono esempi di ipotesi statistiche. Sono\ninfatti delle proposizioni proposito dei valori di un parametro di un\nmodello statistico. Nel caso presente, il modello statistico è la\ndistribuzione della proporzione dei tempi di fissazione una\npopolazione virtuale di infiniti bambini di sei mesi d’età, come\nnell’esperiment di Mehr et al. (2016). Se consideriamo uno specifico\nbambino, la proporzione dei tempi di fissazione avrà un certo valore,\nmentre per un’altro bambino avrà un valore diverso. Il modello\nstatistico considerato descrive la distribuzione dei possibili valori\ndella proporzione del tempo di fissazione nei confronti del video\n“familiare.” Un tale modello statistico può essere messo relazione\ncon dati raccolti dagli sperimentatori perché Mehr et al. (2016) hanno\nmisurato proprio questo aspetto, ovvero la media della proporzione del\ntempo di fissazione rivolto al video “familiare.”","code":""},{"path":"significatività-statistica.html","id":"domanda-della-ricerca-e-ipotesi-statistiche","chapter":"Capitolo 21 Significatività statistica","heading":"21.1.3 Domanda della ricerca e ipotesi statistiche","text":"Ciò che la discussione precedente dovrebbe mettere chiaro è che,\nnella procedura di test di ipotesi, possiamo distinguere tra due tipi di\nipotesi molto diverse tra loro: da una parte abbiamo l’ipotesi della\nricerca che è un’affermazione sulla natura dei fenomeni psicologici;\ndall’altra parte abbiamo un’ipotesi statistica che è una proposizione\nche riguarda il modello generativo dei dati, ovvero le caratteristiche\ndella popolazione. Nell’esempio presente, l’ipotesi della ricerca è “le\npreferenze sociali dei bambini sono influenzate dalla musica; \nparticolare, sono favorite dalla familiarità con materiali musicali.”\nL’ipotesi statistica, invece, è: \\(\\mu > 0.5\\).Ciò che dobbiamo avere ben chiaro è che test vengono applicati alle\nipotesi statistiche, non alle ipotesi della ricerca. Ciò significa\nche, se l’esperimento non viene condotto nella maniera appropriata,\nallora si spezza il collegamento tra l’ipotesi statistica e la domanda\ndella ricerca. Per esempio, se l’attore che canta la melodia familiare\nassomiglia ad uno dei genitori del bambino, mentre l’altro attore ha un\naspetto molto diverso da quello dei genitori, allora sarebbe molto\nfacile trovare evidenze supporto dell’ipotesi statistica secondo cui\n\\(\\mu > 0.5\\); ma questo non avrebbe nulla che fare con la domanda della\nricerca.","code":""},{"path":"significatività-statistica.html","id":"ipotesi-nulla-e-ipotesi-alternativa","chapter":"Capitolo 21 Significatività statistica","heading":"21.2 Ipotesi nulla e ipotesi alternativa","text":"Fino qui il ragionamento è stato semplice: il ricercatore ha\nun’ipotesi proposito dei fenomeni psicologici e tale ipotesi di\nricerca corrisponde un’ipotesi statistica che riguarda il meccanismo\ngenerativo dei dati. Se il fenomeno psicologico possiede le proprietà\nsuggerite dall’ipotesi della ricerca, allora il ricercatore può\naspettarsi che dati osservati abbiano alcune specifiche\ncaratteristiche. questo punto, però, il ragionamento diventa\ncontro-intuitivo perché non è possibile verificare direttamente\nl’ipotesi statistica che corrisponde alla domanda della ricerca.","code":""},{"path":"significatività-statistica.html","id":"apagogia","chapter":"Capitolo 21 Significatività statistica","heading":"21.2.1 Apagogia","text":"linea di principio non è mai possibile dimostrare direttamente la\nverità d’una proposizione. Quello che possiamo fare, invece, è\ndimostrare la verità d’una proposizione maniera indiretta, ovvero\nprovando la falsità della proposizione contraddittoria.L’esempio classico è il seguente. Consideriamo la seguente proposizione:\n“Tutti cigni sono bianchi” (questo è l’esempio ornitologico preferito\nda Popper). L’osservazione di un numero qualsiasi di cigni bianchi non è\nsufficiente dimostrare la verità di questa proposizione – infatti, ci\npotrebbe essere da qualche parte un cigno non bianco che non abbiamo\nosservato (infatti, c’è). D’altra parte, invece, l’osservazione di un\nsolo cigno che non sia bianco (ovvero, per esempio, l’osservazione di un\ncigno nero proveniente dall’Australia) può falsificare la proposizione\nconsiderata. Questa è la logica del falsificazionismo di Popper.Questo modo di pensare è stato trasferito nella procedura di test di\nipotesi di stampo frequentista (ovvero, quello che stiamo discutendo\nora). Dato che non possiamo dimostrare vera l’ipotesi statistica\nassociata alla domanda della ricerca, seguiamo il percorso opposto.\nOvvero, ci poniamo l’obiettivo di dimostrare falso l’evento\ncomplementare quello specificato dall’ipotesi statistica associata\nalla domanda della ricerca. L’ipotesi statistica che vorremmo\nfalsificare si chiama “ipotesi nulla” e viene denotata con \\(H_0\\). Nel\ncaso dell’esempio che stiamo discutendo, l’ipotesi nulla è:\n\\(\\mu \\leq 0.5\\). Si noti che l’ipotesi nulla include tutte le possibili\nipotesi statistiche che si possono formulare (ovvero, \\(\\mu = 0.5\\) e\n\\(\\mu < 0.5\\)), ad eccezione di quella che è associata ’ipotesi della\nricerca (ovvero, \\(\\mu > 0.5\\)).pratica, ciò che stiamo facendo qui è dividere tutti possibili\nvalori di \\(\\pi\\) due gruppi: quei valori che sono coerenti con\nl’ipotesi della ricerca (ovvero, valori che specificano l’ipotesi\nalternativa, denotata con \\(H_1\\)) e quei valori che non sono coerenti con\nl’ipotesi della ricerca (ovvero, valori che specificano l’ipotesi\nnulla).Avendo detto questo, la cosa importante da riconoscere è che l’obiettivo\ndi un test di ipotesi non è quello di dimostrare che l’ipotesi\nalternativa è (probabilmente) vera; l’obiettivo è mostrare che l’ipotesi\nnulla è (probabilmente) falsa. La maggior parte delle persone ritiene\nche questo modo di ragionare sia piuttosto strano.","code":""},{"path":"significatività-statistica.html","id":"la-similitudine-del-processo-penale","chapter":"Capitolo 21 Significatività statistica","heading":"21.2.2 La similitudine del processo penale","text":"Un test di ipotesi è stato paragonato ad un processo penale, ovvero al\nprocesso nei confronti dell’ipotesi nulla. Possiamo immaginare che\nl’ipotesi nulla sia l’imputato, il ricercatore sia il pubblico ministero\ne il test statistico sia il giudice. Proprio come un processo penale,\nc’è una presunzione di innocenza: l’ipotesi nulla si ritiene vera meno\nche il ricercatore non dimostri, oltre ogni ragionevole dubbio, che è\nfalsa. Il ricercatore progetta l’esperimento modo da massimizzare la\npossibilità che dati producano una condanna. Il test statistico\n(ovvero il giudice questa similitudine) stabilisce le regole che\ndevono essere seguite per giungere al verdetto e queste regole sono\npensate per proteggere l’ipotesi nulla – particolare, per garantire\nche sia piccola la probabilità di una condanna se l’ipotesi nulla è\neffettivamente vera. Questo aspetto è importante: ’ipotesi nulla deve\nessere fornita una qualche forma di protezione, dato che il ricercatore\nsta cercando disperatamente di dimostrare che è essa è falsa.","code":""},{"path":"significatività-statistica.html","id":"due-tipi-di-errori","chapter":"Capitolo 21 Significatività statistica","heading":"21.3 Due tipi di errori","text":"Prima di entrare nei dettagli su come viene costruito un test statistico\nè utile capire la logica su cui esso è basato. precedenza abbiamo\nparagonato il test di ipotesi nulla ad un processo penale, ma ora\ndobbiamo essere più espliciti. Idealmente, vorremmo costruire il nostro\ntest modo da non commettere errori. Sfortunatamente, però, questo non\nè possibile: volte il ricercatore è sfortunato e finisce per prendere\nla decisione sbagliata, anche se adotta un processo decisionale\nrazionale. Ad esempio, può succedere che una moneta venga lanciata 10\nvolte di fila e produca testa tutte le 10 volte. Ciò sembra fornire una\nprova molto forte del fatto che la moneta è sbilanciata, ma ovviamente\nc’è una possibilità su 1024 che ciò accada anche se la moneta è\nequilibrata. altre parole, nella vita reale dobbiamo sempre accettare\nla possibilità che le nostre scelte siano sbagliate, anche quando\nsembrano ragionevoli. Di conseguenza, l’obiettivo dei test delle ipotesi\nstatistiche non è quello di eliminare completamente gli errori (questo è\nimpossibile), ma di ridurre gli errori al minimo.questo punto, dobbiamo precisare meglio cosa intendiamo per “errori.” Iniziamo con il rendere esplicito quello che è ovvio: l’ipotesi nulla può essere vera o falsa, e il nostro test ci può condurre rifiutare l’ipotesi nulla o non rifiutarla. La decisione di rigettare o non rigettare l’ipotesi nulla ci espone dunque al rischio di\ncommettere uno di due tipi di errore, come indicato nella figura 21.1. L’errore di tipo, denotato con \\(\\alpha\\), è quello che commettiamo se rigettiamo l’ipotesi nulla quando essa è vera. L’errore di II tipo, denotato con \\(\\beta\\), è quello che commettiamo se accettiamo l’ipotesi nulla mentre invece è vera l’ipotesi\nalternativa.\nFigura 21.1: Due tipi di errori.\n","code":""},{"path":"significatività-statistica.html","id":"errore-di-i-tipo-la-protezione-dei-diritti-dellimputato","chapter":"Capitolo 21 Significatività statistica","heading":"21.3.1 Errore di I tipo: la protezione dei diritti dell’imputato","text":"precedenza abbiamo paragonato il test statistico ad un processo\npenale. Infatti, un processo penale richiede che si stabilisca la\ncolpevolezza dell’imputato “oltre ogni ragionevole dubbio.” Le regole\ndel processo penale sono state progettate per garantire che non ci sia\n(quasi) nessuna possibilità di condannare ingiustamente un imputato\ninnocente: il processo penale è progettato (almeno teoria) per\nproteggere diritti dell’imputato. Detto altri termini, il processo\npenale non mette sullo stesso piano due tipi di errore che si possono\ncommettere: punire un innocente o assolvere un colpevole. L’errore che\nconsiste nel punire un innocente viene considerato assai più grave di\nquello che porta ad assolvere un colpevole.Un test statistico fa praticamente la stessa cosa: test di ipotesi\nstatistiche sono costruiti modo tale da controllare la probabilità di\nun errore di tipo, con l’obiettivo di mantenerla al di sotto di una\ncerta soglia prefissata. Questa probabilità, denotata con \\(\\alpha\\),\nviene chiamata “livello di significatività del test.” Usando parole\ndiverse, possiamo dire che un test di ipotesi ha un livello di\nsignificatività \\(\\alpha\\) se il tasso di errore di tipo non è più\ngrande di \\(\\alpha\\). Per convenzione, ricercatori fanno uso di tre\ndiversi livelli \\(\\alpha\\): 0.05, 0.01 e 0.001.","code":""},{"path":"significatività-statistica.html","id":"errore-di-ii-tipo-lasimmetria-del-giudizio","chapter":"Capitolo 21 Significatività statistica","heading":"21.3.2 Errore di II tipo: l’asimmetria del giudizio","text":"Che dire del tasso di errore di II tipo? realtà, vorremmo tenere\nanche quello sotto controllo e denotiamo la probabilità di un errore di\nII tipo con \\(\\beta\\). Il livello d’errore \\(\\beta\\) viene raramente\ndiscusso ed è molto più comune fare riferimento alla potenza del test,\nche è la probabilità dell’evento complementare, ovvero la probabilità\ncon cui rifiutiamo l’ipotesi nulla quando è realmente falsa, ovvero\n\\(1-\\beta\\). Un test viene detto “potente” quando è caratterizzato da un\npiccolo valore \\(\\beta\\) pur mantenendo il livello \\(\\alpha\\) sotto una\npiccola soglia di probabilità prefissata.Si noti l’asimmetria qui rivelata: test di ipotesi sono progettati per\ngarantire che il livello \\(\\alpha\\) sia mantenuto sotto la soglia\nprefissata, ma non esiste alcuna corrispondente garanzia proposito di\n\\(\\beta\\). Sicuramente è preferibile che il tasso di errore di II tipo sia\npiccolo, e generale ricercatori cercano di progettare loro\nesperimenti maniera tale da avere una ragionevole potenza del test\n(\\(1 - \\beta\\)) – questo si ottiene utilizzando un campione\nsufficientemente grande – ma nella logica della costruzione del test di\nipotesi questo aspetto è secondario rispetto alla necessità di\ncontrollare il tasso di errore di tipo.","code":""},{"path":"significatività-statistica.html","id":"come-si-costruisce-un-test-di-ipotesi","chapter":"Capitolo 21 Significatività statistica","heading":"21.4 Come si costruisce un test di ipotesi?","text":"Ritorniamo ’esempio relativo allo studio di Mehr et al. (2016). questo\ncaso, sulla base ’ipotesi della ricerca, l’ipotesi nulla può essere\nformulata come \\(H_0: \\mu \\leq 0.5\\). Esaminando un campione di 32 bambini\ndi età media pari 5.6 mesi, Mehr et al. (2016) hanno scoperto che, \nmedia, bambini dirigevano lo sguardo verso il video “familiare” nel\n59% del tempo totale di fissazione. Dunque, la media campionaria è\n\\(\\bar{X} = 0.59\\) Questo è il valore campionario rilevante per il test\ndell’ipotesi nulla.Ingenuamente, potremmo pensare che, per decidere se \\(H_0\\) sia falsa o\nmeno, sia sufficiente confrontare la proporzione calcolata nel campione\ncon il valore \\(\\pi\\) specificato dall’ipotesi nulla. Nel caso presente,\nl’ipotesi nulla non specifica un unico valore \\(\\mu\\) ma bensì un\nintervallo di valori: \\([0, 0.5]\\). dati campionari specificano un\nvalore \\(\\bar{X} = 0.56\\), ovvero un valore che non è incluso\nnell’intervallo specificato da \\(H_0\\). Questo è incoraggiante. Se invece\navessimo osservato \\(\\bar{X} = 0.41\\), per esempio, allora non ci sarebbe\nstato nient’altro da dire: se dati osservati sono compatibili con\n\\(H_0\\) non c’è bisogno di eseguire alcun test statistico – abbiamo già\ntrovato la risposta alla domanda della ricerca.","code":""},{"path":"significatività-statistica.html","id":"la-variabilità-campionaria","chapter":"Capitolo 21 Significatività statistica","heading":"21.4.1 La variabilità campionaria","text":"Nel caso dell’esperimento Mehr et al. (2016) che stiamo discutendo,\n\\(\\bar{X}\\) non cade nell’intervallo specificato da \\(H_0\\). Sulla base del\nvalore osservato \\(\\bar{X} = 0.59\\) possiamo dunque concludere che \\(H_0\\) è\nfalsa? Non così presto. Non è sufficiente trovare una differenza\n\\(\\bar{X} - \\mu\\) nella direzione giusta (cioè positiva, nel nostro caso).\nÈ anche necessario tenere considerazione il fenomeno della\nvariabilità campionaria.Infatti, la media \\(\\bar{X}\\) osservata ogni singolo campione di\nampiezza \\(n=32\\) è una variabile aleatoria: ciascun possibile campione\ndi ampiezza 32 bambini si comportano maniera diversa e, di\nconseguenza, \\(\\bar{X}\\) assumerà un valore diverso da campione \ncampione. Le statistiche campionarie – nel nostro caso la media\n\\(\\bar{X}\\) – sono di necessità diverse dai parametri. Ciò cui noi\nsiamo interessati è la media della popolazione, ovvero \\(\\mu\\), ma\nsfortunatamente conosciamo solo una sua realizzazione campionaria,\novvero \\(\\bar{X}\\).Risulta dunque chiaro che la nostra decisione rispetto ad \\(H_0\\) non può\nessere unicamente basata sulla differenza tra \\(\\bar{X} - \\mu\\). Infatti,\nè ragionevole pensare che, indipendentemente dal fatto che l’ipotesi\nnulla sia vera o meno, alcuni campioni la differenza \\(\\bar{X} - \\mu\\)\nsarà positive mentre altri campioni sarà negativa. Dobbiamo dunque\ntrovare una procedura che riduca la possibilità di rifiutare \\(H_0\\) per\neffetto del caso soltanto. Possiamo (e dobbiamo) fare di meglio che\nconsiderare unicamente la differenza \\(\\bar{X} - \\mu\\).","code":""},{"path":"significatività-statistica.html","id":"le-distribuzioni-delle-statistiche-test","chapter":"Capitolo 21 Significatività statistica","heading":"21.4.2 Le distribuzioni delle statistiche test","text":"Il metodo seguito dall’approccio frequentista per affrontare questo\nproblema è quello di costruire la distribuzione della statistica test\n\\(\\mathcal{G}_n\\), rilevante per il test di \\(H_0\\), assumendo come vera\nl’ipotesi nulla. Questo è il concetto più contro-intuitivo di tutta la\nprocedura di test di ipotesi dell’approccio frequentista. Esaminiamolo\npiù dettaglio.È ovvio come calcolare la media delle proporzioni del tempo di\nfissazione un singolo campione. Il problema è che tale media varia da\ncampione campione (fenomeno detto della variabilità campionaria).\nL’approccio frequentista affronta il problema di giungere ad una\ndecisione rispetto ad \\(H_0\\) tenendo considerazione la variabilità\ncampionaria nel modo seguente. Il punto di partenza è quello di\ndescrivere le caratteristiche della distribuzione di tutti possibili\nvalori che la statistica test esame (nel nostro caso, la media del\ncampione, ovvero \\(\\bar{X}\\)) tutti infiniti possibili campioni di\nampiezza \\(n\\) (nel nostro caso \\(n\\) = 32).È facile capire che, espresso questi termini, il problema di\nstabilire quali sono le caratteristiche di tale distribuzione di medie\ncampionarie non è risolvibile. Senza sapere nient’altro, non possiamo\nsapere come si distribuisce \\(\\bar{X}\\) nell’universo dei campioni.\nRicordiamo però che lo scopo della procedura di test statistici\ndell’approccio frequentista non è quello di verificare l’ipotesi\nalternativa: questo non è logicamente possibile. Invece, come suggerito\ndalla similitudine del processo penale ’ipotesi nulla, l’approccio\nfrequentista si pone l’obiettivo di determinare se ci siano indizi\nsufficienti per “condannare” l’ipotesi nulla, ovvero, per rigettarla.questa reductio ad absurdum, la “presunzione di innocenza” di \\(H_0\\)\ncorrisponde ’idea che dobbiamo assumere come vera l’ipotesi nulla,\nfino prova contraria. Nell’esempio che stiamo discutendo, assumere\ncome vera l’ipotesi nulla significa assumere che il parametro \\(\\mu\\) (la\nmedia della popolazione) sia uguale 0.5. Sulla base di questa\nassunzione è possibile costruire la distribuzione delle medie dei\ncampioni di ampiezza 32.Per fare questo, Mehr et al. (2016) utilizzano (implicitamente) ad un famoso\nteorema della teoria della probabilità che possiamo descrivere nel modo\nseguente. Se estraiamo infiniti campioni di ampiezza 32 da una\npopolazione gaussiana di media \\(\\mu = 0.5\\), allora le medie\nstandardizzate di tali campioni seguiranno la distribuzione teorica di\nprobabilità chiamata distribuzione \\(t\\) di Student con 32 - 1 = 31 gradi\ndi libertà. Ricordiamo che standardizzare una variabile significa\nsottrarre dai valori della variabile il suo valore atteso e dividere per\nla deviazione standard. Si può dimostrare che il valore atteso delle\nmedie dei campioni è uguale alla media della popolazione. Nel caso\npresente, avremo che \\[\\mathbb{E}(\\bar{X}) = \\mu_{\\bar{X}} = \\mu\\] e la\nstandardizzazione si effettua mediante il rapporto\n\\[\nT = \\frac{\\bar{X} - \\mu}{\\frac{s}{\\sqrt{n}}},\n\\]\ndove \\(\\bar{X}\\) è la\nmedia del campione (nel nostro caso, 0.56), \\(s\\) è la deviazione standard\ndel campione (gli autori riportano \\(s\\) = 0.179) e \\(n\\) è l’ampiezza del\ncampione (ovvero, \\(n\\) = 32). altre parole, la teoria della\nprobabilità ci dice che la statistica \\(T\\) si distribuisce come \\(t\\) di\nStudent con \\(\\nu = 31\\) gradi di libertà. Il punto cruciale è che, se\nassumiamo come vera l’ipotesi nulla che fissa \\(\\mu = 0.5\\), allora la\ndistribuzione della statistica test \\(T\\) risulta completamente\ndeterminata.L’approccio frequentista fa uso di un insieme teoremi della teoria della\nprobabilità che descrivono la distribuzione di varie statistiche test.\nAbbiamo visto sopra la descrizione di un teorema che specifica la\ndistribuzione della statistica test \\(T\\). Un altro teorema specifica la\ndistribuzione della statistica test che corrisponde alla differenze tra\nle medie di due campioni indipendenti; tale teorema viene utilizzato\nnella procedura statistica frequentista chiamata test sulla differenza\ntra le medie di due campioni indipendenti. Un altro teorema riguarda la\ndistribuzione del rapporto tra la stima di una varianza \\(\\sigma^2\\)\nbasata sulla variabilità delle medie di diversi campioni e la stima\ndella stessa varianza basata sulla variabilità entro campioni; tale\nteorema sta alla base del test statistico chiamato ANOVA, o Analisi\ndella varianza. Un altro teorema ancora specifica la distribuzione di\nuna proporzione campionaria; tale teorema sta alla base del test\nstatistico frequentista chiamato test di ipotesi per la proporzione. E\ncosì via.","code":""},{"path":"significatività-statistica.html","id":"regioni-di-rifiuto-e-regioni-di-non-rifiuto","chapter":"Capitolo 21 Significatività statistica","heading":"21.4.3 Regioni di rifiuto e regioni di non rifiuto","text":"Conoscendo la distribuzione dei valori della statistica test\n(distribuzione che viene determinata assumendo come vera \\(H_0\\))\ndiventa poi possibile dividere l’insieme dei valori possibili di\n\\(\\mathcal{G}_n\\) (il nome che abbiamo assegnato ad una generica\nstatistica test) due regioni: valori che ci portano rigettare\n\\(H_0\\) (regione di rifiuto) e quelli che non ci consentono di rigettare\n\\(H_0\\) (regione di non rifiuto). Come facciamo decidere quanto è grande\nla regione di rifiuto di \\(H_0\\)? È semplice, basta collocare nella\nregione di rifiuto valori estremi della statistica test\n\\(\\mathcal{G}_n\\), ovvero quelli che sarebbe molto improbabile osservare\nse \\(H_0\\) fosse vera. Questo è l’aspetto cruciale della procedura di test\ndi ipotesi, perché così facendo possiamo definire la regione di rifiuto\ndi \\(H_0\\) come quell’intervallo di valori \\(\\mathcal{G}_n\\) cui è\nassociata la probabilità \\(\\alpha\\), ovvero la probabilità di commettere\nun errore di tipo.","code":""},{"path":"significatività-statistica.html","id":"quando-rifiutare-lipotesi-nulla","chapter":"Capitolo 21 Significatività statistica","heading":"21.4.4 Quando rifiutare l’ipotesi nulla","text":"Supponiamo che la figura 21.2 rappresenti la distribuzione\ncampionaria della statistica test \\(\\mathcal{G}_n\\). Se dati producono\nla statistica test \\(\\mathcal{G}_n^1\\), non possiamo rifiutare l’ipotesi\nnulla \\(H_0\\). Se invece dati producono \\(\\mathcal{G}_n^2\\) allora\npossiamo rifiutare l’ipotesi nulla favore dell’ipotesi alternativa.\nCi sono varie cose da notare.La regione di rifiuto è costituita da valori lontani dal centro\ndella distribuzione campionaria della statistica test, la quale è\nstata costruita assumendo come vera \\(H_0\\).La regione di rifiuto è costituita da valori lontani dal centro\ndella distribuzione campionaria della statistica test, la quale è\nstata costruita assumendo come vera \\(H_0\\).La regione di rifiuto è situata nelle code della distribuzione.\nVedremo seguito anche degli esempi di regioni di rifiuto\nunilaterali.La regione di rifiuto è situata nelle code della distribuzione.\nVedremo seguito anche degli esempi di regioni di rifiuto\nunilaterali.questa discussione, l’ipotesi alternativa non è menzionata.\nRifiutiamo o non rifiutiamo \\(H_0\\) basandoci unicamente sulla\ndistribuzione campionaria \\(f(\\mathcal{G}_n \\mid H_0)\\), cioè sulla\nprobabilità della statistica test condizionata ’ipotesi nulla\n\\(H_0\\). L’ipotesi alternativa \\(H_1\\) viene presa considerazione\nquando si sceglie dove posizionare la regione di rifiuto di \\(H_0\\),\nma formalmente non gioca alcun ruolo nel rigettare o meno \\(H_0\\).questa discussione, l’ipotesi alternativa non è menzionata.\nRifiutiamo o non rifiutiamo \\(H_0\\) basandoci unicamente sulla\ndistribuzione campionaria \\(f(\\mathcal{G}_n \\mid H_0)\\), cioè sulla\nprobabilità della statistica test condizionata ’ipotesi nulla\n\\(H_0\\). L’ipotesi alternativa \\(H_1\\) viene presa considerazione\nquando si sceglie dove posizionare la regione di rifiuto di \\(H_0\\),\nma formalmente non gioca alcun ruolo nel rigettare o meno \\(H_0\\).\nFigura 21.2: Distribuzione della statistica test condizionata ’ipotesi nulla \\(H_0\\).\n","code":""},{"path":"significatività-statistica.html","id":"specificazione-delle-regioni-di-rifiuto","chapter":"Capitolo 21 Significatività statistica","heading":"21.4.5 Specificazione delle regioni di rifiuto","text":"L’ipotesi alternativa \\(H_1\\) può assumere forme diverse e ciò conduce \nspecificazioni diverse della regione di rifiuto \\(\\mathcal{R}\\) di \\(H_0\\).\nLa regione di rifiuto \\(\\mathcal{R}\\) dell’ipotesi nulla corrisponde ai\nvalori collocati agli estremi della distribuzione secondo la direzione\ndell’ipotesi alternativa \\(H_1\\).Se l’ipotesi alternativa è \\(H_1: \\theta \\neq \\theta_0\\) (dove\n\\(\\theta\\) è un generico parametro e \\(\\theta_0\\) è uno specifico valore\ndel parametro), allora le evidenze coerenti con l’ipotesi\nalternativa (e che portano al rigetto di \\(H_0\\)) sono contenute negli\nintervalli \\([-\\infty, \\theta_0]\\) e \\([\\theta_0, +\\infty]\\).Se l’ipotesi alternativa è \\(H_1: \\theta \\neq \\theta_0\\) (dove\n\\(\\theta\\) è un generico parametro e \\(\\theta_0\\) è uno specifico valore\ndel parametro), allora le evidenze coerenti con l’ipotesi\nalternativa (e che portano al rigetto di \\(H_0\\)) sono contenute negli\nintervalli \\([-\\infty, \\theta_0]\\) e \\([\\theta_0, +\\infty]\\).Se l’ipotesi alternativa è \\(H_1: \\theta < \\theta_0\\), allora le\nevidenze coerenti con l’ipotesi alternativa (e che portano al\nrigetto di \\(H_0\\)) sono contenute nell’intervallo \\([-\\infty, \\theta_0]\\) e l’intera regione di rifiuto \\(\\mathcal{R}\\) è collocata nella coda di sinistra della distribuzione.Se l’ipotesi alternativa è \\(H_1: \\theta < \\theta_0\\), allora le\nevidenze coerenti con l’ipotesi alternativa (e che portano al\nrigetto di \\(H_0\\)) sono contenute nell’intervallo \\([-\\infty, \\theta_0]\\) e l’intera regione di rifiuto \\(\\mathcal{R}\\) è collocata nella coda di sinistra della distribuzione.Se l’ipotesi alternativa è \\(H_1: \\theta > \\theta_0\\), allora le\nevidenze coerenti con l’ipotesi alternativa (e che portano al\nrigetto di \\(H_0\\)) sono contenute nell’intervallo \\([\\theta_0, \\infty]\\) e l’intera regione di rifiuto \\(\\mathcal{R}\\) è collocata\nnella coda di destra della distribuzione.Se l’ipotesi alternativa è \\(H_1: \\theta > \\theta_0\\), allora le\nevidenze coerenti con l’ipotesi alternativa (e che portano al\nrigetto di \\(H_0\\)) sono contenute nell’intervallo \\([\\theta_0, \\infty]\\) e l’intera regione di rifiuto \\(\\mathcal{R}\\) è collocata\nnella coda di destra della distribuzione.Si chiamano valori critici valori che delimitano la regione di\nrifiuto \\(\\mathcal{R}\\) un test unilaterale e valori che delimitano\nle regioni di rifiuto \\(\\mathcal{R}\\) un test bilaterale. un test\nbidirezionale, valori critici lasciano ciascuna delle due code\ndella distribuzione della statistica test una probabilità pari \n\\(\\alpha/2\\); un test unidirezionale lasciano una probabilità pari ad\n\\(\\alpha\\) una sola coda. Il risultato di un test si dice\nstatisticamente significativo quando il valore della statistica test\nricade nella regione di rifiuto \\(\\mathcal{R}\\).","code":""},{"path":"significatività-statistica.html","id":"problema","chapter":"Capitolo 21 Significatività statistica","heading":"Problema","text":"Supponiamo che \\(f(\\mathcal{G}_n \\mid H_0) = \\mathcal{N}(100, 15)\\)\ndescriva la distribuzione della statistica test \\(x\\). Supponiamo inoltre\nche la regione di rifiuto sia posta nella coda di destra e che il\nlivello di significatività sia \\(\\alpha = 0.05\\). Si trovi il valore\ncritico che delimita la regione di rifiuto di \\(H_0\\).","code":""},{"path":"significatività-statistica.html","id":"soluzione","chapter":"Capitolo 21 Significatività statistica","heading":"Soluzione","text":"Usando R la risposta è: qnorm(0.95, 100, 15) = 124.7. La distribuzione\n\\(\\mathcal{N}(100, 15)\\) è mostrata nella figura figura 21.3. La regione di rifiuto è indicata dall’area ombreggiata.\nFigura 21.3: Distribuzione campionaria con regione di rifiuto unilaterale destra.\n","code":"\nggplot(data.frame(x = c(55, 145)), aes(x)) + \n  stat_function(fun = dnorm, args = list(mean = 100, sd = 15)) +\n  stat_function(\n    fun = dnorm, args = list(mean = 100, sd = 15),\n    geom = \"area\",\n    fill = \"steelblue\",\n    xlim = c(qnorm(0.95, 100, 15), 200)\n  ) +\n  scale_x_continuous(limits = c(55, 145)) +\n  labs(\n    x = \"QI\",\n    y = \"Densità\"\n  )"},{"path":"significatività-statistica.html","id":"problema-1","chapter":"Capitolo 21 Significatività statistica","heading":"Problema","text":"Supponiamo ora che \\(f(\\mathcal{G}_n \\mid H_0) = \\mathcal{N}(100, 15)\\)\ndescriva la distribuzione della statistica test \\(\\mathcal{G}_n\\).\nSupponiamo inoltre che la regione di rifiuto sia posta nella coda di\nsinistra e che il livello di significatività sia \\(\\alpha = 0.01\\). Si\ntrovi il valore critico che delimita la regione di rifiuto di \\(H_0\\).","code":""},{"path":"significatività-statistica.html","id":"soluzione-1","chapter":"Capitolo 21 Significatività statistica","heading":"Soluzione","text":"Usando R, la risposta è qnorm(0.01, 100, 15) = 65.1 – si veda la figura 21.4.\nFigura 21.4: Distribuzione campionaria con regione di rifiuto unilaterale sinistra.\n","code":"\nggplot(data.frame(x = c(55, 145)), aes(x)) + \n  stat_function(fun = dnorm, args = list(mean = 100, sd = 15)) +\n  stat_function(\n    fun = dnorm, args = list(mean = 100, sd = 15),\n    geom = \"area\",\n    fill = \"steelblue\",\n    xlim = c(0, qnorm(0.01, 100, 15))\n  ) +\n  scale_x_continuous(limits = c(55, 145)) +\n  labs(\n    x = \"QI\",\n    y = \"Densità\"\n  )"},{"path":"significatività-statistica.html","id":"problema-2","chapter":"Capitolo 21 Significatività statistica","heading":"Problema","text":"un terzo esempio, supponiamo che \\(f(\\mathcal{G}_n \\mid H_0) = \\mathcal{N}(100, 15)\\) descriva la distribuzione della statistica test \\(\\mathcal{G}_n\\). Supponiamo inoltre che la regione di rifiuto sia bilaterale e che il livello di\nsignificatività sia \\(\\alpha = 0.05\\). Si trovino valori critici che\ndelimitano la regione di rifiuto di \\(H_0\\).","code":""},{"path":"significatività-statistica.html","id":"soluzione-2","chapter":"Capitolo 21 Significatività statistica","heading":"Soluzione","text":"Con la seguente istruzione qnorm(c(0.025, 0.975), 100, 15) troviamo \nvalori \\(70.6\\) e \\(129.4\\) – si veda la figura 21.5.\nFigura 21.5: Distribuzione campionaria con regione di rifiuto bilaterale.\n","code":"\nggplot(data.frame(x = c(55, 145)), aes(x)) + \n  stat_function(fun = dnorm, args = list(mean = 100, sd = 15)) +\n  stat_function(\n    fun = dnorm, args = list(mean = 100, sd = 15),\n    geom = \"area\",\n    fill = \"steelblue\",\n    xlim = c(0, qnorm(0.025, 100, 15))\n  ) +\n  stat_function(\n    fun = dnorm, args = list(mean = 100, sd = 15),\n    geom = \"area\",\n    fill = \"steelblue\",\n    xlim = c(qnorm(0.975, 100, 15), 200)\n  ) +\n  scale_x_continuous(limits = c(55, 145)) +\n  labs(\n    x = \"QI\",\n    y = \"Densità\"\n  )"},{"path":"significatività-statistica.html","id":"la-decisione-statistica","chapter":"Capitolo 21 Significatività statistica","heading":"21.4.6 La decisione statistica","text":"Il processo di decisione statistica viene descritto da von Mises (1964) nel modo seguente:Controllare (checking) o saggiare (testing) ha la forma seguente: se il “risultato osservato” ha una ‘piccola’ probabilità subordinatamente ’ipotesi assunta, respingiamo l’ipotesi. (p. 441)Ovviamente l’ipotesi cui von Mises fa riferimento, la cui validità è\nsolo ipotetica, è l’ipotesi nulla.pratica, possiamo decidere se rigettare o meno l’ipotesi nulla due\nmodi: determinando se la statistica test \\(\\mathcal{G}_n\\) cade o meno\nnella regione di rifiuto (come abbiamo descritto sopra) o confrontando\nil valore-\\(p\\) con \\(\\alpha\\) – due metodi sono equivalenti.Il valore-p rappresenta la probabilità di osservare un valore della\nstatistica test \\(\\mathcal{G}_n\\) pari quello effettivamente osservato,\no maggiore, quanto l’ipotesi nulla è vera. Se il valore-\\(p\\) è minore\ndel livello di significatività \\(\\alpha\\), allora la statistica test cade\nnella regione di rifiuto di \\(H_0\\) e ciò conduce al rifiuto dell’ipotesi\nnulla. Tali concetti sono riassunti nella figura 21.6.\nFigura 21.6: Relazione tra il valore-p e il livello di significatività alpha.\n","code":""},{"path":"significatività-statistica.html","id":"potenza-del-test","chapter":"Capitolo 21 Significatività statistica","heading":"21.5 Potenza del test","text":"Ritorniamo ora al concetto di potenza del test. Il livello di\nsignificatività e la potenza del test vengono usati per quantificare la\nqualità dell’inferenza statistica. Idealmente, la procedura di test di\nipotesi non dovrebbe giungere alla conclusione sbagliata. Ovvero, non\ndovrebbe respingere \\(H_0\\) quando essa è vera e dovrebbe respingere \\(H_0\\)\nfavore dell’alternativa quando \\(H_1\\) è vera. Ma questi sono solo due\ndei quattro esiti che, principio, sono possibili, come indicato nella\ntabella 21.6 e corrispondono alle probabilità\nindicate nella figura 21.7.\nFigura 21.7: Probabilità dei due tipi di errori nel test di ipotesi statistiche.\nPossiamo pensare \\(H_0\\) come ’ipotesi che descrive l’evento “nulla\ndi interessante sta succedendo” – ad esempio, “la moneta è bilanciata,”\n“il trattamento non è migliore del placebo,” ecc. – e pensare ad \\(H_1\\)\ncome al caso contrario, ovvero: “sta accadendo qualcosa di\ninteressante.” Quindi la potenza del test, ovvero la probabilità\n\\(1 - \\beta\\) di rigettare \\(H_0\\) quando essa è falsa, corrisponde alla\nprobabilità di rilevare qualcosa di interessante, quando qualcosa di\ninteressante è effettivamente successo, mentre il livello di\nsignificatività corrisponde alla probabilità di affermare che qualcosa\ndi interessante si è verificato, quando realtà non è successo nulla\ndi interessante.Il calcolo della potenza di un test è spesso difficile, perché richiede\nla conoscenza della distribuzione campionaria di \\(\\mathcal{G}_n\\) quando\nè vera l’ipotesi alternativa \\(H_1\\). Nella figura 21.8, l’area ombreggiata sotto \\(f(\\mathcal{G}_n \\mid H_0)\\) rappresenta il livello di significatività un test unilaterale. Ricordiamo che il livello di significatività è la\nprobabilità di rifiutare falsamente l’ipotesi nulla quando essa è vera.\nInvece, l’area sotto \\(f(\\mathcal{G}_n \\mid H_1)\\) sinistra della linea\nverticale che delimita la regione ombreggiata rappresenta la potenza del\ntest, ovvero la probabilità che la statistica del test si trovi nella\nregione di rifiuto di \\(H_0\\) quando è vera \\(H_1\\). Nella figura 21.8 la potenza del test è alta.\nFigura 21.8: Probabilità dei due tipi di errori nel test di ipotesi statistiche.\nNella figura 21.9, invece, la potenza del test è bassa.\nEntrambi test hanno lo stesso livello di significatività, ma se \\(f(\\mathcal{G}_n \\mid H_1)\\) si sovrappone di molto con \\(f (\\mathcal{G}_n \\mid H_0)\\), allora la potenza del test è bassa.\nFigura 21.9: Probabilità dei due tipi di errori nel test di ipotesi statistiche.\nTipicamente possiamo aumentare la potenza di un test aumentando la numerosità del campione maniera tale da diminuire la varianza delle distribuzioni della statistica test condizionate \\(H_0\\) e ad \\(H_1\\). un disegno sperimentale è importante determinare anticipo il numero di prove o dei soggetti necessari per raggiungere la potenza desiderata.","code":""},{"path":"inferenza-sulle-medie.html","id":"inferenza-sulle-medie","chapter":"Capitolo 22 Inferenza sulle medie","heading":"Capitolo 22 Inferenza sulle medie","text":"Molto spesso psicologia ci troviamo una situazione cui la\nvariabile dipendente è livello di scala ad intervalli o superiore e\nciò che ci interessa è stabilire se il valore medio della variabile\ndipendente sia più grande un gruppo o un altro. Ad esempio, uno\npsicologo potrebbe voler sapere se livelli di ansia sono più alti tra\ngenitori o tra non genitori, o se la capacità della memoria di\nlavoro si riduce quando si ascolta musica, rispetto alla condizione \ncui non si ascolta musica. queste situazioni, la variabile dipendente\nè continua livello di scala ad intervalli o rapporti e il nostro\npredittore è una variabile binaria. altre parole, ciò che vogliamo\nfare situazioni di questo tipo è confrontare le medie dei due gruppi.La risposta tradizionale al problema del confronto tra due medie è\nquella di usare il test statistico che va sotto il nome di \\(t\\) di\nStudent, di cui esistono diverse varianti seconda del tipo di domanda\ncui si vuole rispondere. questo capitolo presenteremo le diverse\nvarianti del test \\(t\\) di Student: il test \\(t\\) campione unico, il test\n\\(t\\) per campioni indipendenti e il test \\(t\\) per il confronto tra le\nmedie di due campioni appaiati.","code":""},{"path":"inferenza-sulle-medie.html","id":"modello-normale-varianza-nota","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.1 Modello Normale: varianza nota","text":"questa sezione inizieremo ad esaminare il test \\(z\\), il quale ci\nfornisce una versione semplificata del test \\(t\\) di Student, che\nprobabilmente è assoluto il test statistico più usato (più di una\nvolta sproposito) dall’approccio frequentista. Lo scopo di questa discussione è quello di presentare la logica che sta alla base della procedura di test di ipotesi frequentista. Il test \\(z\\) chiarisce questa logica esaminando il caso più semplice – un caso che, per motivi che saranno chiariti seguito, non trova molte applicazioni pratiche. Lo presentiamo qui perché rende trasparente la motivazione frequentista della procedura di test di ipotesi. Gli altri test frequentisti, quelli che si usano nelle applicazioni concrete, sono semplicemente degli sviluppi dell’idea sulla quale si basa il test \\(z\\). Per cui, se si capisce il test \\(z\\), si capiscono tutti test frequentisti.Il test \\(z\\) applica la procedura di test di ipotesi statistiche che è stata\npresentata nel capitolo precedente e si pone il problema di verificare\nun’ipotesi proposito della media della popolazione utilizzando la media campionaria quale statistica test. precedenza abbiamo discusso un teorema della teoria della probabilità il quale afferma che la media \\(\\bar{X}_n\\) di \\(n\\) variabili aleatorie ..d., ciascuna distribuita come \\(\\mathcal{N}(\\mu, \\sigma^2)\\), segue una distribuzione normale con parametri \\(\\mu_{\\bar{X}_n} = \\mu\\) e \\(\\sigma^2_{\\,\\bar{X}_n} = \\sigma^2 / n\\). Questo significa che, conoscendo parametri (media e deviazione standard) della popolazione\ndi origine, è possibile specificare completamente la distribuzione\ncampionaria di \\(\\bar{X}_n\\).Ovviamente il valore dei parametri è ignoto, ma è qui che interviene la procedura di test di ipotesi. base ’approccio NHST, la distribuzione campionaria della statistica test viene costruita assumendo come vera l’ipotesi nulla. Il test \\(z\\) – e\nlo stesso approccio viene seguito per tutti gli altri test di stampo\nfrequentista – determina la distribuzione campionaria della statistica\ntest (per esempio, la media del campione quale stimatore della media\ndella popolazione) ipotizzando che il campione osservato provenga da una\npopolazione cui l’ipotesi nulla è vera. La domanda di come determinare valori dei parametri incogniti della popolazione trova quindi una facile risposta: il valore di tali parametri è fornito da \\(H_0\\)!","code":""},{"path":"inferenza-sulle-medie.html","id":"un-test-bilaterale","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.1.1 Un test bilaterale","text":"Per vedere come come si esegue il test \\(z\\), consideriamo il seguente\nesempio. valori antropometrici medi della popolazione italiana adulta\nsono stati descritti, per esempio, da un’indagine nazionale condotta da\nBriziarelli et al. (1994). Ci concentriamo qui sull’altezza media delle\ndonne adulte, la quale risulta essere pari 162.5 cm tra 18 e 24 anni,\ncon una deviazione standard di 12 cm. Sappiamo anche che la variabile\n“altezza” segue la distribuzione normale. Per qualche ragione,\nsospettiamo che, Firenze, l’altezza media sia diversa da quella \nlivello nazionale e, per gli scopi di questo esempio, crediamo che possa essere o maggiore o minore di quella italiana.","code":""},{"path":"inferenza-sulle-medie.html","id":"la-statistica-test","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.1.2 La statistica test","text":"Per sottoporre verifica la nostra ipotesi della ricerca, misuriamo l’altezza di 20 donne fiorentine scelte caso. Supponiamo di avere ottenuto seguenti risultati:Calcoliamo la media del campione:La media campionaria è un po’ più grande della media della popolazione\n\\(\\mu = 162.5\\) e questo suggerisce che, effetti, le donne fiorentine\npotrebbero avere un altezza superiore alla media nazionale. Tuttavia, un\ncampione di ampiezza \\(n = 20\\) è molto piccolo, per cui la diffrenza tra il risultato\nosservato e il valore atteso (\\(\\mu = 162.5\\)) potrebbe essere soltano il prodotto del caso. Per verificare l’ipotesi, che l’altezza delle donne fiorentine sia diversa da quella delle altre donne italiane decidiamo di usare \\(\\bar{X}_{n}\\) quale statistica test, ovvero quale stima di \\(\\mu\\).Per valutare la nostra ipotesi iniziamo ad elencare ciò che sappiamo. Chiamiamo \\(X\\) l’altezza delle donne fiorentine. primo luogo, sappiamo che la media campionaria è \\(\\bar{X}_{n} = 167.418\\). Se siamo disposti ad assumere che la distribuzione dell’altezza delle donne fiorentine ha la stessa deviazione standard dell’altezza delle altre donne della popolazione italiana, allora possiamo dire che la deviazione standard dell’altezza delle donne fiorentine è \\(\\sigma = 12\\). Inoltre, sappiamo che valori dell’altezza delle donne fiorentine sono distribuiti maniera normale dato che, generale, valori dell’altezza seguono la legge della distribuzione normale.Ora elenchiamo ciò che non sappiamo, ma che vorremmo sapere. La nostra ipotesi riguarda il valore incognito \\(\\mu\\), ovvero la media dell’altezza della popolazione delle donne fiorentine – infatti, abbiamo misurato l’altezza di 20 donne fiorentine, non di tutte le donne fiorentine! La nostra ipotesi è \\(X \\sim \\mathcal{N}(\\mu \\neq 162.5, \\sigma = 12)\\), con \\(\\mu\\) sconosciuto. Dato che, nella procedura NHST, l’ipotesi del ricercatore definisce “l’ipotesi alternativa” \\(H_1\\), possiamo scrivere:\\[\nH_1: X \\sim \\mathcal{N}(\\mu \\neq 162.5, \\sigma = 12).\n\\]Una volta definita l’ipotesi alternativa risulta specificata anche l’ipotesi nulla, quanto essa è l’ipotesi opposta e complementare \\(H_1\\). Dunque possiamo scrivere:\\[\nH_0: X \\sim \\mathcal{N}(\\mu = 162.5, \\sigma = 12).\n\\]Le ipotesi nulla e alternativa riguardano parametri della popolazione.\nquesto particolare esempio, il paraemtro \\(\\mu\\) (la media dell’altezza delle donne\nfiorentine) è incognito ma \\(\\sigma\\) è noto (quanto abbiamo assunto che\nl’altezza delle donne fiorentine e l’altezza delle donne italiane sono\ndue Normali con la stessa deviazione standard ma con medie diverse). Per\nstimare \\(\\mu\\) dobbiamo usare una qualche statistica test, e la statistica\novvia questo riguardo è semplicemente la media del campione \\(\\bar{X}\\). Decidiamo dunque di usare \\(\\bar{X}\\) quale statistica test. Quello che dobbiamo ancora stabilire sono le caratteristiche della distribuzione campionaria di \\(\\bar{X}\\) nel caso di campioni di ampiezza \\(n=20\\).","code":"\nx <- c(173.53, 175.01, 165.19, 161.06, 173.77, 144.68, 174.06, 163.19, 163.09, 155.47, 165.11, 188.31, 170.95, 172.74, 157.49, 176.30, 155.86, 162.52, 179.95, 170.08)\nmean(x)\n#> [1] 167.418"},{"path":"inferenza-sulle-medie.html","id":"la-distribuzione-campionaria-della-statistica-test","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.1.3 La distribuzione campionaria della statistica test","text":"base ’approccio NHST, la distribuzione campionaria della statistica test viene determinata assumendo come vera l’ipotesi nulla. Nel caso del nostro esempio, l’ipotesi nulla afferma che \\(X \\sim \\mathcal{N}(\\mu = 162.5, \\sigma = 12)\\). Sotto \\(H_0\\), dunque, la distribuzione campionaria della media di campioni di ampiezza \\(n=20\\) è:\\[\n\\bar{X} \\sim \\mathcal{N}\\left(\\mu_{\\bar{X}} = \\mu = 162.5, \\sigma_{\\bar{X}} = \\frac{\\sigma}{\\sqrt{n}} = \\frac{12}{\\sqrt{20}}\\right).\n\\]Si noti che è l’ipotesi nulla specificare la media \\(\\mu\\) e la deviazione standard \\(\\sigma\\) della popolazione da cui vengono estatti campioni che formano la distribuzione campionaria di \\(\\bar{X}\\). Per questa ragione diciamo che la distribuzione campionaria della statistica test, \\(f(\\bar{X} \\mid H_0)\\), è stata generata assumendo vera l’ipotesi nulla.","code":""},{"path":"inferenza-sulle-medie.html","id":"la-decisione","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.1.4 La decisione","text":"Nel problema che stiamo discutendo l’ipotesi alternativa \\(H_1\\) è bilaterale. Ovvero, possiamo rigettare \\(H_0\\) se troviamo che l’altezza media delle donne fiorentine è molto diverso dal valore postulato da \\(H_0\\), ovvero \\(\\mu_{\\bar{X}} = \\mu = 162.5\\). Rifiuteremo \\(H_0\\) se la statistica test \\(\\bar{X}\\) si dimostra essere di molto maggiore dell’altezza ipotizzata da \\(H_0\\), oppure di molto minore dell’altezza ipotizzata da \\(H_0\\).altre parole, per valutare \\(H_0\\) dobbiamo determinare se la statistica test cade o meno nella regione di rifiuto. È necessario dunque identificare la regione di rifiuto di \\(H_0\\). Per fare questo dobbiamo prima scegliere \\(\\alpha\\). Seguendo la consuetudine usata psicologia, poniamo \\(\\alpha = 0.05\\). Dato che il test è bidirezinale, rigettiamo \\(H_0\\) se la statistica test corrisponde ad un valore estremo che cade o nella coda di\ndestra di \\(f(\\bar{X} \\mid H_0)\\) oppure nella coda di sinistra di \\(f(\\bar{X} \\mid H_0)\\). La regione di rifiuto di \\(H_0\\) sarà dunque divisa due parti: metà sarà collocata nella coda di sinistra di \\(f(\\bar{X} \\mid H_0)\\) e metà nella coda di destra di\n\\(f(\\bar{X} \\mid H_0)\\). Quali sono valori critici che delimitano le due\nregioni di rifiuto di \\(H_0\\)? Per trovarli, dobbiamo calcolare quantili\ndi ordine 0.025 e 0.975 della distribuzione normale di media 162.5 e\ndeviazione standard \\(\\frac{12}{\\sqrt{20}}\\):Le due regioni di rifiuto di \\(H_0\\) sono dunque \\([-\\infty, 157.24]\\) e \\([167.76, +\\infty]\\), come indicato nella figura 22.1.\nFigura 22.1: Distribuzione campionaria delle medie di campioni di ampiezza n = 20 costruita assumendo vera l’ipotesi nulla \\(X \\sim \\mathcal{N}(\\mu = 162.5, \\sigma = 12)\\). Le aree ombreggiate indicano le regioni di rifiuto di \\(H_0\\) per un test bilaterale posto \\(\\alpha\\) = 0.05.\nIl valore osservato della statistica test, ovvero \\(\\bar{X} = 167.418\\), non cade nella regione di rifiuto di \\(H_0\\). Pertanto, sulla base delle informazioni disponibili, non possiamo rigettare \\(H_0\\). E questo conclude la descrizione della logica del test \\(z\\).","code":"\nqnorm(0.025, 162.5, 12/sqrt(20))\n#> [1] 157.2409\nqnorm(0.975, 162.5, 12/sqrt(20))\n#> [1] 167.7591\nggplot(data.frame(x = c(55, 145)), aes(x)) + \n  stat_function(fun = dnorm, args = list(mean = 162.5, sd = 12)) +\n  stat_function(\n    fun = dnorm, args = list(mean = 162.5, sd = 12),\n    geom = \"area\",\n    fill = \"steelblue\",\n    xlim = c(0, qnorm(0.025, 162.5, 12))\n  ) +\n  stat_function(\n    fun = dnorm, args = list(mean = 162.5, sd = 12),\n    geom = \"area\",\n    fill = \"steelblue\",\n    xlim = c(qnorm(0.975, 162.5, 12), 200)\n  ) +\n  scale_x_continuous(limits = c(162.5-3*12, 162.5+3*12)) +\n  labs(\n    x = \"Altezza (cm)\",\n    y = \"Densità\"\n  )"},{"path":"inferenza-sulle-medie.html","id":"la-statistica-test-z","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.1.5 La statistica test Z","text":"Solitamente, per giungere alla conclusione descritta sopra si procede modo diverso, ovvero applicando una semplice formula. tale formula non facciamo altro che standardizzare la media campionaria ’interno della distribuzione campionaria costruita assumendo come vera \\(H_0\\). pratica, per eseguire tale standardizzazione sottraiamo dalla media campionaria la media della distribuzione ipotizzata da \\(H_0\\) e\ndividiamo per la deviazione standard ipotizzata da \\(H_0\\):\\[\\begin{equation}\nZ = \\frac{\\bar{X}_n - \\mu_{\\bar{X}}}{\\sigma_{\\bar{X}}} = \\frac{\\bar{X}_n - \\mu_{\\bar{X}}}{\\frac{\\sigma}{\\sqrt{n}}}, \n\\tag{22.1}\n\\end{equation}\\]ovvero\\[\nZ = \\frac{167.418 - 162.5}{\\frac{12}{\\sqrt{20}}} = 1.8328.\n\\]\nIl valore che abbiamo ottenuto corrisponde alla cosiddetta statistica test \\(Z\\). Il test \\(z\\) si chiama così proprio perché è basato sulla statistica test \\(Z\\), e ovviamente \\(Z\\) ha questo nome perché è una variabile aleatoria normale standard di media 0 e varianza 1.","code":""},{"path":"inferenza-sulle-medie.html","id":"i-valori-critici","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.1.6 I valori critici","text":"Quali sono valori di una normale standard che lasciano ciascuna delle due code il 2.5% dell’area sottesa alla funzione di densità \\(f(\\bar{X}_{20} \\mid H_0)\\)? Usando R troviamoRisultano così specificate le due regioni di rifiuto \\([-\\infty, -1.96]\\)\ne \\([1.96, +\\infty]\\) illustrate nella figura 22.2.\nFigura 22.2: Distribuzione campionaria delle medie di campioni di ampiezza n = 20 costruita assumendo vera l’ipotesi nulla \\(X \\sim \\mathcal{N}(\\mu = 0, \\sigma = 1)\\). Le aree ombreggiate indicano le regioni di rifiuto di \\(H_0\\) per un test bilaterale posto \\(\\alpha\\) = 0.05.\nNon è una sorpresa che, facendo calcoli questo secondo modo, giungiamo alla stessa\nconclusione che avevamo trovato precedenza: la statistica test non cade nella\nregione di rifiuto di \\(H_0\\) e dunque non possiamo rifiutare l’ipotesi\nche dati campionari provengano dalla popolazione specificata da \\(H_0\\),\novvero \\(\\mathcal{N}(\\mu = 162.5, \\sigma = 12)\\).","code":"\nqnorm(0.025, 0, 1)\n#> [1] -1.959964\nqnorm(0.975, 0, 1)\n#> [1] 1.959964\nggplot(data.frame(x = c(-3, 3)), aes(x)) + \n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1)) +\n  stat_function(\n    fun = dnorm, args = list(mean = 0, sd = 1),\n    geom = \"area\",\n    fill = \"steelblue\",\n    xlim = c(-10, qnorm(0.025, 0, 1))\n  ) +\n  stat_function(\n    fun = dnorm, args = list(mean = 0, sd = 1),\n    geom = \"area\",\n    fill = \"steelblue\",\n    xlim = c(qnorm(0.975, 0, 1), 10)\n  ) +\n  scale_x_continuous(limits = c(-3, 3)) +\n  labs(\n    x = \"Altezza (in unità di deviazione standard)\",\n    y = \"Densità\"\n  )"},{"path":"inferenza-sulle-medie.html","id":"il-valore-p","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.1.7 Il valore-p","text":"Introduciamo ora un altro concetto centrale dell’inferenza frequentista: quello del valore-\\(p\\). Il valore-\\(p\\) viene usato per il test dell’ipotesi nulla base alla regola seguente: se il valore-\\(p\\) è minore di \\(\\alpha\\), allora rigettiamo \\(H_0\\). Ottenere un valore-\\(p\\) minore di \\(\\alpha\\), infatti, significa osservare una media campionaria molto distante dal valore ipotizzato dall’ipotesi nulla.Nelle parole di Neyman,il valore-\\(p\\) è la probabilità di osservare un valore della statistica test uguale o più estremo di quello osservato qualora sia vera \\(H_0\\).Detto un altro modo: se il mondo avesse le caratteristiche specificate da \\(H_0\\), il valore-\\(p\\) descriverebbe la probabilità di osservare un campione che una media uguale quella del campione osservato, o una media ancora più lontana da quella specificata da \\(H_0\\). Si noti il carattere ipotetico di questa affermazione: “se il mondo avesse le caratteristiche specificate da \\(H_0\\).”Per trovare il valore-\\(p\\), iniziamo calcolare l’area sottesa alla funzione di densità \\(f(\\bar{X}_{20} \\mid H_0)\\) nell’intervallo \\([162.5, \\infty]\\):Questo però non è il valore-\\(p\\) per un test bidirezionale. Infatti, un test bidirezionale noi rigettiamo \\(H_0\\) sia quando troviamo valori estremi nella coda di destra di \\(f(\\bar{X} \\mid H_0)\\) sia quando troviamo valori estremi nella coda di sinistra di \\(f(\\bar{X}_{20} \\mid H_0)\\). Dunque, dobbiamo calcolare il valore-\\(p\\)\nutilizzando il valore assoluto della statistica test, ovvero sommando\nle aree sottese \\(f(\\bar{X}_{20} \\mid H_0)\\) negli intervalli\n\\([-\\infty, \\mathcal{G}_n]\\) e \\([\\mathcal{G}_n, +\\infty]\\):Dato che il valore-\\(p\\) trovato nel test è maggiore di \\(\\alpha = 0.05\\),\nnon rigettiamo l’ipotesi nulla. Ovviamente, giungiamo alla stessa\nconclusione sia confrontando la statistica test \\(\\mathcal{G}_n\\) con il\nvalore critico, sia confrontando il valore-\\(p\\) con \\(\\alpha\\).","code":"\n1 - pnorm(1.8328, 0, 1)\n#> [1] 0.03341616\n(1 - pnorm(1.8328, 0, 1)) + pnorm(-1.8328, 0, 1)\n#> [1] 0.06683232"},{"path":"inferenza-sulle-medie.html","id":"il-test-unilaterale","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.1.8 Il test unilaterale","text":"Proseguiamo la discussione considerando ora il caso di un test monodirezionale. Un tale test risulta appropriato quando l’ipotesi alternativa ha la forma\\[\nH_1: X \\sim \\mathcal{N}(\\mu > 162.5, \\sigma = 12),\n\\]per cui, di conseguenza, \\(H_0\\) è:\\[\nH_0: X \\sim \\mathcal{N}(\\mu \\leq 162.5, \\sigma = 12).\n\\]Come specificata sopra, l’ipotesi alternativa corrisponde ’ipotesi della ricerca secondo la quale le donne fiorentine, media, sono più alte delle donne italiane.Anche nel caso di un test unilaterale, è necessario usare la statistica test\n\\(Z\\) = 162.5. Ciò che è diverso rispetto al caso di un test bilaterale è dove viene collocata la regione di rifiuto \\(\\mathcal{R}\\) di \\(H_0\\). Se l’ipotesi della ricerca è che le donne fiorentine, media, sono più alte delle donne italiane, è chiaro che evidenze contrarie ’ipotesi nulla vengono fornite quando la media campionaria assume\nvalori molto superiori al valore del parametro specificato da \\(H_0\\),\nla quale afferma che l’altezza media delle donne fiorentine è uguale \nquella delle donne italiane, o addirittura inferiore. Nel caso del test\nunidirezionale specificato sopra, quindi, la regione di rifiuto\n\\(\\mathcal{R}\\) sarà collocata sulla sola coda destra della densità\n\\(f(\\bar{X}_{n} \\mid H_0)\\) – si veda la figura 22.3.\nFigura 22.3: Distribuzione campionaria delle medie di campioni di ampiezza n = 20 costruita assumendo vera l’ipotesi nulla \\(X \\sim \\mathcal{N}(\\mu = 0, \\sigma = 1)\\). L’area ombreggiata indica la regione di rifiuto di \\(H_0\\) per un test unilaterale destro posto \\(\\alpha\\) = 0.05.\ngenerale, un test unidirezionale il valore-\\(p\\) corrisponde\n’area sottesa alla funzione di densità \\(f(\\mathcal{G}_{n} \\mid H_0)\\)\nnell’intervallo \\([\\mathcal{G}_n, +\\infty]\\), se l’ipotesi nulla ha la\nforma \\(H_0: \\mu \\leq \\mu_0\\), oppure nell’intervallo\n\\([-\\infty, \\mathcal{G}_n]\\), se l’ipotesi nulla ha la forma\n\\(H_0: \\mu \\geq \\mu_0\\). differenza del caso bidirezionale, dunque,\ntutta la regione di rifiuto \\(\\mathcal{R}\\) è collocata su una sola coda\ndella distribuzione campionaria della statistica test\n\\(f(\\bar{X}_{n} \\mid H_0)\\).Nel caso dell’esempio che stiamo discutendo, \\(Z = 1.8328\\) e, dunque,\ncade nella regione di rifiuto di \\(H_0\\) per un test unilaterale\nsuperiore. Possiamo dunque rigettare \\(H_0\\) e concludere che il campione\nesaminato fornisce evidenza che le donne fiorentine tendono ad essere\npiù alte della media nazionale.Ma perché possiamo rifiutare \\(H_0\\) nel caso di un test unidirezionale ma\nnon possiamo farlo quando usiamo un test bidirezionale? Perché il test\ndi ipotesi risulta più conservativo quando il test è bidirezionale.\nQuesto ha senso. L’ipotesi della ricerca è molto vaga: dice\nsemplicemente che succederà qualcosa di diverso dal caso di non\ninteresse, ma non sa dire cosa. Di conseguenza, l’ipotesi nulla può\nessere rigettata solo quando osserviamo un risultato campionario\nveramente estremo. D’altra parte, invece, bastano evidenze “più deboli”\nper rigettare \\(H_0\\) quando sappiamo dove guardare, quando possiamo fare\ndelle predizioni su quello che succederà. La procedura di test di\nipotesi, quindi, ci incoraggia ad essere precisi, ad avere la capacità\ndi fare delle predizioni direzionali, piuttosto di chiederci\nsemplicemente se è possibile osservare qualcosa, qualunque cosa, di\ndiverso dall’evento di non interesse specificato da \\(H_0\\).","code":"\nggplot(data.frame(x = c(-3, 3)), aes(x)) + \n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1)) +\n  stat_function(\n    fun = dnorm, args = list(mean = 0, sd = 1),\n    geom = \"area\",\n    fill = \"steelblue\",\n    xlim = c(qnorm(0.95, 0, 1), 10)\n  ) +\n  scale_x_continuous(limits = c(-3, 3)) +\n  labs(\n    x = \"Altezza (in unità di deviazione standard)\",\n    y = \"Densità\"\n  )"},{"path":"inferenza-sulle-medie.html","id":"test-direzionali-e-non-direzionali","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.2 Test direzionali e non direzionali","text":"Riassumendo, un test d’ipotesi può essere bidirezionale, unidirezionale\nsuperiore e unidirezionale inferiore.","code":""},{"path":"inferenza-sulle-medie.html","id":"test-bidirezionale","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.2.0.1 Test bidirezionale","text":"Per un’ipotesi nulla \\[H_0: \\mu = \\mu_0\\] nel caso di un test bidirezionale la regione di non rifiuto \\(\\mathcal{}\\) di \\(H_0\\) è\\[\n\\mathcal{}: \\quad \\mu_0 - \\frac{\\sigma}{\\sqrt{n}}z_{1-\\alpha/2} \\leq \\mu_n \\leq \\mu_0 + \\frac{\\sigma}{\\sqrt{n}}z_{1-\\alpha/2},\n\\]dove \\(\\mu_n\\) è la realizzazione della statistica test, ovvero la media campionaria, \\(n\\) è l’ampiezza del campione e \\(z_{1-\\alpha/2}\\) è il quantile di ordine \\(1-\\alpha/2\\) per la variabile standardizzata\\[\nZ_n = \\frac{\\mu_n - \\mu_0}{\\sigma/\\sqrt{n}}.\\notag\n\\]","code":""},{"path":"inferenza-sulle-medie.html","id":"test-unidirezionale-superiore","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.2.0.2 Test unidirezionale superiore","text":"La regione di non rifiuto di \\(H_0: \\mu \\leq \\mu_0\\), con \\(H_1: \\mu > \\mu_0\\), è l’intervallo aperto sinistra:\\[\n\\mathcal{}: \\quad -\\infty < \\mu_n \\leq \\mu_0 + \\frac{\\sigma}{\\sqrt{n}}z_{1-\\alpha},\n\\]dove \\(z_{1-\\alpha}\\) è il quantile di ordine \\(1-\\alpha\\) della normale\nstandard.","code":""},{"path":"inferenza-sulle-medie.html","id":"test-unidirezionale-inferiore","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.2.0.3 Test unidirezionale inferiore","text":"La regione di non rifiuto di \\(H_0: \\mu \\geq \\mu_0\\), con \\(H_1: \\mu < \\mu_0\\), è l’intervallo aperto destra:\\[\n\\mathcal{}: \\quad \\mu_0 - \\frac{\\sigma}{\\sqrt{n}}z_{1-\\alpha} \\leq \\mu_n < +\\infty,\n\\]\ndove \\(z_{1-\\alpha}\\) è il quantile di ordine \\(1-\\alpha\\) della normale standard.","code":""},{"path":"inferenza-sulle-medie.html","id":"eseguire-il-test-z-con-r","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.2.1 Eseguire il test Z con R","text":"Come abbiamo detto precedenza, nella pratica concreta dell’analisi dei dati il test \\(Z\\) non viene quasi mai usato. Il suo uso è talmente raro che R non c’è neppure una funzione che lo implementa. Vediamo comunque come svolgere calcoli con R. Se dati siano contenuti nel vettore x, non dobbiamo fare altro che calcolare il valore standardizzato della media campionaria assumendo come vera l’ipotesi nulla:Dato che il valore-\\(p\\)è minore di \\(\\alpha = 0.05\\), rifiutiamo \\(H_0\\). Riportiamo il risultato nel modo seguente.Avendo osservato una media campionaria pari 167.418 cm un campione casuale di ampiezza \\(n=20\\), assumendo che la deviazione standard della popolazione sia uguale 12 cm, possiamo concludere che le donne fiorentine tendono ad avere un’altezza maggiore della media nazionale (\\(z = 1.8328\\), \\(n = 20\\), \\(p = 0.0334\\), test unidirezionale).","code":"\nmu_0 <- 162.5\nsigma <- 12\nn <- 20\nz <- (mean(x) - mu_0) / (sigma / sqrt(n))\nz\n#> [1] 1.83283\n1 - pnorm(z, 0, 1)\n#> [1] 0.0334139"},{"path":"inferenza-sulle-medie.html","id":"assunzioni-del-test-z","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.2.2 Assunzioni del test Z","text":"Tutti test statistici fanno delle assunzioni proposito delle\ncaratteristiche della popolazione da cui sono stati tratti dati.\nAlcuni test fanno delle assunzioni ragionevoli, mentre altri test . Il\ntest \\(z\\) che abbiamo appena descritto è basato sulle seguenti ipotesi:Normalità. Il test \\(z\\) presuppone che la vera distribuzione della\npopolazione sia normale. Tale ipotesi è spesso soddisfatta e può\nessere verificata.Normalità. Il test \\(z\\) presuppone che la vera distribuzione della\npopolazione sia normale. Tale ipotesi è spesso soddisfatta e può\nessere verificata.Indipendenza. La seconda ipotesi del test è che le osservazioni\ncampionarie non sono correlate tra loro, né associate tra loro \nqualunque modo. Tale assunzione è difficile da valutare con metodi\nstatistici: deve invece essere garantita dal disegno sperimentale\nche viene utilizzato per raccogliere dati. Un caso ovvio nel quale\ntale assunzione viene falsificata è quando dati riguardano\nosservazioni compiute sugli stessi soggetti condizioni diverse o\ntempi diversi. È chiaro questo caso che ci sarà una\ncorrelazione tra le osservazioni. Per esempio, se misuriamo tempi\ndi reazione, è ovvio che, se un soggetto tende ad essere più veloce\ndella media nella condizione \\(\\), tenderà anche ad essere più veloce\ndella media nella condizione \\(B\\). Lo stesso si può dire per un\nsoggetto che tende ad essere più lento della media. Pertanto, sapere\nse un soggetto è più veloce della media nella condizione \\(\\) ci\nconsente di fare delle predizioni sul suo comportamento nella\ncondizione \\(B\\) – ovvero, dati sono correlati e l’assunzione di\nindipendenza viene violata. L’assunzione di indipendenza, invece,\nnon viene violata quando nelle condizioni \\(\\) e \\(B\\) dell’esempio\nabbiamo dati di soggetti diversi. Conoscendo come si sono\ncomportanti soggetti nella condizione \\(\\) non ci consente di fare\nalcuna predizione su come si comporteranno altri soggetti nella\ncondizione \\(B\\) – ovvero, dati sono indipendenti.Indipendenza. La seconda ipotesi del test è che le osservazioni\ncampionarie non sono correlate tra loro, né associate tra loro \nqualunque modo. Tale assunzione è difficile da valutare con metodi\nstatistici: deve invece essere garantita dal disegno sperimentale\nche viene utilizzato per raccogliere dati. Un caso ovvio nel quale\ntale assunzione viene falsificata è quando dati riguardano\nosservazioni compiute sugli stessi soggetti condizioni diverse o\ntempi diversi. È chiaro questo caso che ci sarà una\ncorrelazione tra le osservazioni. Per esempio, se misuriamo tempi\ndi reazione, è ovvio che, se un soggetto tende ad essere più veloce\ndella media nella condizione \\(\\), tenderà anche ad essere più veloce\ndella media nella condizione \\(B\\). Lo stesso si può dire per un\nsoggetto che tende ad essere più lento della media. Pertanto, sapere\nse un soggetto è più veloce della media nella condizione \\(\\) ci\nconsente di fare delle predizioni sul suo comportamento nella\ncondizione \\(B\\) – ovvero, dati sono correlati e l’assunzione di\nindipendenza viene violata. L’assunzione di indipendenza, invece,\nnon viene violata quando nelle condizioni \\(\\) e \\(B\\) dell’esempio\nabbiamo dati di soggetti diversi. Conoscendo come si sono\ncomportanti soggetti nella condizione \\(\\) non ci consente di fare\nalcuna predizione su come si comporteranno altri soggetti nella\ncondizione \\(B\\) – ovvero, dati sono indipendenti.Deviazione standard nota. La terza ipotesi del test \\(z\\) è che la\ndeviazione standard della popolazione sia nota al ricercatore.\nQuesta assunzione è irragionevole: ciò non si verifica nessuna\napplicazione concreta dell’analisi dei dati. altre parole, questa\nipotesi è sempre falsa.Deviazione standard nota. La terza ipotesi del test \\(z\\) è che la\ndeviazione standard della popolazione sia nota al ricercatore.\nQuesta assunzione è irragionevole: ciò non si verifica nessuna\napplicazione concreta dell’analisi dei dati. altre parole, questa\nipotesi è sempre falsa.Dato che è sempre del tutto fuori luogo assumere che \\(\\sigma\\) sia nota,\nponiamoci il problema di cosa fare quando non vogliamo assumere qualcosa\nche è certamente falso. Questo ci conduce al cosiddetto test \\(t\\) di\nStudent.","code":""},{"path":"inferenza-sulle-medie.html","id":"modello-normale-varianza-sconosciuta","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.3 Modello Normale: varianza sconosciuta","text":"Se la varianza \\(\\sigma^2\\) della popolazione normale non è nota essa deve\nessere stimata con la statistica campionaria corretta \\(s_n^2\\). Il test\ndi ipotesi si esegue valutando se il valore empirico della statistica\n\\[T_n = \\frac{(\\bar{X}_n -\\mu_0)\\sqrt{n}}{\\hat{s}_n}\\] appartiene alla\nregione di accettazione di \\(H_0\\) oppure alla regione di rifiuto\ndell’ipotesi nulla.Se il test è bidirezionale, la regione di non rifiuto di \\(H_0\\) è fornita\ndal seguente intervallo:\\[\n\\mathcal{}: \\quad \\mu_0 - \\frac{s_n}{\\sqrt{n}}t_{1-\\alpha/2} \\leq \\mu_n \\leq \\mu_0 + \\frac{s_n}{\\sqrt{n}}t_{1-\\alpha/2},\n\\]dove \\(s_n\\) è il valore empirico della stima di \\(\\sigma\\) e\n\\(t_{1-\\alpha/2}\\) è il quantile di ordine \\(1-\\alpha/2\\) della\ndistribuzione \\(t\\)-Student con \\(n-1\\) gradi di libertà. modo analogo,\nsi ricavano le regioni di non rifiuto per un test unidirezionale\nsuperiore:\\[\n\\mathcal{}: \\quad -\\infty < \\mu_n \\leq \\mu_0 + \\frac{s_n}{\\sqrt{n}}t_{1-\\alpha},\n\\]\noppure unidirezionale inferiore:\\[\n\\mathcal{}: \\quad \\mu_0 - \\frac{s_n}{\\sqrt{n}}t_{1-\\alpha} \\leq \\mu_n < +\\infty.\n\\]Se il valore empirico della statistica \\(T_n\\) ricavato dal campione\nricade una delle regioni sopra definite l’ipotesi nulla non può\nessere rifiutata.Quanto descritto sopra mostra che, quando ci basiamo su una stima\ndella deviazione standard della popolazione, dobbiamo fare degli\naggiustamenti alla procedura che abbiamo adottato precedenza. Questi\naggiustamenti furono introdotti nel 1908 da William Sealy Gosset, che\n’epoca lavorava come chimico per il birrificio della Guinness. Dal\nmomento che Guinness non vedeva di buon occhio il fatto che suoi\ndipendenti pubblicassero delle analisi statistiche di ciò che ritenevano\nessere un segreto commerciale, Gosset pubblicò il lavoro sotto lo\npseudonimo “Student,” da cui il nome “test t di Student.” Gosset\ncapì che la stima di \\(\\sigma\\) introduce un ulteriore elemento di\nincertezza nella procedura di test di ipotesi. Di conseguenza, si rese\nconto che non è più possibile usare \\(\\mathcal{N}(0, 1)\\) quale funzione\ndi densità che descrive \\(f(\\bar{X}_n \\mid H_0)\\), ma è invece necessario\nutilizzare una diversa funzione di densità che è, appunto, la \\(t\\) di\nStudent.precedenza abbiamo visto che ci sono infinite distribuzioni \\(t\\) di\nStudent, ciascuna definita da un diverso numero di gradi di libertà.\nAbbiamo anche visto che la distribuzione \\(t\\)-Student tende alla normale\nstandard per \\(n \\rightarrow \\infty\\), per cui quando \\(n\\) è\nsufficientemente grande (\\(n > 30\\)), facendo un’approssimazione, \nquantili \\(t_{1-\\alpha/2}\\) e \\(t_{1-\\alpha}\\) possono essere sostituiti dai\ncorrispondenti quantili \\(z_{1-\\alpha/2}\\) e \\(z_{1-\\alpha}\\) della normale\nstandard.","code":""},{"path":"inferenza-sulle-medie.html","id":"effetto-stroop","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.3.1 Effetto Stroop","text":"Per fare un esempio concreto, supponiamo che ad un campione di 59 studenti di psicologia sia stato chiesto di completare una variante del compito Stroop che utilizza come stimoli facce espressive e le parole “felice” o “triste” (Caudek, 2014). ogni prova dell’esperimento, soggetti devono classificare l’immagine di un\nvolto (sorridente o triste) nelle due categorie “volto felice” o “volto\ntriste,” ignorando la parola sovrapposta ’immagine. La parola\nirrilevante per il compito poteva essere compatibile con l’espressione\ndel volto (es., volto felice e parola “felice”: condizione congruente) o\nincompatibile con essa (es., volto felice e parola “triste”: condizione\nincongruente). L’effetto Stroop consiste nel ritardo di elaborazione\ndell’espressione del volto che si riflette un rallentamento dei tempi\ndi reazione e nell’aumento degli errori nella condizione incongruente\nrispetto quella congruente.Per ciascun partecipante, su un totale di 180 prove, è stato calcolato\nl’effetto Stroop, ovvero la differenza tra la media dei tempi di\nreazione nella condizione incongruente e nella condizione congruente.\nValori positivi significano che tempi di reazione medi nella\ncondizione incongruente sono maggiori di quelli nella condizione\ncongruente.Per \\(59\\) soggetti dell’esperimento eseguito da Caudek (2014), l’effetto Stroop è riportato qui sottoe vale, mediacon una deviazione standard pari aL’ipotesi nulla è che la prestazione non subisca un effetto di\ninterferenza da parte della parola irrilevante, ovvero che la media\ndell’effetto Stroop sia 0, \\(H_0: \\mu = 0\\). base ’ipotesi alternativa, invece,\nla media dell’effetto Stroop è diversa da 0, \\(H_1: \\mu \\neq 0\\).Poniamoci il problema di svolgere il test \\(t\\) di Student per questi dati.Per calcolare il valore \\(T\\) del test \\(t\\) di Student dobbiamo\nstandardizzare la media campionaria, ovvero dobbiamo specificare la\nposizione della statistica test ’interno della sua distribuzione\navendo assunto come vera l’ipotesi nulla, ovvero avendo assunto che la\nmedia della popolazione sia \\(0\\). La statistica test dunque si ottiene\ndividendo la media campionaria per una stima dell’errore standard della\nmedia:\\[\nT = \\frac{\\bar{X} - \\mu}{\\frac{s}{\\sqrt{n}}} = \\frac{27.52542 - 0}{\\frac{88.2878}{\\sqrt{59}}} = 2.394745.\n\\]R il calcolo si svolge nel modo seguente:Si noti che, nel test \\(z\\) l’errore standard era dato da \\(\\sigma/\\sqrt{n}\\); nel test \\(t\\) di Student, invece, non conoscendo \\(\\sigma\\), otteniamo una stima dell’errore standard mediante il rapporto \\(\\hat{\\sigma}/\\sqrt{n} = s_n/\\sqrt{n}\\), dove \\(s_n\\) è la stima corretta della deviazione standard della popolazione.Nel caso presente, per trovare il valore-\\(p\\) è necessario calcolare\nl’area sottesa alla densità \\(t_{59-1}\\) negli intervalli \\([-\\infty, -T]\\)\ne \\([T, \\infty]\\), ovvero nel caso di valori della statistica \\(T\\) maggiori\nvalore assoluto al valore osservato. Usando R otteniamoPosto \\(\\alpha = 0.05\\), limiti della regione di rifiuto nel caso di un\ntest bidirezionale sono dati dai quantili della distribuzione \\(t\\) di\nStudent con \\(n-1\\) gradi di libertà cui è associata una probabilità\npari 0.025 ciascuna coda. Mediantesi trovano valori critici di \\(-2.00\\) e \\(2.00\\). Tutti valori della\nstatistica \\(T\\) minori di \\(-2.00\\) o maggiori di \\(2.00\\) portano dunque al\nrifiuto di \\(H_0\\).Come abbiamo visto precedenza, ci sono due modi equivalenti per\nsvolgere il test dell’ipotesi: confrontare il valore-\\(p\\) con \\(\\alpha\\) o\nstabilire se il valore osservato della statistica \\(T\\) cade nella regione\ndi rifiuto di \\(H_0\\). Nel caso presente, il valore-\\(p\\) è minore di\n\\(\\alpha\\) (\\(0.0199 < 0.05\\)) e dunque rifiutiamo \\(H_0\\). Oppure possiamo\nconfrontare il valore della statistica test con limiti della regione\ndi rifiuto dell’ipotesi nulla. La statistica \\(T = 2.39\\) ha un valore\nsuperiore del valore critico che delimita la regione di rifiuto nella\ncoda di destra della distribuzione di \\(T\\): 2.39 > 2.00. Dato che il\nvalore \\(T\\) osservato cade nella regione di rifiuto concludiamo\nrifiutando \\(H_0\\).Calcoliamo anche l’intervallo di confidenza al 95%:\\[\n\\bar{X}_n \\pm t^*\\frac{s_n}{\\sqrt{n}} = 27.52542 \\pm \\frac{88.2878}{\\sqrt{59}} = [4.52, 50.53],\n\\]laddove \\(t^*\\) è il quantile della \\(t\\) di Student con \\(n-1 = 59-1\\) gradi di libertà di ordine \\(1 - \\alpha/2\\), ovveroPossiamo riportare risultati nel modo seguente.L’esperimento ci fornisce evidenze di un effetto di interferenza pari 27.5 ms, \\(t_{59} = 2.39\\), \\(p = 0.0199\\), CI\\(_{95}\\) = [4.52, 50.53].laddove la notazione \\(t_{59}\\) indica il fatto che abbiamo eseguito un test \\(t\\) di Student con 59 gradi di libertà.","code":"\nx <- c(-110, 196, -58, -54, -162, 11, 6, -25, 27, 81, -40, -91, -40, 39, 23, -32, 157,  72, 89, 9, 60, 239, 139, 8, -65, 11, 18, 51, 53, 74, 105, 245, -16, -69, 1, -11, 65, -10, 118, -62, 48, -78, 96, -122, 7, 83, -60, 57, 111, -11, 34, 27, 84, 240, -67, 111, 92, -93, 13)\nmean(x)\n#> [1] 27.52542\nsd(x)\n#> [1] 88.2878\nT <- (mean(x)) / (sd(x) / sqrt(length(x)))\nT\n#> [1] 2.394745\n2 * (1 - pt(T, 59 - 1)) \n#> [1] 0.01988317\nqt(c(0.025, 0.975), 59 - 1)\n#> [1] -2.001717  2.001717\nqt(0.975, 58)\n#> [1] 2.001717"},{"path":"inferenza-sulle-medie.html","id":"test-t-di-student-con-r","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.3.2 Test T di Student con R","text":"La procedura del test \\(t\\) di Student è quasi identica quella del test\n\\(z\\), parte il fatto che abbiamo usato la stima della deviazione\nstandard della popolazione al posto di \\(\\sigma\\) e poi abbiamo valutato\nla nostra ipotesi usando la distribuzione \\(t\\) con \\(n-1\\) gradi di libertà\nal posto di \\(\\mathcal{N}(0, 1)\\). Dato che è sempre possibile fare degli\nerrori quando svolgiamo dei calcoli tediosi, controlliamo se risultati\nottenuti sono corretti. Dopo avere inserito dati nel vettore x,\nconfrontiamo risultati che abbiamo svolto mano\nnell’esercizio sull’effetto Stroop con quelli forniti dalla funzione\nt.test() di :risultati sono identici quelli che abbiamo trovato svolgendo calcoli “mano.”","code":"\nt.test(x)\n#> \n#>  One Sample t-test\n#> \n#> data:  x\n#> t = 2.3947, df = 58, p-value = 0.01988\n#> alternative hypothesis: true mean is not equal to 0\n#> 95 percent confidence interval:\n#>   4.517497 50.533351\n#> sample estimates:\n#> mean of x \n#>  27.52542"},{"path":"inferenza-sulle-medie.html","id":"test-unidirezionale","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.4 Test unidirezionale","text":"realtà, si parla di effetto Stroop solo quando tempi di reazione\nsono maggiori, media, nella condizione incongruente rispetto quella\ncongruente. Nel caso presente, dunque, è sensato porre tutta la regione\ndi rifiuto nella coda di destra della distribuzione della statistica\n\\(T\\). Per calcolare il valore-\\(p\\) di un test unidirezionale superiore è\nsufficiente calcolare l’area sottesa alla funzione di densità\nnell’intervallo \\([T, +\\infty]\\). Posto \\(\\alpha = 0.05\\), il valore critico\ndella regione di rifiuto, nel caso di un test unidirezionale superiore,\nè dato dal quantile della distribuzione \\(t\\) di Student con \\(n-1\\) gradi\ndi libertà cui è associata una probabilità pari 0.05 nella coda di\ndestra. Utilizzando qt(0.95, 59 - 1) tale valore risulta essere pari \n\\(1.67\\). Tutti valori della statistica \\(T\\) maggiori di 1.67 portano al\nrifiuto di \\(H_0\\). È ovvio che, se abbiamo trovato un risultato\nstatisticamente significativo con un test bilaterale la stessa\nconclusione sarà ottenuta, maggior ragione, con un test unilaterale se\nla statistica test cade nella coda appropriata della distribuzione\ncampionaria (ovvero, nel caso presente, nella coda di destra). \nconclusione, il test dell’ipotesi nulla fornisce evidenze coerenti con\nl’idea che tempi di reazione dei soggetti di questo esperimento\ntendano ad essere più lenti, media, nella nella condizione\nincongruente rispetto quella congruente.","code":""},{"path":"inferenza-sulle-medie.html","id":"assunzioni","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.4.1 Assunzioni","text":"Dato che il test \\(t\\) di Student per un campione non è altro che il test\n\\(z\\) nel caso cui \\(\\sigma\\) non viene considerata come nota, non\ndovrebbe sorprenderci che le assunzioni del test \\(t\\) di Student siano\nmolto simili quelle del test \\(z\\).Normalità. Assumiamo che la distribuzione della popolazione sia\nnormale.Normalità. Assumiamo che la distribuzione della popolazione sia\nnormale.Indipendenza. Dobbiamo assumere che le osservazioni nel nostro\ncampione siano generate indipendentemente le une dalle altre.Indipendenza. Dobbiamo assumere che le osservazioni nel nostro\ncampione siano generate indipendentemente le une dalle altre.Queste due assunzioni sembrano sensate. Di conseguenza, il test \\(t\\) di\nStudent per un campione viene ampiamente usato nella pratica corrente\nper svolgere il confronto tra una media campionaria e la media\nipotizzata di una popolazione.","code":""},{"path":"inferenza-sulle-medie.html","id":"popolazione-non-normale","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.4.2 Popolazione non Normale","text":"Abbiamo visto precedenza che la distribuzione campionaria della media, al crescere di \\(n\\), è ben approssimata dalla legge normale \\(\\mathcal{N}(\\mu, \\sigma^2/n)\\), indipendentemente dalla forma della distribuzione della popolazione. Di conseguenza, se \\(n\\) è sufficientemente grande (\\(n > 30\\)) e se \\(H_0\\) è vera, la distribuzione\ndelle medie campionarie si può approssimare con una legge normale avente\nmedia \\(\\mu_0\\) e varianza \\(\\sigma^2/n\\), se \\(\\sigma^2\\) è nota, oppure\n\\(\\hat{s}_n^2/n\\), se \\(\\sigma^2\\) sconosciuta. Pertanto, nel caso di grandi\ncampioni, le regioni di accettazione dell’ipotesi nulla sono ancora\nquelle descritte nel presente capitolo, indipendentemente dalla forma\ndella distribuzione della popolazione di origine. Nel caso di piccoli\ncampioni tratti da una popolazione non normale, invece, non è possibile,\ngenerale, procedere al test sul valore medio mediante la procedura qui descritta.","code":""},{"path":"inferenza-sulle-medie.html","id":"due-gruppi-indipendenti","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.5 Due gruppi indipendenti","text":"Anche se il \\(t\\) di Student per un singolo campione viene spesso usato,\nnon corrisponde al caso più comune di uso del test \\(t\\) di Student. Una\nsituazione molto più comune è quella nella quale vengono confrontati due\ngruppi di osservazioni indipendenti. psicologia, questo corrisponde\nal caso di due gruppi diversi di partecipanti, un gruppo per ciascuna\ncondizione sperimentale. Per ogni partecipante allo studio viene\nmisurata una variabile di interesse e la domanda della ricerca è se \ndue gruppi provengano o meno da due popolazioni aventi la stessa media.\ntale situazione viene applicato il test \\(t\\) per campioni\nindipendenti.","code":""},{"path":"inferenza-sulle-medie.html","id":"test-bidirezionale-1","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.5.1 Test bidirezionale","text":"Supponiamo che due popolazioni abbiano distribuzioni normali, con la\nstessa varianza e con medie incognite. Le due popolazioni sono dunque\ndistribuite come due variabili aleatorie indipendenti\\[\nX \\sim \\mathcal{N}(\\mu_1, \\sigma^2), \\quad Y \\sim \\mathcal{N}(\\mu_2, \\sigma^2).\n\\]\nCi chiediamo se ci sono differenze fra le medie di queste due\npopolazioni e procediamo con il test della seguente ipotesi nulla:\\[\nH_0: \\mu_1 - \\mu_2 = 0\\quad \\text{(non ci sono differenze fra le medie)}.\n\\]\nL’ipotesi alternativa bidirezionale è\\[\nH_1: \\mu_1  - \\mu_2 \\neq 0.\n\\]\nAvendo osservato dati di due campioni indipendenti estratti dalle due\npopolazioni, possiamo calcolare la statistica\\[\nT_n = \\frac{(\\bar{X} - \\bar{Y}) - (\\mu_1-\\mu_2)}{\\sqrt{s_p^2 \\big(\\frac{1}{n_1} + \\frac{1}{n_2}\\big) }} \\notag\n\\]\nche si distribuisce come una variabile aleatoria \\(t\\)-Student con\n\\(\\nu = n_1 + n_2 - 2\\) gradi di libertà, dove una stima combinata della\nvarianza, \\(s^2_p\\), si trova come indicato ’interno della radice quadrata al denominatore della formula precedente. Se l’ipotesi nulla è vera, dunque, la\nstatistica\\[\nT_n = \\frac{\\bar{X} - \\bar{Y}}{\\sqrt{s_p^2 \\big(\\frac{1}{n_1} + \\frac{1}{n_2}\\big) }} \\notag\n\\]\nsi distribuirà come una variabile aleatoria \\(t\\)-Student con \\(\\nu = n_1 + n_2 - 2\\) gradi di libertà.Fissato il livello \\(\\alpha\\), la regione di non rifiuto dell’ipotesi nulla è data da:\\[\n\\mathcal{}: \\quad -t^{\\ast} \\cdot s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}} < (\\bar{X} - \\bar{Y}) < +t^{\\ast} \\cdot s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}},\\notag\n\\]dove \\(t^{\\ast} = t_{\\nu, 1-\\alpha/2}\\) è il quantile di ordine \\((1-\\alpha/2)\\) della distribuzione \\(t\\)-Student con \\(\\nu = n_1 + n_2 - 2\\) gradi di libertà.","code":""},{"path":"inferenza-sulle-medie.html","id":"la-durata-della-gravidanza","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.5.2 La durata della gravidanza","text":"Per fare un esempio, consideriamo uno studio svolto su 1408 donne ospedalizzate (1) per un ricovero ordinario o (2) per un ricovero d’urgenza relativo al parto. La durata della gravidanza (chiamiamola \\(x\\)) è misurata settimane complete dall’inizio dell’ultimo periodo mestruale. dati sono riassunti nel modo seguente.Ricovero ordinario: 775 osservazioni con \\(\\bar{x}_o = 39.08\\) e\n\\(\\sigma^2 = 7.77\\).Ricovero ordinario: 775 osservazioni con \\(\\bar{x}_o = 39.08\\) e\n\\(\\sigma^2 = 7.77\\).Ricovero d’urgenza: 633 osservazioni con \\(\\bar{x}_u = 39.60\\) e\n\\(\\sigma^2 = 4.95\\).Ricovero d’urgenza: 633 osservazioni con \\(\\bar{x}_u = 39.60\\) e\n\\(\\sigma^2 = 4.95\\).Ci chiediamo se ci sono evidenze sufficienti per concludere che la\ndurata della gravidanza sia diversa nel caso di un ricovero ordinario o\nnel caso di un ricovero d’urgenza.Se possiamo assumere che dati provengano da due distribuzioni normali\naventi uguale varianza, il test \\(t\\) di Student si svolge nel modo\nseguente. Una stima combinata della varianza è data da\\[\ns^2_p = \\frac{774 \\cdot 7.77 + 632 \\cdot 4.95}{1406} \\Big(\\frac{1}{775} \\frac{1}{633}\\Big) = 0.0187.\n\\]\nLa statistica test è\\[\nT = \\frac{\\bar{x}_o - \\bar{x}_u}{s_p} = -3.8064.\n\\]\nAbbiamo \\(1,406\\) gradi di libertà. Usando R per calcolare il valore-\\(p\\) di un test\nbilaterale otteniamo\\[\np = P(|T| > |t|) = \\texttt{2 * pt(-3.8064, 1406) = 0.00015}.\n\\]Con \\(\\alpha = 0.05\\) possiamo dunque rigettare l’ipotesi nulla di eguaglianza della durata delle gravidanze per due gruppi di donne.","code":""},{"path":"inferenza-sulle-medie.html","id":"test-unidirezionale-1","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.5.3 Test unidirezionale","text":"Se invece siamo interessati sapere se la media della prima popolazione\nè maggiore di quella della seconda popolazione, per esempio, le ipotesi\nstatistiche diventano: \\[\\begin{aligned}\nH_0: \\mu_1 \\leq \\mu_2, \\quad H_1: \\mu_1 > \\mu_2. \\notag\\end{aligned}\\]\nCome precedenza, la statistica test\n\\[T_n = \\frac{\\bar{X} - \\bar{Y}}{\\sqrt{s_p^2 \\big(\\frac{1}{n_1} + \\frac{1}{n_2}\\big) }} \\notag\\]\nsi distribuisce come una variabile aleatorie \\(t\\)-Student con\n\\(\\nu = n_1 + n_2 - 2\\) gradi di libertà. questo caso, però, fissato il\nlivello \\(\\alpha\\), la regione di accettazione del test è data da:\n\\[\\mathcal{}: \\quad -\\infty < (\\bar{X} - \\bar{Y}) < +t^{\\ast} \\cdot s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}},\\notag\\]\ndove \\(t^{\\ast} = t_{\\nu, 1 - \\alpha}\\) è il quantile di ordine\n\\((1 - \\alpha)\\) della distribuzione \\(t\\)-Student con \\(\\nu = n_1 + n_2 - 2\\)\ngradi di libertà.","code":""},{"path":"inferenza-sulle-medie.html","id":"assunzioni-1","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.5.4 Assunzioni","text":"Il test \\(t\\) per campioni indipendenti si basa sulle seguenti ipotesi.Normalità. Come nel caso del test \\(t\\) per un singolo campione,\nanche il test \\(t\\) per campioni indipendenti presume che dati siano\nnormalmente distribuiti. Specificamente, assumiamo che entrambe le\npopolazioni da cui sono tratti due gruppi siano normalmente\ndistribuite. Vedremo seguito come sia possibile verificare tale\nassunzione.Normalità. Come nel caso del test \\(t\\) per un singolo campione,\nanche il test \\(t\\) per campioni indipendenti presume che dati siano\nnormalmente distribuiti. Specificamente, assumiamo che entrambe le\npopolazioni da cui sono tratti due gruppi siano normalmente\ndistribuite. Vedremo seguito come sia possibile verificare tale\nassunzione.Indipendenza. Ancora una volta, si presume che le osservazioni\nsiano campionate indipendentemente. Nel contesto del test \\(t\\) per\ncampioni indipendenti questa assunzione significa due cose diverse.\nprimo luogo, assumiamo che le osservazioni ’interno di ciascun\ncampione siano indipendenti l’una dall’altra (esattamente come ne\ncaso di un test \\(t\\) per un singolo campione). secondo luogo,\nassumiamo anche che non ci siano dipendenze tra due campioni. Se,\nad esempio, scopriamo di avere accidentalmente incluso alcuni\npartecipanti entrambe le condizioni sperimentali dello studio (ad\nesempio, permettendo alla stessa persona di iscriversi due\ncondizioni diverse), allora questo introduce delle dipendenze le\nosservazioni dei due campioni e l’ipotesi di indipendenza viene\nviolata.Indipendenza. Ancora una volta, si presume che le osservazioni\nsiano campionate indipendentemente. Nel contesto del test \\(t\\) per\ncampioni indipendenti questa assunzione significa due cose diverse.\nprimo luogo, assumiamo che le osservazioni ’interno di ciascun\ncampione siano indipendenti l’una dall’altra (esattamente come ne\ncaso di un test \\(t\\) per un singolo campione). secondo luogo,\nassumiamo anche che non ci siano dipendenze tra due campioni. Se,\nad esempio, scopriamo di avere accidentalmente incluso alcuni\npartecipanti entrambe le condizioni sperimentali dello studio (ad\nesempio, permettendo alla stessa persona di iscriversi due\ncondizioni diverse), allora questo introduce delle dipendenze le\nosservazioni dei due campioni e l’ipotesi di indipendenza viene\nviolata.Omogeneità della varianza (detta anche “omoscedasticità”). La\nterza ipotesi è che le due popolazioni abbiano la stessa la\ndeviazione standard. È possibile verificare questa ipotesi usando il\ntest di Levene. Tuttavia, c’è un rimedio più semplice per la\nviolazione di questa assunzione, di cui parleremo nella prossima\nsezione.Omogeneità della varianza (detta anche “omoscedasticità”). La\nterza ipotesi è che le due popolazioni abbiano la stessa la\ndeviazione standard. È possibile verificare questa ipotesi usando il\ntest di Levene. Tuttavia, c’è un rimedio più semplice per la\nviolazione di questa assunzione, di cui parleremo nella prossima\nsezione.","code":""},{"path":"inferenza-sulle-medie.html","id":"test-di-welch","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.5.5 Test di Welch","text":"Il problema più grande relativo ’uso del test \\(t\\) di Student per\ncampioni indipendenti ha che fare con la terza ipotesi elencata nella\nsezione precedente: l’ipotesi che entrambe le popolazioni abbiano la\nstessa deviazione standard. Questo accade raramente nella vita reale: se\ndue popolazioni non hanno la stessa media, perché dovrebbero avere la\nstessa deviazione standard? Non c’è davvero alcuna ragione per\naspettarsi che questa ipotesi sia vera. Per superare tale difficoltà,\nWelch (1947) sviluppò una seconda forma del test \\(t\\) di Student per\ncampioni indipendenti la quale non richiede l’omogeneità della varianza.Il test di Welch è molto simile al test \\(t\\) di Student per campioni\nindipendenti. La statistica test è identica quella calcolata \nprecedenza\\[\\begin{equation}\nT_n = \\frac{\\bar{X} - \\bar{Y}}{\\hat{\\sigma}_{\\bar{X} - \\bar{Y}}}\n\\tag{22.2}\n\\end{equation}\\]ovvero, è data dal rapporto tra la differenza tra le medie campionarie e l’errore standard di tale differenza. Ciò che distingue il test di Welch dalla procedura descritta precedenza è il modo di calcolare l’errore standard della differenza tra due medie. Nel test di Welch, l’errore standard viene stimato nel modo seguente:\\[\n\\hat{\\sigma}_{\\bar{X} - \\bar{Y}} = \\sqrt{\\frac{\\hat{\\sigma}_1^2}{n_1} + \\frac{\\hat{\\sigma}_2^2}{n_2}}.\n\\]La statistica test viene poi valutata utilizzando una correzione dei gradi di liberà fornita dall’equazione di Welch–Satterthwaite:\\[\ngdl = \\frac{\n(\\hat{\\sigma}_1^2/n_1 + \\hat{\\sigma}_2^2/n_2)^2\n}{\n(\\hat{\\sigma}_1^2/n_1)^2/(n_1-1) + (\\hat{\\sigma}_2^2/n_2)^2/(n_2-1)\n}.\n\\]\nVediamo ora un caso concreto come applicare il test di Welch.Consideriamo il seguente estratto dell’articolo di Mehr et al. (2014):infants’ degree song exposure comparable across two experiments: estimated total number song performances similar Experiment 1 (\\(M\\) = 76.3, \\(SD\\) = 56.2) Experiment 2 (\\(M\\) = 81.8, \\(SD\\) = 50.5), \\(t_{61.3}\\) = 0.41, \\(p\\) = .68 (Satterthwaite’s \\(t\\) test) …Senza entrare nei dettegli dello studio, poniamoci l’obiettivo di\nreplicare l’analisi statistica descritta dagli autori. dati del primo\nesperimento sono:e dati del secondo experimento sono:Dobbiamo eseguire un test \\(t\\) di Student per campioni indipendenti con il metodo di Welch.questo caso, \\(n_1=n_2 = 32\\). Abbiamo inoltre che \\(\\bar{X} = 76.32191\\)\ne \\(\\bar{Y} = 81.77619\\), con \\(s_1^2 = 3163.961\\) e \\(s_2^2 = 2554.029\\).\nL’errore standard stimato mediante la procedura di Welch è pari 13.36739 per cui, utilizzando\nl’equazione del test di Welch otteniamo la statistica \\(T = -0.4080286\\). \ngradi di libertà per il test di Welch sono pari 61.30249 il che ci conduce ad un\nvalore-\\(p\\) pari aQuesti risultati riproducono perfettamente ciò che è stato riportato da Mehr et al. (2014). calcoli si possono svolgere utilizzando la funzione t.test() di R:Si noti che R utilizza di default il test di Welch quando sottopone verifica l’ipotesi nulla dell’eguaglianza di due medie.L’intervallo di confidenza al 95% è dato dail che riproduce il risultato trovato dalla funzione t.test().Il messaggio che si può ricavare dalla discussione sul test di Welch è\nche esso dovrebbe sempre essere eseguito al posto del “tradizionale”\ntest \\(t\\) di Student (infatti, questa è l’impostazione di default ).\nQuesto perché il test di Welch si comporta meglio del test \\(t\\) di\nStudent se le dimensioni e le varianze dei campioni non sono uguali tra\ngruppi e dà lo stesso risultato del test \\(t\\) di Student quando le\ndimensioni e le varianze del campione sono uguali. Un approccio che\nviene raccomandato nei testi di statistica è di verificare con il test\ndi Levene l’ipotesi che le varianze siano uguali tra gruppi, ma molti\nricercatori ritengono che sia preferibile utilizzare sempre il test di\nWelch, indipendentemente dai risultati del test di Levene. Infatti, il\ntest di Levene ha spesso una bassa potenza – ovvero non è grado di\nrespingere l’ipotesi nulla che le varianze siano uguali anche quando\nesse sono effettivamente diverse – il che rende problematico assumere\nche le varianze siano uguali anche se il risultato del test di Levene è\nnullo.","code":"\nx1 <- c(35.0, 239.0, 102.0, 27.0, 60.0, 126.0, 134.6667, 63.77777, 44.0, 55.0, 88.0, 53.66666, 59.5, 94.0, 54.0, 26.0, 44.0, 23.0, 38.0, 31.0, 78.4, 135.0, 26.0, 120.9091, 13.0, 245.0, 66.5, 63.0, 57.16667, 29.71428, 70.0, 140.0)\nx2 <- c(43.16666, 63.0, 35.0, 100.8, 69.0, 66.0, 105.0, 270.6667, 62.0, 80.0, 128.0, 104.0, 49.0, 80.0, 51.0, 114.3333, 168.0, 105.0, 37.0, 38.0,  45.0, 48.0,  84.0, 99.0,  38.5, 74.57143, 49.0, 28.0, 64.0, 86.8, 49.0, 182.0)\n2 * pt(-0.4080286, 61.30249)\n#> [1] 0.6846743\nt.test(x1, x2)\n#> \n#>  Welch Two Sample t-test\n#> \n#> data:  x1 and x2\n#> t = -0.40803, df = 61.302, p-value = 0.6847\n#> alternative hypothesis: true difference in means is not equal to 0\n#> 95 percent confidence interval:\n#>  -32.18136  21.27281\n#> sample estimates:\n#> mean of x mean of y \n#>  76.32191  81.77619\nse <- sqrt(var(x1) / length(x1) + var(x2) / length(x2))\ndf <- 61.302\nci <- (mean(x1) - mean(x2)) + c(-1, 1) * qt(0.975, df) * se \nci\n#> [1] -32.18137  21.27281"},{"path":"inferenza-sulle-medie.html","id":"assunzioni-del-test-di-welch","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.5.6 Assunzioni del test di Welch","text":"Le assunzioni alla base del test di Welch sono simili quelle del test\n\\(t\\) di Student per campioni indipendenti, ad eccezione del fatto\nche il test di Welch non presuppone l’omogeneità della varianza.\nRimangono dunque solo l’assunzione di normalità e l’assunzione di\nindipendenza.","code":""},{"path":"inferenza-sulle-medie.html","id":"test-t-per-dati-appaiati","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.6 Test T per dati appaiati","text":"Se consideriamo il test \\(t\\) di Student per campioni indipendenti o il\ntest di Welch è evidente che tali test possono essere usati \nsituazioni cui due campioni sono, appunto, indipendenti l’uno\ndall’altro. Una tale situazione si presenta, ad esempio, quando \npartecipanti ad un esperimento vengono assegnati casualmente una di\ndue condizioni sperimentali. Ma ci possono anche essere disegni\nsperimentali con caratteristiche diverse. particolare, un disegno\nmisure ripetute ciascun partecipante viene valutato (rispetto alla\nstessa variabile dipendente) tutte le condizioni sperimentali e, \ntali circostanze, due campioni non sono indipendenti. Ad esempio,\npotremmo essere interessati sapere se ascoltare musica riduce la\ncapacità della memoria di lavoro delle persone. tal fine, potremmo\nmisurare la capacità della memoria di lavoro di ciascun soggetto due\ncondizioni: con la musica e senza musica. un disegno sperimentale di\nquesto tipo ciascun partecipante fa parte di ciascuno dei due gruppi che\nvengono esaminati. Non possiamo dunque usare l’approccio descritto \nprecedenza e dobbiamo procedere un modo diverso, ovvero mediante\nl’uso del test \\(t\\) per dati appaiatiNel test \\(t\\) per dati appaiati disponiamo di una coppia ordinata di\nosservazioni per ciascuna u.s. (per esempio, l’osservazione effettuata\nad un pre-test e ad un post-test, oppure nelle condizioni con la musica\ne senza musica dell’esempio precedente) e diventa così possibile\ncalcolare una misura della variazione \\(D\\) della variabile di interesse\nrispetto alle due osservazioni. Avendo un insieme \\(D_1, \\dots, D_n\\) di\nvariazioni, possiamo calcolarne la media \\(\\bar{D}\\) e la deviazione\nstandard \\(s_D\\):\\[\n\\bar{D} = \\frac{1}{n} \\sum_{= 1}^n D_i, \\quad s_D = \\sqrt{\\frac{1}{n-1}\\sum_{=1}^n (D_i - \\bar{D})^2}.\n\\]L’errore standard per la media delle differenze è dato da\\[\ns_{\\bar{D}} = \\frac{s_D}{\\sqrt{n}}.\n\\]Se \\(\\delta\\) è la variazione media della popolazione, allora la statistica\\[\nT_n = \\frac{\\bar{D} - \\delta}{s_{\\bar{D}}}\n\\]\nsi distribuisce come una v.. \\(t\\)-Student con\n\\(\\nu = n - 1\\) gradi di libertà, sotto l’ipotesi che il campione (di\nvariazioni) provenga da una popolazione distribuita maniera normale.\nPer il test dell’ipotesi nulla \\(H_0: \\delta = 0\\), si calcola il valore\n\\(T_n = \\bar{D}/s_{\\bar{D}}\\) e si procede con il confronto con il valore\ncritico per \\(\\nu = n - 1\\) gradi di libertà, dove \\(n\\) è il numero di\ncoppie di osservazioni. Come per tutti test \\(t\\), la statistica \\(T_n\\)\ntende distribuirsi come una \\(t\\)-Student, indipendentemente dalla forma\ndella distribuzione della popolazione di origine, se \\(n\\) è\nsufficientemente grande.","code":""},{"path":"inferenza-sulle-medie.html","id":"proporzione-di-maschi-e-femmine","chapter":"Capitolo 22 Inferenza sulle medie","heading":"22.6.1 Proporzione di maschi e femmine","text":"Per fare un esempio, consideriamo dati forniti dal censimento indiano relativi rapporto numerico tra due sessi nel 2001 e nel 2011 35 stati dell’India (dati grezzi sono forniti sulla pagina Moodle di Psicometria).Al momento della nascita, la percentuale di bambini di sesso\nmaschile varia nelle diverse zone del mondo, ma media nascono 101\nmaschi ogni 100 femmine (Orzack et al., 2015). Nonostante il fatto che\nle donne, generale, vivano più lungo degli uomini, ci sono due\npaesi nel mondo che hanno al loro interno un grande squilibrio nel\nrapporto tra sessi: la Cina ha quasi 50 milioni di uomini più\nrispetto alle donne e l’India 43 milioni. Lo squilibrio di Cina e\nIndia è dovuto alle pratiche ampiamente documentate degli aborti\nselettivi sulla base del genere (causa anche della disponibilità\ndi tecniche di diagnosi prenatale prezzi accessibili) e\n’infanticidio delle neonate (Miller, 2001).Nell’insieme di dati considerato, ogni osservazione corrisponde ad uno stato dell’India. La variabile considerata (child_sex_ratio) è il numero medio di bambine femmine per ogni 1000 bambini maschi – ciò consente di escludere la maggiore longevità delle donne\n(l’età dei bambini non è specificata). Nel 2001, risultano esserci \nmedia \\(934\\) bambine rispetto 1000 bambini maschi e nel 2011 risultano\n\\(926\\) bambine, media, per ogni 1000 bambini maschi. Per\nciascuno stato, sottraiamo il numero medio di bambine calcolate rispetto 1000\nbambini nel 2011 da quello del 2001. Le \\(35\\) differenze così trovate\nhanno una media pari \\(-7.66\\) con una deviazione standard di \\(22.92\\).\nLa statistica test diventa\\[\nT = \\frac{-7.66 - 0}{22.92/\\sqrt{35}} = -1.976.\n\\]Per un test bilaterale, il valore-\\(p\\) è l’area sottesa alla funzione di densità \\(t\\)\ncon 34 gradi di libertà negli intervalli \\([-\\infty, T]\\) e \\([T, +\\infty]\\)\ne risulta essere uguale \\(0.056\\). Essendo il valore-\\(p\\) maggiore di\n\\(\\alpha = 0.05\\), non possiamo rigettare l’ipotesi nulla \\(H_0: \\delta = 0\\) che la media della popolazione di differenze sia zero (ovvero che nell’arco temporale considerato non vi siano differenze nel rapporto numerico tra sessi). conclusione, non ci sono evidenze che nel decennio 2001-2011 la situazione sia migliorata. Addirittura, la\ndifferenza media è negativa, il che suggerisce il contrario.","code":""},{"path":"inferenza-sulle-medie.html","id":"conclusioni-9","chapter":"Capitolo 22 Inferenza sulle medie","heading":"Conclusioni","text":"Il test \\(t\\) di Student nelle sue varianti rappresenta senza dubbio lo\nstrumento statistico di stampo frequentista più ampiamente usato nel\nmondo della ricerca. Abbiamo visto che è basato su assunzioni\nragionevoli, molte applicazioni pratiche, e quindi potremmo\nconcludere che sia uno strumento utile. Tuttavia, le cose non sono così\nsemplici – non lo sono mai. questo capitolo abbiamo visto come il\ntest \\(t\\) di Student viene calcolato, come si giunge ad una decisione\nsulla base della statistica test e del livello di significatività,\neccetera. Tali considerazioni, però, sono considerazioni di tipo\nstatistico, ovvero non riguardano le pratiche del mondo reale, ma\ndescrivono solo le proprietà di alcuni teoremi che fanno parte della\nteoria della probabilità. Il test \\(t\\) di Student, però, non è solo una\nprocedura astratta, che va valutata per la sua eleganza concettuale, ma\nè invece una procedura che viene usata nella pratica concreta\ndell’attività di ricerca per rispondere domande che hanno una grande\nrilevanza pratica. Per esempio: la psicoterapia è grado di ridurre lo\nstato di ansia e depressione? Oppure: l’idrossiclorochina contrasta \nmaniera efficace il Covid-19?Qualcuno, ingenuamente, potrebbe pensare che il mondo della ricerca sia\nuna torre d’avorio ’interno della quale l’attività dei ricercatori è\nmotivata, primo luogo, e quasi soltanto, dal desiderio di fare\navanzare le nostre conoscenze. Non è così. La sociologia della scienza\nci fornisce un’immagina ben diversa di come stanno le cose. Le\nmotivazioni dei ricercatori sono ben più prosaiche: l’avanzamento \ncarriera, il potere, il prestigio, il denaro; tutto ciò descrive molto\nmeglio le motivazioni dei ricercatori del “desiderio di fare avanzare le\nnostre conoscenze.” Ma cosa c’entra il test \\(t\\) di Student tutto\nquesto? È facile capire che, se lo stipendio dei ricercatori dipende\ndalle loro pubblicazioni, e se si possono pubblicare solo risultati\nstatisticamente significativi, allora ricercatori faranno tutto quello\nche è loro potere per ottenere risultati statisticamente\nsignificativi. Qui non faccio riferimento al problema della frode nel\nmondo scientifico, ma al fatto che è inevitabile che, dopo una lunga e\nonerosa fase di progettazione dello studio e di raccolta dati, \nricercatori eseguano il test \\(t\\) di Student più di una volta, per\nconfrontare tra loro più di due condizioni e per valutare se da qualche\nparte nei loro dati emerge un risultato statisticamente significativo.\nNella pratica corrente, però, la consuetudine è quella di non\nriportare il fatto che il test sia stato eseguito più volte, quando\nesso non produce un risultato statisticamente significativo dove avrebbe\ndovuto, base alle ipotesi iniziali dei ricercatori. Ma, se questo è\nquello che fanno ricercatori nel mondo reale, dobbiamo chiederci: cosa\nsuccede tali circostanze alla probabilità di errore di tipo? Non\noccorre essere degli statistici per renderci conto che, così facendo, la\nprobabilità di errore di tipo non può rimanere al livello nominale\n\\(\\alpha\\): nella pratica concreta, dunque, la probabilità di falsi\npositivi è ben più alta della famosa soglia del 5%.Per concludere, ricordiamoci che la giustificazione ultima\ndell’approccio NHST (di cui il test \\(t\\) di Student è la procedura più\nnota) è proprio quella di mantenere sotto controllo la probabilità di\nerrore di tipo. Ma, alla luce di quanto abbiamo detto sopra, e\nconsiderando soprattutto le le considerazioni svolte da\nGelman & Carlin (2014) che esamineremo nel prossimo capitolo, la domanda\n(retorica) che dovrebbe venirci mente è: l’approccio frequentista\nriesce mantenere la sua promessa?","code":""},{"path":"critiche-e-difese.html","id":"critiche-e-difese","chapter":"Capitolo 23 Critiche e difese","heading":"Capitolo 23 Critiche e difese","text":"Nell’epoca della crisi della riproducibilità dei risultati della ricerca\n(Baker, 2016) la pratica del test dell’ipotesi nulla e\ndegli intervalli di confidenza frequentisti sono stati individuati come\nuna delle cause della crisi, spingendo molti ricercatori cercare\nun’alternativa altrove.","code":""},{"path":"critiche-e-difese.html","id":"limiti-dellinferenza-frequentista","chapter":"Capitolo 23 Critiche e difese","heading":"23.1 Limiti dell’inferenza frequentista","text":"’approccio frequentista sono state rivolte le seguenti critiche.È un approccio ad-hoc che non è dotato del carattere cogente della\nlogica deduttiva. Il concetto di “dati più estremi di” non risulta\nben definito. Il valore-\\(p\\) dipende dalla specifica ipotesi nulla\nscelta dallo sperimentatore.È un approccio ad-hoc che non è dotato del carattere cogente della\nlogica deduttiva. Il concetto di “dati più estremi di” non risulta\nben definito. Il valore-\\(p\\) dipende dalla specifica ipotesi nulla\nscelta dallo sperimentatore.Gli esperimenti devono essere completamente specificati anticipo\n– una pratica estremamente onerosa e molto di rado seguita\nnell’effettiva pratica della ricerca scientifica.Gli esperimenti devono essere completamente specificati anticipo\n– una pratica estremamente onerosa e molto di rado seguita\nnell’effettiva pratica della ricerca scientifica.Il valore-\\(p\\) e il livello di significatività sono notoriamente\nsoggetti grandi errori di interpretazione. Gli esperti sanno che\nun livello di significatività di \\(0.05\\) significa che la probabilità\ndi un errore di tipo è del 5%. Cioè, se l’ipotesi nulla è vera, il\n5% delle volte verrà rifiutata per effetto del caso soltanto. La\nmaggior parte di coloro che usano la logica del test dell’ipotesi\nnulla invece pensa erroneamente che un valore-\\(p\\) di \\(0.05\\)\nsignifichi che la probabilità che l’ipotesi nulla sia vera è il 5%.\nSi potrebbe sostenere che questa non è una critica ’inferenza\nfrequentista, ma piuttosto una critica ad una forma diffusa di\nignoranza. Tuttavia, sembra legittimo mettere dubbio l’utilità di\nuno strumento cui risultati vengono continuamente fraintesi dalla\nmaggior parte di coloro che lo usano.Il valore-\\(p\\) e il livello di significatività sono notoriamente\nsoggetti grandi errori di interpretazione. Gli esperti sanno che\nun livello di significatività di \\(0.05\\) significa che la probabilità\ndi un errore di tipo è del 5%. Cioè, se l’ipotesi nulla è vera, il\n5% delle volte verrà rifiutata per effetto del caso soltanto. La\nmaggior parte di coloro che usano la logica del test dell’ipotesi\nnulla invece pensa erroneamente che un valore-\\(p\\) di \\(0.05\\)\nsignifichi che la probabilità che l’ipotesi nulla sia vera è il 5%.\nSi potrebbe sostenere che questa non è una critica ’inferenza\nfrequentista, ma piuttosto una critica ad una forma diffusa di\nignoranza. Tuttavia, sembra legittimo mettere dubbio l’utilità di\nuno strumento cui risultati vengono continuamente fraintesi dalla\nmaggior parte di coloro che lo usano.difesa dell’approccio frequentista sono stati presentati seguenti\nargomenti.Fornisce uno strumento oggettivo per prendere delle decisioni: tutti\ncoloro che lo usano sono d’accordo sul significato del valore-\\(p\\) e\nconcordano sul fatto che esso sia o meno sufficiente per rifiutare\nl’ipotesi nulla.Fornisce uno strumento oggettivo per prendere delle decisioni: tutti\ncoloro che lo usano sono d’accordo sul significato del valore-\\(p\\) e\nconcordano sul fatto che esso sia o meno sufficiente per rifiutare\nl’ipotesi nulla.test di ipotesi che seguono l’approccio frequentista vengono\napplicati nell’analisi statistica delle indagini scientifiche,\nvalutando la forza dell’evidenza fornita dai dati rispetto ad\nun’ipotesi nulla. L’interpretazione dei risultati è lasciata\n’utilizzatore dei test statistici. Ricercatori diversi possono\nscegliere diversi livelli per la probabilità di errore di tipo che\ndetermina la significatività statistica. L’approccio frequentista\nnon pretende di fornire un metodo per scegliere il livello di\nsignificatività; piuttosto descrive esplicitamente il trade-\ntra errori di tipo e di II tipo.test di ipotesi che seguono l’approccio frequentista vengono\napplicati nell’analisi statistica delle indagini scientifiche,\nvalutando la forza dell’evidenza fornita dai dati rispetto ad\nun’ipotesi nulla. L’interpretazione dei risultati è lasciata\n’utilizzatore dei test statistici. Ricercatori diversi possono\nscegliere diversi livelli per la probabilità di errore di tipo che\ndetermina la significatività statistica. L’approccio frequentista\nnon pretende di fornire un metodo per scegliere il livello di\nsignificatività; piuttosto descrive esplicitamente il trade-\ntra errori di tipo e di II tipo.La progettazione degli esperimenti richiede un’attenta descrizione\ndi tutte le fasi dell’esperimento e di tutte le fasi dell’analisi\ndei dati, prima che dati vengano raccolti. Questa pratica\ncontribuisce ridurre bias interpretativi da parte del\nricercatore.La progettazione degli esperimenti richiede un’attenta descrizione\ndi tutte le fasi dell’esperimento e di tutte le fasi dell’analisi\ndei dati, prima che dati vengano raccolti. Questa pratica\ncontribuisce ridurre bias interpretativi da parte del\nricercatore.L’approccio frequentista è stato usato per oltre \\(100\\) anni un\nperiodo storico che ha testimoniato progressi scientifici enormi.\nAnche se frequentisti non possono associare una probabilità\n’ipotesi che la statistica frequentista sia utile, la storia\nrecente forse dovrebbe costringere bayesiani ad assegnare una\nprobabilità priori alta ’ipotesi che metodi frequentisti\nfunzionano.L’approccio frequentista è stato usato per oltre \\(100\\) anni un\nperiodo storico che ha testimoniato progressi scientifici enormi.\nAnche se frequentisti non possono associare una probabilità\n’ipotesi che la statistica frequentista sia utile, la storia\nrecente forse dovrebbe costringere bayesiani ad assegnare una\nprobabilità priori alta ’ipotesi che metodi frequentisti\nfunzionano.Recentemente, l’American Psychological Association ha proposto nuovi\nstandard per riportare risultati dei test dell’ipotesi nulla,\nraccomandando che vengano indicati la dimensione dell’effetto, gli\nintervalli di confidenza (CI) e la stima della potenza del test\n(American Psychological Association, 2010). Queste raccomandazioni non sono però necessariamente\nsufficienti per rispondere alle critiche che sono state rivolte\n’approccio frequentista.Recentemente, l’American Psychological Association ha proposto nuovi\nstandard per riportare risultati dei test dell’ipotesi nulla,\nraccomandando che vengano indicati la dimensione dell’effetto, gli\nintervalli di confidenza (CI) e la stima della potenza del test\n(American Psychological Association, 2010). Queste raccomandazioni non sono però necessariamente\nsufficienti per rispondere alle critiche che sono state rivolte\n’approccio frequentista.","code":""},{"path":"critiche-e-difese.html","id":"attenti-al-valore-p","chapter":"Capitolo 23 Critiche e difese","heading":"23.2 Attenti al valore-\\(p\\)!","text":"Consideriamo il seguente problema.Eseguiamo un \\(t\\)-test per due campioni indipendenti e sottoponiamo \nverifica l’ipotesi nulla dell’eguaglianza delle due medie. Sia\n\\(\\alpha = 0.05\\). Otteniamo un valore-\\(p\\) di \\(0.04\\). Qual è la\nprobabilità che due campioni siano tratti da distribuzioni con la\nstessa media?\\(\\) \\(19/20; \\quad\\) (b) \\(1/19; \\quad\\) (c) \\(1/20; \\quad\\) (d)\n\\(95/100; \\quad\\) (e) sconosciuta.La risposta corretta è: (e) sconosciuta. La statistica frequentista\ndefinisce le probabilità dei dati condizionatamente alle ipotesi\n(assunte come vere). Non consente di stabilire la probabilità di\nun’ipotesi.","code":""},{"path":"critiche-e-difese.html","id":"conclusioni","chapter":"Capitolo 23 Critiche e difese","heading":"Conclusioni","text":"anni recenti è stato sollevato il problema della non replicabilità\ndei risultati della ricerca, inclusa la ricerca psicologica. Questo tema\nè rilevante questo contesto considerato che, tra gli aspetti del\nmetodo scientifico che sono stati evidenziati quali potenziali\nresponsabili di questa “crisi della ricerca scientifica,” il concetto di\nvalore-p e la pratica della verifica della significatività\ndell’ipotesi nulla (NHST, Null Hypothesis Significance Testing) figurano\nmodo prominente. Una breve introduzione questo problema è fornita\nda Gelman (2016), il quale ritiene che la pratica NHST sia\nintrinsecamente problematica, ovvero sia problematico il tentativo del\nricercatore di cercare di rigettare un’ipotesi “fantoccio” (straw-man)\nche è certamente falsa priori o, almeno, poco interessante dal punto\ndi vista scientifico, favore di un’ipotesi alternativa favorita dal\nricercatore. generale, sembra più sensato dire che la differenza tra\ndue condizioni sia molto piccola, piuttosto di dire che sia esattamente\nuguale zero.Il messaggio che viene solitamente trasmesso dai libri di testo di\nstatistica è che la NHST sia una forma di “alchimia,” “convert\nrandomness sort certainty, associated words \n‘confidence’ ‘significance’” (Gelman, 2016, p. 12). Viene raccolto\nun campione di dati, viene eseguita l’analisi statistica e l’inferenza\nstatistica che ne risulta viene riassunta una conclusione formulata\nnei termini di un valore-p e di un intervallo di confidenza che\nesclude lo zero, quali trasmettono la falsa certezza che il\nricercatore abbia compreso le proprietà del fenomeno esaminato. \nrealtà, il problema della NHST è che essa produce risultati\n“statisticamente significativi” un grande numero di casi nei quali le\ncaratteristiche del fenomeno esame non giustificano la conclusione \ncui giunge il ricercatore; ciò conduce, come ovvia conseguenza, alla non\nreplicabilità dei risultati delle ricerche.La comunità degli statistici ha messo evidenza come problemi della\nnon replicabilità dei risultati delle ricerche sono soprattutto evidenti\nquando le conclusioni (erronee) cui giunge il ricercatore derivano,\ntramite l’uso della metodologia NHST, dall’osservazione di (1) piccoli\ncampioni nei quali (2) la dimensione dell’effetto è piccola. Questo tipo\ndi situazioni rendono estremamente problematica l’applicazione della\nNHST (anche se non sono le uniche). E, sfortunatamente, tali due\ncondizioni descrivono le caratteristiche di molte (gran parte) delle\nrecenti ricerche psicologia.Una famosa definizione della statistica è che essa sia un metodo che ci\nconsente di prendere delle decisioni razionali una situazione di\nincertezza. Gli statistici suggeriscono ai ricercatori non soltanto di\ndiventare buoni conoscitori delle tecniche statistiche, ma anche di\nimparare convivere con l’incertezza, nonostante la sofisticazione\nsempre crescente delle tecniche statistiche disponibili. Convivere con\nl’incertezza significa evitare di pensare che l’avere ottenuto un\nvalore-\\(p\\) “statisticamente significativo” significhi avere risolto un\nproblema scientifico. Alla luce di quanto abbiamo detto sopra, dovrebbe\nrisultare evidente che le cose non stanno così.Come possiamo dunque avere alcuna fiducia ciò che pensiamo di avere\nimparato dai dati? Una strategia possibile è la replicazione e la\nconvalida esterna, ma questa strategia è spesso difficilmente\nperseguibile nel mondo reale della ricerca psicologia e nelle scienze\nsociali per grandi oneri che comporta. Il problema di quali siano gli\nstrumenti metodologici e metodi statistici più appropriati per\nindagare fenomeni psicologici, senza essere ingannati, resta dunque un\nproblema aperto.","code":""},{"path":"introduzione-4.html","id":"introduzione-4","chapter":"Introduzione","heading":"Introduzione","text":"L’inferenza Bayesiana è un approccio ’inferenza statistica cui le probabilità non sono interpretate come frequenze, proporzioni o concetti analoghi, ma piuttosto come livelli di fiducia nel verificarsi di un dato evento. Come suggerito dal nome stesso, la statistica bayesiana è un approccio ’analisi dei dati e alla stima dei parametri basato sul teorema di Bayes.","code":""},{"path":"modellistica-bayesiana.html","id":"modellistica-bayesiana","chapter":"Capitolo 24 Modellistica Bayesiana","heading":"Capitolo 24 Modellistica Bayesiana","text":"","code":""},{"path":"modellistica-bayesiana.html","id":"modelli-statistici","chapter":"Capitolo 24 Modellistica Bayesiana","heading":"24.1 Modelli statistici","text":"dati non interpretati non sono informativi. Non possiamo generalizzare, trarre inferenze o tentare di fare previsioni meno di non fare ipotesi (per quanto minime) sui dati disposizione: cosa rappresentano, come sono stati generati, quali aspetti sono associati quali altri aspetti, ecc. modelli statistici rappresentano un modo per rendere esplicite le nostre assunzioni sui dati.Nel suo senso naturale più comune, un “modello” è un modello di qualcosa. Intende rappresentare qualcosa d’altro una forma semplificata, astratta e più maneggevole. Le caratteristiche di un modello dipendono dallo scopo per il quale il modello verrà usato. generale, un buon modello è grado di riprodurre alcuni aspetti della realtà mentre ignora, nel contempo, tutte quelle caratteristiche irrilevanti che potrebbero altrimenti offuscare la nostra comprensione di ciò che il modello vuole rappresentare.Lo scopo più comune di un modello statistico è quello di imparare qualcosa sulla realtà traendo inferenze dai dati - possibilmente con l’ulteriore obiettivo di consentirci di prendere una decisione razionale - o di fare previsioni su eventi sconosciuti (futuri, presenti o passati).Un modello statistico M è un modello di un processo aleatorio R che potrebbe avere generato dati che abbiamo osservato. Il modello M descrive un modo formale le nostre ipotesi sul processo aleatorio R.Spesso vogliamo spiegare una parte dei nostri dati, ovvero le variabili dipendenti \\(D_{DV}\\), nei termini di altre osservazioni, ovvero le variabili indipendenti \\(D_{IV}\\). Ma è anche possibile che non ci siano delle variabili indipendenti ma solo una o più variabili dipendenti \\(D_{DV}\\).Un modello M per dati D necessariamente include una fuzione di verosimiglianza per \\(D_{DV}\\). La funzione di verosimiglianza descrive la plausibilità delle osservazioni \\(D_{DV}\\) alla luce delle corrispondenti osservazioni \\(D_{IV}\\). Molto spesso, la funzione di verosimiglianza ha anche dei parametri liberi, rappresentati da un vettore \\(\\theta\\).La funzione di verosimiglianza del modello M per dati D con parametri \\(\\theta\\) si può scrivere come:\\[\nP_M(D_{DV} \\mid D_{IV}, \\theta).\n\\]\nOltre alla verosimiglianza, modelli Bayesiani includono una componente aggiuntiva, ovvero una distribuzione priori sui valori dei parametri, comunemente scritta come:\\[\nP_M(\\theta).\n\\]\nLa distribuzione priori sui parametri rappresenta qualsiasi ipotesi priori motivata e giustificabile sui valori che, alla luce delle nostre conoscenze presenti, possiamo attribuire ai parametri.Esempio 24.1  Supponiamo che il nostro campione di dati sia costituito dagli esiti di una sequenza di lanci di una moneta avente probabilità di successo (testa) \\(\\theta \\[0, 1]\\). Abbiamo osservato k successi N prove. Dunque, conosciamo N e k ma non conosciamo \\(\\theta\\). Il parametro \\(\\theta\\) è l’unico parametro di questo modello statistico. La variabile dipendente è k. questo caso, possiamo pensare N come alla variabile indipendente.La funzione di verosimiglianza per questo modello statistico è la distribuzione Binomiale:\\[\nP_M(k \\mid \\theta, N) = \\text{Binomial}(k, N, \\theta) = {N \\choose k} \\theta^k (1 - \\theta)^{N-k}.\n\\]Per ragioni che diventeranno chiare seguito, è possibile usare una distribuzione Beta per la distribuzione priori di \\(\\theta\\). Ad esempio, potremmo definire parametri della distribuzione Beta modo tale che la distribuzione risultante sia piatta, così da generare una “distribuzione priori non informativa”:","code":""},{"path":"modellistica-bayesiana.html","id":"notazione-1","chapter":"Capitolo 24 Modellistica Bayesiana","heading":"24.2 Notazione","text":"Per rappresentare un modo conciso modelli statistici viene usata una notazione particolare, la quale è molto intuitiva se pensiamo al processo del campionamento. Ad esempio, invece di scrivere\\[\nP_M(\\theta) = \\text{Beta}(\\theta, 1, 1),\n\\]scriviamo:\\[\n\\theta \\sim \\text{Beta}(1, 1).\n\\]\nIl simbolo “\\(\\sim\\)” viene spesso letto “è distribuito come.” Possiamo anche pensare che significhi che \\(\\theta\\) costituisce un campione estratto dalla distribuzione Beta(1, 1). Allo stesso modo, per l’esempio precedente la verosimiglianza può essere scritta nel modo seguente:\\[\nk \\sim \\text{Binomial}(k, N, \\theta).\n\\]","code":""},{"path":"modellistica-bayesiana.html","id":"parametri-e-distribuzioni-a-priori","chapter":"Capitolo 24 Modellistica Bayesiana","heading":"24.3 Parametri e distribuzioni a priori","text":"Un modello Bayesiano è costituito da una funzione di verosimiglianza e da una distribuzione priori dei parametri di interesse:\\[ \n\\begin{aligned}\n  & \\text{Verosimiglianza: } & P_M(D \\mid \\theta) \\\\ \n  & \\text{Distribuzione priori: } & P_M(\\theta) \n\\end{aligned}\n\\]questa sezione, esamineremo (nuovamente) il significato di “parametro,” esamineremo il significato di “distribuzione priori” \\(P_M(\\theta)\\) e ci porremo l’obiettivo di usare un modello statistico per fare previsioni partire dai dati.L’esempio che considereremo farà uso del modello Binomiale. Come esempio concreto di dati, consideriamo il caso di \\(N = 24\\) lanci di una moneta e di \\(k = 7\\) successi (esito testa).","code":""},{"path":"modellistica-bayesiana.html","id":"cosè-un-parametro-del-modello","chapter":"Capitolo 24 Modellistica Bayesiana","heading":"24.3.1 Cos’è un parametro del modello?","text":"Un parametro del modello è un valore da cui dipende la verosimiglianza dei dati. Ad esempio, il singolo parametro \\(\\theta\\) nel modello Binomiale determina la forma della funzione di verosimiglianza Binomiale. Ricordiamo che la funzione di verosimiglianza per il modello Binomiale è:\\[ \nP_M(k \\mid \\theta, N) = \\text{Binomial}(k, N, \\theta) = \\binom{N}{k}\\theta^k(1-\\theta)^{N-k}. \n\\]\nPer comprendere il ruolo del parametro \\(\\theta\\), possiamo generare un grafico della verosimiglianza dei dati (qui: \\(k = 7\\) e \\(N = 24\\)) come funzione di \\(\\theta\\). La figura mostra, per ogni possibile valore di \\(\\theta \\[0; 1]\\) (sull’asse orizzontale), la verosimiglianza dei dati (sull’asse verticale). Dalla figura notiamo che la verosimiglianza dei dati dipende dal valore del parametro \\(\\theta\\): dati risultano più o meno verosimili seconda dei valori di \\(\\theta\\).\nFigura 24.1: Funzione di verosimiglianza per il modello Binomiale con \\(k=7\\) e \\(N=24\\).\n","code":""},{"path":"modellistica-bayesiana.html","id":"distribuzione-a-priori-sui-parametri","chapter":"Capitolo 24 Modellistica Bayesiana","heading":"24.3.2 Distribuzione a priori sui parametri","text":"Quando adottiamo un approccio Bayesiano ’analisi dei dati, la distribuzione priori sui valori dei parametri \\(P_M (\\theta)\\) è parte integrante del modello statistico. Ciò implica che due modelli (Bayesiani) possono condividere la stessa funzione di verosimiglianza, ma tuttavia devono essere considerati come modelli diversi, se specificano diverse distribuzioni priori. Ciò significa che, quando diciamo “Modello binomiale,” intendiamo realtà un’intera classe di modelli, ovvero tutti possibili modelli che hanno la stessa verosimiglianza ma diverse distribuzioni priori su \\(\\theta\\).Nell’analisi dei dati Bayesiana, la distribuzione priori \\(P_M(\\theta)\\) codifica le credenze del ricercatore proposito dei valori dei parametri, prima di avere osservato dati. Idealmente, le credenze priori che supportano la specificazione di una distribuzione priori dovrebbero essere supportate da una qualche motivazione, come ad esempio risultati di ricerche precedenti, o altre motivazioni giustificabili. Tuttavia, le credenze soggettive sono solo uno dei possibili modi per giustificare le distribuzioni priori sui parametri.Possiamo distinguere tre tipi principali di motivazioni per le distribuzioni priori \\(P_M (\\theta)\\).Le distribuzioni priori soggettive catturano le credenze del ricercatore nel senso sopra descritto.Le distribuzioni priori con finalità pratiche sono distribuzioni priori che vengono utilizzate pragmaticamente causa di una loro utilità specifica, ad esempio, perché semplificano un calcolo matematico o una simulazione al computer, o perché aiutano nel ragionamento statistico, come ad esempio quando vengono formulate gli skeptical priors che hanno l’obiettivo di lavorare senso contrario ad una particolare conclusione.Le distribuzioni priori oggettive sono distribuzioni priori che, come alcuni sostengono, dovrebbero essere adottate per una data funzione di verosimiglianza per evitare conseguenze concettualmente paradossali. Non tratteremo le distribuzioni priori oggettive questo corso introduttivo e le menzioniamo qui solo per completezza.Oltre alla motivazione che giustifica una distribuzione priori, possiamo distinguere tra distribuzioni priori base quanto fortemente impegnano il ricercatore ritenere come plausibile un particolare intervallo di valori dei parametri. Il caso più estremo è quello che rivela una totale assenza di conoscenze priori, il che conduce alle distribuzioni priori non informative, ovvero quelle che assegnano lo stesso livello di credibilità tutti valori dei parametri. Le distribuzioni priori informative, d’altra parte, possono essere debolmente informative o fortemente informative, seconda della forza della credenza che esprimono. Il caso più estremo di credenza priori è quello che riassume il punto di vista del ricercatore nei termini di un unico valore del parametro, il che assegna tutta la probabilità (massa o densità) su di un singolo valore di un parametro. Poiché questa non è più una distribuzione di probabilità, sebbene ne soddisfi la definizione, questo caso si parla di una distribuzione priori degenerata.La figura seguente mostra esempi di distribuzioni priori non informative, debolmente o fortemente informative, così come una distribuzione priori espressa nei termini di un valore puntuale per il modello Binomiale. Le distribuzione priori illustrate di seguito sono le seguenti:non informativa : \\(\\theta_c \\sim \\text{Beta}(1,1)\\);debolmente informativa : \\(\\theta_c \\sim \\text{Beta}(5,2)\\);fortemente informativa : \\(\\theta_c \\sim \\text{Beta}(50,20)\\);valore puntuale : \\(\\theta_c \\sim \\text{Beta}(\\alpha, \\beta)\\) con \\(\\alpha, \\beta \\rightarrow \\infty\\) e \\(\\frac{\\alpha}{\\beta} = \\frac{5}{2}\\).\nFigura 24.2: Esempi di distribuzioni priori per il parametro \\(\\theta_c\\) nel Modello Binomiale.\nLa selezione delle distribuzioni priori è stata spesso vista come una delle\nscelte più importanti che un ricercatore fa quando implementa un modello\nBayesiano quanto può avere un impatto sostanziale sui risultati\nfinali.La soggettività delle distribuzioni priori è evidenziata dai critici\ncome un potenziale svantaggio dei metodi Bayesiani. questa critica,\nSchoot et al. (2021) rispondono dicendo che, al di là\ndella scelta delle distribuzioni priori, ci sono molti elementi del processo di inferenza statistica che sono soggettivi, ovvero la scelta del modello statistico e le ipotesi sulla distribuzione degli errori. secondo luogo, Schoot et al. (2021) notano come le distribuzioni priori svolgono due ruoli statistici importanti: quello della “regolarizzazione della stima,” ovvero, quel processo che porta ad indebolire l’influenza\nindebita di osservazioni estreme, e quello del miglioramento dell’efficienza\ndella stima, ovvero, la facilitazione dei processi di calcolo numerico\ndi stima della distribuzione posteriori.","code":""},{"path":"modellistica-bayesiana.html","id":"procedura-bayesiana-di-stima-dei-parametri","chapter":"Capitolo 24 Modellistica Bayesiana","heading":"24.4 Procedura Bayesiana di stima dei parametri","text":"","code":""},{"path":"modellistica-bayesiana.html","id":"finalità","chapter":"Capitolo 24 Modellistica Bayesiana","heading":"24.4.1 Finalità","text":"Sulla base di un modello statistico \\(M\\) di parametri \\(\\theta\\), l’analisi statistica Bayesiana si pone il problema di trovare valori più plausibili di \\(\\theta\\) alla luce dei dati \\(D\\).\nIl teorema di Bayes viene usato per aggiornare le credenze priori su \\(\\theta\\) (ovvero, la distribuzione priori) modo tale da produrre le nuove credenze posteriori \\(P_M(\\theta \\mid D)\\) che combinano le informazioni fornite dai dati \\(D\\) con le credenze precedenti. La distribuzione posteriori riflette dunque l’aggiornamento delle conoscenze del ricercatore alla luce dei dati.","code":""},{"path":"modellistica-bayesiana.html","id":"metodi","chapter":"Capitolo 24 Modellistica Bayesiana","heading":"24.4.2 Metodi","text":"Ci sono due diversi metodi per calcolare la distribuzione posteriori\n\\(P_M(\\theta \\mid D)\\):una precisa derivazione matematica formulata nei termini della distribuzione priori coniugata alla distribuzione posteriori; tale procedura però ha un’applicabilità molto limitata;un metodo approssimato, molto facile da utilizzare pratica, che dipende da metodi Monte Carlo basati su Catena di Markov (MCMC).questo capitolo introdurremo la terminologia e le idee di base che stanno alla base della stima delle funzione posteriori. seguito ci porremo il problema di sviluppare un’intuizione dei metodi MCMC.","code":""},{"path":"modellistica-bayesiana.html","id":"terminologia-2","chapter":"Capitolo 24 Modellistica Bayesiana","heading":"24.4.3 Terminologia","text":"Consideriamo un modello Bayesiano \\(M\\) avente una verosimiglianza \\(P(D \\mid \\theta)\\) sui dati osservati \\(D\\) e una distribuzione priori \\(P(\\theta)\\) sui parametri. Applichiamo il teorema di Bayes per produrre la distribuzione posteriori:\\[\nP(\\theta \\mid D) = \\frac{P(D \\mid \\theta) \\ P(\\theta)}{P(D)}.\n\\]L’equazione precedente è costituita dalle seguenti componenti:la distribuzione posteriori \\(P(\\theta \\mid D)\\) - la nuova credenza posteriori relativamente alla plausibilità di ciascun valore \\(\\theta\\) alla luce di \\(D\\);la funzione di verosimiglianza \\(P(D \\mid \\theta)\\) - quanto sono verosimili dati \\(D\\) per ciascun valore fisso \\(\\theta\\);la distribuzione priori \\(P(\\theta)\\) - la credenza iniziale riguardo alla plausibilità di ciascun valore \\(\\theta\\);la verosimiglianza marginale \\(P(D) = \\int P(D \\mid \\theta) \\ P(\\theta) \\ \\text{d}\\theta\\) - quanto sono verosimili dati \\(D\\) alla luce della nostra credenza priori relativamente \\(\\theta\\).La formula precedente applica il teorema di Bayes per produrre la distribuzione posteriori dei parametri sconosciuti \\(\\theta\\). Tuttavia, molto spesso la probabilità posteriori è scritta nel modo seguente:\\[\n\\underbrace{P(\\theta \\, | \\, D)}_{posterior} \\propto \\underbrace{P(\\theta)}_{prior} \\ \\underbrace{P(D \\, | \\, \\theta)}_{likelihood},\n\\]dove il segno di proporzionalità indica che le probabilità sinistra del simbolo \\(\\propto\\) sono definite dai termini destra di \\(\\propto\\) meno di una costante di normalizzazione. Se \\(F \\colon X \\rightarrow \\mathbb{R}^+\\) è una funzione positiva non normalizzata di probabilità, \\(P(x) \\propto F(x)\\) è equivalente \\(P(x) = \\frac{F(x)}{\\sum_{x' \\X} F(x')}\\).","code":""},{"path":"modellistica-bayesiana.html","id":"leffetto-della-distribuzione-a-priori-sulla-distribuzione-a-posteriori","chapter":"Capitolo 24 Modellistica Bayesiana","heading":"24.5 L’effetto della distribuzione a priori sulla distribuzione a posteriori","text":"La notazione \\(P(\\theta \\mid D) \\propto P(\\theta) \\ P(D \\mid \\theta)\\) rende particolarmente chiaro che la distribuzione posteriori è un “miscuglio” della distribuzione priori e della verosimiglianza. Prima di preoccuparci di come calcolare concretamente la distribuzione posteriori, cerchiamo di capire cosa significa “mescolare” la distribuzione priori e la verosimiglianza.Consideriamo una serie di lanci di una moneta con probabilità di successo (testa) sconosciuta \\(\\theta\\). Supponiamo di osservare \\(k\\) successi \\(N\\) prove. Per descrivere questo esperimento casuale usiamo il modello Binomiale, utilizzando una distribuzione priori espressa mediante la distribuzione Beta. Ciò produce il seguente modello statistico:\\[ \n\\begin{aligned}\nk & \\sim \\text{Binomial}(N, \\theta) \\\\ \n\\theta & \\sim \\text{Beta}(, b)\n\\end{aligned}\n\\]Per studiare l’impatto della distribuzione priori sulla funzione di verosimiglianza confronteremo due campioni di dati. Nel primo campione, \\(N = 24\\) e \\(k = 7\\); nel secondo campione, \\(k = 109\\) e \\(N = 311\\).\nPer entrambi campioni, la funzione di verosimiglianza dei dati è fornita dalla figura seguente.\nFigura 24.3: Verosimiglianza per due campioni di dati binomiali. Per il primo campione abbiamo \\(k = 7\\) e \\(N = 24\\); per il secondo campione \\(k = 109\\) e \\(N = 311\\).\nLa cosa più importante da notare è che, maggiore è la quantità di dati (\\(k = 109\\) e \\(N = 311\\)), più piccolo diventa l’intervallo di valori dei parametri che rendono plausibili dati che sono stati osservati. Intuitivamente, questo significa che più dati abbiamo, più piccolo sarà l’intervallo posteriori dei valori plausibili dei parametri, parità di tutto il resto.Consideriamo ora le quattro distribuzioni priori che abbiamo descrito precedenza:\nFigura 24.4: Esempi di distribuzioni priori per il parametro \\(\\theta_c\\) nel Modello Binomiale.\nCombiniamo le quattro distribuzioni priori con la verosimiglianza dei due campioni di dati. Così facendo notiamo che la distribuzione posteriori è effettivamente un “miscuglio” della distribuzione priori e della verosimiglianza.\nFigura 24.5: Distribuzioni posteriori per il parametro \\(\\theta\\) calcolate mediante diverse distribuzioni priori per due campioni di dati.\nCiò che è importante notare è che, se il campione è grande, una distribuzioni priori debolmente informativa ha uno scarso effetto sulla distribuzione posteriori. Invece, se il campione è piccolo, anche una distribuzioni priori debolmente informativa ha un grande effetto sulla distribuzione posteriori, confronto ad una distribuzione priori non informativa.","code":""},{"path":"modellistica-bayesiana.html","id":"le-aspettative-dei-pazienti-con-disturbo-depressivo-maggiore","chapter":"Capitolo 24 Modellistica Bayesiana","heading":"24.6 Le aspettative dei pazienti con disturbo depressivo maggiore","text":"Esaminiamo ora un altro esempio che ha lo scopo di chiarite le relazioni\nche legano tra loro le tre distribuzioni che abbiamo introdotto sopra:\nla distribuzione priori, la verosimiglianza e la distribuzioni \nposteriori. Nell’esempio faremo riferimento alla ricerca di Zetsche et al. (2019).Zetsche et al. (2019) si sono chiesti se gli individui depressi manifestino delle aspettative accurate circa il loro umore futuro, oppure se tali aspettative siano distorte negativamente.\nEsamineremo qui 30 partecipanti dello studio di Zetsche et al. (2019)\nche hanno riportato la presenza di un episodio di depressione maggiore\natto. ’inizio della settimana di test, questi pazienti è stato\nchiesto di valutare l’umore che si aspettavano di esperire nei giorni\nseguenti della settimana. Mediante una app, partecipanti dovevano poi\nvalutare il proprio umore cinque momenti diversi di ciascuno dei\ncinque giorni successivi. Lo studio considera diverse emozioni, ma qui\nci concentriamo solo sulla tristezza.Sulla base dei dati forniti dagli autori, abbiamo calcolato la media dei\ngiudizi relativi al livello di tristezza raccolti da ciascun\npartecipante tramite la app. Tale media è stata poi sottratta\ndall’aspettativa del livello di tristezza fornita ’inizio della\nsettimana. Per semplificare l’analisi abbiamo considerato la discrepanza\ntra aspettative e realtà come un evento dicotomico: valori positivi di\ntale differenza indicano che le aspettative circa il livello di\ntristezza sono maggiori del livello di tristezza che seguito viene\neffettivamente esperito; ciò significa che le aspettative sono\nnegativamente distorte (evento codificato con “1”). Si può dire il\ncontrario (le aspettative sono positivamente distorte) se tale\ndifferenza assume valori negativi (evento codificato con “0”).Nel campione dei 30 partecipanti clinici esaminati da\nZetsche et al. (2019), 23 partecipanti manifestano delle aspettative\nnegativamente distorte e 7 partecipanti manifestano delle aspettative\npositivamente distorte. Nella seguente discussione, chiameremo \\(\\theta\\)\nla probabilità dell’evento “le aspettative del partecipante sono\ndistorte negativamente.” Il problema che ci poniamo è quello di ottenere\nla stima posteriori di \\(\\theta\\), avendo osservato 23 “successi” 30\nprove, ovvero \\(\\hat{\\theta}\\) = 23/30 = 0.77.Si noti un punto importante qui: un problema di scrivere semplicemente la stima di \\(\\theta\\) come 0.77 è che tale valore ignora l’incertezza della nostra stima. Infatti, il valore di 0.77 si può ottenere come 23/30, o come 230/300, o 2300/3000, o 23000/30000. L’incertezza della stima 0.77 è diversa ciascuno di questi casi e questo è molto importante quando si traggono conclusioni dai dati.Nell’approccio frequentista, l’unico strumento che abbiamo per caratterizzare la nostra incertezza relativa alla stima di \\(\\theta\\) è la distribuzione campionaria della stima di questo parametro nel caso di un ipotetico campionamento ripetuto; non è invece possibile fare riferimento ad un’incertezza relativa al vero valore del parametro stesso. Per una dimensione campionaria pari 30, la nostra incertezza deriva dalle caratteristiche della distribuzione campionaria e viene calcolata trovando la varianza campionaria – ovvero, \\(n \\cdot \\hat{\\theta} (1 - \\hat{\\theta}) = 30 \\cdot 0.77 (1 - 0.77) = 5.31\\) – e poi l’errore standard, \\(\\sigma / \\sqrt{n}\\) – qui 0.42. Per la stessa proporzione di successi pari 0.77, l’aumento della dimensione del campione rende questo errore standard sempre più piccolo. Questa maggiore precisione corrisponde alle proprietà della distribuzione campionaria di \\(\\hat{\\theta}\\), ma non quantifica l’incertezza relativa al vero valore di \\(\\theta\\).L’approccio Bayesiano procede modo diverso e ci fornisce invece l’opportunità di quantificare direttamente la nostra incertezza relativa al vero valore del parametro \\(\\theta\\), alla luce dei dati – non della distribuzione campionaria di \\(\\hat{\\theta}\\). Tale quantificazione dell’incertezza si trova costruendo la distribuzione posteriori di \\(\\theta\\) mediante il teorema di Bayes.Per costruire la distribuzione posteriori di \\(\\theta\\), questo esempio utilizzeremo l’approccio chiamato grid-based. Il metodo basato su griglia è un metodo di approsimazione numerica basato su una griglia di punti uniformemente spaziati (si veda\nil capitolo Stima della funzione posteriori). Anche se la maggior parte dei parametri è continua (ovvero, linea di principio ciascun parametro può assumere un numero infinito di valori), possiamo ottenere un’eccellente approssimazione della distribuzione posteriori considerando solo una griglia finita di valori dei parametri. un tale metodo, la densità di probabilità posteriori può dunque essere approssimata tramite le densità di probabilità cacolate ciascuna cella della griglia.Per calcolare la probabilità posteriori si procede come indicato di seguito.\n\nPer ciascuno specifico valore \\(\\theta'\\) (ovvero, per ciascun elemento della griglia) è necessario moltiplicare l’ordinata della distribuzione di probabilità priori corrispondenza di \\(\\theta'\\) per l’ordinata della funzione di verosimiglianza corrispondenza di \\(\\theta'\\). Tale procedura va ripetuta per ciascun elemento della griglia.\n\nC’è ovviamente bisogno di una griglia molto densa per ottenere buone approssimazioni.Il metodo basato su griglia è, primo luogo, un utile strumento didattico quanto rende trasparente la logica del processo dell’aggiornamento Bayesiano. Per ragioni che vedremo seguito, tale metodo non può essere usato per la stima di modelli complessi che includono un grande numero di parametri – ma non è questo il nostro scopo qui. Ma, al di là di questo limite del metodo basato su griglia, è importante sottolineare che, quale che sia il metodo che si usa per stimare la funzione posteriori, il significato della funzione posteriori non cambia ed è ben illustrato dall’esempio qui discusso.Iniziamo costruire la griglia di valori del parametro \\(\\theta\\). questo esempio considereremo 50 valori egualmente spaziati nell’intervallo [0, 1]: 0.000, 0.0204, …, 0.978, 1.000. Per ottenere valori griglia procediamo nel modo seguente:","code":"\nn_points <- 50\np_grid <- seq(from = 0, to = 1, length.out = n_points)\np_grid\n#>  [1] 0.00000000 0.02040816 0.04081633 0.06122449 0.08163265 0.10204082 0.12244898 0.14285714\n#>  [9] 0.16326531 0.18367347 0.20408163 0.22448980 0.24489796 0.26530612 0.28571429 0.30612245\n#> [17] 0.32653061 0.34693878 0.36734694 0.38775510 0.40816327 0.42857143 0.44897959 0.46938776\n#> [25] 0.48979592 0.51020408 0.53061224 0.55102041 0.57142857 0.59183673 0.61224490 0.63265306\n#> [33] 0.65306122 0.67346939 0.69387755 0.71428571 0.73469388 0.75510204 0.77551020 0.79591837\n#> [41] 0.81632653 0.83673469 0.85714286 0.87755102 0.89795918 0.91836735 0.93877551 0.95918367\n#> [49] 0.97959184 1.00000000"},{"path":"modellistica-bayesiana.html","id":"distribuzione-a-priori","chapter":"Capitolo 24 Modellistica Bayesiana","heading":"24.6.1 Distribuzione a priori","text":"Supponiamo che le nostre credenze priori sulla tendenza di un individuo clinicamente depresso manifestare delle aspettative distorte negativamente circa il suo umore futuro siano molto scarse. Assumiamo quindi per \\(\\theta\\) una distribuzione priori non informativa – ovvero, ipotizziamo che la distribuzione priori sia una distribuzione uniforme nell’intervallo [0, 1]. Dato che consideriamo soltanto \\(n = 50\\) valori possibili per il parametro \\(\\theta\\), creiamo un vettore di 50 elementi che conterrà valori della distribuzione priori scalando ciascun valore del vettore per \\(n\\) modo tale che la somma di tutti valori sia uguale 1.0 (questo modo viene definita una funzione di massa di probabilità):Verifichiamo:La distribuzione priori così costruita è rappresentata nella figura 24.6.\nFigura 24.6: Rappresentazione grafica della distribuzione priori per il parametro \\(\\theta\\), ovvero la probabilità di aspettative future distorte negativamente (Zetsche et al., 2019).\n","code":"\nprior1 <- dbeta(p_grid, 1, 1) / sum(dbeta(p_grid, 1, 1))\nprior1\n#>  [1] 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n#> [20] 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\n#> [39] 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02\nsum(prior1)\n#> [1] 1\np1 <- data.frame(p_grid, prior1) %>%\n  ggplot(aes(x=p_grid, xend=p_grid, y=0, yend=prior1)) +\n  geom_line()+\n  geom_segment(color = \"#8184FC\") +\n  ylim(0, 0.17) +\n  labs(\n    x = \"Parametro \\U03B8\",\n    y = \"Probabilità a priori\",\n    title = \"50 punti\"\n  )\np1"},{"path":"modellistica-bayesiana.html","id":"funzione-di-verosimiglianza","chapter":"Capitolo 24 Modellistica Bayesiana","heading":"24.6.2 Funzione di verosimiglianza","text":"Calcoliamo ora la funzione di verosimiglianza utilizzando 50 valori griglia per \\(\\theta\\) che abbiamo definito precedenza. Per ciascuno dei valori della griglia applichiamo la formula della probabilità binomiale, tendendo sempre costanti valori dei dati (ovvero 23 “successi” 30 prove).Considderiamo, ad esempio, il valore griglia \\(\\theta = 0.816\\). Per tale elemento della griglia l’ordinata della funzione di verosimiglianza è pari \\[\n\\begin{aligned}\n\\binom{30}{23}& \\cdot 0.816^{23} \\cdot (1 - 0.816)^{7} = 0.135.\\notag\n\\end{aligned}\n\\]Per fare un secondo esempio, consideriamo il valore griglia \\(\\theta = 0.837\\). Per tale elemento della griglia l’ordinata della funzione di verosimiglianza è uguale \\[\n\\begin{aligned}\n\\binom{30}{23}& \\cdot 0.837^{23} \\cdot (1 - 0.837)^{7} = 0.104.\\notag\n\\end{aligned}\n\\]Dobbiamo svolgere questo calcolo per tutti gli elementi della griglia. Usando R il risultato cercato si trova nel modo seguente:Il vettore likelihood è stato ottenuto passando alla funzione dbinom() un vettore di valori, ovvero gli elementi della griglia p_grid. La funzione dbinom(x, size, prob) richiede che vengano specificati tre parametri: il numero di “successi,” il numero di prove e la probabilità di successo. Dato che x (numero di successi) e size (numero di prove bernoulliane) sono degli scalari e prob è un vettore, questo significa che la formula della probabilità binomiale verrà applicata ciascun elemento di p_grid tenendo costanti valori di x e size, ovvero dati. questo modo otteniamo output un vettore cui valori corrispondono ’ordinata della funzione di verosimiglianza per il corrispondente valore griglia di \\(\\theta\\). La funzione di verosimiglianza così ottenuta è riportata nella figura 24.7.\nFigura 24.7: Rappresentazione della funzione di verosimiglianza per il parametro \\(\\theta\\), ovvero la probabilità di aspettative future distorte negativamente (Zetsche et al., 2019).\n","code":"\nlikelihood <- dbinom(x = 23, size = 30, prob = p_grid)\nlikelihood\n#>  [1] 0.000000e+00 2.352564e-33 1.703051e-26 1.644169e-22 1.053708e-19 1.525217e-17 8.602222e-16\n#>  [8] 2.528440e-14 4.606907e-13 5.819027e-12 5.499269e-11 4.105534e-10 2.520191e-09 1.311195e-08\n#> [15] 5.919348e-08 2.362132e-07 8.456875e-07 2.749336e-06 8.196948e-06 2.259614e-05 5.798673e-05\n#> [22] 1.393165e-04 3.148623e-04 6.720574e-04 1.359225e-03 2.611870e-03 4.778973e-03 8.340230e-03\n#> [29] 1.390025e-02 2.214199e-02 3.372227e-02 4.909974e-02 6.830377e-02 9.068035e-02 1.146850e-01\n#> [36] 1.378206e-01 1.568244e-01 1.681749e-01 1.688979e-01 1.575211e-01 1.348746e-01 1.043545e-01\n#> [43] 7.133007e-02 4.165680e-02 1.972669e-02 6.936821e-03 1.535082e-03 1.473375e-04 1.868105e-06\n#> [50] 0.000000e+00\np2 <- data.frame(p_grid, likelihood) %>%\n  ggplot(aes(x=p_grid, xend=p_grid, y=0, yend=likelihood)) +\n  geom_segment(color = \"#8184FC\") +\n  ylim(0, 0.17) +\n  labs(\n    x = \"Parametro \\U03B8\",\n    y = \"Verosimiglianza\"\n  )\np2"},{"path":"modellistica-bayesiana.html","id":"la-stima-della-distribuzione-a-posteriori","chapter":"Capitolo 24 Modellistica Bayesiana","heading":"24.6.3 La stima della distribuzione a posteriori","text":"La distribuzione posteriori per il parametro \\(\\theta\\) si ottiene facendo prima il prodotto della verosimiglianza e della distribuzione priori, e poi scalando tale prodotto per una costante di normalizzazione. Quindi, se ci limitiamo fare il prodotto dei valori della distribuzione priori e dei valori della funzione di verosimiglianza otteniamo la funzione posteriori non standardizzata.Ricordiamo che, usando il metodo basato su griglia, stiamo manipolando funzioni di massa di probabilità. Ovvero, siamo un “mondo discreto.” questo contesto, una funzione di massa di probabilità non è altro che un’elenco di valori la cui somma deve essere uguale 1.0. un “mondo continuo,” invece, le probabilità sono definite un modo completamente diverso: corrispondo ’area un intervallo di valori sotteso alla funzione di densità. Ma nel nostro esempio corrente ci limitiamo al caso discreto cui, per calcolare le probabilità, è sufficiente fare delle somme, non sono necessari gli integrali.Nel caso presente abbiamo deciso di usare una distribuzione priori non informativa, ovvero una distribuzione uniforme. Per ottenere la funzione posteriori (di massa di probabilità) non standardizzata è dunque sufficiente moltiplicare ciascun valore della funzione di verosimiglianza per 0.02. Per esempio, per il primo valore della funzione di verosimiglianza che abbiamo discusso quale esempio nella sezione precedente, avremo\\[\n0.135 \\cdot 0.02;\n\\]per il secondo valore della funzione di verosimiglianza che abbiamo discusso nell’esempio precedente avremo\\[\n0.104 \\cdot 0.02;\n\\]e così via.Usando R, possiamo svolgere tutti calcoli necessari nel modo seguente:Ricordiamo il principio dell’aritmetica vettorializzata: il vettore likelihood è costituito da 50 elementi e il vettore prior1 è anch’esso costituito da 50 elementi. Se facciamo il prodotto tra due vettori otteniamo un vettore di 50 elementi ciascuno dei quali uguale al prodotto dei corrispondenti elementi di likelihood e prior1.Avendo calcolato valori della funzione posteriori non standardizzata è poi necessario dividere per una costante di normalizzazione. Nel caso discreto, trovare il denominatore del teorema di Bayes è molto facile: esso è dato semplicemente dalla somma di tutti valori della distribuzione posteriori non normalizzata. Per dati presenti, tale costante di\nnormalizzazione è uguale 0.032:Per fare un esempio, standardizziamo due valori che abbiamo discusso negli esempi precedenti: \\(0.135 \\cdot 0.02 / 0.032\\) e \\(0.104 \\cdot 0.02 / 0.032\\).\nCosì facendo, otteniamo il risultato per cui la somma di tutti e 50 valori della distribuzione posteriori normalizzata diventa uguale 1.0.Svolgiamo tutti calcoli R:Verifichiamo:questo particolare esempio, la distribuzione posteriori trovata\ncome descritto sopra non è altro che la versione normalizzata della\nfunzione di verosimiglianza: questo avviene perché la distribuzione \npriori uniforme non ha aggiunto altre informazioni oltre quelle che\nerano già fornite dalla funzione di verosimiglianza.La funzione posteriori che abbiamo calcolato con il metodo grid-based è riportata nella figura 24.8.\nFigura 24.8: Rappresentazione della distribuzione posteriori per il parametro \\(\\theta\\), ovvero la probabilità di aspettative future distorte negativamente (Zetsche et al., 2019).\nLe funzioni rappresentate nelle figure 24.6, 24.7 e 24.8 sono state calcolate utilizzando una griglia di 50 valori equi-spaziati per il parametro \\(\\theta\\). segmenti verticali rappresentano l’intensità della funzione corrispondenza di ciascuna modalità parametro \\(\\theta\\). Nella figura 24.6 e nella figura 24.8 la somma delle lunghezze dei segmenti verticali è pari ad 1.0 (altri termini, la funzione priori e la funzione posteriori sono delle funzioni di massa di probabilità, questo esempio); ciò non si verifica, invece, nel caso della figura 24.8 (la funzione di verosimiglianza non è mai una funzione di probabilità, né nel caso discreto né quello continuo).","code":"\nunstd_posterior <- likelihood * prior1\nunstd_posterior\n#>  [1] 0.000000e+00 4.705127e-35 3.406102e-28 3.288337e-24 2.107415e-21 3.050433e-19 1.720444e-17\n#>  [8] 5.056880e-16 9.213813e-15 1.163805e-13 1.099854e-12 8.211068e-12 5.040382e-11 2.622390e-10\n#> [15] 1.183870e-09 4.724263e-09 1.691375e-08 5.498671e-08 1.639390e-07 4.519229e-07 1.159735e-06\n#> [22] 2.786331e-06 6.297247e-06 1.344115e-05 2.718450e-05 5.223741e-05 9.557946e-05 1.668046e-04\n#> [29] 2.780049e-04 4.428398e-04 6.744454e-04 9.819948e-04 1.366075e-03 1.813607e-03 2.293700e-03\n#> [36] 2.756411e-03 3.136488e-03 3.363497e-03 3.377958e-03 3.150422e-03 2.697491e-03 2.087091e-03\n#> [43] 1.426601e-03 8.331361e-04 3.945339e-04 1.387364e-04 3.070164e-05 2.946751e-06 3.736209e-08\n#> [50] 0.000000e+00\nsum(unstd_posterior)\n#> [1] 0.0316129\nposterior <- unstd_posterior / sum(unstd_posterior)\nposterior\n#>  [1] 0.000000e+00 1.488357e-33 1.077440e-26 1.040188e-22 6.666313e-20 9.649330e-18 5.442222e-16\n#>  [8] 1.599625e-14 2.914574e-13 3.681425e-12 3.479129e-11 2.597379e-10 1.594406e-09 8.295316e-09\n#> [15] 3.744893e-08 1.494410e-07 5.350268e-07 1.739376e-06 5.185824e-06 1.429552e-05 3.668548e-05\n#> [22] 8.813904e-05 1.991986e-04 4.251792e-04 8.599178e-04 1.652408e-03 3.023432e-03 5.276472e-03\n#> [29] 8.794033e-03 1.400820e-02 2.133450e-02 3.106310e-02 4.321259e-02 5.736920e-02 7.255582e-02\n#> [36] 8.719259e-02 9.921545e-02 1.063963e-01 1.068538e-01 9.965619e-02 8.532881e-02 6.602021e-02\n#> [43] 4.512719e-02 2.635430e-02 1.248015e-02 4.388601e-03 9.711744e-04 9.321354e-05 1.181862e-06\n#> [50] 0.000000e+00\nsum(posterior)\n#> [1] 1\np3 <- data.frame(p_grid, posterior) %>%\n  ggplot(aes(x=p_grid, xend=p_grid, y=0, yend=posterior)) +\n  geom_segment(color = \"#8184FC\") +\n  ylim(0, 0.17) +\n  labs(\n    x = \"Parametro \\U03B8\",\n    y = \"Probabilità a posteriori\"\n  )\np3"},{"path":"modellistica-bayesiana.html","id":"la-stima-della-distribuzione-a-posteriori-versione-2","chapter":"Capitolo 24 Modellistica Bayesiana","heading":"24.6.4 La stima della distribuzione a posteriori (versione 2)","text":"Continuiamo la discussione dell’esempio precedente ed esaminiamo l’impatto sulla distribuzione posteriori di una distribuzione priori informativa. Una distribuzione priori informativa riflette un alto grado di certezza sui parametri del modello da stimare.\nUn ricercatore può utilizzare una distribuzione priori informativa per introdurre nel processo di stima le informazioni esistenti che suggeriscono delle restrizioni sulla possibile gamma di valori di un particolare parametro.Nel caso presente, supponiamo che la letteratura psicologica fornisca delle informazioni proposito del valore di \\(\\theta\\), ovvero ci fornisca delle informazioni sul valore della probabilità che le aspettative future di un individuo clinicamente depresso siano distorte negativamente – altri termini, sono già state svolte ricerche precedenti su questo aspetto e risultati empirici sono già stati raccolti: una serie di ricerche precedenti è stato trovato che \\(\\theta\\) assumeva valori compresi una certa gamma. tali circostanze, anziché utilizzare una distribuzione priori non informativa per \\(p(\\theta)\\), il ricercatore può decidere di utilizzare una distribuzione priori informativa che riflette le conoscenze che sono state acquisite precedenza sul possibile valore del parametro. Nel caso presente, supponiamo (irrealisticamente) che tali conoscenze pregresse si possano esprimere nei termini di una distribuzione che ha la forma di una Beta di parametri \\(\\alpha = 2\\) e \\(\\beta = 10\\). Tali ipotetiche conoscenze pregresse (ripeto, del tutto irrealistiche) le quali si riflettono una Beta(2, 10) ritengono molto plausibili valori bassi di \\(\\theta\\) e considerano come impossibili valori \\(\\theta\\) superiori 0.5. Questo è equivalente dire che ci aspettiamo che le aspettative relative ’umore futuro siano distorte negativamente solo per pochissimi individui clinicamente depressi – altre parole, ci aspettiamo che la maggioranza degli individui clinicamente depressi sia inguaribilmente ottimista. Questa è, ovviamente, una credenza priori del tutto irrealistica. La esamino qui, non perché abbia alcun senso nel contesto dei dati di Zetsche et al. (2019), ma soltanto per fare un esempio che illustra come la distribuzione posteriori fornisca una sorta di “compromesso” tra la distribuzione priori e la verosimiglianza, ovvero per chiarire l’impatto che la distribuzione priori ha sulla distribuzione posteriori.Con calcoli del tutto simili quelli descritti sopra si giunge alla distribuzione posteriori rappresentata nella figura 24.9. Iniziamo definire una griglia\nunidimensionale equispaziata di possibili valori del parametro \\(\\theta\\). Anche questo caso usiamo 50 valori possibili del parametro \\(\\theta\\):Per la distribuzione priori scelgo una Beta(2, 10).Tale distribuzione priori è rappresentata nella figura\n24.9.\nFigura 24.9: Rappresentazione di una funzione priori informativa per il parametro \\(\\theta\\).\nCalcoliamo il valore della funzione di verosimiglianza corrispondenza\ndi ciascun punto della griglia. La funzione di verosimiglianza è\nidentica quella considerata nell’esempio precedente.Calcolo il prodotto tra la verosimiglianza e la distribuzione priori,\nper ciascun punto della griglia:Normalizzo la distribuzione posteriori modo tale che la somma sia\n1.La nuova funzione posteriori è rappresentata nella figura\n24.10.\nFigura 24.10: Rappresentazione della funzione posteriori per il parametro \\(\\theta\\) calcolata utilizzando una distribuzione priori informativa.\nFacendo un confronto tra le figure 24.9 e\n24.10 si nota come la distribuzione priori per il\nparametro \\(\\theta\\) e la distribuzione posteriori per il parametro\n\\(\\theta\\) sono molto diverse. particolare, si noti che la\ndistribuzione posteriori rappresentata nella 24.10\nrisulta spostata verso destra su posizioni più vicine quelle della\nverosimiglianza, rappresentata nella figura 24.7. Si\nnoti anche, causa dell’effetto della distribuzione priori, le\ndistribuzioni posteriori riportate nelle figure 24.8 e\n24.10 sono molto diverse tra loro. Discuteremo seguito\nl’influenza della distribuzione priori sull’inferenza finale.","code":"\nn_points <- 50\np_grid <- seq(from = 0, to = 1, length.out = n_points)\nalpha <- 2\nbeta <- 10\nprior2 <- dbeta(p_grid, alpha, beta) / sum(dbeta(p_grid, alpha, beta))\nsum(prior2)\n#> [1] 1\nplot_df <- data.frame(p_grid, prior2)\np4 <- plot_df %>%\n  ggplot(aes(x=p_grid, xend=p_grid, y=0, yend=prior2)) +\n  geom_segment(color = \"#8184FC\") +\n  ylim(0, 0.17) +\n  labs(\n    x = \"\",\n    y = \"Probabilità a priori\",\n    title = \"50 punti\"\n  )\np4\nlikelihood <- dbinom(23, size = 30, prob = p_grid)\nunstd_posterior2 <- likelihood * prior2\nposterior2 <- unstd_posterior2 / sum(unstd_posterior2)\nsum(posterior2)\n#> [1] 1\nplot_df <- data.frame(p_grid, posterior2)\np5 <- plot_df %>%\n  ggplot(aes(x = p_grid, xend = p_grid, y = 0, yend = posterior2)) +\n  geom_segment(color = \"#8184FC\") +\n  ylim(0, 0.17) +\n  labs(\n    x = \"Parametro \\U03B8\",\n    y = \"Probabilità a posteriori\"\n  )\np5"},{"path":"modellistica-bayesiana.html","id":"sommario-della-funzione-a-posteriori","chapter":"Capitolo 24 Modellistica Bayesiana","heading":"24.6.5 Sommario della funzione a posteriori","text":"Una volta calcolata la distribuzione posteriori dobbiamo riassumerla\nqualche modo. Nel caso cui venga usato un metodo grid-based, il\nproblema del calcolo delle aree sottese alla funzione posteriori \nqualunque intervallo può essere risolto vari modi. Tuttavia, questo\nproblema trova una soluzione molto più semplice se viene utilizzato un\nmetodo diverso per la stima della distribuzione posteriori, come\nvedremo di seguito. Non discuteremo dunque la possibile soluzione di\nquesto problema nel caso presente, quanto il metodo metodo\ngrid-based per il calcolo della distribuzione posteriori è solo un\nesempio didattico.","code":""},{"path":"modellistica-bayesiana.html","id":"differenza-tra-intervalli-di-confidenza-e-di-credibilità","chapter":"Capitolo 24 Modellistica Bayesiana","heading":"24.7 Differenza tra intervalli di confidenza e di credibilità","text":"L’approccio frequentista generalmente ipotizza che il mondo abbia certe proprietà (ad esempio, un parametro viene assunto che un dato parametro ha un particolare valore vero) e cercano di condurre esperimenti la cui conclusione risultante sarà corretta con almeno un livello minimo di probabilità. Per esprimere l’incertezza della nostra conoscenza dopo un esperimento, l’approccio frequentista utilizza un “intervallo di confidenza” – ovvero, un intervallo di valori progettato per includere il vero valore del parametro con una probabilità minima, diciamo il 95%. Un frequentista progetterà l’esperimento e la procedura di calcolo dell’intervallo di confidenza al 95% modo tale che su ogni 100 esperimenti eseguiti si prevede che almeno 95 degli intervalli di confidenza risultanti includano il vero valore del parametro; gli altri 5 potrebbero essere leggermente sbagliati, o potrebbero essere del tutto assurdi. Dal punto di vista dell’approccio frequentista, questo è accettabile, purché 95 inferenze su 100 siano corrette (ma ovviamente noi preferiremmo che 5 risultati sbagliati fossero leggermente sbagliati, non totalmente assurdi).L’approccio Bayesiano formula il problema modo diverso. Invece di dire che il parametro ha un valore vero (ma sconosciuto), il metodo Bayesiano dice che, prima di eseguire l’esperimento, è possibile assegnare una distribuzione di probabilità, che chiamano stato di credenza, quello che è il vero valore del parametro. Questa distribuzione priori potrebbe essere nota (per esempio, sappiamo che la distribuzione dei punteggi del QI è normale con media 100 e deviazione standard 15) o potrebbe essere del tutto arbitraria. L’inferenza Bayesiana è semplice: si raccolgono alcuni dati e si calcola la probabilità di diversi valori del parametro dati dati. Questa nuova distribuzione di probabilità è chiamata “distribuzione posteriori.” L’approccio Bayesiano riassumere l’incertezza descrivendo un intervallo di valori sulla distribuzione di probabilità posteriori che include il 95% della probabilità – questo intervallo è chiamato “intervallo di credibilità del 95%.”Un proponente dell’approccio Bayesiano potrebbe criticare l’intervallo di confidenza frequentista questo modo: “Perché dovrei dare importanza al fatto che 95 esperimenti su 100 producono un intervallo di confidenza che include il vero valore del parametro sconosciuto? Non mi interessano 95 esperimenti che non ho eseguito; mi interessa l’unico esperimento che ho effettivamente eseguito. La regola decisionale frequentista consente che 5 risultati su 100 siano completamente privi di senso [es., valori negativi, valori impossibili] purché gli altri 95 siano corretti. Ma questo è inaccettabile.”Un proponente dell’approccio frequentista potrebbe criticare l’intervallo di credibilità Bayesiano questo modo: “Perché dovrei dare importanza al fatto che il 95% della probabilità posteriori è incluso un dato intervallo? La risposta Bayesiana è corretta solo se la distribuzione priori è corretta. Ma chi mi garantisce che tale distribuzione non sia stata scelta un modo del tutto inappropriato?”Vorrei rendere esplicito il fatto che, questo insegnamento, io mi schiero maniera chiara favore dell’approccio Bayesiano. La critica che Bayesiani rivolgono ’approccio frequentista mi sembra sensata. La critica che frequentisti rivolgono ’approccio Bayesiano mi sembra, invece, debole e poco convincente. Spero che ciò che verrà detto seguito chiarirà questo punto.","code":""},{"path":"modellistica-bayesiana.html","id":"conclusioni-10","chapter":"Capitolo 24 Modellistica Bayesiana","heading":"Conclusioni","text":"Possiamo specificare un modello Bayesiano definendo una distribuzione congiunta su variabili osservate, \\(\\mathcal Y\\), e un insieme di parametri sconosciuti, \\(\\theta\\).\\[\np(\\mathcal Y, \\theta).\n\\]\nQuesta distribuzione congiunta si decompone convenientemente due termini,\\[\n  p(\\mathcal Y, \\theta) = p(\\theta)  p(\\mathcal Y \\mid \\theta).\n\\]Il primo termine, \\(p(\\theta)\\), è la densità priori e codifica l’insieme di valori plausibili dei parametri, con valori più plausibili aventi una densità maggiore. È chiamato “priori” perché racchiude la nostra conoscenza - e la sua mancanza - sui parametri da stimare prima di osservare dati. Il secondo termine, \\(p(\\mathcal Y \\mid \\theta)\\), è la verosimiglianza. Dati parametri del modello \\(\\theta\\), \\(p(\\mathcal Y \\mid \\theta)\\) definisce il processo di generazione per \\(\\mathcal Y\\).L’inferenza esegue il reverse engineering del processo di generazione dei dati e si chiede:dato un modello e un campione di osservazioni, \\(\\mathcal Y\\), quali sono valori più plausibili dei parametri che potrebbero aver generato le osservazioni?un contesto Bayesiano, l’insieme dei valori plausibili dei parametri condizionati ai dati è caratterizzato dalla distribuzione posteriori, \\(p(\\theta \\mid \\mathcal Y)\\). La regola di Bayes stabilisce che\\[\n  p(\\theta \\mid \\mathcal Y) \\propto p(\\theta)  p(\\mathcal Y \\mid \\theta),\n\\]dove \\(\\propto\\) sta per “proporzionale ” e indica che la distribuzione posteriori combina le informazioni fornite dai dati e la nostra conoscenza precedente. Un’espressione analitica per \\(p(\\theta \\mid \\mathcal Y)\\) è raramente disponibile e dobbiamo fare affidamento su algoritmi di calcolo numerico per conoscere la distribuzione posteriori. Una strategia generale che esamineremo seguito consiste nel prelevare campioni approssimativi dalla distribuzione posteriori e utilizzarli per costruire stime empiriche della media posteriori, della varianza, della mediana, dei quantili e di altre quantità di interesse. Qui abbiamo presentato il metodo grid-based per il calcolo della distribuzione posteriori. metodi basati su griglia funzionano benissimo quando la distribuzione posteriori dipende da un numero molto piccolo di parametri sconosciuti, ma non possono essere usati nel caso di modelli statistici più complessi che includono un numero maggiore di parametri.","code":""},{"path":"stima-della-funzione-a-posteriori.html","id":"stima-della-funzione-a-posteriori","chapter":"Capitolo 25 Stima della funzione a posteriori","heading":"Capitolo 25 Stima della funzione a posteriori","text":"Quando usiamo il teorema di Bayes per calcolare la distribuzione posteriori del parametro di un modello statistico, al denominatore troviamo un integrale. Se vogliamo costruire la distribuzione posteriori con metodi analitici è necessario usare distribuzioni priori coniugate per la verosimiglianza. Due distribuzioni si dicono coniugate se la forma funzionale della distribuzione priori e della distribuzione posteriori sono uguali. Questo significa che, nel caso di distribuzioni priori coniugate, è possibile determinare la distribuzione posteriori per via analitica. Per quanto “semplice” termini formali, questo approccio, però, limita di molto le possibili scelte del ricercatore. Nel senso che non è sempre sensato, dal punto di vista teorico, utilizzare distribuzioni priori coniugate per la verosimiglianza per parametri di interesse. Dunque, se usiamo delle distribuzioni priori non coniutate per la verosimiglianza, ci troviamo una condizione nella quale, per determinare la distribuzione posteriori, è necessario calcolare un integrale che, nella maggior parte dei casi, non si può risolvere per via analitica. Detto altre parole: è possibile ottenere la distribuzione posteriore per via analitica solo per alcune specifiche combinazioni di distribuzioni priori e verosimiglianza, il che limita considerevolmente la flessibilità della modellazione.Per questa ragione, la strada principale che viene seguita nella modellistica Bayesiana è quella che porta determinare la distribuzione posteriori non per via analitica, ma bensì mediante metodi numerici. La simulazione fornisce dunque la strategia generale del calcolo Bayesiano.questo fine vengono usati metodi di campionamento detti Monte-Carlo Markov-Chain (MCMC). Tali metodi costituiscono una potente e praticabile alternativa per la costruzione della distribuzione posteriori per modelli complessi e consentono di decidere quali distribuzioni priori e quali distribuzioni di verosimiglianza usare sulla base di considerazioni teoriche soltanto, senza dovere preoccuparsi dei vincoli dei metodi analitici.Dato che è basata su metodi computazionalmente intensivi, la stima numerica della funzione posteriori può essere svolta soltanto mediante software. anni recenti metodi Bayesiani di analisi dei dati sono diventati sempre più popolari proprio perché la potenza di calcolo necessaria per svolgere tali calcoli è ora alla portata di tutti. Questo non era vero solo pochi decenni fa.questo capitolo vedremo come sia possibile approssimare per via numerica la distribuzione posteriori. Presenteremo tre diverse tecniche che possono essere utilizzate questo scopo:metodi basati sull’uso di griglie (grid-based),il metodo dell’approssimazione quadratica,metodi Monte Carlo basati su Catena di Markov (MCMC).","code":""},{"path":"stima-della-funzione-a-posteriori.html","id":"metodi-basati-su-griglie","chapter":"Capitolo 25 Stima della funzione a posteriori","heading":"25.1 Metodi basati su griglie","text":"È possibile stimare l’intera distribuzione posteriori mediante metodi basati su griglie (grid-based), come abbiamo fatto nel capitolo Modellistica bayesiana. Questo è l’approccio più semplice. Tuttavia, anche se tali metodi possono fornire risultati accuratissimi, causa della “maledizione della dimensionalità” tali procedure numeriche sono utilizzabili solo nel caso di modelli statistici semplici, con non più di due parametri. Nella pratica concreta tali metodi vengono dunque sostituiti da altre tecniche più efficienti quanto, anche comuni modelli utilizzati psicologia, vengono stimati centinaia se non migliaia di\nparametri.","code":""},{"path":"stima-della-funzione-a-posteriori.html","id":"approssimazione-quadratica","chapter":"Capitolo 25 Stima della funzione a posteriori","heading":"25.2 Approssimazione quadratica","text":"L’approssimazione quadratica è uno dei metodi che possono essere usati per superare il problema della “maledizione della dimensionalità.” La motivazione di tale metodo è la seguente. Sappiamo che, generale, la regione della distribuzione posteriori che si trova prossimità del suo massimo può essere ben approssimata dalla forma di una distribuzione Normale. Descrivere la distribuzione posteriori mediante la distribuzione Normale significa utilizzare un’approssimazione che viene, appunto, chiamata “quadratica” (tale approssimazione si dice quadratica perché il logaritmo di una distribuzione gaussiana forma una parabola e la parabola è una funzione quadratica – dunque, mediante questa approssimazione descriviamo il logaritmo della distribuzione posteriori mediante una parabola).L’approssimazione quadratica si pone due obiettivi.Trovare la moda della distribuzione posteriori. Ci sono varie\nprocedure di ottimizzazione, implementate R, \ngrado di trovare il massimo di una distribuzione.Trovare la moda della distribuzione posteriori. Ci sono varie\nprocedure di ottimizzazione, implementate R, \ngrado di trovare il massimo di una distribuzione.Stimare la curvatura della distribuzione prossimità della moda.\nUna stima della curvatura è sufficiente per trovare\nun’approssimazione quadratica dell’intera distribuzione. alcuni\ncasi, questi calcoli possono essere fatti seguendo una procedura\nanalitica, ma solitamente vengono usate delle tecniche numeriche.Stimare la curvatura della distribuzione prossimità della moda.\nUna stima della curvatura è sufficiente per trovare\nun’approssimazione quadratica dell’intera distribuzione. alcuni\ncasi, questi calcoli possono essere fatti seguendo una procedura\nanalitica, ma solitamente vengono usate delle tecniche numeriche.Una descrizione della distribuzione posteriori ottenuta mediante l’approssimazione quadratica si ottiene mediante la funzione quap() contenuta nel pacchetto rethinking. Tale pacchetto, creato da Richard McElreath per accompagnare il suo testo Statistical Rethinking\\(^2\\), può essere scaricato utilizzando le istruzioni seguenti:È possibile che, per diversi sistemi operativi, sia necessaria l’installazione di componenti ulteriori. Si veda https://github.com/rmcelreath/rethinking.Le analisi Bayesiane che discuteremo queste dispense, per la maggior parte, faranno uso della funzione rethinking::quap(). È dunque fondamentale che gli studenti installino sul loro computer il pacchetto rethinking.Dal nostro punto di vista non è importante capire come si svolgono pratica calcoli necessari per la stima della distribuzione posteriori con il metodo dell’approssimazione quadratica. Quello che è importante capire è il significato della distribuzione posteriori e questo significato è stato chiarito nell’esempio discusso nel capitolo Modellistica bayesiana. L’approssimazione quadratica fornisce risultati simili (o identici) quelli ottenuti con il metodo grid-based. Il vantaggio dell’approssimazione quadratica è che disponiamo di una serie di funzioni R che svolgono tutti calcoli per noi.realtà, l’approssimazione quadratica è poco usata pratica, perché per problemi complessi è più conveniente usare metodi Monte Carlo basati su Catena di Markov (MCMC) che verranno descritti nella successiva sezione. Per potere utilizzare metodi MCMC è necessario installare sul proprio computer del software aggiuntivo e tale operazione, talvolta, può risultare complessa. Non è l’obiettivo di questo insegnamento affrontare questo problema Per questa ragione, per svolgere gli esercizi che discuteremo sarà sufficiente fare ricorso al metodo dell’approssimazione quadratica; ovvero sarà sufficiente usare la funzione rethinking::quap().","code":"\ninstall.packages(c(\"coda\", \"mvtnorm\", \"devtools\", \"loo\", \"dagitty\"))\nlibrary(\"devtools\")\ndevtools::install_github(\"rmcelreath/rethinking\")"},{"path":"stima-della-funzione-a-posteriori.html","id":"integrazione-con-metodo-monte-carlo","chapter":"Capitolo 25 Stima della funzione a posteriori","heading":"25.3 Integrazione con metodo Monte Carlo","text":"Questi algoritmi estraggono campioni da una distribuzione target mediante la seguente procedura (1) facendo una proposta per un nuovo valore casuale del parametro sconosciuto (o dei parametri sconosciuti) e poi (2) accettando o rifiutando tala proposta. Se entrambi questi passaggi vengono eseguiti correttamente, valori accettati dei parametri costituiranno dei campioni casuali della distribuzione target.L’idea è semplice: per calcolare le statistiche che ci interessano – solitamente, una qualche misura di tendenza centrale e un qualche intervallo che contiene una data proporzione della massa della distribuzione – non abbiamo bisogno di conoscere l’esatta funzione di densità della distribuzione posteriori \\(p(\\theta \\mid \\mathcal{Y})\\). È sufficiente, per la ragione spiegata nella sezione successiva, riuscire ottenere un grande numero di campioni casuali della distribuzione posteriori. Se tali campioni che estraiamo dalla distribuzione posteriori sono veramente casuali, allora le statistiche che ci interessano, ovvero una qualche misura di tendenza centrale e un qualche intervallo che contiene una data proporzione della massa della distribuzione, saranno stimati con esattezza. E come facciamo sapere che un insieme di campioni della distribuzione posteriori è veramente estratto maniera casuale da \\(p(\\theta \\mid \\mathcal{Y})\\)? Basta che, seguendo il secondo passo descritto sopra, decidiamo se accettare o rifiutare il valore proposto del parametro base ad una regola che dipende dal valore della densità di \\(p(\\theta \\mid \\mathcal{Y})\\) corrispondenza della proposta. E un valore che sia proporzionale tale densità è facile da ottenere: infatti non è altro che il prodotto della funzione priori e della verosimiglianza corrispondenza del valore della proposta. Questo è essenza l’algoritmo di Metropolis.\nPrima di introdurre metodi MCMC per la stima della funzione posteriori, spendiamo però qualche parola sul metodo Monte Carlo.","code":""},{"path":"stima-della-funzione-a-posteriori.html","id":"legge-forte-dei-grandi-numeri","chapter":"Capitolo 25 Stima della funzione a posteriori","heading":"25.4 Legge forte dei grandi numeri","text":"Il termine Monte-Carlo si riferisce al fatto che per la computazione si ricorre ad un ripetuto campionamento casuale attraverso la generazioni di sequenze di numeri casuali.\nUna delle sue applicazioni più potenti è il calcolo degli integrali mediante simulazione numerica.Consideriamo la formula del valore atteso di una variabile aleatoria continua:\n\\[\n\\mathbb{E}(X) = \\int_{-\\infty}^{+\\infty} x f(x) dx\n\\]\nIl calcolo del valore atteso, questo caso, richiede che si facciano le somme dei prodotti \\(x f(x)\\) per tutti gli infinitesimi “incrementi” \\(dx\\) per tutti possibili valori \\(X\\).\nVediamo ora come si possa risolvere un problema di questo tipo maniera semplice, senza dovere calcolare l’integrale esatto per via analitica.generale, diciamo che l’integrazione con metodo Monte Carlo trova la sua giustificazione nella Legge forte dei grandi numeri la quale, termini formali, può essere espressa nel modo seguente. Data una successione di variabili casuali \\(Y_{1}, Y_{2},\\dots, Y_{n},\\dots\\) indipendenti e identicamente distribuite con media \\(\\mu\\), ne segue che\n\\[\nP\\left( \\lim_{n \\rightarrow \\infty} \\frac{1}{n} \\sum_{=1}^n Y_i = \\mu \\right) = 1.\n\\]\nCiò significa che, al crescere di \\(n\\), la media delle realizzazioni di \\(Y_{1}, Y_{2},\\dots, Y_{n},\\dots\\) converge con probabilità 1 al vero valore \\(\\mu\\).Possiamo fornire un esempio intuitivo della legge forte dei grandi numeri facendo riferimento ad una serie di lanci di una moneta dove \\(Y=1\\) significa “testa” e \\(Y=0\\) significa “croce.” Per la legge forte dei grandi numeri, nel caso di una moneta equilibrata la proporzione di eventi “testa” converge alla vera probabilità dell’evento “testa”\n\\[\n\\frac{1}{n} \\sum_{=1}^n Y_i \\rightarrow \\frac{1}{2}\n\\]\ncon probabilità di uno.Quello che è stato detto sopra non è che un modo sofisticato per dire che, se vogliamo calcolare un’approssimazione del valore atteso di una variabile aleatoria, non dobbiamo fare altro che la media aritmetica di un grande numero di realizzazioni della variabile aleatoria. Come è facile intuire, l’approssimazione migliora al crescere del numero di dati che abbiamo disposizione. Questa è la giustificazione dell’affermazione precedente secondo la quale una stima del valore atteso di \\(p(\\theta \\mid \\mathcal{Y})\\) può essere ottenuta mediante un grande numero di campioni casuali della distribuzionea posteriori.","code":""},{"path":"stima-della-funzione-a-posteriori.html","id":"metodi-mc-basati-su-catena-di-markov","chapter":"Capitolo 25 Stima della funzione a posteriori","heading":"25.5 Metodi MC basati su Catena di Markov","text":"Abbiamo chiarito il problema che vogliamo risolvere ’interno dell’analisi Bayesiana, ovvero costruire la distribuzione posteriori del parametro di interesse avendo osservato dati. La costruzione della distribuzione posteriori, generale, richiede il calcolo di un integrale “intrattabile” per via analitica. Quindi affrontiamo il problema un altro modo, ovvero facciamo una simulazione numerica che produce un risultato approssimato (ma sufficientemente preciso per tutti gli scopi pratici). tale scopo usiamo cosiddetti metodi Monte Carlo basati su Catena di Markov quali consentono di costruire sequenze di punti (le “catene”) nello spazio dei parametri, la cui densità è proporzionale alla distribuzione posteriori – altre parole, consentono di ottenere un grande numero di campioni casuali dalla distribuzione posteriori.La generazioni di elementi di una catena ha una natura probabilistica e esistono diversi algoritmi per costruire catene di Markov. Due aspetti da tenere considerazione sotto questo punto di vista sono il periodo di burn-e le correlazioni tra punti. Al crescere degli step della catena si ottiene una migliore approssimazione della distribuzione target. ’inizio del campionamento però la distribuzione può essere significativamente lontana dalla distribuzione stazionaria. Ci vuole un certo tempo prima di raggiungere la distribuzione stazionaria di equilibrio e tale periodo è detto di burn-. Perciò campioni provenienti da tale parte iniziale della catena vanno tipicamente scartati poiché non rappresentano accuratamente la distribuzione desiderata.Normalmente, un algoritmo MCMC genera catene di Markov di campioni, ognuno dei quali è autocorrelato quelli generati immediatamente prima e dopo di lui. Conseguentemente campioni successivi non sono indipendenti ma formano una catena di Markov con un certo grado di correlazione. Questa correlazione introduce una distorsione nella soluzione che si ottiene con questo metodo. L’arte dei diversi algoritmi MCMC risiede nel rendere il meccanismo efficiente e capace di produrre un risultato non distorto, il che implica la riduzione al minimo del tempo di burn-e della correlazione tra diversi campioni.Presentiamo ora, una forma intuitiva, l’algoritmo di Metropolis, ovvero il primo algoritmo MCMC che è stato proposto. Tale algoritmo è stato sviluppato seguito per renderlo via via più efficiente. Il nostro obiettivo, però, è solo quello di illustrare la logica sottostante – lasciamo che siano gli ingegneri risolvere il problema di rendere l’algoritmo più efficiente.","code":""},{"path":"stima-della-funzione-a-posteriori.html","id":"il-problema-del-turista-viaggiatore","chapter":"Capitolo 25 Stima della funzione a posteriori","heading":"25.6 Il problema del turista viaggiatore","text":"L’algoritmo di Metropolis è stato presentato usando varie metafore: quella di un politico che viaggia tra isole diverse (Kruschke, 2014), o quella di un re che, anche lui, si sposta tra le isole di un arcipelago (McElreath, 2020). Qui mutiamo leggermente la metafora e immaginiamo un turista vacanza su un’isola che dispone di 10 spiagge di grandezza diversa. Muovendosi senso orario, la grandezza delle spiagge aumenta: partendo dalla spiaggia più piccola si arriva ad una spiaggia un po’ più grande, via via fino ad arrivare ’ultima spiaggia, la decima, che è la più grande di tutte. Quindi indicheremo con numeri da 1 10 le spiagge dell’isola. Tali numeri rappresentano anche la grandezza (relativa) di ciascuna spiaggia. Dato che l’isola è circolare, la decima spiaggia confina con la prima spiaggia.Nella nostra metafora, immaginiamo un turista vacanza sull’isola che abbiamo appena descritto. Per non annoiarsi, il nostro turista vuole passare un po’ di tempo su ogni spiaggia, ma con il vincolo che il tempo passato su ciascuna spiaggia deve essere proporzionale alla grandezza della spiaggia. Infatti, il turista preferisce le spiagge più grandi; nel contempo, però, vuole anche visitare spiagge diverse, quindi il vincolo descritto sopra sembra un buon compromesso tra il desiderio di cambiare spiaggia di tanto tanto e il desiderio di passare più tempo sulle spiagge più grandi.Essendo vacanza, il turista non vuole preparare un calendario che stabilisca anticipo la spiaggia da visitare ogni giorno, ma vuole decidere maniera rilassata e un po’ casuale, ogni mattina, restando però fedele al vincolo che si è dato. Al bar incontra un altro turista, l’ingegnere Metropolis, che gli suggerisce come fare per ottenere l’obiettivo che si è prefissato. Seguendo le istruzioni di Metropolis, il nostro turista decide di comportarsi nel modo seguente.Ogni mattina decide tra due alternative: ritornare sulla\nspiaggia dove era stato il giorno prima (chiamiamola spiaggia\ncorrente) oppure andare una delle due spiagge contigue.Ogni mattina decide tra due alternative: ritornare sulla\nspiaggia dove era stato il giorno prima (chiamiamola spiaggia\ncorrente) oppure andare una delle due spiagge contigue.Lancia una moneta. Se esce testa, considera la possibilità di andare\nnella spiaggia che confina con la spiaggia corrente muovendosi \nsenso orario; se esce croce, considera la possibilità di andare\nnella spiaggia che confina con la spiaggia corrente muovendosi \nsenso antiorario. La spiaggia individuata questo modo viene\nchiamata spiaggia proposta.Lancia una moneta. Se esce testa, considera la possibilità di andare\nnella spiaggia che confina con la spiaggia corrente muovendosi \nsenso orario; se esce croce, considera la possibilità di andare\nnella spiaggia che confina con la spiaggia corrente muovendosi \nsenso antiorario. La spiaggia individuata questo modo viene\nchiamata spiaggia proposta.Dopo avere trovato la spiaggia proposta, il turista deve decidere se\neffettivamente andare lì oppure e, per decidere,\nprocede questo modo. Prende un numero di conchiglie proporzionale\nalla grandezza della spiaggia proposta – per esempio, se la\nspiaggia proposta è la numero 7, allora prenderà 7 conchiglie.\nPrende un numero di sassolini proporzionale alla grandezza della\nspiaggia corrente – per esempio, se la spiaggia corrente è la\nnumero 6, allora prenderà 6 sassolini.Dopo avere trovato la spiaggia proposta, il turista deve decidere se\neffettivamente andare lì oppure e, per decidere,\nprocede questo modo. Prende un numero di conchiglie proporzionale\nalla grandezza della spiaggia proposta – per esempio, se la\nspiaggia proposta è la numero 7, allora prenderà 7 conchiglie.\nPrende un numero di sassolini proporzionale alla grandezza della\nspiaggia corrente – per esempio, se la spiaggia corrente è la\nnumero 6, allora prenderà 6 sassolini.Se il numero di conchiglie è maggiore del numero di sassolini, il\nturista si sposta sempre nella spiaggia proposta. Ma se ci sono meno\nconchiglie che sassolini, scarta un numero di sassolini uguale al\nnumero di conchiglie e mette gli oggetti rimanenti un sacchetto\n– per esempio, se la spiaggia proposta è la 5 e la spiaggia\ncorrente è la 6, allora metterà nel sacchetto 5 conchiglie e 1\nsassolino. Mescola bene ed estrae dal sacchetto un oggetto: se è una\nconchiglia si sposta nella spiaggia proposta, se è un sassolino\nresta nella spiaggia corrente. Di conseguenza, la probabilità che il\nturista cambi spiaggia (ovvero \\(\\frac{5}{6}\\)) è uguale al numero di\nconchiglie diviso per il numero originale di sassolini.Se il numero di conchiglie è maggiore del numero di sassolini, il\nturista si sposta sempre nella spiaggia proposta. Ma se ci sono meno\nconchiglie che sassolini, scarta un numero di sassolini uguale al\nnumero di conchiglie e mette gli oggetti rimanenti un sacchetto\n– per esempio, se la spiaggia proposta è la 5 e la spiaggia\ncorrente è la 6, allora metterà nel sacchetto 5 conchiglie e 1\nsassolino. Mescola bene ed estrae dal sacchetto un oggetto: se è una\nconchiglia si sposta nella spiaggia proposta, se è un sassolino\nresta nella spiaggia corrente. Di conseguenza, la probabilità che il\nturista cambi spiaggia (ovvero \\(\\frac{5}{6}\\)) è uguale al numero di\nconchiglie diviso per il numero originale di sassolini.Decidere di procedere questo modo potrebbe sembrare un modo per rovinarsi le vacanze. Invece, questo algoritmo funziona! Seguendo la proposta di Metropolis, il turista passerà su ciascuna spiaggia un numero di giorni proporzionale alla grandezza della spiaggia.McElreath (2020) ha implementato R l’algoritmo di Metropolis che abbiamo descritto sopra nel modo seguente:Le istruzioni seguenti sono state usate per generare la figura 25.1. Se guardiamo la figura e consideriamo un giorno qualsiasi è difficile capire qual è la spiaggia scelta dal turista.\nFigura 25.1: Risultati dell’algoritmo di Metropolis utilizzato dal turista viaggiatore. La figura mostra la spiaggia scelta dal turista (asse verticale) funzione di ciascun giorno della sua vacanza (asse orizzontale).\nTuttavia, se esaminiamo la figura 25.2 che descrive il comportamento lungo termine dell’algoritmo, ci rendiamo conto che l’algoritmo ha prodotto il risultato che si voleva ottenere: il tempo trascorso dal turista su ciascuna spiaggia è proporzionale alla grandezza della spiaggia.\nFigura 25.2: Risultati dell’algoritmo di Metropolis utilizzato dal turista viaggiatore. La figura mostra che il numero di volte cui ciascuna spiaggia è stata visitata è proporzionale alla grandezza della spiaggia.\nL’algoritmo di Metropolis funziona anche se il turista decide di spostarsi dalla spiaggia corrente qualunque altra spiaggia, non solo su quelle confinanti. Inoltre, l’algoritmo funziona per qualunque numero di spiagge e anche se il turista non sa quante spiagge ci sono sull’isola. Affinché l’algoritmo funzioni è solo necessario conoscere la grandezza della spiaggia “corrente” e quella della spiaggia “proposta.”","code":"\nnum_weeks <- 1e5\npositions <- rep(0, num_weeks)\ncurrent <- 10\nfor (i in 1:num_weeks) {\n  # record current position\n  positions[i] <- current\n  # flip coin to generate proposal\n  proposal <- current + sample(c(-1, 1), size = 1)\n  # now make sure he loops around the archipelago\n  if (proposal < 1) proposal <- 10\n  if (proposal > 10) proposal <- 1\n  # move?\n  prob_move <- proposal / current\n  current <- ifelse(runif(1) < prob_move, proposal, current)\n}\nggplot(\n    data.frame(x = 1:100, y = positions[1:100]),\n    aes(x, y)\n) +\n  geom_point(color = \"#8184FC\") +\n  labs(\n    x = \"Giorno\",\n    y = \"Isola\"\n  ) +\n  scale_y_continuous(breaks=1:10)\nggplot(\n  data.frame(x = 1:10, y = as.numeric(table(positions))),\n  aes(x = x, xend = x, y = 0, yend = y)\n  ) +\n  geom_segment(color = \"#8184FC\", size = 1.5) +\n  labs(\n    x = \"Isola\",\n    y = \"Numero di giorni\"\n  ) +\n  scale_x_continuous(breaks=1:10)"},{"path":"stima-della-funzione-a-posteriori.html","id":"lalgoritmo-di-metropolis","chapter":"Capitolo 25 Stima della funzione a posteriori","heading":"25.7 L’algoritmo di Metropolis","text":"L’algoritmo descritto nella sezione Il problema del turista viaggiatore è un caso speciale dell’algoritmo di Metropolis e l’algoritmo di Metropolis è un caso speciale dei metodi MCMC. L’algoritmo di Metropolis, al di là dell’uso che ne fa il fortunato turista dell’esempio discusso precedenza, viene realtà impiegato per per ottenere una sequenza di campioni casuali da una distribuzione posteriori la cui forma è, solitamente, sconosciuta. Fuor di metafora:numeri che identificano ciascuna spiaggia corrispondono ai valori del parametro che vogliamo stimare – non è necessario che il parametro assuma solo valori discreti, può anche assumere un insieme continuo di valori;numeri che identificano ciascuna spiaggia corrispondono ai valori del parametro che vogliamo stimare – non è necessario che il parametro assuma solo valori discreti, può anche assumere un insieme continuo di valori;la grandezza della spiaggia corrisponde alla densità posteriori associata ciascuno dei possibili valori del parametro;la grandezza della spiaggia corrisponde alla densità posteriori associata ciascuno dei possibili valori del parametro;giorni di permanenza su una spiaggia corrispondono al numero di campioni estratti dalla distribuzione posteriori.giorni di permanenza su una spiaggia corrispondono al numero di campioni estratti dalla distribuzione posteriori.L’aspetto cruciale di questa discussione è il fatto che, ’aumentare delle ripetizioni dell’algoritmo di Metropolis, la distribuzione dei valori così ottenuti diventa via via più simile alla distribuzione posteriori del parametro \\(\\theta\\), anche se questa è sconosciuta. Per un grande numero di passi della catena l’approssimazione è sufficiente. Con questo metodo è dunque possibile generare un grande numero di campioni casuali dalla distribuzione posteriori per poi poterne calcolare misure di sintesi e potere fare inferenza.L’esempio precedente ci presenta, maniera intuitiva, è la logica dell’algoritmo di Metropolis. Una illustrazione visiva di come si svolge questo processo di “esplorazione” di \\(p(\\theta \\mid \\mathcal{Y})\\) è fornita questo post.","code":""},{"path":"stima-della-funzione-a-posteriori.html","id":"una-applicazione-concreta","chapter":"Capitolo 25 Stima della funzione a posteriori","heading":"25.8 Una applicazione concreta","text":"L’algoritmo di Metropolis consente di effettuare quello che viene chiamato un dependent sampling, ovvero ci consente di generare campioni casuali dalla distribuzione posteriori utilizzando soltanto il numeratore del teorema di Bayes:\\[\nP(\\theta \\mid x) = \\frac{P(x \\mid \\theta)P(\\theta)}{P(x)}\n\\]\novvero\\[\nP(\\theta \\mid x) \\propto P(x \\mid \\theta)P(\\theta)\n\\]\nL’algoritmo di Metropolis è la versione più semplice e più conosciuta degli algoritmi MCMC. Guardiamolo ora più da vicino cercando, di nuovo, di sviluppare un intuizione della logica che sta alla base di esso. Abbiamo detto precedenza che, fondamentalmente, l’algoritmo di Metropolis fa due cose: (1) genera una proposta per un nuovo valore casuale del parametro sconosciuto e (2) accetta o rifiuta tala proposta. Vediamo concreto come questo viene fatto.Per prima cosa troviamo un valore casuale del parametro estraendolo da una distribuzione “proposta”: \\(\\theta_0 \\sim \\Pi(\\theta)\\). La distribuzione proposta può essere qualunque distribuzione, anche se, idealmente, è meglio che sia simile alla distribuzione posteriori. Ma pratica la distribuzione posteriori è sconosciuta e quindi utilizziamo un qualche metodo arbitrario di iniziare la catena di Markov (ovvero utilizziamo un valore iniziale arbitrario).Per prima cosa troviamo un valore casuale del parametro estraendolo da una distribuzione “proposta”: \\(\\theta_0 \\sim \\Pi(\\theta)\\). La distribuzione proposta può essere qualunque distribuzione, anche se, idealmente, è meglio che sia simile alla distribuzione posteriori. Ma pratica la distribuzione posteriori è sconosciuta e quindi utilizziamo un qualche metodo arbitrario di iniziare la catena di Markov (ovvero utilizziamo un valore iniziale arbitrario).ciascuna iterazione \\(t\\) viene proposto un nuovo valore del parametro, \\(\\theta'_t\\). Il valore \\(\\theta'_t\\) viene estratto maniera casuale da una qualsiasi distribuzione simmetrica centrata sul valore del parametro dell’interazione precedente, \\(t-1\\). Ad esempio, possiamo usare la distribuzione Normale con una appropriata deviazione standard: \\(\\theta_t \\sim \\mathcal{N}(\\theta_{t-1}, \\sigma)\\). pratica, questo significa che il valore proposto del parametro sarà un valore nella prossimità di quello attualmente considerato.ciascuna iterazione \\(t\\) viene proposto un nuovo valore del parametro, \\(\\theta'_t\\). Il valore \\(\\theta'_t\\) viene estratto maniera casuale da una qualsiasi distribuzione simmetrica centrata sul valore del parametro dell’interazione precedente, \\(t-1\\). Ad esempio, possiamo usare la distribuzione Normale con una appropriata deviazione standard: \\(\\theta_t \\sim \\mathcal{N}(\\theta_{t-1}, \\sigma)\\). pratica, questo significa che il valore proposto del parametro sarà un valore nella prossimità di quello attualmente considerato.Calcoliamo poi il rapporto \\(r\\) tra la distribuzione posteriori non normalizzata determinata dal valore proposto \\(\\theta'_t\\) e la distribuzione posteriori non normalizzata determinata dal valore del parametro \\(\\theta'_{t-1}\\) dell’iterazione precedente della catena: \\(r = \\frac{P(x \\mid \\theta'_t) P(\\theta'_t)}{P(x \\mid \\theta'_{t-1}) P(\\theta'_{t-1})}\\). Soffermiamoci su tale formula per capire bene cosa significa. La distribuzione posteriori non normalizzata corrisponde al numeratore del teorema di Bayes, ovvero \\(P(x \\mid \\theta) P(\\theta)\\), laddove \\(P(x \\mid \\theta)\\) è la verosimiglianza di \\(x\\) dato \\(\\theta\\) e \\(P(\\theta)\\) è la distribuzione priori di \\(\\theta\\). Abbiamo visto nella sezione Un esempio pratico (versione 2) che ciascuna di tali densità può essere rappresentata mediante una curva e che il prodotto di due densità si ottiene facendo il prodotto dei valori delle ordinate corrispondenti di discuna delle due curve. Il numeratore del teorema di Bayes ci fornisce la distribuzione posteriori non normalizzata quanto l’area sottesa alla curva così ottenuta non è unitaria (quindi tale curva non rappresenta una funzione di densità). Dato che qui facciamo un rapporto, però, questo è irrilevante. Al numeratore del rapporto \\(r\\) dobbiamo fare il prodotto tra due scalari: la densità (l’ordinata) della funzione di verosimiglianza corrispondenza del valore proposto \\(x = \\theta'_t\\) e la densità della distribuzione priori corrispondenza del valore proposto \\(x = \\theta'_t\\). maniera corrispondente, al denominatore del rapporto \\(r\\) dobbiamo fare il prodotto tra due scalari: la densità (l’ordinata) della funzione di verosimiglianza corrispondenza del valore \\(\\theta_{t-1}\\) e la densità della distribuzione priori corrispondenza del valore \\(\\theta_{t-1}\\).Calcoliamo poi il rapporto \\(r\\) tra la distribuzione posteriori non normalizzata determinata dal valore proposto \\(\\theta'_t\\) e la distribuzione posteriori non normalizzata determinata dal valore del parametro \\(\\theta'_{t-1}\\) dell’iterazione precedente della catena: \\(r = \\frac{P(x \\mid \\theta'_t) P(\\theta'_t)}{P(x \\mid \\theta'_{t-1}) P(\\theta'_{t-1})}\\). Soffermiamoci su tale formula per capire bene cosa significa. La distribuzione posteriori non normalizzata corrisponde al numeratore del teorema di Bayes, ovvero \\(P(x \\mid \\theta) P(\\theta)\\), laddove \\(P(x \\mid \\theta)\\) è la verosimiglianza di \\(x\\) dato \\(\\theta\\) e \\(P(\\theta)\\) è la distribuzione priori di \\(\\theta\\). Abbiamo visto nella sezione Un esempio pratico (versione 2) che ciascuna di tali densità può essere rappresentata mediante una curva e che il prodotto di due densità si ottiene facendo il prodotto dei valori delle ordinate corrispondenti di discuna delle due curve. Il numeratore del teorema di Bayes ci fornisce la distribuzione posteriori non normalizzata quanto l’area sottesa alla curva così ottenuta non è unitaria (quindi tale curva non rappresenta una funzione di densità). Dato che qui facciamo un rapporto, però, questo è irrilevante. Al numeratore del rapporto \\(r\\) dobbiamo fare il prodotto tra due scalari: la densità (l’ordinata) della funzione di verosimiglianza corrispondenza del valore proposto \\(x = \\theta'_t\\) e la densità della distribuzione priori corrispondenza del valore proposto \\(x = \\theta'_t\\). maniera corrispondente, al denominatore del rapporto \\(r\\) dobbiamo fare il prodotto tra due scalari: la densità (l’ordinata) della funzione di verosimiglianza corrispondenza del valore \\(\\theta_{t-1}\\) e la densità della distribuzione priori corrispondenza del valore \\(\\theta_{t-1}\\).Utilizziamo poi il valore del rapporto \\(r\\) per decidere se dobbiamo effettivamente muoverci nella nuova posizione \\(\\theta'_t\\), oppure se dobbiamo campionare un diverso valore \\(\\theta'_t\\). Per decidere, confrontiamo il valore \\(r\\) con un valore casuale estratto da una distribuzione uniforme che assume valori tra zero e uno: \\(U(0, 1)\\). Se \\(r > u \\sim U(0, 1)\\) allora accettiamo \\(\\theta'_t\\) e la catena si muove quella nuova posizione, ovvero \\(\\theta_t = \\theta'_t\\). Altrimenti \\(\\theta_t = \\theta_{t-1}\\) e ripetiamo la procedura descritta sopra campionando un nuovo valore \\(\\theta'_t\\).Utilizziamo poi il valore del rapporto \\(r\\) per decidere se dobbiamo effettivamente muoverci nella nuova posizione \\(\\theta'_t\\), oppure se dobbiamo campionare un diverso valore \\(\\theta'_t\\). Per decidere, confrontiamo il valore \\(r\\) con un valore casuale estratto da una distribuzione uniforme che assume valori tra zero e uno: \\(U(0, 1)\\). Se \\(r > u \\sim U(0, 1)\\) allora accettiamo \\(\\theta'_t\\) e la catena si muove quella nuova posizione, ovvero \\(\\theta_t = \\theta'_t\\). Altrimenti \\(\\theta_t = \\theta_{t-1}\\) e ripetiamo la procedura descritta sopra campionando un nuovo valore \\(\\theta'_t\\).Per fare un esempio concreto, consideriamo nuovamente 30 pazienti esaminati da Zetsche et al. (2019) e discussi nella sezione Un esempio pratico. Di essi, 23 hanno manifestato delle aspettative distorte negativamente sul loro stato d’animo futuro. Utilizzando l’algoritmo di Metropolis, ci poniamo il problema di ottenere la stima posteriori di \\(\\theta\\) (probabilità di manifestare un’aspettativa distorta negativamente) dati 23 “successi” 30 prove e usando la stessa distribuzione priori per \\(\\theta\\) che è stata usata nella sezione Un esempio pratico (versione 2).","code":""},{"path":"stima-della-funzione-a-posteriori.html","id":"verosimiglianza","chapter":"Capitolo 25 Stima della funzione a posteriori","heading":"25.8.1 Verosimiglianza","text":"Per trovare la funzione di verosimiglianza usando 30 valori di Zetsche et al. (2019) definisco la funzione likelihood() come indicato sotto. Tale funzione ritorna l’ordinata della funzione di verosimiglianza binomiale per ciascun valore del vettore param che viene dato input alla funzione.","code":"\nx <- 23\nN <- 30\nparam <- seq(0, 1, length.out = 100)\n\nlikelihood <- function(param, x = 23, N = 30) {\n  dbinom(x, N, param)\n}\n\ndata.frame(x=param, y=likelihood(param)) %>% \n  ggplot(aes(x, y)) +\n  geom_line() +\n  labs(\n    x = expression(theta),\n    y = \"Verosimiglianza\"\n  )"},{"path":"stima-della-funzione-a-posteriori.html","id":"distribuzione-a-priori-1","chapter":"Capitolo 25 Stima della funzione a posteriori","heading":"25.8.2 Distribuzione a priori","text":"Se abbiamo ragioni forti per avere delle aspettative rispetto al valore possibile della nostra stima, una distribuzione priori informativa verrà combinata con le informazioni fornite dal campione per produrre una stima ``razionale’’ posteriori. Nel caso presente utilizziamo la distribuzione informativa presentata nella sezione Un esempio pratico (versione 2) unicamente scopo esemplicativo, ovvero per fare modo da “allontanare” la distribuzione posteriori dalla distribuzione di verosimiglianza.","code":"\nprior <- function(param, alpha = 2, beta = 10) {\n  param_vals <- seq(0, 1, length.out = 100)\n  dbeta(param, alpha, beta) # / sum(dbeta(param_vals, alpha, beta))\n}\n\ndata.frame(x=param, y=prior(param)) %>% \n  ggplot(aes(x, y)) +\n  geom_line() +\n  labs(\n    x = expression(theta),\n    y = \"Densità\"\n  )"},{"path":"stima-della-funzione-a-posteriori.html","id":"distribuzione-a-posteriori","chapter":"Capitolo 25 Stima della funzione a posteriori","heading":"25.8.3 Distribuzione a posteriori","text":"Abbiamo visto precedenza come la funzione posteriori è data dal prodotto della densità priori e della verosimiglianza.Questo è il risultato che vogliamo ottenere utilizzando l’algoritmo di Metropolis. Dalla figura precedente vediamo che la moda della distribuzione posteriori è pari circa 0.6. Questo è il valore più verosimile posteriori per il parametro \\(\\theta\\).","code":"\nposterior <- function(param) {\n  likelihood(param) * prior(param)\n}\n\ndata.frame(x=param, y=posterior(param)) %>% \n  ggplot(aes(x, y)) +\n  geom_line() +\n  labs(\n    x = expression(theta),\n    y = \"Densità\"\n  )"},{"path":"stima-della-funzione-a-posteriori.html","id":"algoritmo-di-metropolis","chapter":"Capitolo 25 Stima della funzione a posteriori","heading":"25.8.4 Algoritmo di Metropolis","text":"Implementiamo ora l’algoritmo di Metropolis. Utilizziamo una distribuzione proposta gaussiana. Il valore proposto da tale distribuzione ausiliaria corrisponde ad un valore selezionato caso da una distribuzione gaussiana con media uguale al valore del parametro attualmente considerato nella catena e con una deviazione standard ``adeguata’’. questo esempio, la deviazione standard è stata scelta empiricamente modo tale da ottenere un tasso di accettazione sensato. È stato mostrato che un tasso di accettazione ottimale dovrebbe essere tra il 20% e il 30%. Se il tasso di accettazione è troppo grande, infatti, l’algoritmo esplora uno spazio troppo ristretto della distribuzione posteriori. Il tasso di accettazione è influenzato dalla distribuzione proposta: generale, tanto più la distribuzione proposta è simile alla distribuzione target, tanto più alto diventa il tasso di accettazione.questa implementazione molto semplice della distribuzione proposta ho inserito dei controlli che fanno modo che il valore proposto da tale distribuzione ausiliaria sia incluso nell’intervallo [0, 1]. Si possono trovare implementazioni migliori di questa idea di quella fornita qui. Ma lo scopo è solo quello di spiegare la struttura logica dell’algoritmo di Metropolis, non quella di proporre un’implementazione efficente dell’algoritmo. Per nostri scopi, tale implementazione “ingenua” funziona, e tanto basta.L’algoritmo di Metropolis è implementato nella funzione seguente:Generiamo dunqe una catena di valori \\(\\theta\\) con le seguenti istruzioni:Otteniamo così 4,000 valori della distribuzione posteriori per il parametro \\(\\theta\\). Di questi valori, 2,000 vengono considerati burn-e vengono esclusi. Ci restano dunque con 2,000 stime posteriori di \\(\\theta\\).Il tasso di accettazione è pari ail che conferma che la deviazione standard che abbiamo scelto per la distribuzione proposta (\\(\\sigma\\) = 0.9) è adeguata.Una figura che rappresenta la distribuzione posteriori per \\(\\theta\\), insieme alla rappresentazione dei valori della catena di Markov realizzata dall’algoritmo di Metropolis, può essere prodotta mediante le seguenti istruzioni:questo punto è molto facile trovare il massimo posteriori per il parametro \\(\\theta\\):","code":"\nproposal_distribution <- function(param) {\n  while(1) {\n    res = rnorm(1, mean = param, sd = 0.9)\n    if (res > 0 & res < 1)\n      break\n  }\n  res\n}\nrun_metropolis_MCMC <- function(startvalue, iterations) {\n  chain <- vector(length = iterations + 1)\n  chain[1] <- startvalue\n  for (i in 1:iterations) {\n    proposal <- proposal_distribution(chain[i])\n    r <- posterior(proposal) / posterior(chain[i])\n    if (runif(1) < r) {\n      chain[i + 1] <- proposal\n    } else {\n      chain[i + 1] <- chain[i]\n    }\n  }\n  chain\n}\nset.seed(123)\nstartvalue <- runif(1, 0, 1)\nniter <- 1e4\nchain <- run_metropolis_MCMC(startvalue, niter)\nburnIn <- niter / 2\nacceptance <- 1 - mean(duplicated(chain[-(1:burnIn)]))\nacceptance\n#> [1] 0.2511498\np1 <- data.frame(x=chain[-(1:burnIn)]) %>% \n  ggplot(aes(x)) +\n  geom_histogram() +\n  labs(\n    x = expression(theta),\n    y = \"Frequenza\", \n    title = \"Distribuzione a posteriori\"\n  ) +\n  geom_vline(xintercept = mean(chain[-(1:burnIn)]))\n\np2 <- data.frame(x=1:length(chain[-(1:burnIn)]), y=chain[-(1:burnIn)]) %>% \n  ggplot(aes(x, y)) +\n  geom_line() +\n  labs(\n    x = \"Numero di passi\",\n    y = expression(theta), \n    title = \"Valori della catena\"\n  ) +\n  geom_hline(yintercept = mean(chain[-(1:burnIn)]))\n\np1 + p2\n#> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\nmean(chain[-(1:burnIn)])\n#> [1] 0.5921799"},{"path":"stima-della-funzione-a-posteriori.html","id":"conclusioni-11","chapter":"Capitolo 25 Stima della funzione a posteriori","heading":"Conclusioni","text":"Lo scopo di questa discussione è stato quello di mostrare come sia possibile combinare le nostre conoscenze priori (espresse nei termini di una densità di probabilità) con le evidenze fornite dai dati (espresse nei termini della funzione di verosimiglianza), così da determinare, mediante il teorema di Bayes, una distribuzione posteriori, la quale condensa l’incertezza che si ha sul parametro \\(\\theta\\). Per illustrare tale problema, nel caso più semplice abbiamo considerato una situazione nella quale \\(\\theta\\) corrisponde alla probabilità di successo una sequenza di prove Bernoulliane. Abbiamo visto come, queste circostanze, è ragionevole esprimere le nostre credenze priori mediante la densità Beta, con opportuni parametri. L’inferenza rispetto ad una proporzione rappresenta un caso particolare, ovvero un caso nel quale la distribuzione priori è Beta e la verosimiglianza è Binomiale. tali circostanze, anche la distribuzione posteriori sarà una distribuzione Beta. Per questa ragione, questo caso specifico, parametri della distribuzione posteriori possono essere determinati analiticamente (la soluzione richiede una serie di passaggi algebrici che qui non vengono discussi). generale, però, tale approccio non è perseguibile.La determinazione della distribuzione posteriori richiede il calcolo della funzione di verosimiglianza e dell’integrale che si trova al denominatore del rapporto di Bayes. Nel caso di parametri continui, però, spesso tale integrale può essere impossibile da risolvere analiticamente. passato, tale difficoltà è stata affrontata limitando l’analisi statistica al caso di funzioni di verosimiglianza semplici, le quali possono essere combinate con distribuzioni priori coniugate per la verosimiglianza, così da produrre un integrale trattabile.Invece di approcci matematici analitici, un’altra classe di metodi fa ricorso ’approssimazione numerica dell’integrale. Tale approssimazione numerica dipende dall’uso di metodi MCMC, ovvero dipende dall’uso di una classe di algoritmi per il campionamento da distribuzioni di probabilità che sono estremamente onerosi dal punto di vista computazionale e che possono essere utilizzati nelle applicazioni pratiche solo grazie alla grande potenza di calcolo dei moderni computer. Lo sviluppo di software che rendono sempre più semplice l’uso dei metodi MCMC, insieme ’incremento della potenza di calcolo dei computer, ha contribuito rendere sempre più popolare il metodo dell’inferenza Bayesiana che, questo modo, può essere estesa problemi di qualunque grado di complessità.Come ci ricorda Richard McElreath, nel 1989 erano popolari Depeche Mode, fu rilasciata la prima versione di Microsoft Office, grandi dimostrazioni popolari contribuirono ad abbattere il muro di Berlino e un gruppo di statistici nel Regno Unito si posero il problema di come potere simulare le catene di Markov su un personal computer. Nel 1997 ci riuscirono, con il primo rilascio pubblico di un’implementazione Windows dell’inferenza bayesiana basata su Gibbs sampling, detta BUGS. Quello che discutiamo questo insegnamento sono gli sviluppi contemporanei del percorso che è iniziato questo modo.","code":""},{"path":"sintesi-a-posteriori.html","id":"sintesi-a-posteriori","chapter":"Capitolo 26 Sintesi a posteriori","heading":"Capitolo 26 Sintesi a posteriori","text":"La distribuzione posteriori è un modo per descrivere il nostro grado\ndi incertezza rispetto al parametro incognito (o rispetto ai parametri\nincogniti) oggetto dell’inferenza. La distribuzione posteriori\ncontiene tutte le informazioni disponibili sui possibili valori del\nparametro. Se il parametro esaminato è monodimensionale (o\nbidimensionale) è possibile fornire un grafico di tutta la distribuzione\nposteriori \\(p(\\theta \\mid \\mathcal{Y})\\). Tuttavia, spesso vogliamo anche\ngiungere ad una sintesi numerica della distribuzione posteriori,\nsoprattutto se il vettore dei parametri ha più di due dimensioni. \nquesto proposito è possibile utilizzare le consuete statistiche\ndescrittive, come media, mediana, moda, varianza, deviazione standard e\ndiversi quantili. alcuni casi, queste statistiche descrittive sono\npiù facili da presentare e interpretare rispetto alla rappresentazione\ngrafica completa della distribuzione posteriori.","code":""},{"path":"sintesi-a-posteriori.html","id":"stima-puntuale","chapter":"Capitolo 26 Sintesi a posteriori","heading":"26.1 Stima puntuale","text":"Per sintetizzare la distribuzione posteriori modo da giungere ad\nuna stima puntuale di \\(\\theta\\) si è soliti scegliere tra moda, mediana o\nmedia seconda del tipo di distribuzione con cui si ha che fare e\ndella sua forma. Ogni stima puntuale ha una sua interpretazione. La\nmedia è il valore atteso posteriori del parametro. La moda può essere\ninterpretata come il singolo valore più credibile (“più probabile”) del\nparametro, dati dati, ovvero il valore per il parametro \\(\\theta\\) che\nmassimizza la distribuzione posteriori. Per questa ragione la moda\nviene detta massimo posteriori, MAP. Il limite della moda quale\nstatistica riassuntiva della distribuzione posteriori è che, talvolta,\ntale distribuzione è multimodale e il MAP non è necessariamente il\nvalore “più credibile.” Infine, la mediana è il valore del parametro\ntale per cui, su entrambi lati di essa, giace il 50% della massa di\nprobabilità posteriori.La misura di variabilità per il parametro è la varianza posteriori\nla quale, nel caso di una distribuzione posteriori ottenuta per via\nnumerica, si calcola con la formula della varianza che conosciamo\nrispetto alla tendenza centrale data dalla media posteriori. La radice\nquadrata della varianza posteriori è la deviazione standard \nposteriori che fornisce l’incertezza posteriori circa il parametro di\ninteresse il quale, un’ottica bayesiana, è una variabile aleatoria.Tutte le procedure bayesiane si basano su sull’uso di metodi MCMC per\nottenere le stime posteriori. Usando un numero finito di campioni, le\nsimulazioni introducono un ulteriore livello di incertezza\nsull’accuratezza della stima. L’errore standard della stima (\ninglese Monte Carlo standard error, MCSE) misura l’accuratezza della\nsimulazione. La deviazione standard posteriori e l’errore standard\ndella stima sono due concetti molto diversi. La deviazione standard \nposteriori descrive l’incertezza circa il parametro ed è una funzione\ndella dimensione del campione; il MCSE descrive invece l’incertezza\nnella stima del parametro come risultato della simulazione MCMC ed è una\nfunzione del numero di iterazioni nella simulazione.","code":""},{"path":"sintesi-a-posteriori.html","id":"intervallo-di-credibilità","chapter":"Capitolo 26 Sintesi a posteriori","heading":"26.2 Intervallo di credibilità","text":"Molto spesso la stima puntuale è accompagnata da una stima intervallare.\nNella statistica bayesiana, se il parametro \\(\\theta \\\\Theta\\) è\nmonodimensionale, si dice “intervallo di credibilità” (o intervallo di\nconfidenza bayesiano) un intervallo di valori \\(I_{\\alpha}\\) che contiene\nla proporzione \\(1 - \\alpha\\) della massa di probabilità della funzione \nposteriori:\n\\[\\begin{equation}\np(\\Theta \\I_{\\alpha} \\mid \\mathcal{Y}) = 1 - \\alpha.\n\\tag{26.1}\n\\end{equation}\\]\nL’intervallo di credibilità ha lo scopo di\nesprimere il nostro grado di incertezza riguardo la stima del parametro.\nSe il parametro \\(\\theta\\) è multidimensionale, si parla invece di\n“regione di credibilità.”La condizione (26.1) non determina un unico intervallo di\ncredibilità al \\((1 - \\alpha) \\cdot 100\\%\\). realtà esiste un numero\ninfinito di tali intervalli. Ciò significa che dobbiamo definire alcune\ncondizioni aggiuntive per la scelta dell’intervallo di credibilità.\nEsaminiamo due delle condizioni aggiuntive più comuni.","code":""},{"path":"sintesi-a-posteriori.html","id":"intervallo-di-credibilità-a-code-uguali","chapter":"Capitolo 26 Sintesi a posteriori","heading":"26.2.1 Intervallo di credibilità a code uguali","text":"Un intervallo di credibilità code uguali livello \\(\\alpha\\) è un\nintervallo \\[I_{\\alpha} = [q_{\\alpha/2}, 1 - q_{\\alpha/2}],\\] dove \\(q_z\\)\nè un quantile \\(z\\) della distribuzione posteriori. Per esempio,\nl’intervallo di credibilità code uguali al 95% è un intervallo\n\\[I_{0.05} = [q_{0.025}, q_{0.975}]\\] che lascia il 2.5% della massa di\ndensità posteriori ciascuna coda. Un esempio è fornito nella\nfigura successiva che fornisce una generica rappresentazione di una distribuzione priori e di una distribuzione posteriori; l’area evidenziata grigio rappresenta l’intervallo di credibilità code uguali al 95%.","code":""},{"path":"sintesi-a-posteriori.html","id":"intervallo-di-credibilità-a-densità-a-posteriori-più-alta","chapter":"Capitolo 26 Sintesi a posteriori","heading":"26.2.2 Intervallo di credibilità a densità a posteriori più alta","text":"Nell’intervallo di credibilità code uguali alcuni valori del parametro\nche sono inclusi nell’intervallo possono avere una più bassa probabilità\nposteriori rispetto quelli fuori dell’intervallo. L’intrevallo di\ncredibilità densità posteriori più alta (inglese High\nPosterior Density Interval, HPD) è invece costruito modo tale da\nassicurare di avere ’interno dell’intervallo tutti valori di\n\\(\\theta\\) che sono posteriori più plausibili. Graficamente questo\nintervallo può essere ricavato tracciando una linea orizzontale sulla\nrappresentazione della distribuzione posteriori e regolando l’altezza\ndella linea modo tale che l’area sotto la curva sia pari \n\\(1 - \\alpha\\). Questo tipo di intervallo è il meno ampio che si possa\ndeterminare e inoltre se la distribuzione posteriori è simmetrica\nunimodale l’intervallo di credibilità densità posteriori più alta\ncorrisponde ’intervallo di credibilità code uguali.","code":""},{"path":"sintesi-a-posteriori.html","id":"interpretazione","chapter":"Capitolo 26 Sintesi a posteriori","heading":"26.3 Interpretazione","text":"L’interpretazione dell’intervallo di credibilità è molto intuitiva:\nl’intervallo di credibilità è un intervallo di valori ’interno del\nquale cade il valore del parametro incognito con un particolare livello\ndi probabilità soggettiva. Possiamo dire che, dopo aver visto dati\ncrediamo, con un determinato livello di probabilità soggettiva, che il\nvalore del parametro (ad esempio, la dimensione dell’effetto di un\ntrattamento) abbia un valore compreso ’interno dell’intervallo che è\nstato calcolato, laddove per probabilità soggettiva intendiamo “il grado\ndi fiducia che lo sperimentatore ripone nel verificarsi di un evento.”\nSolitamente gli intervalli di credibilità si calcolano con un software.","code":""},{"path":"sintesi-a-posteriori.html","id":"un-esempio-concreto","chapter":"Capitolo 26 Sintesi a posteriori","heading":"26.4 Un esempio concreto","text":"Consideriamo nuovamente l’esempio del mappamondo, ovvero il problema di\ntrovare la distribuzione posteriori della probabilità di “acqua.”\nRicordiamo che abbiamo osservato “acqua” 6 volte 9 lanci. Abbiamo\nvisto come sia possibile, mediante il metodo dell’approssimazione\nnumerica, trovare la distribuzione posteriori di \\(p\\) (probabilità di\nosservare “acqua”) assumendo, ad esempio, una distribuzione uniforme per\nil parametro di interesse. Le istruzioni R per ottenere tale risultato\nsono riportate qui sotto.Consideriamo ora la possibilità di estrarre 10000 valori del parametro\n\\(p\\) casuali dalla distribuzione posteriori. Immaginiamo che la\ndistribuzione posteriori sia un’urna che contiene valori del\nparametro \\(p\\) (ovvero, numeri come 0.107, 0.793, 0.534, 0.908, ecc.).\n’interno dell’urna, ciascun valore esiste proporzione alla sua\ndensità posteriori: valori nell’intorno della moda della\ndistribuzione posteriori sono molto più comuni di quelli che si\ntrovano nelle code. Estrarremo ora 10000 valori da quest’urna. Se \nvalori nell’urna sono ben mescolati, il campione che verrà estratto avrà\nle stesse proporzioni della densità posteriori. Pertanto, il nostro\ncampione conterrà valori di \\(p\\) che si addenseranno sulla linea dei\nnumeri reali maniera proporzionale alla densità della distribuzione \nposteriori. Questo risultato può essere ottenuto   con una riga di\ncodice:La funzione sample() estrae caso (con rimessa) 10000 valori dal\nvettore p_grid, associando ciascun valore p_grid una probabilità\ndi essere estratto proporzionale alla densità della distribuzione \nposteriori, così come specificato dall’argomento prob = posterior. Il\ncampione dei 10000 valori posteriori del parametro è rappresentato\nnella figura seguente che riporta la densità della distribuzione posteriori del parametro \\(p\\) = probabilità di osservare “acqua” nell’esperimento casuale del mappamondo.","code":"\n# Grid\nn_points <- 1e4\np_grid <- seq(from = 0, to = 1, length.out = n_points)\n# Prior\nalpha <- 1\nbeta <- 1\nprior <- dbeta(p_grid, alpha, beta) / \n  sum(dbeta(p_grid, alpha, beta))\n# Likelihood\nk <- 6\nn <- 9\nlikelihood <- dbinom(k, size = n, prob = p_grid)\n# Unstandardized posterior\nunstd_posterior <- likelihood * prior\n# Posterior distribution\nposterior <- unstd_posterior / sum(unstd_posterior)\nsamples <- sample(\n  p_grid, prob = posterior, size = 1e4, replace = TRUE\n)\ndens(samples) "},{"path":"sintesi-a-posteriori.html","id":"indici-di-sintesi-della-distribuzione-a-posteriori","chapter":"Capitolo 26 Sintesi a posteriori","heading":"26.4.1 Indici di sintesi della distribuzione a posteriori","text":"Una volta trovata la distribuzione posteriori prodotta\ndall’aggiornamento Bayesiano, il lavoro del modello statistico è\nterminato. Ma il lavoro del ricercatore è appena iniziato. È infatti\nnecessario sintetizzare e interpretare la distribuzione posteriori.\nEsattamente quali indici di sintesi usare dipende dallo scopo della\nricerca. Ma le domande più comuni includono:Qual è la probabilità posteriori che può essere associata valori\ndel parametro minori di un certo valore?Qual è la probabilità posteriori che può essere associata valori\ndel parametro minori di un certo valore?Qual è la probabilità posteriori che può essere associata ad un\nintervallo di valori del parametro?Qual è la probabilità posteriori che può essere associata ad un\nintervallo di valori del parametro?Quale valore del parametro corrisponde al 5% inferiore della\ndistribuzione posteriori?Quale valore del parametro corrisponde al 5% inferiore della\ndistribuzione posteriori?Quale intervallo di valori del parametro contiene il 90% della\ndistribuzione posteriori?Quale intervallo di valori del parametro contiene il 90% della\ndistribuzione posteriori?quale valore del parametro è associata la densità posteriori\nmaggiore?quale valore del parametro è associata la densità posteriori\nmaggiore?","code":""},{"path":"sintesi-a-posteriori.html","id":"probabilità-della-distribuzione-a-posteriori","chapter":"Capitolo 26 Sintesi a posteriori","heading":"26.4.2 Probabilità della distribuzione a posteriori","text":"Supponiamo che si voglia conoscere la probabilità posteriori che la\nproporzione di acqua sia inferiore 0.5. Supponiamo inoltre di volere\nrispondere questa domanda avendo disposizione dati forniti dal\nmetodo dell’approssimazione numerica. Ricordiamo che, mediante il metodo\ndell’approssimazione numerica, la distribuzione posteriori è una\ndistribuzione di massa di probabilità. Dunque, usando il metodo\ndell’approssimazione numerica, è possibile trovare la risposta alla\ndomanda che ci siamo posti semplicemente sommando tutte le probabilità\nper le quali il valore del parametro è inferiore 0.5:ovvero 0.17. Questo significa che l’area sottesa alla distribuzione \nposteriori del parametro \\(p\\) nell’intervallo \\([-\\infty, 0.5]\\) è circa\nuguale al 17%.Usando lo stesso approccio è possibile trovare l’area sottesa alla\ndistribuzione posteriori nell’intervallo compreso tra 0.5 e 0.75:ovvero 0.6. Quindi, l’area sottesa alla funzione di densità \nposteriori nell’intervallo compreso tra 0.5 e 0.75 è pari circa il\n61%.Negli esempi discussi sopra, il codice R utilizza la funzione sum()\nper contare quanti elementi del vettore samples soddisfano un criterio\nlogico. Perché è possibile fare questo? Questo è possibile perché R\nconverte internamente un’espressione logica, come samples < 0.5 un\nvettore di risultati TRUE e FALSE, uno per ciascun elemento del\nvettore samples, indicando se ciascun elemento di samples soddisfa o\nmeno il criterio logico. Quando questo vettore di TRUE e FALSE viene\nsommato, R valuta ogni TRUE come 1 e ogni FALSE come 0. Quindi\nfinisce per contare quanti valori TRUE sono presenti nel vettore, il\nche è la stessa cosa che contare il numero di elementi samples che\nsoddisfano il criterio logico.","code":"\nsum(samples < 0.5) / n_points\n#> [1] 0.1696\nsum(samples > 0.5 & samples < 0.75) / n_points\n#> [1] 0.6"},{"path":"sintesi-a-posteriori.html","id":"quantili-della-distribuzione-a-posteriori","chapter":"Capitolo 26 Sintesi a posteriori","heading":"26.4.3 Quantili della distribuzione a posteriori","text":"È più comune sintetizzare la distribuzione posteriori mediante un\nintervallo di valori, detto “intervallo di credibilità.” Supponiamo di\nvolere trovare il quantile di ordine 0.8 per la distribuzione \nposteriori. Questo risultato, utilizzando il metodo dell’approssimazione\nnumerica, può essere trovato nel modo seguente.ovvero, 0.76. maniera simile, l’intervallo che lascia il 2.5%\ndell’area della distribuzione posteriori ciascuna coda èLa funzione PI() (percentile intervals) del pacchetto rethinking\nrestituisce lo stesso risultato:Se la distribuzione posteriori è asimmetrica, non è sempre una buona\nidea utilizzare l’approccio descritto sopra per calcolare gli intervalli\ndi credibilità. Un approccio alternativo è quello di calcolare\nl’intervallo minore che contiene la massa di probabilità specificata –\nquesto non corrisponde necessariamente con l’intervallo che lascia la\nstessa massa di probabilità ciascuna coda. Tale intervallo può essere\ntrovato con la funzione HPDI() di rethinking:Nel caso presente, il risultato di HPDI() è molto simile quello trovato precedenza. Ma questo non è sempre vero.","code":"\nquantile(samples, 0.8)\n#>       80% \n#> 0.7627763\nquantile(samples, c(0.025, 0.975))\n#>      2.5%     97.5% \n#> 0.3554230 0.8824907\nPI(samples, prob = 0.95)\n#>        3%       98% \n#> 0.3554230 0.8824907\nHPDI(samples, prob = 0.95)\n#>     |0.95     0.95| \n#> 0.3610361 0.8860886"},{"path":"sintesi-a-posteriori.html","id":"stime-puntuali-della-distribuzione-a-posteriori","chapter":"Capitolo 26 Sintesi a posteriori","heading":"26.4.4 Stime puntuali della distribuzione a posteriori","text":"Una volta trovata l’intera distribuzione posteriori, quale valore di\nsintesi è necessario riportare? Questa sembra una domanda innocente, ma\nrealtà è una domanda cui è difficile rispondere. La stima Bayesiana\ndei parametri è fornita dall’intera distribuzione posteriori, che non\nè un singolo numero, ma una funzione che mappa ciascun valore di\nparametro ad un valore di plausibilità. Quindi la cosa più importante da\ncapire è che non è necessario scegliere una stima puntuale. linea di\nprincipio, ciò non è quasi mai necessario ed è spesso dannoso quanto\ncomporta una perdita di informazioni.Tuttavia ci sono dei casi nei quali tale scelta è necessaria. Diverse\nrisposte sono possibili. Una stima del massimo della probabilità \nposteriori, o brevemente massimo posteriori, MAP (da maximum \nposteriori probability), è una moda della distribuzione posteriori.\nNel caso del metodo dell’approssimazione numerica, una stima del MAP può\nessere ottenuta nel modo seguente:e, nel caso presente, corrisponde 0.67. Lo stesso risultato si\nottiene utilizzando campioni della distribuzione posteriori:alternativa, si possono calcolare la media o la medianale quali, nel caso presente, sono entrambe uguali 0.64.","code":"\np_grid[which.max(posterior)]\n#> [1] 0.6666667\nchainmode(samples, adj = 0.01)\n#> [1] 0.6966315\nmean(samples)\n#> [1] 0.6381123\nmedian(samples)\n#> [1] 0.6453645"},{"path":"sintesi-a-posteriori.html","id":"conclusioni-12","chapter":"Capitolo 26 Sintesi a posteriori","heading":"Conclusioni","text":"Questo capitolo ha introdotto le procedure di base per la manipolazione\ndella distribuzione posteriori. Lo strumento fondamentale che è stato\nutilizzato è quello fornito dai campioni di valori dei parametri tratti\ndalla distribuzione posteriori. Lavorare con campioni di parametri\ntratti dalla distribuzione posteriori trasforma un problema di calcolo\nintegrale un problema di riepilogo dei dati. Abbiamo visto quali sono\nle procedure che, mediante R, consentono di utilizzare campioni \nposteriori per produrre gli indici di sintesi della distribuzione \nposteriori più usati: gli intervalli di credibilità e le stime puntuali.","code":""},{"path":"una-breve-introduzione-al-modello-di-regressione.html","id":"una-breve-introduzione-al-modello-di-regressione","chapter":"Capitolo 27 Una breve introduzione al modello di regressione","heading":"Capitolo 27 Una breve introduzione al modello di regressione","text":"questo capitolo verrà presentata un’introduzione “pratica” ’analisi della regressione. Qui ci preoccuperemo solo di capire cosa serve l’analisi di regressione e come si interpretano risultati prodotti da tale metodo di analisi statistica. Nel capitolo successivo, gli stessi argomenti verranno trattati un modo più “formale” e con maggiori approfondimenti teorici. Questo capitolo contiene tutto quello che c’è da sapere e non si può non sapere su questo argomento.\nL’ho pensato per miei laureandi, ovvero per degli studenti che devono usare queste procedure statistiche per risolvere un problema pratico (quello di concludere la tesi). L’altro capitolo è più convenzionalmente “didattico” ed è stato pensato primo luogo per chi deve superare l’esame di Psicometria. Questo primo capitolo su questo tema può essere dunque pensato come un’introduzione “gentile” ciò che verrà discusso nel prossimo capitolo.","code":""},{"path":"una-breve-introduzione-al-modello-di-regressione.html","id":"regressione-bivariata","chapter":"Capitolo 27 Una breve introduzione al modello di regressione","heading":"27.1 Regressione bivariata","text":"La regressione è una classe di tecniche statistiche che si pongono il problema di comprendere la relazione che intercorre tra una variabile di esito (chiamata anche criterio / risposta / variabile dipendente) e una o più predittori (chiamate anche variabili esplicative / indipendenti). Considereremo inizialmente il caso di una sola variabile esplicativa.maniera più specifica, possiamo dire che la regressione bivariata si pone il problema di descrivere la relazione statistica lineare che intercorre tra due variabili, \\(x\\) e \\(y\\). Per relazione “statistica” intendo dire che, un campione di dati \\(\\{x, y\\}\\), non c’è mai una “perfetta” relazione lineare. Consideriamo le le coppie \\(\\{x_i, y_i\\}\\), con = 1, …, N, dove N è l’ampiezza campionaria. Se rappresentiamo queste coppie di numeri un un diagramma cartesiano, otteniamo quello che si chiama un diagramma dispersione. Nel caso di dati reali, punti del diagramma dispersione di \\(\\{x, y\\}\\) non si situeranno mai tutti su una retta ma, alcuni casi, formeranno una nube di punti che può essere approssimata da una retta che passa attraverso la nube di punti. una tale situazione, è ragionevole descrivere la relazione tra le variabili \\(x\\) e \\(y\\) mediante la retta che approssima al meglio la nube di punti nel diagramma dispersione.L’analisi di regressione si pone tre problemi. Il primo è quello di stabilire qual è l’inclinazione della retta che passa il più vicino possibile ai punti del diagramma dispersione. Il secondo è quello di quantificare “la distanza media” tra punti del diagramma dispersione e la retta di regressione. Il terzo è quello di fare inferenza, ovvero di capire cosa ci dice la retta di regressione che abbiamo osservato nel campione proposito della possibile relazione tra \\(x\\) e \\(y\\) nella popolazione da cui il campione è stato tratto.","code":""},{"path":"una-breve-introduzione-al-modello-di-regressione.html","id":"scioglimento-del-ghiaccio-marino","chapter":"Capitolo 27 Una breve introduzione al modello di regressione","heading":"27.1.1 Scioglimento del ghiaccio marino","text":"Iniziamo con un esempio. Uno degli impatti più importanti dei cambiamenti climatici che stanno investendo il nostro Pianeta è la riduzione dell’estensione della calotta di ghiaccio marino artico. Poniamoci il problema di usare il modello di regressione per esplorare come l’estensione del ghiaccio marino artico sta cambiando nel tempo. dati sono forniti da National Snow Ice Data Center e sono espressi milioni di chilometri quadrati.dati sono seguenti:Quale domanda di ricerca possiamo porci con questi dati? Propongo la seguente domanda.Domanda di ricerca: l’estensione del ghiaccio marino artico sta diminuendo nel tempo?Per esplorare la risposta questa domanda, iniziamo creare una rappresentazione grafica dei dati. Dato che abbiamo due variabi continue (il tempo, espresso anni, e l’estensione del ghiaccio marino artico, milioni di chilometri quadrati), questi dati possono essere rappresentati graficamente mediante un diagramma dispersione.Vogliamo sapere come varia l’estensione del ghiaccio marino artico funzione del tempo e quindi rappresentiamo dati ponendo la variabile tempo sull’asse delle ascisse e l’estensione del ghiaccio marino artico sull’asse delle ordinate.\nGuardando la figura vediamo che è ragionevole descrivere mediante una retta la relazione tra l’estensione del ghiaccio marino artico (chiamiamola y) e il tempo (chiamiamolo x). Aggiungiamo al diagramma di dispersione una retta, scegliendola modo tale che si avvicini il più possibile alla nube di punti rappresentata nel grafico. Ovviamente, è possibile scegliere tra infinite rette diverse. La retta che è rappresentata qui è stata scelta base ad un criterio particolare, detto “dei minimi quadrati.” Vedremo meglio seguito cosa questo significa. Per ora ci accontentiamo di riconoscere che la nostra è una buona scelta, per gli scopi presenti.","code":"\ndata.frame(seaice)\n#>    year extent_north extent_south\n#> 1  1979       12.328       11.700\n#> 2  1980       12.337       11.230\n#> 3  1981       12.127       11.435\n#> 4  1982       12.447       11.640\n#> 5  1983       12.332       11.389\n#> 6  1984       11.910       11.454\n#> 7  1985       11.995       11.618\n#> 8  1986       12.203       11.088\n#> 9  1987       12.135       11.554\n#> 10 1988       11.923       12.131\n#> 11 1989       11.967       11.426\n#> 12 1990       11.694       11.410\n#> 13 1991       11.749       11.545\n#> 14 1992       12.110       11.399\n#> 15 1993       11.923       11.420\n#> 16 1994       12.011       11.774\n#> 17 1995       11.415       11.795\n#> 18 1996       11.841       11.769\n#> 19 1997       11.668       11.390\n#> 20 1998       11.757       11.738\n#> 21 1999       11.691       11.761\n#> 22 2000       11.508       11.747\n#> 23 2001       11.600       11.673\n#> 24 2002       11.363       11.222\n#> 25 2003       11.397       11.969\n#> 26 2004       11.240       11.961\n#> 27 2005       10.907       11.695\n#> 28 2006       10.773       11.461\n#> 29 2007       10.474       11.687\n#> 30 2008       10.978       12.239\n#> 31 2009       10.932       12.049\n#> 32 2010       10.711       12.107\n#> 33 2011       10.483       11.501\n#> 34 2012       10.406       12.004\n#> 35 2013       10.897       12.524\n#> 36 2014       10.790       12.776\n#> 37 2015       10.566       12.414\n#> 38 2016       10.151       11.156\n#> 39 2017       10.373       10.693\nseaice %>% \n  ggplot(aes(year, extent_north)) +\n  geom_point()\nseaice %>% \n  ggplot(aes(year, extent_north)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) \n#> `geom_smooth()` using formula 'y ~ x'"},{"path":"una-breve-introduzione-al-modello-di-regressione.html","id":"interpretazione-dei-coefficienti-a-e-b","chapter":"Capitolo 27 Una breve introduzione al modello di regressione","heading":"27.2 Interpretazione dei coefficienti \\(a\\) e \\(b\\)","text":"La retta che abbiamo disegnato nella figura precedente rappresenta la risposta alla nostra domanda di ricerca: l’estensione del ghiaccio marino artico sta diminuendo nel tempo.Anziché considerare questa risposta unicamente dal punto di vista grafico, proviamo descrivere la retta disegnata nella figura maniera quantitativa, con dei numeri. Per fare questo, dobbiamo innanzitutto ricordare qual è l’equazione di una retta:\\[\\begin{equation}\ny = + b \\times x\n\\end{equation}\\]Prima di calcolare coefficienti \\(\\) e \\(b\\) della retta di regressione, rimaneggiamo nostri dati. particolare, rinominiamo le variabili e indicizziamo gli anni da 1 39. Nel caso presente, vogliamo sapere se l’estensione del ghiaccio marino artico dall’inizio alla fine del periodo temporale considerato, indipendentemente dal fatto che l’anno iniziale sia il 1979 e l’anno finale il 2017. Quindi sottraiamo 1979 dalle modalità della variabile year modo tale che il primo punto temporale corrisponda zero.Il diagramma dispersione avrà ora la forma seguente:Per trovare coefficienti \\(\\) e \\(b\\) della retta di regressione possiamo usare, ad esempio, la funzione lm():L’output della funzione lm() ci dice che è uguale 12.501 e che b è uguale -0.055. Ma che significato (geometrico) hanno questi valori?Ai coefficienti \\(\\) e \\(b\\) possiamo assegnare la seguente interpretazione:il coefficiente \\(\\) rappresenta il valore della coordinata \\(y\\) (l’estensione del ghiaccio marino artico) della retta di regressione quando la coordinata \\(x\\) vale zero (nel nostro caso, l’anno 1979) – altre parole, corrisponde al punto dove la retta di regressione interseca l’asse \\(y\\) del sistema di assi cartesiani;il coefficiente \\(\\) rappresenta il valore della coordinata \\(y\\) (l’estensione del ghiaccio marino artico) della retta di regressione quando la coordinata \\(x\\) vale zero (nel nostro caso, l’anno 1979) – altre parole, corrisponde al punto dove la retta di regressione interseca l’asse \\(y\\) del sistema di assi cartesiani;il coefficiente \\(b\\) ci dice di quanto aumenta la coordinata \\(y\\) della retta di regressione, quando \\(x\\) aumenta di un’unità.il coefficiente \\(b\\) ci dice di quanto aumenta la coordinata \\(y\\) della retta di regressione, quando \\(x\\) aumenta di un’unità.Il valore \\(\\) = 12.501 significa che, nel 1979, l’estensione del ghiaccio marino artico era pari 12.501 milioni di chilometri quadrati, dato che la modalità x = 0 della variabile indipendente corrisponde ’anno 1979.Il segno di \\(b\\) è negativo; questo significa che l’estensione del ghiaccio marino artico sta diminuendo nel corso del tempo. Il valore -0.055 ci dice che, per ogni anno che passa (nel periodo dal 1979 al 2017), l’estensione del ghiaccio marino artico diminuisce, media, di -0.055 milioni di chilometri quadrati.Se guardiamo la figura, infatti, vediamo che, se ci sposiamo da \\(x = 10\\) \\(x = 20\\) (ovvero, di dieci anni), la coordinata \\(y\\) della retta diminuisce di 10 volte \\(b\\), ovvero di -0.55 milioni di chilometri quadrati. Questo è indicato nella figura qui sotto.","code":"\nseaice <- seaice %>% \n  mutate(\n    x = year - 1979\n  ) %>% \n  rename(\n    y = extent_north\n  )\nglimpse(seaice)\n#> Rows: 39\n#> Columns: 4\n#> $ year         <int> 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991…\n#> $ y            <dbl> 12.328, 12.337, 12.127, 12.447, 12.332, 11.910, 11.995, 12.203, 12.135, 11.9…\n#> $ extent_south <dbl> 11.700, 11.230, 11.435, 11.640, 11.389, 11.454, 11.618, 11.088, 11.554, 12.1…\n#> $ x            <dbl> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21…\nseaice %>% \n  ggplot(aes(x, y)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) \n#> `geom_smooth()` using formula 'y ~ x'\nfm <- lm(y ~ x, data = seaice)\ncoef(fm)\n#> (Intercept)           x \n#> 12.50131410 -0.05457389\ndplot <- data.frame(\n  x1 = 10,\n  x2 = 20,\n  y1 = 12.50131410 + -0.05457389 * 10,\n  y2 = 12.50131410 + -0.05457389 * 20\n)\n\nseaice %>%\n  ggplot(aes(x, y)) +\n  geom_point(color=\"gray\") +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_segment(aes(x = x2, y = y1, xend = x2, yend = y2),\n               arrow=arrow(), size=1.1, data = dplot) +\n  geom_segment(aes(x = x1, y = y1, xend = x2, yend = y1),\n               arrow=arrow(), size=1.1, data = dplot) +\n  annotate(\"text\", x = 24.0, y = 11.75, label = \"10 b = -0.55\") +\n  annotate(\"text\", x = 15, y = 12.15, label = \"delta x = 10.0\")\n#> `geom_smooth()` using formula 'y ~ x'"},{"path":"una-breve-introduzione-al-modello-di-regressione.html","id":"scomposizione-della-y","chapter":"Capitolo 27 Una breve introduzione al modello di regressione","heading":"27.3 Scomposizione della \\(y\\)","text":"Uno degli aspetti importanti della regressione lineare è che, pratica, la retta di regressione scompone ciascun punteggio \\(y\\) due componenti:\\[\\begin{equation}\ny = (+ b \\times x) + e\n\\end{equation}\\]laddove \\(\\hat{y} = + b \\times x\\) è la componente di \\(y\\) che è linearmente predicibile conoscendo \\(x\\), mentre la componente residua, \\(e\\), è la componente di \\(y\\) che non è linearmente predicibile conoscendo \\(x\\).Nei nostri dati, questi significa quanto segue. Esaminiamo le prime 5 osservazioni del nostro campione:Aggiungo al data.frame una colonna che rappresenta valori \\(y\\) predetti dal modello lineare (ovvero, \\(\\hat{y} = + b \\times x\\): le coordinate \\(y\\) della retta di regressione per ciascuna delle osservazioni):Aggiungo ora al data.frame residui del modello di regressione. residui sono definiti come\\[\\begin{equation}\ne = y - (+ b \\times x) = y - \\hat{y}\n\\end{equation}\\]ovveroCiò che volevamo dimostrare è che la somma di \\(\\hat{y}\\) e dei residui è uguale alla \\(y\\). Infatti:altre parole, il modello di regressone scompone la \\(y\\) due componenti: la porzione della \\(y\\) che possiamo prevedere conoscendo \\(x\\) (ovvero, \\(\\hat{y} = + b \\times x\\)) e la porzione della \\(y\\) che non possiamo prevedere sulla base di \\(x\\).","code":"\nseaice %>% \n  dplyr::select(x, y) %>% \n  top_n(5) \n#> Selecting by y\n#>   x      y\n#> 1 0 12.328\n#> 2 1 12.337\n#> 3 3 12.447\n#> 4 4 12.332\n#> 5 7 12.203\nseaice$yhat <- coef(fm)[1] + coef(fm)[2] * seaice$x\nseaice %>% \n  dplyr::select(x, y, yhat) %>% \n  top_n(5) \n#> Selecting by yhat\n#>   x      y     yhat\n#> 1 0 12.328 12.50131\n#> 2 1 12.337 12.44674\n#> 3 2 12.127 12.39217\n#> 4 3 12.447 12.33759\n#> 5 4 12.332 12.28302\nseaice$e <- seaice$y - (coef(fm)[1] + coef(fm)[2] * seaice$x)\nseaice %>% \n  dplyr::select(x, y, yhat, e) %>% \n  top_n(5) \n#> Selecting by e\n#>    x      y     yhat         e\n#> 1 13 12.110 11.79185 0.3181464\n#> 2 15 12.011 11.68271 0.3282942\n#> 3 19 11.757 11.46441 0.2925897\n#> 4 20 11.691 11.40984 0.2811636\n#> 5 22 11.600 11.30069 0.2993114\nseaice$sum <- seaice$yhat + seaice$e\nseaice %>% \n  dplyr::select(x, y, yhat, e, sum) %>% \n  top_n(5) \n#> Selecting by sum\n#>   x      y     yhat           e    sum\n#> 1 0 12.328 12.50131 -0.17331410 12.328\n#> 2 1 12.337 12.44674 -0.10974022 12.337\n#> 3 3 12.447 12.33759  0.10940756 12.447\n#> 4 4 12.332 12.28302  0.04898144 12.332\n#> 5 7 12.203 12.11930  0.08370310 12.203"},{"path":"una-breve-introduzione-al-modello-di-regressione.html","id":"metodo-di-stima-dei-coefficienti-del-modello-di-regressione","chapter":"Capitolo 27 Una breve introduzione al modello di regressione","heading":"27.3.1 Metodo di stima dei coefficienti del modello di regressione","text":"Come abbiamo fatto calcolare coefficienti dei minimi quadrati \\(\\) e \\(b\\)? Ci sono tanti metodi; il più comune si chiama “metodo dei minimi quadrati.” Lo esamineremo seguito. Per nostri scopi, è poco importante: per ora ci accontentiamo di chiedere ad R di fare calcoli per noi.","code":""},{"path":"una-breve-introduzione-al-modello-di-regressione.html","id":"inferenza-sul-modello-di-regressione","chapter":"Capitolo 27 Una breve introduzione al modello di regressione","heading":"27.4 Inferenza sul modello di regressione","text":"Finora siamo riusciti descrivere la relazione statistica tra \\(x\\) e \\(y\\) un campione di osservazioni. Siamo ben consapevoli che, un altro campione di osservazioni, la relazione statistica tra \\(x\\) e \\(y\\) non sarà identica quella osservata nel caso del primo campione – dato che dati saranno diversi. La domanda cruciale dunque diventa la seguente: quanto sono simili coefficienti dei minimi quadrati calcolati sui dati campionari ai coefficienti di un’ipotetica retta di regressione che, sempre mediante il metodo dei minimi quadrati, descriverebbe la relazione tra tutte le osservazioni \\(\\{x, y\\}\\) nella popolazione? Ciò che vogliamo è dunque una quantificazione della nostra incertezza: vogliamo sapere quanto dobbiamo fidarci delle stime campionarie come descrizioni dei valori (sconosciuti) della popolazione. Ci sono due possibilità.Se le stime di \\(\\) e \\(b\\) fornite dal particolare campione che abbiamo osservato sono simili ai valori teorici della popolazione, allora dati del campione ci forniscono informazioni utili per capire quali sono le proprietà della popolazione.Se le stime di \\(\\) e \\(b\\) fornite dal particolare campione che abbiamo osservato sono simili ai valori teorici della popolazione, allora dati del campione ci forniscono informazioni utili per capire quali sono le proprietà della popolazione.Se invece le stime campionarie di \\(\\) e \\(b\\) sono molto diverse dai valori teorici della popolazione, allora dati del campione non ci aiutano capire quali sono le proprietà della popolazione.Se invece le stime campionarie di \\(\\) e \\(b\\) sono molto diverse dai valori teorici della popolazione, allora dati del campione non ci aiutano capire quali sono le proprietà della popolazione.Il problema che abbiamo è quello di decidere quale di queste due situazioni ci troviamo: la prima o la seconda. Questo è il problema dell’inferenza statistica sul modello di regressione.Il problema dell’inferenza viene affrontato utilizzando gli strumenti della teoria della probabilità per costruire un intervallo di valori. Nell’approccio Bayesiano, tale intervallo di valori si chiama intervallo di credibilità. Se calcoliamo, ad esempio, l’intervallo di credibilità ’89% per il parametro \\(\\beta\\) (inclinazione della retta di regressione nella popolazione), interpretiamo tale intervallo di valori nel modo seguente: possiamo dire che “siamo sicuri ’89% che il vero valore di \\(\\beta\\) è contenuto nell’intervallo stimato” – laddove per “vero valore di \\(\\beta\\)” intendiamo il valore del parametro sconosciuto della popolazione. Se calcoliamo l’intervallo di credibilità, ad un dato livello di certezza, possiamo giungere una di tre possibili conclusioni.L’intervallo di credibilità non include lo 0 e il suo limite inferiore è positivo: possiamo concludere, con una certezza dell’89%, che c’è una relazione positiva tra \\(x\\) e \\(y\\) nella popolazione;l’intervallo di credibilità non include lo 0 e il suo limite superiore è negativo: possiamo concludere, con una certezza del’89%, che c’è una relazione negativa tra \\(x\\) e \\(y\\) nella popolazione;l’intervallo di credibilità include lo 0: con un un livello di certezza dell’89%, non possiamo negare la possibilità che nella popolazione la relazione tra \\(x\\) e \\(y\\) sia nulla – ovvero, non abbiamo sufficienti informazioni per sapere se è positiva o negativa.Ritorniamo ora ai nostri dati e calcoliamo, con un metodo che discuteremo seguito, l’intervallo di credibilità ’89%. Per ora non ci preoccupiamo della sintassi dei comandi R, né di cosa significano tali istruzioni. Ci preoccupiamo solo di ottenere le stime dei coefficienti della retta di regressione e gli intervalli di credibilità:L’intervallo di credibilità per \\(b\\) così ottenuto, ovvero [-0.059, -0.049], non include lo zero. Possiamo dunque concludere, con un livello di certezza dell’89%, che nella popolazione c’è una relazione negativa tra \\(x\\) e \\(y\\). altre parole, siamo certi, con un livello di certezza dell’89%, che dal 1979 al 2017 l’estensione del ghiaccio marino artico è diminuita.Se vogliamo, possiamo anche ottenere una stima di \\(b\\) che corrisponde ad un livello di certezza più alto, il che porterà ad un aumento dell’ampiezza dell’interallo di credibilità. Stimiamo dunque l’interallo di credibilità ad un livello di certezza del 99%:Anche questo caso l’interallo di credibilità non include lo zero per cui, anche se pretendiamo un livello di certazza del 99%, confermiamo la conclusione secondo la quale dal 1979 al 2017 l’estensione del ghiaccio marino artico è diminuita.Per quel che riguarda \\(\\), con un livello di certezza dell’99% possiamo dire che il valore dell’intercetta della retta di regressione nella popolazione è incluso nell’intervallo [12.313, 12.661]. Nel caso presente, ciò ha una semplice interpretazione: significa che la nostra stima dell’esensione del ghiaccio marino artico nell’anno 1979 corrisponde un valore compreso tra [12.313, 12.661], con un livello di certezza del 99%.","code":"\nflist <- alist(\n    y ~ dnorm(mu, sigma),\n    mu <- a + b*x,\n    c(a, b) ~ dnorm(0, 2), \n    sigma ~ dcauchy(0, 2)\n)\n\nfit <- quap(\n  flist, \n  data = list(y=seaice$y, x=seaice$x), \n  start = list(a=0, b=0, sigma=0.1)\n)\n\nout <- round(precis(fit), 3)\nout\n#>         mean    sd   5.5%  94.5%\n#> a     12.487 0.068 12.379 12.595\n#> b     -0.054 0.003 -0.059 -0.049\n#> sigma  0.215 0.024  0.176  0.254\nout1 <- round(precis(fit, prob=0.99), 3)\nout1\n#>         mean    sd   0.5%  99.5%\n#> a     12.487 0.068 12.313 12.661\n#> b     -0.054 0.003 -0.062 -0.046\n#> sigma  0.215 0.024  0.152  0.277"},{"path":"una-breve-introduzione-al-modello-di-regressione.html","id":"osservazione-1","chapter":"Capitolo 27 Una breve introduzione al modello di regressione","heading":"Osservazione","text":"Potremmo chiedersi perché sia necessario fare delle inferenze sul fenomeno della variazione dell’estensione del ghiaccio marino artico. Se dati ci dicono che l’estensione del ghiaccio marino artico è diminuita, che bisogno abbiamo di fare un’inferenza? La risposta sembra già essere contenuta nei dati.realtà, le cose sono un po’ più complicate. La misurazione dell’aspetto di interesse, questo caso, l’estensione del ghiaccio marino artico, non è priva di errori di misurazione. È ovvio che, se facessimo misurazioni ripetute nel corso dello stesso anno, otterremmo valori diversi. Inltre, al di là degli errori di misurazione, l’estensione del ghiaccio marino artico è soggetta variazioni stagionali e continue nel tempo e fluttuazioni stagionali.Quindi, dati del nostro campione non catturano perfettamente ciò che vogliamo sapere. Siamo infatti consapevoli del fatto che, se ripetessimo le nostre misurazioni, otterremmo valori diversi. Il problema che abbiamo è dunque il seguente: come facciamo rispondere alla domanda della ricerca avendo osservato solo uno degli infiniti campioni diversi di osservazioni che descrivono l’aspetto che ci interessa? Per quantificare la nostra incertezza associamo alla stima della quantità di interesse (questo caso, la variazione dell’estensione del ghiaccio marino artico nell’unità di tempo) un intervallo di credibilità calcolato utilizzando un determinato livello di certezza.Queste affermazioni sono certamente vere nel caso del ghiaccio marino dell’Artico. Ma un lettore attento si sarà anche reso conto del fatto che tale problema (l’errore di misurazione e la variabilità campionaria) è certamente presente anche quando di occupiamo della misurazione dei costrutti psicologici. Questa è la ragione per la quale, come psicologi, dobbiamo essere grado di quantificare la nostra incertezza quando stimiamo le caratteristiche generali di ciò che ci interessa, ovvero quando vogliamo descrivere ciò che ci interessa al di là degli aspetti idiosincratici del campione di dati che abbiamo osservato.","code":""},{"path":"una-breve-introduzione-al-modello-di-regressione.html","id":"errore-standard-della-stima","chapter":"Capitolo 27 Una breve introduzione al modello di regressione","heading":"27.4.1 Errore standard della stima","text":"Il parametto sigma nell’output di precis() ci fornisce un altro utile pezzo di informazione: esso stima infatti quanto sono distanti, media, le osservazioni dalla retta di regressione nella popolazione. Il valore sigma, chiamato errore standard della stima, ci dice che il modello di regressione, stimando la relazione tra \\(y\\) e \\(x\\), compie un errore medio di 0.215 milioni di chilometri quadrati – laddove 0.215 è la stima della distanza media (milioni di chilometri quadrati) tra ciascuno dei punti del diagramma dispersione e la retta di regressione nella popolazione.","code":""},{"path":"una-breve-introduzione-al-modello-di-regressione.html","id":"errori-standard-delle-stime-a-e-b","chapter":"Capitolo 27 Una breve introduzione al modello di regressione","heading":"27.4.2 Errori standard delle stime \\(a\\) e \\(b\\)","text":"Il valore sd associato \\(b\\) nell’output di precis() ci dice invece invece di quanto dobbiamo aspettarci che vari la stima di \\(b\\) da campione campione. altri termini, causa della variabilità campionaria, la stima di \\(b\\) assume un valore diverso ciascuno degli infinti campioni di \\(n\\) osservazioni che descrivono la relazione tra \\(x\\) e \\(y\\), nel periodo temporale considerato. Il valore sd uguale 0.003 ci dice che, media, la stima della pendenza della retta di regressione differirà dal vero valore di questo parametro di una quantità pari 0.003 milioni di chilometri quadrati.\nUna affermazione simile può essere fatta proposito del valore sd associato ad \\(\\) nell’output di precis().","code":""},{"path":"una-breve-introduzione-al-modello-di-regressione.html","id":"una-variabile-indipendente-qualitativa","chapter":"Capitolo 27 Una breve introduzione al modello di regressione","heading":"27.5 Una variabile indipendente qualitativa","text":"Il modello statistico della regressione bivariato che abbiamo descritto sopra è molto limitato: può solo descrivere la relazione lineare tra due variabili continue. Estendiamolo ora al caso cui, oltre ad includere un predittore continuo \\(x\\), il modello di regressione comprende anche una variabile che consente di suddividere le osservazioni del campione due gruppi.Per semplicità, simuliamo un insieme di dati che utilizzeremo nella seguente discussione.Esaminiamo il diagramma dispersione che indica chiaramente che ci sono due gruppi distinti di osservazioni:È ovvio, che nel caso presente, non è sufficiente un modello di regressione che ignora il fatto che dati appartengono due gruppi diversi. Infatti, se adattiamo ai dati un’unica retta di regressione, è facile rendersi conto che tale retta si situerà una posizione molto distante dai dati.Per questi dati è ovviamente più sensato adattare una diversa retta di regressione ciascun gruppo di osservazioni:Come possiamo modificare il modello di regressione che abbiamo esaminato precedenza modo tale da essere grado di stimare coefficienti di regressione delle due rette rappresentate nella figura precedente? Questo problema si risolve nel modo seguente. Crediamo una variabile, chiamata dummy, che ha valore 0 per un gruppo, diciamo gr1, e valore 1 per l’altro gruppo:Esaminiamo ora il modello di regressione che include tale variabile dummy, che chiameremo D:\\[\\begin{equation}\ny = \\alpha + \\beta x + \\gamma D + \\varepsilon.\n\\end{equation}\\]Quando \\(D = 0\\):\\[\\begin{align}\ny &= \\alpha + \\beta x + \\gamma D + \\varepsilon,\\notag\\\\\n &= \\alpha + \\beta x + \\gamma \\times 0 + \\varepsilon,\\notag\\\\\n &= \\alpha + \\beta x + \\varepsilon.\\notag\n\\end{align}\\]Quando \\(D = 1\\):\\[\\begin{align}\ny &= \\alpha + \\beta x + \\gamma D + \\varepsilon,\\notag\\\\\n &= \\alpha + \\beta x + \\gamma \\times 1 + \\varepsilon,\\notag\\\\\n &= (\\alpha + \\gamma) + \\beta x + \\varepsilon.\\notag\n\\end{align}\\]Quindi, se assumiamo che le due rette di regressione siano parallele (nella discussione precedente abbiamo previsto un unico valore \\(\\beta\\)), coefficienti del modello avranno la seguente interpretazione:\\(\\alpha\\) = intercetta della retta di regressione per il gruppo codificato con D = 0;\\(\\beta\\) = pendenza della retta di regressione per il gruppo codificato con D = 0;\\(\\gamma\\) = differenza tra l’intercetta della retta di regressione per il gruppo codificato con D = 1 e l’intercetta della retta di regressione per il gruppo codificato con D = 0.","code":"\nset.seed(1234)\nn <- 100\nx1 <- rnorm(n, 4, 1)\ny1 <- 5 + 5 * x1 + rnorm(n, 0, 2)\n\nx2 <- rnorm(n, 4, 1)\ny2 <- -3 + 2 * x2 + rnorm(n, 0, 2)\n\ny <- c(y1, y2)\nx <- c(x1, x2)\ngroup <- rep(c(\"gr1\", \"gr2\"), each = n)\n\nd <- data.frame(x, y, group) \n\nd %>%\n  group_by(group) %>% \n  do(head(., 5))\n#> # A tibble: 10 x 3\n#> # Groups:   group [2]\n#>       x     y group\n#>   <dbl> <dbl> <fct>\n#> 1  2.79 19.8  gr1  \n#> 2  4.28 25.4  gr1  \n#> 3  5.08 30.6  gr1  \n#> 4  1.65 12.3  gr1  \n#> 5  4.43 25.5  gr1  \n#> 6  4.49  4.81 gr2  \n#> # … with 4 more rows\nd %>%\n  ggplot(aes(x, y)) +\n  geom_point(aes(color = group))\nd %>%\n  ggplot(aes(x, y)) +\n  geom_point(aes(color = group)) +\n  geom_smooth(method = \"lm\", se = FALSE) \n#> `geom_smooth()` using formula 'y ~ x'\nd %>%\n  ggplot(aes(x, y, color = group)) +\n  geom_point(aes(color = group)) +\n  geom_smooth(method = \"lm\", se = FALSE)\n#> `geom_smooth()` using formula 'y ~ x'\nd$gr <- ifelse(d$group == \"gr1\", 0, 1) \n\nd %>%\n  group_by(gr) %>% \n  do(head(., 5)) %>% \n  as.data.frame()\n#>           x         y group gr\n#> 1  2.792934 19.793718   gr1  0\n#> 2  4.277429 25.437709   gr1  0\n#> 3  5.084441 30.554193   gr1  0\n#> 4  1.654302 12.266556   gr1  0\n#> 5  4.429125 25.493626   gr1  0\n#> 6  4.485227  4.810540   gr2  1\n#> 7  4.696769  4.486980   gr2  1\n#> 8  4.185514  5.012171   gr2  1\n#> 9  4.700734  8.421083   gr2  1\n#> 10 4.311681  5.670615   gr2  1"},{"path":"una-breve-introduzione-al-modello-di-regressione.html","id":"interazione","chapter":"Capitolo 27 Una breve introduzione al modello di regressione","heading":"27.5.1 Interazione","text":"generale, però, le due rette di regressione non sono parallele. Per potere rappresentare una tale possibilità, introduciamo nel data.frame d una seconda variabile e la chiamiamo DX. Creaimo DX facendo il prodotto delle variabili D e x:Si noti che, quando D = 0, allora DX = 0; quando D = 1, allora DX = x.Riscriviamo il modello di regressione nel modo seguente:\\[\\begin{equation}\ny = \\alpha + \\beta x + \\gamma D + \\zeta DX + \\varepsilon.\n\\end{equation}\\]tali circostanze, quando \\(D = 0\\), abbiamo che:\\[\\begin{align}\ny &= \\alpha + \\beta x + \\gamma D + \\zeta DX  + \\varepsilon,\\notag\\\\\n &= \\alpha + \\beta x + \\gamma \\times 0 + \\zeta \\times 0 + \\varepsilon,\\notag\\\\\n &= \\alpha + \\beta x + \\varepsilon.\\notag\n\\end{align}\\]Quando \\(D = 1\\) (ricordiamo: questo caso \\(DX = x\\)):\\[\\begin{align}\ny &= \\alpha + \\beta x + \\gamma D + \\zeta DX + \\varepsilon,\\notag\\\\\n &= \\alpha + \\beta x + \\gamma \\times 1 + \\zeta x + \\varepsilon,\\notag\\\\\n &= (\\alpha + \\gamma) + (\\beta + \\zeta) x + \\varepsilon.\\notag\n\\end{align}\\]Ciò significa che coefficienti del modello di regressione avranno ora la seguente interpretazione:\\(\\alpha\\) = intercetta della retta di regressione per il gruppo codificato con D = 0;\\(\\beta\\) = pendenza della retta di regressione per il gruppo codificato con D = 0;\\(\\gamma\\) = differenza tra l’intercetta della retta di regressione per il gruppo codificato con D = 1 e l’intercetta della retta di regressione per il gruppo codificato con D = 0;\\(\\zeta\\) = differenza tra la pendenza della retta di regressione per il gruppo codificato con D = 1 e la pendenza della retta di regressione per il gruppo codificato con D = 0;Ritorniamo al nostro esempio numerico e calcoliamo coefficienti del modello di regressione utilizzando l’approccio Bayesiano:un tale modello, la prima domanda che dobbiamo porci è se dati giustificano la conclusione secondo la quale, nella popolazione, le due rette hanno una pendenza diversa. Per rispondere tale domanda esaminiamo l’intervallo di credibilità del coefficiente associato al termine d’interazione, ovvero del coefficiente \\(\\zeta\\). R ci dice che l’intervallo di credibilità ’89% per il coefficiente \\(\\zeta\\) è pari [-3.36, -2.41]. Dato che tale intervallo non include lo zero, con un livello di certezza dell’89% concludiamo che la retta di regressione del gruppo codificato con D = 1 (ovvero gr2) ha una pendenza minore della retta di regressione per il gruppo codificato con D = 0 (ovvero gr1).","code":"\nd$DX <- d$gr * d$x\n\nd %>%\n  group_by(gr) %>% \n  do(head(., 5)) %>% \n  as.data.frame()\n#>           x         y group gr       DX\n#> 1  2.792934 19.793718   gr1  0 0.000000\n#> 2  4.277429 25.437709   gr1  0 0.000000\n#> 3  5.084441 30.554193   gr1  0 0.000000\n#> 4  1.654302 12.266556   gr1  0 0.000000\n#> 5  4.429125 25.493626   gr1  0 0.000000\n#> 6  4.485227  4.810540   gr2  1 4.485227\n#> 7  4.696769  4.486980   gr2  1 4.696769\n#> 8  4.185514  5.012171   gr2  1 4.185514\n#> 9  4.700734  8.421083   gr2  1 4.700734\n#> 10 4.311681  5.670615   gr2  1 4.311681\nflist1 <- alist(\n    y ~ dnorm(mu, sigma),\n    mu <- a + b*x + gamma*d + zeta*DX,\n    c(a, b, gamma, zeta) ~ dnorm(0, 10), \n    sigma ~ dnorm(0, 5)\n)\nfit1 <- quap(\n  flist1, \n  data = list(y=d$y, x=d$x, d=d$gr, DX=d$DX), \n  start = list(a=0, b=0, gamma=0, zeta=0, sigma=0.5)\n  )\n\nprecis(fit1)\n#>            mean        sd       5.5%     94.5%\n#> a      5.202783 0.8167093   3.897524  6.508043\n#> b      4.967164 0.2057473   4.638340  5.295988\n#> gamma -8.569902 1.2250868 -10.527828 -6.611977\n#> zeta  -2.881817 0.2970176  -3.356509 -2.407126\n#> sigma  2.069882 0.1034130   1.904608  2.235155"},{"path":"una-breve-introduzione-al-modello-di-regressione.html","id":"regressione-multipla","chapter":"Capitolo 27 Una breve introduzione al modello di regressione","heading":"27.6 Regressione multipla","text":"","code":""},{"path":"una-breve-introduzione-al-modello-di-regressione.html","id":"assenza-di-interazione","chapter":"Capitolo 27 Una breve introduzione al modello di regressione","heading":"27.6.1 Assenza di interazione","text":"Esaminiamo ora dati epi.bfi contenuti nel pacchetto psychTools che contengono 231 osservazioni relative 5 scale dall’Eysenck Personality Inventory, 5 scale del Big 5, valori del Beck Depression Inventory e misure di ansia di stato e ansia di tratto.Supponiamo di chiederi se c’è una relazione tra la depressione (bdi), considerata quale variabile dipendente, e Neuroticismo e ansia di stato. Considereremo seguito il problema della possibile interazione tra Neuroticismo e ansia di stato. Per ora, scriviamo il modello di regressione nel modo seguente:\\[\\begin{equation}\ny = \\alpha + \\beta_1 x_1 + \\beta_2 x_2 + \\varepsilon.\n\\end{equation}\\]Abbiamo visto precedenza come si interpretano coefficienti di regressione nel caso della regressione bivariata. coefficienti di regressione, detti parziali, che fanno parte del modello di regressione multipla hanno però un significato diverso da quello descritto precedenza. Poniamoci dunque il problema di capire qual è la differenza tra un coefficiente di regressione (nel modello bivariato) e un coefficiente parziale di regressione (nel modello di regressione multipla).precedenza abbiamo visto che il coefficiente di regressione \\(\\beta\\) ha il seguente significato: indica la variazione del valore atteso della \\(y\\) base al modello lineare nel caso di un cambiamento unitario della \\(x\\). Ma adesso questa spiegazione non basta, quanto nel modello di regressione multipla non c’è una sola variabile indipendente: nel caso considerato qui ce ne sono due. Dunque, qual è il significato di \\(\\beta_1\\) e di \\(\\beta_2\\)?","code":"\nsuppressMessages(library(\"sjPlot\"))\nsuppressMessages(library(\"sjmisc\"))\nlibrary(\"psychTools\")\ndata(epi.bfi)\nglimpse(epi.bfi)\n#> Rows: 231\n#> Columns: 13\n#> $ epiE     <int> 18, 16, 6, 12, 14, 6, 15, 18, 15, 8, 13, 14, 15, 19, 15, 11, 16, 17, 7, 13, 14, …\n#> $ epiS     <int> 10, 8, 1, 6, 6, 4, 9, 9, 11, 5, 9, 12, 10, 11, 10, 5, 10, 11, 4, 8, 7, 7, 10, 10…\n#> $ epiImp   <int> 7, 5, 3, 4, 5, 2, 4, 7, 3, 2, 3, 3, 4, 7, 4, 6, 5, 6, 2, 4, 5, 3, 7, 1, 4, 3, 6,…\n#> $ epilie   <int> 3, 1, 2, 3, 3, 5, 3, 2, 3, 2, 3, 6, 5, 0, 2, 7, 0, 4, 1, 4, 3, 1, 2, 2, 1, 1, 3,…\n#> $ epiNeur  <int> 9, 12, 5, 15, 2, 15, 12, 10, 1, 10, 9, 1, 2, 3, 7, 13, 18, 11, 10, 12, 3, 10, 10…\n#> $ bfagree  <int> 138, 101, 143, 104, 115, 110, 109, 92, 127, 74, 124, 131, 133, 117, 99, 126, 97,…\n#> $ bfcon    <int> 96, 99, 118, 106, 102, 113, 58, 57, 108, 100, 114, 107, 114, 126, 107, 78, 90, 1…\n#> $ bfext    <int> 141, 107, 38, 64, 103, 61, 99, 94, 108, 61, 100, 99, 114, 139, 124, 112, 102, 13…\n#> $ bfneur   <int> 51, 116, 68, 114, 86, 54, 55, 72, 35, 87, 110, 92, 56, 47, 62, 83, 106, 72, 84, …\n#> $ bfopen   <int> 138, 132, 90, 101, 118, 149, 110, 114, 86, 89, 129, 121, 131, 128, 139, 132, 109…\n#> $ bdi      <int> 1, 7, 4, 8, 8, 5, 7, 0, 0, 7, 8, 3, 0, 0, 1, 4, 14, 7, 9, 4, 1, 11, 1, 9, 6, 10,…\n#> $ traitanx <int> 24, 41, 37, 54, 39, 51, 40, 32, 22, 35, 43, 33, 23, 23, 27, 45, 58, 39, 43, 38, …\n#> $ stateanx <int> 22, 40, 44, 40, 67, 38, 32, 41, 26, 31, 39, 25, 32, 23, 28, 28, 56, 44, 56, 35, …"},{"path":"una-breve-introduzione-al-modello-di-regressione.html","id":"significato-dei-coefficienti-parziali-di-regressione","chapter":"Capitolo 27 Una breve introduzione al modello di regressione","heading":"27.6.1.1 Significato dei coefficienti parziali di regressione","text":"La risposta è che un generico \\(\\beta_j\\) nel modello di regressione multipla rappresenta la variazione del valore atteso della \\(y\\) base al modello lineare nel caso di un cambiamento unitario di \\(x_j\\) al netto dell’effetto (lineare) di tutte le altre variabili \\(x\\) incluse nel modello.La seconda parte dell’affermazione precedente (“al netto di…”) è ciò che dobbiamo capire.Iniziamo calcolare con R coefficienti parziali del modello di regressione multipla descritto sopra:coefficienti parziali di regressione sono:Iniziamo considerare il coefficiente parziale associato Neuroticismo. Il valore \\(\\beta_1\\) = 0.054414 ci dice che ci aspettiamo che il valore di depressione aumenti media di \\(\\beta_1\\) = 0.054414 punti quando il livello di Neuroticismo aumenta di un punto e il livello di ansia di stato viene mantenuto costante.\nMa che vuol dire “mantenere costante” il livello di ansia di stato? Questo è un esempio di controllo statistico e può essere spiegato nel modo seguente.Abbiamo visto precedenza che il modello lineare scompone la \\(y\\) due componenti: la componente predicibile da \\(x\\) e la componente della \\(y\\) che un modello lineare non può prevedere.\nScomponiamo dunque valori bdi due componenti: la quota del bdi che l’ansia di stato può prevedere (con un modello lineare) e la quota del bdi che l’ansia di stato non può prevedere. Tale seconda componente di bdi è data dai residui (\\(\\varepsilon\\)) del seguente modello di regressione:\\[\\begin{equation}\n\\text{bdi} = \\alpha + \\beta \\cdot \\text{stateanx} + \\varepsilon.\n\\end{equation}\\]Usando R, tali residui sono dati da:Eseguiamo una scomposizione simile per valori di Neuroticismo: troviamo la quota di bfneur che l’ansia di stato può prevedere e la quota di bfneur che l’ansia di stato non può prevedere. Tale seconda componente di bfneur è data dai residui del seguente modello di regressione:\\[\\begin{equation}\n\\text{bfneur} = \\alpha + \\beta \\cdot \\text{stateanx} + \\varepsilon.\n\\end{equation}\\]Usando R, tali residui sono dati da:Abbiamo così ottenuto la componente della variabile dipendente linermente indipendente da stateanx e la componente di bfneur linermente indipendente da stateanx. altri termini, abbiamo “statisticamente controllato” l’effetto di stateanx su bdi e su bfneur. Se adesso vogliamo sapere qual è l’effetto di bfneur su bdi, indipendentemente dall’effetto di stateanx su entrambe le variabili, basta che eseguiamo l’analisi di regressione sulle componenti di bdi e bfneur che sono linearmente indipendenti da stateanx. Ovvero, dobbiamo calcolare il coefficiente \\(b\\) del seguente modello di regressione:Il coefficiente di regressione del modello precedenteè identico al coefficiente parziale di regressione associato alla variabile bfneur nel modello di regressione multipla:\\[\\begin{equation}\ny = \\alpha + \\beta_1 x_1 + \\beta_2 x_2 + \\varepsilon.\n\\end{equation}\\]Ciò chiarisce il significato di “controllo statistico” e fa capire qual è la differenza tra il coefficiente di regressione del modello bivariato e il coefficiente parziale di regressione nel modello di regressione multipla.","code":"\nm <- lm(bdi ~ bfneur + stateanx, data = epi.bfi)\nout <- coef(m)\nround(out, 3)\n#> (Intercept)      bfneur    stateanx \n#>      -8.039       0.054       0.252\nm1 <- lm(bdi ~ stateanx, data = epi.bfi)\nhead(m1$res)\n#>          1          2          3          4          5          6 \n#> -0.3151358  0.1743948 -4.0501540  1.1743948 -7.0913093 -1.2133308\nm2 <- lm(bfneur ~ stateanx, data = epi.bfi)\nhead(m2$res)\n#>         1         2         3         4         5         6 \n#> -19.12342  27.87881 -24.12070  25.87881 -29.11785 -32.12144\nm3 <- lm(m1$res ~ m2$res)\ncoef(m3)[2]\n#>     m2$res \n#> 0.05441396\nout[2]\n#>     bfneur \n#> 0.05441396"},{"path":"una-breve-introduzione-al-modello-di-regressione.html","id":"interazione-tra-i-regressone","chapter":"Capitolo 27 Una breve introduzione al modello di regressione","heading":"27.6.2 Interazione tra i regressone","text":"Esaminiamo ora l’ultima possibilità, ovvero quella di un modello di regressione multipla che contiene due variabili indipendenti che “interagiscono” tra loro.\nCosa significa il concetto di “interazione” tra due variabili indipendenti?Per rispondere questa domanda iniziamo considerare un modello senza interazione tra \\(x_1\\) e \\(x_2\\), ovvero il modello di regressione multipla con due regressori continui che abbiamo descritto precedenza. Esaminiamo una rappresentazione geometrica delle predizioni di tale modello.Per esaminare le predizioni del modello\\[\\begin{equation}\ny = \\alpha + \\beta_1 x_1 + \\beta_2 x_2 + \\varepsilon.\n\\end{equation}\\]non possiamo procedere come abbiamo fatto precedenza, quando avevamo due gruppi di osservazioni, ovvero, non possiamo disegnare una diversa retta di regressione per ciascun gruppo (non essendoci dei gruppi separati). Possiamo invece usare una funzione R come plot_model() che calcola la retta di regressione di bfneur su bdi selezionando alcuni valori “fissi” della variabile stateanx – nello specifico, la media di stateanx, la media meno una deviazione standard, e la media più una deviazione standard. Si produce così la rappresentazione di tre rette di regressione.Quello che notiamo dalla figura precedente è che le tre rette sono parallele. Un modello di regressione multipla che non include alcun termine di interazione è infatti un modello additivo: per quale che sia il livello della variabile stateanx, l’effetto di bfneur (ovvero, la pendenza della retta di regressione) non cambia. Quindi, l’effetto di stateanx semplicemente si somma ’effetto di bfneur.Una situazione ben diversa si ottiene nel caso di un modello con interazione, come il seguente:\\[\\begin{equation}\ny = \\alpha + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_1 \\cdot x_2 + \\varepsilon.\n\\end{equation}\\]Adattiamo questo modello ai datie esaminiamo la souluzione ottenuta:Se rappresentiamo graficamente le predizioni del modellovediamo che, ora, le rette di regressione di bfneur su bdi corrispondenza dei tre valori prescelti di stateanx non sono più parallele. Questo significa che l’effetto di bfneur su bdi (la pendenza della retta di regressione) dipende dal valore di stateanx. Questo è il significato di “interazione”: bfneur ha un effetto diverso su bdi seconda del livello di stateanx.Nel caso presente, vediamo dalla figura che il Neuroticismo ha un effetto più grande sul livello di depressione quando consideriamo coloro che hanno livelli di ansia di stato elevati.coefficienti si interpretano come precedenza. L’intercetta corrisponde al valore atteso di bdi quando bfneur e stateanx hanno il valore di zero. Questo è di poco interesse. Per cui trasformiamo dati modo da utilizzare variabili indipendenti “centrate,” ovvero variabili da cui abbiamo sottratto la media.Riadattiamo il modello con le variabili centrate:Si vede che il coefficiente associato al termine di interazione è rimasto immutato. Ma ora è più facile interpretare il coefficiente dell’intercetta. questo caso, l’intercetta corrisponde al valore atteso di bdi quando bfneur e stateanx assumono il loro valore medio (ovvero zero, per le variabili trasformate). Per quanto riguarda gli effetti separati di bfneur e stateanx, questi non sono interpretabili, quanto la presenza di un’interazione significa, appunto, che bfneur e stateanx non hanno effetti separati su bdi.","code":"\nplot_model(m, type = \"pred\", terms = c(\"bfneur\", \"stateanx\"))\nm4 <- lm(bdi ~ bfneur * stateanx, data = epi.bfi)\nsummary(m4)\n#> \n#> Call:\n#> lm(formula = bdi ~ bfneur * stateanx, data = epi.bfi)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -9.3273 -2.7107 -0.4746  1.9646 14.3104 \n#> \n#> Coefficients:\n#>                  Estimate Std. Error t value Pr(>|t|)  \n#> (Intercept)      0.768518   3.763671   0.204   0.8384  \n#> bfneur          -0.040827   0.040952  -0.997   0.3199  \n#> stateanx         0.012673   0.100598   0.126   0.8999  \n#> bfneur:stateanx  0.002501   0.001008   2.483   0.0138 *\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 4.416 on 227 degrees of freedom\n#> Multiple R-squared:  0.4229, Adjusted R-squared:  0.4152 \n#> F-statistic: 55.44 on 3 and 227 DF,  p-value: < 2.2e-16\nplot_model(m4, type = \"pred\", terms = c(\"bfneur\", \"stateanx\"))\nepi.bfi$neur_c <- epi.bfi$bfneur - mean(epi.bfi$bfneur)\nepi.bfi$stateanx_c <- epi.bfi$stateanx - mean(epi.bfi$stateanx)\nm5 <- lm(bdi ~ neur_c * stateanx_c, data = epi.bfi)\nsummary(m5)\n#> \n#> Call:\n#> lm(formula = bdi ~ neur_c * stateanx_c, data = epi.bfi)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -9.3273 -2.7107 -0.4746  1.9646 14.3104 \n#> \n#> Coefficients:\n#>                   Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)       6.450781   0.319275  20.204  < 2e-16 ***\n#> neur_c            0.058853   0.014445   4.074 6.38e-05 ***\n#> stateanx_c        0.232727   0.030117   7.727 3.51e-13 ***\n#> neur_c:stateanx_c 0.002501   0.001008   2.483   0.0138 *  \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 4.416 on 227 degrees of freedom\n#> Multiple R-squared:  0.4229, Adjusted R-squared:  0.4152 \n#> F-statistic: 55.44 on 3 and 227 DF,  p-value: < 2.2e-16"},{"path":"il-modello-statistico-della-regressione-lineare.html","id":"il-modello-statistico-della-regressione-lineare","chapter":"Capitolo 28 Il modello statistico della regressione lineare","heading":"Capitolo 28 Il modello statistico della regressione lineare","text":"Lo scopo della ricerca è trovare le associazioni tra le variabili e fare\nconfronti fra le condizioni sperimentali. Nel caso della psicologia, il\nricercatore vuole scoprire le leggi generali che descrivono le relazioni\ntra costrutti psicologici e le relazioni che intercorrono tra \nfenomeni psicologici e quelli non psicologici (sociali, economici,\nstorici, …). Abbiamo già visto come la correlazione di Pearson sia uno\nstrumento adatto questo scopo. Infatti, essa ci informa sulla\ndirezione e sull’intensità della relazione lineare tra due variabili.\nTuttavia, la correlazione non è sufficiente, quanto il ricercatore ha\ndisposizione solo dati di un campione, mentre vorrebbe descrivere la\nrelazione tra le variabili nella popolazione. causa della variabilità\ncampionaria, le proprietà dei campioni sono necessariamente diverse da\nquelle della popolazione: ciò che si può osservare nella popolazione\npotrebbe non emergere nel campione e, al contrario, il campione\nmanifesta caratteristiche che non sono necessariamente presenti nella\npopolazione. È dunque necessario chiarire, dal punto di vista\nstatistico, il legame che intercorre tra le proprietà del campione e le\nproprietà della popolazione da cui esso è stato estratto. Come nel caso\ndella media, anche questo caso dovrà essere costruita la\ndistribuzione di una statistica; ma però, nel caso presente, la\nstatistica di interesse sarà costruita utilizzando, non dati di una\nsola variabile, ma bensì dati che descrivono l’andamento congiunto di\ndue variabili.Il modello di regressione utilizza la funzione matematica più semplice\nper descrivere la relazione fra due variabili, ovvero la funzione\nlineare. Inizieremo descrivere le proprietà geometriche della funzione lineare per poi utilizzare questa semplice funzione per costruire il modello statistico della regressione lineare.","code":""},{"path":"il-modello-statistico-della-regressione-lineare.html","id":"la-funzione-lineare","chapter":"Capitolo 28 Il modello statistico della regressione lineare","heading":"28.1 La funzione lineare","text":"Si chiama funzione lineare una funzione del tipo\\[\nf(x) = + b x,\n\\]\ndove \\(\\) e \\(b\\) sono delle costanti.\nIl grafico di tale funzione è una retta di cui il parametro \\(b\\) è detto coefficiente angolare e il parametro \\(\\) è detto intercetta con l’asse delle \\(y\\) (infatti, la retta interseca l’asse \\(y\\) nel punto \\((0,)\\), se \\(b \\neq 0\\)).Per assegnare un’interpretazione geometrica alle costanti \\(\\) e \\(b\\) si consideri la funzione\\[\ny = b x.\n\\]\nTale funzione rappresenta un caso particolare, ovvero quello della proporzionalità diretta tra \\(x\\) e \\(y\\). Il caso generale della linearità\\[\ny = + b x\n\\]\nnon fa altro che sommare una costante \\(\\) ciascuno dei valori \\(y = b x\\). Nella funzione lineare \\(y = + b x\\), se \\(b\\) è positivo allora \\(y\\) aumenta al crescere di \\(x\\); se \\(b\\) è negativo allora \\(y\\) diminuisce al crescere di \\(x\\); se \\(b=0\\) la retta è orizzontale, ovvero \\(y\\) non muta al variare di \\(x\\).Consideriamo ora il coefficiente \\(b\\). Si consideri un punto \\(x_0\\) e un incremento arbitrario \\(\\varepsilon\\) come indicato nella figura 28.1. Le differenze \\(\\Delta x = (x_0 + \\varepsilon) - x_0\\) e \\(\\Delta y = f(x_0 + \\varepsilon) - f(x_0)\\) sono detti incrementi di \\(x\\) e \\(y\\). Il coefficiente angolare \\(b\\) è uguale al rapporto\\[\n    b = \\frac{\\Delta y}{\\Delta x} = \\frac{f(x_0 + \\varepsilon) - f(x_0)}{(x_0 + \\varepsilon) - x_0},\n\\]\nindipendentemente dalla grandezza degli incrementi \\(\\Delta x\\) e \\(\\Delta y\\). Il modo più semplice per assegnare un’interpretazione geometrica al coefficiente angolare (o pendenza) della retta è dunque quello di porre \\(\\Delta x = 1\\). tali circostanze infatti \\(b = \\Delta y\\).\nFigura 28.1: La funzione lineare \\(y = + bx\\).\n","code":""},{"path":"il-modello-statistico-della-regressione-lineare.html","id":"lerrore-di-misurazione","chapter":"Capitolo 28 Il modello statistico della regressione lineare","heading":"28.2 L’errore di misurazione","text":"Per descrivere l’associazione tra due variabili, tuttavia, la funzione lineare non è sufficiente. Nel mondo empirico, infatti, la relazione tra variabili non è mai perfettamente lineare. È dunque necessario includere nel modello di regressione anche una componente d’errore, ovvero una componente della \\(y\\) che non può essere spiegata dal modello lineare. Nel caso di due sole variabili, questo ci conduce alla seguente formulazione del modello di regressione:\\[\\begin{equation}\ny = \\alpha + \\beta x + \\varepsilon,\n\\tag{28.1}\n\\end{equation}\\]laddove parametri \\(\\alpha\\) e \\(\\beta\\) descrivono l’associazione tra le variabili aleatorie \\(y\\) e \\(x\\) (nella popolazione), e il termine d’errore \\(\\varepsilon\\) specifica quant’è grande la porzione della variabile \\(y\\) che non può essere predetta nei termini di una relazione lineare con la \\(x\\).Si noti che l’eq. (28.1) ci consente di formulare una predizione, nei termini di un modello lineare, del valore atteso della \\(y\\) conoscendo \\(x\\), ovvero\\[\\begin{equation}\n\\hat{y} = \\mathbb{E}(y \\mid x) = \\alpha + \\beta x.\n\\tag{28.2}\n\\end{equation}\\]altri termini, se parametri del modello (\\(\\alpha\\) e \\(\\beta\\)) sono noti, allora è possibile predire \\(y\\) sulla base della nostra conoscenza della \\(x\\).Per esempio, se conosciamo la relazione lineare tra quoziente di intelligenza ed aspettativa di vita, allora possiamo prevedere quanto lungo vivrà una persona sulla base del suo QI. Sì, c’è una relazione lineare tra intelligenza e aspettativa di vita! – per una discussione, si veda, ad esempio, l’articolo di David Z. Hambrick pubblicato su Scientific American il 22 dicembre 2015. Ma quando sarà accurata la nostra previsione? Ciò dipende dal termine d’errore dell’eq. (28.1). L’analisi di regressione ci fornisce un metodo per rispondere domande di questo tipo.","code":""},{"path":"il-modello-statistico-della-regressione-lineare.html","id":"scopi-della-regressione-lineare","chapter":"Capitolo 28 Il modello statistico della regressione lineare","heading":"28.3 Scopi della regressione lineare","text":"Il modello di regressione lineare si pone tre obiettivi:descrivere l’associazione tra le variabili \\(x\\) e \\(y\\) nel campione esaminato;misurare la bontà dell’adattamento dell’associazione tra \\(x\\) e \\(y\\);fare inferenze sull’associazione tra \\(x\\) e \\(y\\) nella popolazione da cui il campione è stato estratto.Il primo obiettivo intende rispondere alla stessa domanda cui risponde il coefficiente di correlazione: quali sono l’intensità e il segno della relazione lineare che descrive l’associazione tra due variabili? Vedremo che c’è una precisa relazione tra il coefficiente \\(b\\) del modello di regressione (che rappresenta la pendenza della retta di regressione) e\nil coefficiente di correlazione \\(r\\) di Pearson: il coefficiente di\ncorrelazione non è altro che la pendenza della retta di regressione\nquando dati sono standardizzati. Vi è però un’importante differenza\ntra la correlazione ed il modello di regressione. La correlazione è un\nindicatore simmetrico di associazione tra due caratteri. Il modello di\nregressione, invece, si chiede come varia una variabile, detta\ndipendente e solitamente denotata con \\(y\\), al variare di un’altra\nvariabile, detta indipendente (o predittore), solitamente denotata con\n\\(x\\). L’analisi della regressione lineare si pone dunque il problema di\nstudiare la relazione asimmetrica tra due variabili.Il secondo obiettivo del modello di regressione lineare si chiede se il\nmodello di regressione sia sensato per descrivere l’associazione\nosservata tra le due variabili. Vogliamo trovare un indice che descriva\nquanto distanti sono dati dalla retta di regressione. Se punti di un\ndiagramma dispersione sono molto vicini alla retta di regressione,\nallora il modello di regressione è adeguato per descrivere\nl’associazione tra le due variabili. questo caso la bontà di\nadattamento del modello ai dati è grande. Oppure può succedere che \npunti di un diagramma dispersione siano molto lontani alla retta di\nregressione e/o che la retta di regressione sia piatta. questi due\nultimi casi non vi è evidenza di una associazione lineare tra le due\nvariabili e l’indice che misura la bontà dell’adattamento\ndell’associazione tra \\(x\\) e \\(y\\) assume un valore basso e prossimo allo\nzero. Tale indice va sotto il nome di coefficiente di determinazione.Il terzo obiettivo è quello più ambizioso: ci chiediamo quale potrebbe\nessere l’associazione tra le variabili \\(x\\) e \\(y\\) nella popolazione, alla\nluce delle informazioni che sono state osservate nel campione. Quello che vorremmo conoscere è \\(p(\\theta \\mid \\text{dati})\\), laddove \\(\\theta\\) è il parametro sconosciuto che rappresenta la pendenza della retta di regressione nella popolazione. Vedremo come l’approccio Bayesiano può essere usato per rispondere questa domanda.Il modello di regressione è, probabilmente, il più importante dei modelli statistici. Noi qui ne\nesamineremo solo le sue caratteristiche di base. Ma tale modello può\nessere esteso modo tale da includere più di un predittore (nel qual\ncaso si parla di modello di regressione multipla), oppure una variabile\ndipendente qualitativa (il che produce il modello di regressione\nlogistica), oppure molteplici variabili dipendenti continue (il che\nproduce il modello di regressione multivariato). Sviluppi più moderni di\nquesto modello considerano inoltre il caso della violazione\ndell’assunzione di indipendenza tra le osservazioni, il che conduce alla\ncostruzione dei modelli ad effetti misti (mixed-effects models).\nInfine, uno sviluppo importante del modello di regressione lineare è\nl’analisi fattoriale, nel qual caso viene ipotizzata l’esistenza di\nvariabili indipendenti inosservabili (latenti), le quali corrispondono\nai costrutti psicologici. Il modello fattoriale, così formulato,\ncostituisce il fondamento della Psicometria, ovvero di quelle tecniche\nstatistiche che stanno alla base della costruzione e della validazione\ndei reattivi psicologici.","code":""},{"path":"il-modello-statistico-della-regressione-lineare.html","id":"quantificare-lassociazione-fra-due-caratteri-quantitativi","chapter":"Capitolo 28 Il modello statistico della regressione lineare","heading":"28.4 Quantificare l’associazione fra due caratteri quantitativi","text":"Consideriamo tre variabili aleatorie \\(X\\), \\(Y\\) ed \\(\\varepsilon\\) legate dalla relazione lineare\\[\ny = \\alpha + \\beta x + \\varepsilon,\n\\]dove \\(\\alpha\\) e \\(\\beta\\) sono numeri reali e \\(\\mathbb{E}(\\varepsilon) = 0\\). Chiameremo modello lineare (semplice) la relazione dell’eq. (28.1) e chiameremo retta di regressione la retta\\[\\begin{equation}\ny = \\alpha + \\beta x.\n\\tag{28.3}\n\\end{equation}\\]Il parametro \\(\\alpha\\) è l’ordinata ’origine (o intercetta) mentre il parametro \\(\\beta\\) è il coefficiente angolare della retta. Possiamo interpretare l’eq. (28.1) pensando che le variabili aleatorie \\(x\\) ed \\(y\\) siano legate tra loro da una relazione lineare perturbata da un errore casuale \\(\\varepsilon\\).Dato un insieme di realizzazioni campionarie delle variabili aleatorie \\(x\\) e \\(y\\), ci poniamo lo scopo di determinare la retta di regressione campionaria\\[\\begin{equation}\n\\hat{y}_i  =  + b x_i\n\\tag{28.4}\n\\end{equation}\\]che approssima il meglio possibile la distribuzione dei punti \\(x_i\\), \\(y_i\\), \\(= 1, \\dots, n\\). Lo studio di questo problema è detto regressione lineare.","code":""},{"path":"il-modello-statistico-della-regressione-lineare.html","id":"stime-dei-minimi-quadrati","chapter":"Capitolo 28 Il modello statistico della regressione lineare","heading":"28.5 Stime dei minimi quadrati","text":"Il primo obiettivo dell’analisi di regressione è quello di trovare la retta che meglio descrive l’andamento dei dati osservati un campione. Iniziamo con il definire residui \\(e_i\\) tramite la relazione\\[\\begin{equation}\ne_i  = y_i - (+ b x_i).\n\\tag{28.5}\n\\end{equation}\\]altri termini, il residuo \\(\\)-esimo è la differenza fra l’ordinata del punto (\\(x_i\\), \\(y_i\\)) e quella del punto di ascissa \\(x_i\\) sulla retta di regressione campionaria.Per determinare coefficienti \\(\\) e \\(b\\) della retta (28.4) non è sufficiente minimizzare la somma dei residui \\(\\sum_{=1}^{n}e_i\\), quanto residui possono essere sia positivi che negativi e la loro somma può essere molto prossima allo zero anche per differenze molto grandi tra valori osservati e la retta\ndi regressione. Infatti, ciascuna retta passante per il punto (\\(\\bar{x}, \\bar{y}\\)) ha \\(\\sum_{=1}^{n}e_i=0\\).Dimostrazione. Una retta passante per il punto (\\(\\bar{x}, \\bar{y}\\)) soddisfa l’equazione \\(\\bar{y} = + b \\bar{x}\\). Sottraendo tale equazione dall’equazione \\(y_i = + b x_i + e_i\\) otteniamo\n\\[\ny_i - \\bar{y} =  b (x_i - \\bar{x}) + e_i.\n\\]\nSommando su tutte le osservazioni, si ha che\\[\n\\sum_{=1}^n e_i = \\sum_{=1}^n (y_i - \\bar{y} ) -  b \\sum_{=1}^n (x_i - \\bar{x}) = 0 - b(0) = 0. \n\\]Questo problema viene risolto scegliendo coefficienti \\(\\) e \\(b\\) che\nminimizzano, non tanto la somma dei residui, ma bensì l’errore\nquadratico, cioè la somma dei quadrati degli errori:\\[\nS(, b) = \\sum_{=1}^{n} e_i^2 = \\sum (y_i - - b x_i)^2.\n\\]Il metodo più diretto per determinare quelli che vengono chiamati coefficienti dei minimi quadrati è quello di trovare le derivate parziali della funzione \\(S(, b)\\) rispetto ai coefficienti \\(\\) e \\(b\\):\\[\\begin{equation}\n\\begin{aligned}\n\\frac{\\partial S(,b)}{\\partial } &= \\sum (-1)(2)(y_i - - b x_i), \\notag \\\\\n\\frac{\\partial S(,b)}{\\partial b} &= \\sum (-x_i)(2)(y_i - - b x_i).\n\\end{aligned}\n\\tag{28.6}\n\\end{equation}\\]Ponendo le derivate uguali zero e dividendo entrambi membri per \\(-2\\) si ottengono le equazioni normali\\[\\begin{equation}\n\\begin{aligned}\n + b \\sum x_i &= \\sum y_i, \\notag \\\\\n \\sum x_i + b \\sum x_i^2 &= \\sum x_i y_i. \n\\end{aligned}\n\\tag{28.7}\n\\end{equation}\\]coefficienti dei minimi quadrati \\(\\) e \\(b\\) si trovano risolvendo le equazioni (28.7) e sono uguali :\\[\\begin{equation}\n\\begin{aligned}\n&= \\bar{y} - b \\bar{x},\\\\\nb &= \\frac{\\sum (x_i - \\bar{x}) (y_i - \\bar{y})}{\\sum (x_i - \\bar{x})^2}.\n\\end{aligned}\n\\tag{28.8}\n\\end{equation}\\]","code":""},{"path":"il-modello-statistico-della-regressione-lineare.html","id":"monotwinsiq","chapter":"Capitolo 28 Il modello statistico della regressione lineare","heading":"28.5.1 Un esempio concreto","text":"Consideriamo dati relativi 34 coppie di gemelli monozigoti separati alla nascita (Anderson & Finn (2012)). Dei gemelli conosciamo l’ordine della nascita e il quoziente di intelligenza misurato con il Dominoes Intelligence test. Il test è costituito da 48 domande ciascuna delle quali viene assegnato un punto nel caso di risposta corretta. La media del test nella popolazione è di 28 punti, che corrisponde al punteggiodi 100 sulla scala WAIS. dati sono:Un diagramma di dispersione per questi dati, insieme alla retta di regressione dei minimi quadrati, è riportato nella figura 28.2.\nFigura 28.2: Retta di regressione che descrive la relazione lineare tra il quoziente di intelligenza del secondo nato e il quoziente di intelligenza del primo nato.\ncoefficienti di regressione si trovano con le formule dei minimi quadrati. Usando R, per \\(b\\) otteniamoe per \\(\\) otteniamoTali risultati corrispondono ai valori trovati dalla funzione lm() con la seguente sintassi:L’oggetto creato da {lm() può essere visionato utilizzando coef(fm) o con summary(fm).valori predetti dal modello di regressione sono dati dao, maniera equivalente, possono essere trovati con predict(fm)residui di regressione, ovvero la differenza tra il valore osservato e il valore predetto dal modello, si trovano mediante l’istruzioneo, maniera equivalente, con residuals(fm)residui possono essere rappresentanti graficamente come riportato nella figura 28.3.\nFigura 28.3: Residui del modello di regressione che esprime il quoziente di intelligenza del secondo nato funzione del quoziente di intelligenza del primo nato.\n","code":"\niq1 <- c(22, 32, 29, 13, 32, 24, 33, 19, 13, 36, 26, 26, 32, 27, 6, 16, 41, 29, 13, 20, 28, 30, 22, 23, 27, 40, 30, 30, 21, 27, 15, 38, 4, 12)\n\niq2 <- c(12, 28, 35, 4, 18, 33, 26, 9, 22, 34, 17, 20, 33, 28, 10, 28, 40, 30, 10, 24, 22, 34, 23, 21, 25, 38, 25, 26, 27, 24, 9, 27, 2, 9)\n\ndf <- data.frame(iq1, iq2)\np <- df %>% \n  ggplot(aes(x = iq1, y = iq2)) +\n  geom_smooth(method = \"lm\", se=FALSE, color=\"lightgrey\", formula = y ~ x) +\n  geom_point() +\n  labs(\n    x = \"Qi primo nato\",\n    y = \"QI secondo nato\",\n    title = \"Gemelli monozigoti separati alla nascita\",\n    caption = \"(Fonte: Anderson e Finn, 2012)\"\n  )\np\nb <- cov(df$iq1, df$iq2) / var(df$iq1) \nb\n#> [1] 0.8498545\na <- mean(df$iq2) - b * mean(df$iq1)\na\n#> [1] 1.838871\nfm <- lm(iq2 ~ iq1, data = df)\nsummary(fm)\n#> \n#> Call:\n#> lm(formula = iq2 ~ iq1, data = df)\n#> \n#> Residuals:\n#>      Min       1Q   Median       3Q      Max \n#> -11.0342  -3.8218  -0.5852   3.4658  12.5635 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)   1.8389     3.0269   0.608    0.548    \n#> iq1           0.8499     0.1155   7.357 2.29e-08 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 6.102 on 32 degrees of freedom\n#> Multiple R-squared:  0.6285, Adjusted R-squared:  0.6169 \n#> F-statistic: 54.13 on 1 and 32 DF,  p-value: 2.288e-08\nyhat <- a + b * df$iq1\npredict(fm) \n#>         1         2         3         4         5         6         7         8         9 \n#> 20.535671 29.034216 26.484652 12.886980 29.034216 22.235380 29.884070 17.986107 12.886980 \n#>        10        11        12        13        14        15        16        17        18 \n#> 32.433634 23.935089 23.935089 29.034216 24.784943  6.937998 15.436543 36.682907 26.484652 \n#>        19        20        21        22        23        24        25        26        27 \n#> 12.886980 18.835962 25.634798 27.334507 20.535671 21.385525 24.784943 35.833052 27.334507 \n#>        28        29        30        31        32        33        34 \n#> 27.334507 19.685816 24.784943 14.586689 34.133343  5.238289 12.037125\ne <- df$iq2 - yhat\nresiduals(fm)\n#>           1           2           3           4           5           6           7           8 \n#>  -8.5356706  -1.0342160   8.5153476  -8.8869798 -11.0342160  10.7646203  -3.8840705  -8.9861070 \n#>           9          10          11          12          13          14          15          16 \n#>   9.1130202   1.5663659  -6.9350888  -3.9350888   3.9657840   3.2150567   3.0620019  12.5634566 \n#>          17          18          19          20          21          22          23          24 \n#>   3.3170932   3.5153476  -2.8869798   5.1640385  -3.6347978   6.6654931   2.4643294  -0.3855252 \n#>          25          26          27          28          29          30          31          32 \n#>   0.2150567   2.1669478  -2.3345069  -1.3345069   7.3141839  -0.7849433  -5.5866889  -7.1333432 \n#>          33          34 \n#>  -3.2382890  -3.0371253\ndf$predicted <- predict(fm)   \ndf$residuals <- residuals(fm) \n\np1 <- df %>% \n  ggplot(aes(x = iq1, y = iq2)) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"lightgrey\") +  \n  geom_segment(aes(xend = iq1, yend = predicted), alpha = .2) + \n  geom_point() +\n  geom_point(aes(y = predicted), shape = 1) + \n  labs(\n    x = \"Qi primo nato\",\n    y = \"QI secondo nato\",\n    title = \"Gemelli monozigoti separati alla nascita\",\n    caption = \"(Fonte: Anderson e Finn, 2012)\"\n  )\np1\n#> `geom_smooth()` using formula 'y ~ x'"},{"path":"il-modello-statistico-della-regressione-lineare.html","id":"sec:beta_r","chapter":"Capitolo 28 Il modello statistico della regressione lineare","heading":"28.5.2 Coefficiente angolare e correlazione di Pearson","text":"Ricordando che \\(r_{xy}=s_{xy} / (s_x s_y)\\) è il coefficiente di\ncorrelazione lineare e che \\(b=s_{xy} /s_x^2\\) è la stima dei minimi\nquadrati del coefficiente angolare della retta di regressione,\nsostituendo \\(r_{xy}s_xs_y\\) al numeratore dell’equazione di \\(b\\) e\nsemplificando, si ottiene\n\\[\\begin{equation}\nb = r_{yx}\\frac{s_y}{s_x}.\n\\end{equation}\\]\nSe dati vengono standardizzati, dunque, l’equazione della retta di regressione\ncampionaria diventa\n\\[\\begin{equation}\nz_{y_i} = r_{xy} z_{x_i} + e_i,\n\\end{equation}\\]\nquanto \\(= \\bar{z}_y - b\\bar{z}_x =0\\) e \\(s_x = s_y = 1\\).Si può dunque assegnare al coefficiente di correlazione di Pearson la seguente\ninterpretazione: \\(r_{xy}\\) è uguale alla pendenza \\(b\\) della retta di\nregressione quando le variabili \\(x\\) e \\(y\\) vengono standardizzate\n(Rodgers & Nicewander, 1988).Facciamo un esempio calcolando coefficienti di regressione sui punteggi standardizzati del\nquoziente di intelligenza dei gemelli monozigoti.Utilizzando valori standardizzati del QI l’intercetta diventa pari zero e la pendenza della retta di regressione diventa uguale alla correlazione tra le due variabili:","code":"\nziq1 <- scale(df$iq1)\nziq2 <- scale(df$iq2)\nfm1 <- lm(ziq2 ~ ziq1)\ncoef(fm1)\n#>  (Intercept)         ziq1 \n#> 1.818206e-16 7.927594e-01\ncor(df$iq1, df$iq2)\n#> [1] 0.7927594"},{"path":"il-modello-statistico-della-regressione-lineare.html","id":"regressione-verso-la-media","chapter":"Capitolo 28 Il modello statistico della regressione lineare","heading":"28.5.3 Regressione verso la media","text":"Il termine regressione fu introdotto da Francis Galton (1822-1911), un\nantropologo che fu, tra le altre cose, promotore dell’eugenetica. Nel\n1886, nell’ambito dei suoi studi sull’ereditarietà dei caratteri, Galton\nraccolse le stature di \\(928\\) figli adulti e dei loro \\(205\\) genitori\n(padri e madri) – dati sono disponibili nel data.frame Galton\ncontenuto nel pacchetto R  HistData. Galton esaminò la relazione tra\nl’altezza media dei figli e l’altezza media dei genitori, che chiamò\n“mid-parent height.” questi dati, genitori e figli hanno la stessa\naltezza media di \\(68.2\\) pollici. Galton osservò però come l’altezza\nmedia dei figli nati da genitori di una data altezza era più simile al\nvalore dell’altezza media della popolazione intera di quanto lo fosse la\nmid-height dei genitori. Ad esempio, per genitori con una mid-height\ncompresa tra \\(70\\) e \\(71\\) pollici, l’altezza media dei figli risultò\nessere di \\(69.5\\) pollici. Nelle parole di Galton, questo corrispondeva\nad una regression toward mediocrity, un concetto che noi oggi\nchiamiamo “regressione verso la media.” Nonostante l’interpretazione\n(errata) di Galton, è importante capire come questo sia un fenomeno\nstatistico, non genetico. Esaminiamo la ragione per cui ciò si verifica.precedenza abbiamo visto come, nel caso di dati standardizzati, la retta di\nregressione campionaria diventa: \\[\\hat{z}_{y_i} = r_{xy} z_{x_i}.\\] Dal\nmomento che \\(r_{xy}\\) è il coefficiente di regressione, esso assume\nvalori compresi tra \\(-1\\) e \\(1\\). Assumiamo che \\(r_{xy}\\) sia positivo e\nminore di \\(1\\) (ovvero, assumiamo che la correlazione tra \\(x\\) e \\(y\\) sia\npositiva ma non perfetta). La formula \\(\\hat{z}_{y_i} = r_{xy} z_{x_i}\\)\nimplica che, se \\(z_{x_i}\\) è positivo, allora il valore predetto\n\\(\\hat{z}_{y_i}\\) dovrà essere minore di \\(z_{x_i}\\). maniera equivalente,\nsi può dire che la ‘distanza’ tra il valore predetto \\(\\hat{y}\\) della\nvariabile di risposta e la media \\(\\bar{y}\\) tenderà ad essere minore della\ndistanza tra \\(x\\) e \\(\\bar{x}\\):\\[\n\\frac{\\hat{y} - \\bar{y}}{s_y} < \\frac{x - \\bar{x}}{s_x}.\n\\]Il termine ‘distanza’ è stato messo tra virgolette quanto è necessario tenere \nconsiderazione l’unità di misura delle variabili. Per fare questo, la\ndistanza tra le osservazioni e il centro della distribuzione viene\nmisurata solo dopo avere standardizzato le variabili – ovvero, viene\nmisurata unità di deviazioni standard.","code":""},{"path":"il-modello-statistico-della-regressione-lineare.html","id":"punti-influenti-e-valori-anomali","chapter":"Capitolo 28 Il modello statistico della regressione lineare","heading":"28.5.4 Punti influenti e valori anomali","text":"La soluzione dei minimi quadrati è fortemente influenzata dalla presenza di punti influenti che sono anche delle osservazioni anomale. Un’osservazione anomala è un’osservazione con un residuo elevato (ovvero, avente un valore anomalo di \\(y\\) rispetto alla previsione). Un punto di leva è un punto con un valore anomalo \\(x\\). Un punto influente è un’osservazione che influenza maniera rilevante le stime dei minimi quadrati. Non sempre un punto anomalo è anche un punto influente. Per contro esistono punti non anomali che influiscono notevolmente sulle stime dei minimi quadrati – si veda la Figura 28.4.\nFigura 28.4: Osservazioni anomale e osservazioni influenti.\n","code":""},{"path":"il-modello-statistico-della-regressione-lineare.html","id":"bontà-delladattamento","chapter":"Capitolo 28 Il modello statistico della regressione lineare","heading":"28.6 Bontà dell’adattamento","text":"Il secondo obiettivo dell’analisi della regressione è quello di misurare la bontà di adattamento del modello di regressione ai dati.","code":""},{"path":"il-modello-statistico-della-regressione-lineare.html","id":"errore-standard-della-stima-1","chapter":"Capitolo 28 Il modello statistico della regressione lineare","heading":"28.6.1 Errore standard della stima","text":"Un indice assoluto della bontà di adattamento è fornito dalla deviazione\nstandard dei residui, \\(s_e\\), chiamata anche errore standard della\nstima. Uno stimatore non distorto della varianza dei residui nella\npopolazione è dato da\\[\\begin{equation}\ns^2_e = \\frac{\\sum e_i^2}{n-2}\n\\tag{28.9}\n\\end{equation}\\]\ne quindi l’errore standard della stima sarà\n\\[\\begin{equation}\ns_e = \\sqrt{\\frac{\\sum e_i^2}{n-2}}.\n\\tag{28.10}\n\\end{equation}\\]\nDato che \\(s_e\\) è possiede la stessa unità di misura della variabile \\(y\\), l’errore standard della stima può essere considerato come una sorta di “residuo medio.”Consideriamo nuovamente l’esempio dei gemelli monozigoti separati alla\nnascita. L’errore standard della regressioneè simile, anche se non identico, al valore medio dei residuiIn conclusione, se usiamo la retta di regressione per predire il quoziente di intelligenza del gemello nato per secondo partire dal quoziente di intelligenza del gemello nato per primo compiamo, media, un errore di circa 6 punti.","code":"\nsqrt(sum(e^2) / (length(e) - 2)) \n#> [1] 6.101646\nmean(abs(fm$residuals)) \n#> [1] 4.91695"},{"path":"il-modello-statistico-della-regressione-lineare.html","id":"indice-di-determinazione","chapter":"Capitolo 28 Il modello statistico della regressione lineare","heading":"28.6.2 Indice di determinazione","text":"Un importante risultato dei minimi quadrati riguarda la cosiddetta scomposizione della devianza di regressione mediante la quale si definisce l’indice di determinazione, il quale fornisce una misura relativa della bontà di adattamento del modello di regressione ai dati\ndel campione. Come indicato nella figura 28.5, per una generica osservazione\n\\(x_i, y_i\\), la variazione di \\(y_i\\) rispetto alla media \\(\\bar{y}\\) può essere descritta come la somma di due componenti: il residuo \\(e_i=y_i- \\hat{y}_i\\) e lo scarto di \\(\\hat{y}_i\\) rispetto alla media \\(\\bar{y}\\): \\(y_i - \\bar{y} = (y_i- \\hat{y}_i) + (\\hat{y}_i - \\bar{y}) = e_i + (\\hat{y}_i - \\bar{y})\\).\nFigura 28.5: Scomposizione della devianza.\nSe consideriamo tutte le osservazioni, la devianza delle \\(y\\) può essere scomposta nel seguente modo:\\[\n\\begin{aligned}\n \\sum (y_i - \\bar{y})^2 &= \\sum \\left[ e_i + (\\hat{y}_i - \\bar{y})\n \\right]^2 \n = \\sum e_i^2 + \\sum (\\hat{y}_i - \\bar{y})^2 + 2 \\sum e_i (\\hat{y}_i -\n \\bar{y}) \\notag\\end{aligned}\n \\]Per vincoli imposti sui residui dalle equazioni normali, il doppio prodotto si annulla, infatti\\[\n\\begin{aligned}\n\\sum e_i (\\hat{y}_i - \\bar{y}) &= \\sum e_i \\hat{y}_i - \\bar{y}\\sum e_i = \\sum e_i (+ b x_i) \\notag \\\\\n&= \\sum e_i + b \\sum e_i x_i = 0 \\notag\\end{aligned}\n\\]Di conseguenza, possiamo concludere che la devianza totale (\\(\\dev_T\\)) si scompone nella somma della devianza di dispersione (\\(dev_E\\)) e della devianza di regressione (\\(\\dev_T\\)):\\[\n\\begin{aligned}\n\\underbrace{\\sum_{=1}^n (y_i - \\bar{y})^2}_{\\tiny{\\text{Devianza\ntotale}}} &= \\underbrace{\\sum_{=1}^n e_i^2}_{\\tiny{\\text{Devianza\ndi dispersione}}} + \\underbrace{\\sum_{=1}^n  (\\hat{y}_i -\n\\bar{y})^2}_{\\tiny{\\text{Devianza di regressione}}} \\notag\n\\end{aligned}\n\\]La devianza di regressione, \\(dev_R \\triangleq dev_T - dev_E\\), indica dunque la riduzione degli errori al quadrato che è imputabile alla regressione lineare. Il rapporto \\(dev_T/dev_T\\), detto indice di determinazione, esprime tale riduzione degli errori termini proporzionali e definisce il coefficiente di correlazione al quadrato:\\[\\begin{equation}\nr^2 \\triangleq \\frac{dev_R}{dev_T} = 1 - \\frac{dev_E}{dev_T}.\n\\tag{28.11}\n\\end{equation}\\]Quando l’insieme di tutte le deviazioni della \\(y\\) dalla media è spiegato dall’insieme di tutte le deviazioni della variabile teorica \\(\\hat{y}\\) dalla media, si ha che l’adattamento (o accostamento) del modello al campione di dati è perfetto, la devianza residua è nulla ed \\(r^2 = 1\\); nel caso opposto, la variabilità totale coincide con quella residua, per cui \\(r^2 = 0\\). Tra questi due estremi, \\(r\\) indica l’intensità della relazione lineare tra le due variabili e \\(r^2\\), con \\(0 \\leq r^2 \\leq 1\\), esprime la porzione della devianza totale della \\(y\\) che è spiegata dalla regressione lineare sulla \\(x\\).Per dati dei gemelli monozitoti separati alla nascita, la devianza totale si scompone nelle componenti di “devianza spiegata” e “devianza non spiegata” nel modo seguente:le quali assumono valori, rispettivamente, pari \\(3206.618\\), \\(2015.255\\) e \\(1191.363\\). Ne segue che il coefficiente di determinazione è dev_r / dev_t = 0.628, ovvero 1 - dev_e / dev_t = 0.628. Questo risultato coincide con quello trovato con lm():Possiamo quindi concludere che, nel caso del campione esaminato, fattori genetici spiegano circa il 63% della varianza del quoziente di intelligenza dei gemelli monozigoti (quando prevediamo il QI dei secondi nati dal QI dei primi nati).","code":"\ndev_t <- sum((df$iq2 - mean(df$iq2))^2) \ndev_r <- sum((yhat - mean(df$iq2))^2)\ndev_e <- sum((df$iq2 - yhat)^2)\nsummary(fm)$r.squared\n#> [1] 0.6284675"},{"path":"il-modello-statistico-della-regressione-lineare.html","id":"inferenza-sullassociazione-tra-x-e-y-nella-popolazione","chapter":"Capitolo 28 Il modello statistico della regressione lineare","heading":"28.7 Inferenza sull’associazione tra \\(x\\) e \\(y\\) nella popolazione","text":"Il terzo obiettivo dell’analisi di regressione è quello di fare inferenze sull’associazione tra le due variabili nella popolazione da cui il campione deriva. Ci chiediamo se l’associazione osservata nel campione rifletta le proprietà della popolazione oppure sia imputabile agli errori di campionamento.Se si segue la scuola frequentista, nella regressione bivariata il\nproblema dell’inferenza statistica è basato sulla stessa logica seguita\nnel caso di una singola variabile aleatoria. Nell’inferenza su una\nmedia, per esempio, viene valutata l’ipotesi nulla \\(H_0: \\mu=0\\) e il\nparametro di interesse, la media \\(\\mu\\) della popolazione, viene stimato\nmediante un’opportuna statistica, ovvero la media campionaria \\(\\bar{y}\\).\nLe inferenze statistiche sono basate sulla conoscenza delle proprietà\ndella distribuzione della statistica campionaria \\(\\bar{y}\\).È possibile però anche definire degli stimatori che dipendono da due (o\npiù) caratteri. Per esempio, il coefficiente \\(b\\) della retta di\nregressione campionaria, che viene usato quale stimatore del\ncoefficiente angolare \\(\\beta\\) della funzione di regressione nella\npopolazione \\(y = \\alpha + \\beta x + \\varepsilon\\), è definito rispetto \ndue caratteri, \\(x\\) e \\(y\\). Per ciascun campione casuale di \\(n\\)\nosservazioni \\(x, y\\), lo stimatore \\(b\\) di \\(\\beta\\) assume un diverso\nvalore (\\(b\\) è una variabile aleatoria). L’insieme delle stime \\(b\\) di\n\\(\\beta\\) nell’universo dei campioni di ampiezza \\(n\\) costituisce la\ndistribuzione campionaria di \\(b\\). Analogamente si può dire dello\nstimatore \\(\\) di \\(\\alpha\\). Il problema che ci poniamo ora è appunto\nquello di descrivere le proprietà delle distribuzioni campionarie dei\ndue stimatori dei minimi quadrati \\(\\) e \\(b\\). Per fare questo, dobbiamo\nperò prima introdurre il modello statistico della regressione lineare.","code":""},{"path":"il-modello-statistico-della-regressione-lineare.html","id":"modello-statistico-di-regressione-lineare","chapter":"Capitolo 28 Il modello statistico della regressione lineare","heading":"28.7.1 Modello statistico di regressione lineare","text":"corrispondenza di ciascun valore della variabile \\(x\\), che si\nipotizza essere costante da campione campione, corrisponde nella\npopolazione una distribuzione di valori \\(y\\). Ci chiediamo che relazione\nintercorra tra le medie condizionali \\(\\bar{y}_i \\mid x_i\\) e la variabile\n\\(x\\). Se disponiamo di un campione di ciascuna distribuzione condizionata\n\\(y_i \\mid x_i\\), allora possiamo calcolare la media condizionale nel\ncampione per stimare la corrispondente media nella popolazione. Una tale\nsituazione si può verificare un contesto sperimentale, cui,\nmantenendo fissi valori del carattere \\(x\\), la ripetizione delle prove\nproduce un campione del carattere \\(y\\) subordinatamente ad ogni \\(x\\).\nNel caso di dati di tipo osservazionale, invece, vengono osservate\ncoppie di valori (\\(x_i, y_i\\)), con \\(=1, \\dots, n\\), e per ogni valore\n\\(x\\) si ha disposizione un unico valore \\(y\\).Allo scopo di attenuare le conseguenze derivanti dalle limitazioni di\ncui soffrono dati disposizione, si definisce il modello statistico\ndi regressione lineare introducendo nell’analisi delle ipotesi sulla\npopolazione. Il modello statistico di regressione è basato sulle quattro seguenti\nipotesi proposito della struttura della popolazione.La funzione di regressione è lineare (linearità):\n\\[\n\\mathbb{E}(y_i \\mid x_1, \\dots, x_n) = \\alpha + \\beta x_i, \\quad\n=1, \\dots, n,\n\\]\novvero, le medie delle distribuzioni condizionali \\(y \\mid x_i\\) sono linearmente associate alla variabile esplicativa x.La funzione di regressione è lineare (linearità):\n\\[\n\\mathbb{E}(y_i \\mid x_1, \\dots, x_n) = \\alpha + \\beta x_i, \\quad\n=1, \\dots, n,\n\\]\novvero, le medie delle distribuzioni condizionali \\(y \\mid x_i\\) sono linearmente associate alla variabile esplicativa x.Le varianze delle distribuzioni condizionali \\(y \\mid x_i\\) sono costanti al variare della \\(x\\) (omoschedasticità):\n\\[\nvar(y_i \\mid x_1, \\dots,  x_n) = \\sigma^2, \\quad =1,\n\\dots, n.\n\\]Le varianze delle distribuzioni condizionali \\(y \\mid x_i\\) sono costanti al variare della \\(x\\) (omoschedasticità):\n\\[\nvar(y_i \\mid x_1, \\dots,  x_n) = \\sigma^2, \\quad =1,\n\\dots, n.\n\\]Le osservazioni \\(y_i\\) sono tra loro incorrelate subordinatamente alle \\(x_i\\) (indipendenza):\n\\[\ncov(y_i, y_j \\mid x_1, \\dots, x_n) = 0, \\quad per \\hskip.1 \\neq j,\n\\]\novvero, l’osservazione \\(y_i\\) è selezionata dalla distribuzione condizionale \\(y_i \\mid x_i\\) tramite un campionamento casuale indipendente.Le osservazioni \\(y_i\\) sono tra loro incorrelate subordinatamente alle \\(x_i\\) (indipendenza):\n\\[\ncov(y_i, y_j \\mid x_1, \\dots, x_n) = 0, \\quad per \\hskip.1 \\neq j,\n\\]\novvero, l’osservazione \\(y_i\\) è selezionata dalla distribuzione condizionale \\(y_i \\mid x_i\\) tramite un campionamento casuale indipendente.La distribuzione di \\(y_i\\) subordinata \\(X=x_i\\) segue la distribuzione gaussiana (normalità):\n\\[\n(y_i \\mid x_i) \\sim \\mathcal{N}(\\alpha+\\beta x_i, \\sigma^2).\n\\]La distribuzione di \\(y_i\\) subordinata \\(X=x_i\\) segue la distribuzione gaussiana (normalità):\n\\[\n(y_i \\mid x_i) \\sim \\mathcal{N}(\\alpha+\\beta x_i, \\sigma^2).\n\\]","code":""},{"path":"il-modello-statistico-della-regressione-lineare.html","id":"proprietà-degli-stimatori-dei-minimi-quadrati","chapter":"Capitolo 28 Il modello statistico della regressione lineare","heading":"28.7.2 Proprietà degli stimatori dei minimi quadrati","text":"Può essere dimostrato (vedi Appendici) che, se le assunzioni del modello lineare sono soddisfatte, allora coefficienti dei minimi quadrati avranno le seguenti proprietà:\\[\\begin{equation}\n\\begin{aligned}\nb &\\sim \\mathcal{N}\\bigg(\\beta,  \\frac{\\sigma^2_{\\varepsilon}}{\\sum(x_i-\\bar{x})^2}\\bigg),\\\\\n&\\sim \\mathcal{N}\\bigg(\\alpha, \\frac{\\sigma^2_{\\varepsilon}\\textstyle\\sum x_i^2}{n \\textstyle\\sum (x_i-\\bar{x})^2} \\bigg).\n\\end{aligned}\n\\tag{28.12}\n\\end{equation}\\]","code":""},{"path":"il-modello-statistico-della-regressione-lineare.html","id":"le-inferenze-sul-modello-di-regressione","chapter":"Capitolo 28 Il modello statistico della regressione lineare","heading":"28.7.3 Le inferenze sul modello di regressione","text":"L’inferenza statistica sul modello di regressione può essere svolta modi diversi. Esamineremo qui l’approccio frequentista per affrontare seguito l’approccio Bayesiano.L’inferenza statistica frequentista si articola nella formulazione degli intervalli di confidenza per parametri di interesse e nei test di significatività statistica.\nUn’ipotesi che viene frequentemente sottoposta verifica è quella di significatività, cioè l’ipotesi che alla variabile esplicativa sia associato un coefficiente nullo. tal caso, l’ipotesi nulla è\n\\[\nH_0:\\beta=0\n\\]\ne l’ipotesi alternativa è\n\\[\nH_1:\\beta \\neq 0.\n\\]\nSotto l’ipotesi nulla \\(H_0: \\beta = 0\\) la statistica\n\\[\nt_{\\hat{\\beta}} = \\frac{\\hat{\\beta}}{s_{\\hat{\\beta}}}\n\\]\nsi distribuisce come una variabile aleatoria \\(t\\) di Student con \\(n-2\\) gradi\ndi libertà.Di fronte al problema di decidere se il valore stimato \\(\\hat{\\beta}\\) sia\nsufficientemente ‘distante’ da zero, modo da respingere l’ipotesi\nnulla che il vero valore \\(\\beta\\) sia nullo, non è sufficiente basarsi\nsoltanto sul valore numerico assunto da \\(\\hat{\\beta}\\), ma occorre tener\nconto della variabilità campionaria. La statistica ottenuta dividendo\n\\(\\hat{\\beta}\\) per la stima del suo errore standard, \\(s_{\\hat{\\beta}}\\),\nci permette di utilizzare la distribuzione \\(t\\) di Student come metrica\nper stabilire se la stima trovata si debba considerare ‘diversa’ da\nquanto ipotizzato sotto \\(H_0\\).L’ipotesi nulla viene rifiutata quando il valore assoluto del rapporto è\nesterno alla regione di accettazione, cui limiti sono definiti dai\nvalori critici della distribuzione \\(t\\) di Student con \\(n - 2\\) gradi di\nlibertà per il livello di significatività \\(\\alpha\\) prescelto. Se\nl’ipotesi nulla viene rifiutata si dice che il coefficiente\n\\(\\hat{\\beta}\\) è “statisticamente significativo” ammettendo così la\npossibilità di descrivere con un modello lineare la relazione esistente\ntra le variabili \\(x\\) e \\(y\\). Quando non si può rifiutare l’ipotesi nulla\nnel modello di regressione, si conclude che il coefficiente angolare\ndella retta non risulta significativamente diverso da zero, individuando\ncosì nella popolazione una retta parallela ’asse delle ascisse.Il valore-\\(p\\) esprime la probabilità di ottenere un valore del test\nuguale o superiore quello ottenuto nel campione esaminato, utilizzando\nla distribuzione campionaria del test sotto l’ipotesi nulla. Se\n\\(t_{\\hat{\\beta}}\\) è il valore osservato del rapporto \\(t\\) per il\ncoefficiente angolare della retta di regressione, allora il \\(p\\)-valore è\ndato da \\[p = 2 \\times Pr(t \\geq |t_{\\hat{\\beta}}|),\\] dove \\(t\\) è il\nvalore di una variabile aleatoria \\(t\\) di Student con \\((n-2)\\) gradi di\nlibertà.Ogni volta che il \\(p\\)-valore del test è inferiore al livello di\nsignificatività che si è scelto per \\(H_0\\), il test porta al rifiuto\ndell’ipotesi nulla. Solitamente si sceglie un livello \\(\\alpha\\) pari \n0.05 o 0.01.Consideriamo nuovamente la regressione del QI del secondo nato sul QI del primo nato nei gemelli monozigoti esaminati da Anderson & Finn (2012). Dall’output prodotto dalla funzione lm() possiamo ricavare le informazioni per il calcolo della statistica \\(t\\):che risulta essere\\[\nt = \\frac{B}{s_{\\hat{\\beta}}}=\\frac{0.8499}{0.1155} = 7.357.\n\\]\nSupponendo un’ipotesi alternativa bidirezionale, \\(H_1: \\beta \\neq 0\\), la regione critica sarà suddivisa nelle due code della distribuzione \\(t\\) di Student con \\(25\\) gradi di libertà. Essendo il valore critico \\(t_{n-2, 1-\\alpha/2}\\) pari asi può rifiutare \\(H_0\\).maniera corrispondente, possiamo considerare il \\(p\\)-valore. Il \\(p\\)-valore è l’area sottesa alla funzione di densità \\(t\\) di Student con \\(n-2=32\\) gradi di libertà nei due intervalli \\([-\\infty, -t_{\\hat{\\beta}}]\\) e \\([t_{\\hat{\\beta}}, \\infty]\\) èDato che il \\(p\\)-valore è minore di \\(\\alpha = 0.05\\), l’approccio frequentista conclude rigettando \\(H_0\\). Il risultato si può riportare nel modo seguente:L’analisi della regressione bivariata ha rivelato una relazione lineare positiva tra il QI dei gemelli monozigoti primi nati e il QI dei gemelli secondi nati, \\(\\hat{\\beta} = 0.85\\), \\(t_{32} = 7.36\\), \\(p = .0001\\).test di significatività possono essere eseguiti con R  utilizzando la funzione summary() applicata ’oggetto creato dal lm(): Il test statistico sul parametro \\(\\beta\\) del modello di regressione verifica l’ipotesi nulla di indipendenza, ovvero l’ipotesi che, nella popolazione, la pendenza della retta di regressione sia uguale zero.Più informativo del test statistico \\(H_0: \\beta=0\\) è l’intervallo di confidenza per il parametro \\(\\beta\\):\n\\[\n\\hat{\\beta} \\pm t_{\\alpha/2} s_{\\hat{\\beta}}.\n\\]\nNel caso presente, abbiamoDato che il limite inferiore dell’intervallo di confidenza è superiore allo zero, possiamo concludere che vi è un’associazione (lineare) positiva tra il QI del primo nato e il QI del secondo nato, nelle coppie di gemelli monozigoti che sono state esaminate da Anderson & Finn (2012).","code":"\nsummary(fm)\n#> \n#> Call:\n#> lm(formula = iq2 ~ iq1, data = df)\n#> \n#> Residuals:\n#>      Min       1Q   Median       3Q      Max \n#> -11.0342  -3.8218  -0.5852   3.4658  12.5635 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)   1.8389     3.0269   0.608    0.548    \n#> iq1           0.8499     0.1155   7.357 2.29e-08 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 6.102 on 32 degrees of freedom\n#> Multiple R-squared:  0.6285, Adjusted R-squared:  0.6169 \n#> F-statistic: 54.13 on 1 and 32 DF,  p-value: 2.288e-08\nqt(.975, 32)\n#> [1] 2.036933\n1 - pt(7.357, 32)\n#> [1] 1.145083e-08\nfm$coef[2] + c(-1, 1) * qt(.025, 32) * 0.1155\n#> [1] 1.0851203 0.6145887"},{"path":"il-modello-statistico-della-regressione-lineare.html","id":"considerazioni-conclusive","chapter":"Capitolo 28 Il modello statistico della regressione lineare","heading":"Considerazioni conclusive","text":"Il modello di regressione lineare semplice viene usato per descrivere la\nrelazione tra due variabili e per determinare il segno e l’intensità di\ntale relazione. Inoltre, il modello di regressione ci consente di\nprevedere il valore della variabile dipendente base ad alcuni nuovi\nvalori della variabile indipendente. Il modello di regressione lineare\nsemplice è realtà molto limitato, quanto descrive soltanto la\nrelazione tra la variabile dipendente \\(y\\) e una sola variabile\nesplicativa \\(x\\). Esso diventa molto più utile quando incorpora più\nvariabili indipendenti. questo secondo caso, però, calcoli per la\nstima dei coefficienti del modello diventano più complicati. Abbiamo\ndeciso qui di presentare solo il modello di regressione lineare semplice\nperché, quel caso, sia la logica dell’inferenza sia le procedure di\ncalcolo sono facilmente maneggiabili. Nel caso più generale, quello del\nmodello di regressione multipla, la logica dell’inferenza rimarrà\nidentica quella discussa qui, ma le procedure di calcolo richiedono\nl’uso dell’algebra matriciale che esula dagli scopi del presente\ninsegnamento. Il modello di regressione multipla può includere sia\nregressori quantitativi, sia regressori qualitativi, utilizzando un\nopportuna schema di codifica. È interessante notare come un modello di\nregressione multipla che include una sola variabile esplicativa\nquantitativa corrisponde ’analisi della varianza ad una via; un\nmodello di regressione multipla che include più di una variabile\nesplicativa quantitativa corrisponde ’analisi della varianza più vie.\nQuesti argomenti verranno sviluppati negli insegnamenti di carattere\nquantitativo più avanzati. Possiamo qui concludere dicendo che il\nmodello di regressione, nelle sue varie forme e varianti, costituisce la\ntecnica di analisi dei dati maggiormente usata psicologia.","code":""},{"path":"inferenza-bayesiana.html","id":"inferenza-bayesiana","chapter":"Capitolo 29 Inferenza Bayesiana","heading":"Capitolo 29 Inferenza Bayesiana","text":"Prima di descrivere come il modello di regressione lineare possa essere applicato ai dati mediante l’approccio Bayesiano, esamineremo modelli statistici Bayesiani che vengono utilizzati alcuni casi più semplici, ovvero (1) il modello statistico per una proporzione e (2) il modello statistico utilizzato per il confronto tra due proporzioni. Estenderemo poi la discussione al caso cui viene considerato (3) un campione di osservazioni misurate su scala continua, assumendo che ciascuna osservazione provenga da una distribuzione Normale. tali circostanze, l’oggetto dell’inferenza sarà il parametro \\(\\mu\\) che rappresenta la media della popolazione da cui le osservazioni sono state tratte. questo punto saremo nelle condizioni di discutere (4) l’inferenza Bayesiana sulla differenza tra le medie di due popolazioni. Tale problema verrà affrontato specificando un modello di regressione lineare che include una variabile dipendente continua e una variabile indipendente dicotomica. Una volta chiarite le proprietà del modello di regressione questo caso semplice, sarà immediato estendere la discussione (5) al caso di una variabile indipendente continua.","code":""},{"path":"inferenza-bayesiana.html","id":"modello-binomiale","chapter":"Capitolo 29 Inferenza Bayesiana","heading":"29.1 Modello Binomiale","text":"Se facciamo nuovamente riferimento ’esempio del mappamondo di McElreath (2020), nel quale abbiamo osservato \\(= 6\\) volte “acqua” \\(N = 9\\) prove Bernoulliane indipendenti, allora il modello statistico che descrive l’esperimento casuale può essere\nformulato nei termini seguenti:\\[\\begin{equation}\n\\begin{aligned}\n&\\sim \\text{Binom}(N, p) \\\\\np &\\sim \\text{Unif}(0, 1) \n\\end{aligned}\n\\tag{29.1}\n\\end{equation}\\]dove la prima riga definisce la funzione di verosimiglianza e la seconda riga definisce la distribuzione priori. Il segno \\(\\sim\\) (tilde) si può leggere “si distribuisce come.” La prima riga, dunque, ci dice che la variabile aleatoria \\(\\) segue la distribuzione Binomiale di parametri \\(N\\) e \\(p\\). La seconda riga specifica che, quale distribuzione priori, assumiamo una distribuzione uniforme (0 e 1) per il parametro \\(p\\). Sulla base di queste informazioni, il nostro obiettivo è di costruire la distribuzione posteriori \\(P(p \\mid , N)\\). Per ottenere questo risultato utilizzeremo il teorema di Bayes:\\[\n\\text{distribuzione posteriori} \\propto \\text{verosimiglianza} \\times \\text{distribuzione priori}.\n\\]","code":""},{"path":"inferenza-bayesiana.html","id":"il-presidente-trump-e-lidrossiclorochina","chapter":"Capitolo 29 Inferenza Bayesiana","heading":"29.2 Il presidente Trump e l’idrossiclorochina","text":"Cito dal Washington Post del 7 aprile 2020:One bizarre disturbing aspects President Trump’s nightly press briefings coronavirus pandemic turns drug salesman. Like cable TV pitchman hawking ‘male enhancement’ pills, Trump regularly extols virtues taking hydroxychloroquine, drug used treat malaria lupus, potential ‘game changer’ just might cure Covid-19.Tralasciamo qui il fatto che il presidente Trump non è un esperto questo campo. Esaminiamo invece le evidenze iniziali supporto dell’ipotesi che l’idrossiclorochina possa essere utile per la cura del Covid-19, ovvero le evidenze che erano disponibili nel momento cui il presidente Trump ha fatto le affermazioni riportate sopra (seguito, quest’idea è stata completamente screditata). Tali evidenze sono state fornite da Gautret et al. (2020).Il disegno sperimentale di Gautret et al. (2020) comprende, tra le altre cose, il confronto tra una condizione sperimentale e una condizione di controllo. Un articolo pubblicato da Hulme et al. (2020) si è posto il problema di rianalizzare dati di Gautret et al. (2020) – si veda\nhttps://osf.io/5dgmx/. Tra gli autori di questo secondo articolo figura anche Eric-Jan Wagenmakers, uno psicologo molto conosciuto per suoi contributi metodologici. Hulme et al. (2020) sottolineano il fatto che Gautret et al. (2020) si sono concentrati, nella loro analisi dei dati, soltanto su una parte del loro campione. Se però vengono considerati anche pazienti che sono stati esclusi dall’analisi dei dati, le conclusioni cui sono giunti Gautret et al. (2020) risultano fortemente indebolite.L’analisi dei dati proposta da Hulme et al. (2020) richiede l’uso di alcuni\nstrumenti statistici che, queste dispense, non verranno discussi. Ma\npossiamo giungere alle stesse conclusioni di Hulme et al. (2020) anche usando le\nprocedure statistiche che abbiamo descritto finora. Nella ricerca di\nGautret et al. (2020) il confronto importante è tra la proporzione di paziente\npositivi al virus SARS-CoV-2 nel gruppo cui è stata somministrata\nl’idrossiclorochina (6 su 14) e nel gruppo di controllo (cui non è\nstata somministrata l’idrossiclorochina: 14 positivi su 16). Ciò che\nfaremo sarà di calcolare la distribuzione posteriori per queste due\nproporzioni. Rappresenteremo graficamente le due distribuzioni \nposteriori per il parametro \\(p\\) che rappresenta la probabilità di\nrisultare positivo al SARS-CoV-2. Calcoleremo anche, separatamente per \ndue gruppi, l’intervallo di credibilità al 95%. Quindi concluderemo\nfacendo il confronto tra gli intervalli di credibilità dei due gruppi.Leggiamo dati R  creando due vettori seguenti. Il vettore ym\ncontiene dati del gruppo cui è stata somministrata\nl’idrossiclorochina e il vettore yc dati del gruppo di controllo. Il\nvalore \\(y = 1\\) indica che il paziente è positivo al virus SARS-CoV-2\n(l’ordine di 0 e 1 è irrilevante).Utilizziamo ora la sintassi di rethinking per definire il modello statistico appropriato per una proporzione. Specifichiamo inoltre una distribuzione priori non informativa:La funzione alist crea un oggetto R di tipo lista, ovvero un insieme ordinato di oggetti. Nel nostro caso, il primo oggetto contenuto nella lista è la specificazione della funzione di verosimiglianza y ~ dbinom(1, p), mentre il secondo oggetto è la specificazione della distribuzione priori per il parametro p p ~ dbeta(1, 1). La funzione di verosimiglianza indica che dati (nel nostro caso, la frequenza assoluta di casi positivi al virus SARS-CoV-2) si distribuiscono come una variabile aleatoria binomiale di parametro \\(p\\) (il valore \\(N\\) è fisso e conosciuto). La distribuzione priori per il parametro sconosciuto \\(p\\) è inoltre specificata mediante una Beta(1, 1), ovvero mediante una distribuzione uniforme nell’intervallo unitario [0, 1].Il calcolo della distribuzione posteriori per il parametro \\(p\\) può essere svolto mediante la funzione qmap(). Tale funzione richiede due argomenti: il modello statistico specificato da alist() e dati. Tale funzione stima la funzione posteriori mediante il metodo dell’approssimazione quadratica discusso precedenza. Anche dati devono essere un oggetto R di tipo lista. Tale oggetto può essere creato mediante l’istruzione list(). Nel caso del gruppo sperimentale abbiamoLa funzione quap() crea un oggetto che abbiamo chiamato m il quale contiene tutte le informazioni che ci servono proposito della distribuzione posteriori. Per rappresentare conun grafico la distribuzione posteriori del parametro \\(p\\) usiamo le seguenti istruzioni:\nPossiamo sintetizzare la distribuzione posteriori del parametro \\(p\\) mediante la specificazione dell’intervallo di credibilità al 95%:L’intervallo di credibilità al 95% per il parametro \\(p\\) che abbiamo ottenuto per il gruppo sperimentale ci dice che possiamo essere sicuri al 95% che, nel gruppo sperimentale, la probabilità di risultare positivi al virus SARS-CoV-2 è un valore compreso nell’intervallo [.17, 0.69]. Questo intervallo è piuttosto ampio, il che suggerisce che abbiamo una grande incertezza su quale sia l’effettiva probabilità di risultare positivi al virus SARS-CoV-2 nella popolazione che ha le stesse caratteristiche del gruppo sperimentale, ovvvero coloro che hanno assunto l’idrossiclorochina.La nostra domanda riguarda però l’efficacia dell’idrossiclorochina. Dunque vogliamo confrontare la stima della probabilità di risultare positivi al virus SARS-CoV-2 per coloro che hanno assunto l’idrossiclorochina e coloro che non l’hanno assunta. Dobbiamo dunque calcolare l’intervallo di credibilità al 95% per il gruppo di controllo e confrontarlo con quello trovato sopra.Ripetiamo quindi la stessa procedura appena eseguita, usando però dati del gruppo di controllo.Una rappresentazione grafica della distribuzione posteriori del parametro \\(p\\) nella condizione di controllo si ottiene con le istruzioni seguenti:L’intervallo di credibilità al 95% per il gruppo di controllo èLe due figure che abbiamo realizzato presentano le distribuzioni posteriori del parametro \\(p\\) (cioè la probabilità di risultare positivo al virus SARS-CoV-2) per due gruppi di pazienti considerati nella ricerca di Gautret et al. (2020). Come si possono interpretare? Le figure ci mostrano che le due distribuzioni posteriori sono chiaramente separate, il che suggerisce che il parametro \\(p\\) assume valori diversi nei due gruppi.Infatti, coerentemente con la conclusioni di Gautret et al. (2020), le stime posteriori per il parametro \\(p\\) che abbiamo trovato suggeriscono che pazienti del gruppo sperimentale (cui è stata somministrata l’idrossiclorochina) hanno unaprobabilità minore di risultare positivi al SARS-CoV-2 rispetto ai pazienti del gruppo di controllo (cui non è stata somministrata l’idrossiclorochina).\nCiò è indicato dal confronto tra due intervalli di credibilità al 95% che abbiamo calcolato. Gli intervalli di credibilità dei due gruppi non si sovrappongono. Questo fatto viene interpretato dicendo che il parametro \\(p\\) è diverso nei due gruppi. Sulla base di queste evidenza, dunque, possiamo concludere, con un grado di certezza soggettiva del 95%, che nel gruppo sperimentale vi è una probabilità più bassa di risultare positivi al SARS-CoV-2 rispetto al gruppo di controllo. altri termini, la conclusione di questa analisi dei dati suggerisce che l’idrossiclorochina è efficace come terapia per il Covid-19. Svolgendo le analisi precedenti abbiamo dunque replicato le conclusioni cui sono giunti Gautret et al. (2020), sia pur utilizzando una procedura statistica diversa.Tuttavia, nella ricerca di Gautret et al. (2020) è presente un aspetto che non abbiamo finora considerato. Hulme et al. (2020) hanno infatti osservato che Gautret et al. (2020), nelle loro analisi statistiche, hanno escluso alcuni dati. Sono stati infatti osservati dei pazienti quali, nel gruppo sperimentale, sono realtà peggiorati, anziché essere migliorati. L’analisi di Gautret et al. (2020) non considera questi dati.Se consideriamo tutti pazienti – non solo quelli selezionati da Gautret et al. (2020) – la situazione è la seguente. Gruppo sperimentale: 10 positivi su 18; gruppo di controllo: 14 positivi su 16. Ripetiamo dunque l’analisi descritta precedenza utilizzando, per il gruppo sperimentale, tutti dati che abbiamo disposizione. Così facendo otteniamo il seguente intervallo di credibilità al 95%:Quando utilizziamo tutti dati – non soltanto pazienti selezionati da Gautret et al. (2020) – otteniamo il seguente intervallo di credibilità al 95% per il gruppo sperimentale: [0.33, 0.79]. Tale intervallo si sovrappone ’intervallo di credibilità al 95% per il gruppo di controllo, [0.71 1.04]. base agli standard correnti, un risultato di questo tipo non viene considerato come evidenza sufficiente per potere concludere che il parametro \\(p\\) assume un valore diverso nei due gruppi. altri termini, se consideriamo tutti dati, e non solo quelli selezionati dagli autori, non vi è evidenza alcuna che l’idrossiclorochina sia efficace come terapia per il Covid-19.Concludiamo questa discussione dicendo che ciò che è stato presentato questo capitolo è solo un esercizio didattico: la ricerca di Gautret et al. (2020) include tante altre informazioni che qui non sono state qui considerate. Tuttavia, notiamo che la semplice analisi statistica che abbiamo descritto è stata grado di replicare completamente le conclusioni cui sono giunti (per altra via) Hulme et al. (2020).","code":"\nym <- c(rep(1, 6), rep(0, 8))\nym\n#>  [1] 1 1 1 1 1 1 0 0 0 0 0 0 0 0\nyc <- c(rep(1, 14), rep(0, 2))\nyc\n#>  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\nsuppressPackageStartupMessages(library(\"rethinking\"))\noptions(mc.cores = parallel::detectCores())\n\nflist <- alist(\n  y ~ dbinom(1, p),\n  p ~ dbeta(1, 1) \n)\nm <- quap( \n  flist, \n  data = list(y = ym)\n)\npost <- extract.samples(m)\nplot(\n  density(post$p), \n  xlim = c(0, 1),\n  ylim = c(0, 5),\n  main = \"\",\n  xlab = \"Parametro p\",\n  ylab = \"Densità\"\n)\nprecis(m, prob = 0.95)\n#>        mean        sd      2.5%     97.5%\n#> p 0.4285638 0.1322588 0.1693412 0.6877863\nmc <- quap( \n  flist, \n  data = list(y = yc)\n)\npostc <- extract.samples(mc)\nplot(\n  density(postc$p), \n  xlim = c(0, 1),\n  ylim = c(0, 5),\n  main = \"\",\n  xlab = \"Parametro p\",\n  ylab = \"Densità\"\n)\nlines(density(postc$p), xlim = c(0, 1))\nprecis(mc, prob = 0.95)\n#>        mean         sd      2.5%    97.5%\n#> p 0.8749966 0.08267702 0.7129526 1.037041\nym <- c(rep(1, 10), rep(0, 8))\nym\n#>  [1] 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0\nm <- quap( \n  flist, \n  data = list(y = ym)\n)\nprecis(m, prob = 0.95)\n#>        mean        sd      2.5%     97.5%\n#> p 0.5555554 0.1171209 0.3260026 0.7851081"},{"path":"inferenza-bayesiana.html","id":"modello-normale","chapter":"Capitolo 29 Inferenza Bayesiana","heading":"29.3 Modello Normale","text":"Consideriamo ora un altro esempio esaminando, questo caso, un campione di dati estratto dalla distribuzione Normale:\\[\n\\begin{aligned}\nY_i &\\sim \\mathcal{N}(\\mu, \\sigma) \\\\\n\\mu &\\sim \\mathcal{N}(\\mu = \\bar{X}, \\sigma = 100) \\\\\n\\sigma &= s_Y \n\\end{aligned}\n\\]\nQuesto modello statistico ci dice che la variabile aleatoria \\(Y\\) segue la distribuzione Normale di parametri \\(\\mu\\) e \\(\\sigma\\). Il parametro \\(\\mu\\) è sconosciuto e abbiamo deciso di descrivere la nostra incertezza priori relativa ad esso mediante una distribuzione priori che segue la legge Normale con media uguale alla media campionaria e con deviazione standard paria 100. questo esempio, il parametro \\(\\sigma\\) è fissato ad un valore pari alla deviazione standard del campione, \\(s_y\\). Prendiamo questa decisione qui per presentare un esempio nelle condizioni più semplici, ovvero quelle nelle quali l’unica incognita è \\(\\mu\\). generale, però, anche il parametro \\(\\sigma\\) viene considerato ignoto e ad esso viene assegnata una distribuzione priori; ad esempio, \\(\\sigma \\sim \\text{Unif}(0, 100)\\).","code":""},{"path":"inferenza-bayesiana.html","id":"il-modello-normale-con-quap","chapter":"Capitolo 29 Inferenza Bayesiana","heading":"29.3.1 Il modello normale con quap()","text":"Per fare un esempio pratico, consideriamo 30 valori del BDI-II dei soggetti clinici di Zetsche et al. (2019):Calcoliamo le statistiche descrittive per questi dati:Definiamo ora il modello statistico mediante la funzione alist():Le precedenti istruzioni R specificano un variabile aleatoria \\(x\\) che si distribuisce come una Normale di parametri \\(\\mu\\) e \\(\\sigma\\); questa è la verosimiglianza. Per utilizzare una notazione che impiegheremo seguito (ma che qui non è necessaria!), diciamo che la distribuzione priori di \\(\\mu\\) è \\(\\), e che \\(\\) si distribuisce come una Normale di parametri \\(\\mu\\) = media del campione e deviazione standard uguale 100. Il parametro \\(\\sigma\\), inoltre, viene considerato come conosciuto e di valore pari alla deviazione standard del campione. La sintassi presentata sopra non è per nulla elegante e può essere semplificata. La utilizzo qui per facilitare la discussione successiva.La distribuzione posteriori di \\(\\mu\\) può essere ottenuta nel modo seguente:L’intervallo di credibilità al 95% è dato dalla funzione precis():Possiamo dunque dire che, con un grado di certezza soggettivo del 95%, siamo sicuri che la media della popolazione da cui abbiamo tratto dati è compresa nell’intervallo [28.57, 33.3].Questo esempio ci mostra come calcolare l’intervallo di credibilità per la media di una popolazione. Nella sezione successiva ci porremo il problema di come sia possibile fare il confronto tra le medie di due popolazioni indipendenti.","code":"\ndf <- data.frame(\n  x <- c(26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, 28, 35, 30, 26, 31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22)\n)\ntrue_sd <- sd(df$x)\ntrue_sd\n#> [1] 6.606858\n\nsample_mean <- mean(df$x)\nsample_mean\n#> [1] 30.93333\nflist <- alist(\n  x ~ dnorm(mu, sigma), \n  mu ~ a,\n  a ~ dnorm(sample_mean, 100),\n  sigma ~ true_sd\n)\nset.seed(123)\nm1 <- quap( \n    flist,\n    data = df \n)\nout <- precis(m1, prob = 0.95)\nout\n#>       mean       sd     2.5%    97.5%\n#> a 30.93333 1.206154 28.56931 33.29735"},{"path":"inferenza-bayesiana.html","id":"il-modello-di-regressione-lineare","chapter":"Capitolo 29 Inferenza Bayesiana","heading":"29.4 Il modello di regressione lineare","text":"due modelli statistici che abbiamo presentato sopra descrivono il comportamento di una singola variabile aleatoria: una proporzione di “successi” o la media del valore BDI-II un campione. Se la distribuzione priori non è informativa, la distribuzione posteriori risulta centrata sul valore della statistica campionaria (\\(p\\) o \\(\\bar{x}\\)) utilizzata per la stima del parametro corrispondente (\\(\\pi\\) o \\(\\mu\\)). Quello che “guadagnamo” calcolando la distribuzione posteriori del parametro sconosciuto è la possibilità di quantificare la nostra incertezza rispetto alla stima del parametro: se l’intervallo di credibilità è molto largo questo significa che dati del campione sono poco informativi rispetto al valore del parametro; se l’intervallo di credibilità è molto stretto, allora concludiamo che siamo piuttosto certi del valore della nostra stima.Tuttavia, modelli di interesse per la psicologia (e per le altre scienze) non si limitano alla stima di un singolo parametro ma descrivono le relazioni tra due o più variabili. Per esempio, nel suo studio Regression towards mediocrity hereditary stature, Galton (1886) si è chiesto come sia possibile descrivere la relazione tra l’altezza dei figli e l’altezza dei padri. Il modo più semplice per rispondere ad una domanda di questo tipo è quello di formulare la risposta nei termini di un modello di regressione lineare – infatti, la tecnica statistica della regressione lineare fu inventata da Galton proprio per questo scopo.Il modello di regressione lineare è il più semplice dei modelli statistici che descrivono la relazione tra due (o più) variabili. Abbiamo esaminato il modello statistico della regressione lineare nei capitoli precedenti. Vediamo qui come sia possibile fare inferenza sul modello di regressione usando il metodo Bayesiano.Usando la notazione che abbiamo introdotto nelle sezioni precedenti di questo capitolo, scriviao il modello statistico di regressione ineare nel modo seguente:\\[\n\\begin{aligned}\nY_i &\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta(X_i - \\bar{X}) \\\\\n\\alpha &\\sim \\mathcal{N}(0, \\sigma_{\\alpha}) \\\\\n\\beta &\\sim \\mathcal{N}(0, \\sigma_{\\beta}) \\\\\n\\sigma &\\sim \\text{Unif}(0, 50) \n\\end{aligned}\n\\]\nLa verosimiglianza indica che ciascun valore \\(Y_i\\) (la nostra variabile dipendente) segue una distribuzione Normale. Tuttavia, si noti il pedici \\(\\). Scrivendo \\(Y_i\\) con il pedice intendiamo dire che ciascuna \\(Y_i\\) segue una distribuzione Normale avente una media diversa (\\(\\mu_i\\)). questa formulazione del modello, tutte le distribuzioni Normali relative alla \\(Y\\) hanno la stessa deviazione standard (\\(\\sigma\\), il che corrisponde ’assunzione di omoschedasticità). La cosa importante da notare è che non dobbiamo stimare un singolo parametro \\(\\mu\\), come avveniva invece nel caso del modello Normale che abbiamo discusso nel caso dei valori BDI-II. Nel modello statistico della regressione lineare, invece, \\(\\mu_i\\) è espresso nei termini di due due parametri incogniti, \\(\\alpha\\) e \\(\\beta\\), e nei termini di una quantità osservabile chiamata \\(X\\) (la nostra variabile indipendente). Ciò è indicato nella seconda riga della descrizione del modello statistico.La seconda riga della specificazione del modello statistico della regressione lineare non descrive una relazione stocastica (non viene usato il simbolo \\(\\sim\\)), ma bensì una relazione deterministica (come indicato dall’uso del simbolo \\(=\\)). Ciò significa che, una volta fissati parametri \\(\\alpha\\) e \\(\\beta\\), il valore \\(\\mu_i\\) è determinato maniera univoca (ovvero, corrisponde alla componente deterministica del modello di regressione lineare che abbiamo descritto precedenza). Se il modello di regressione lineare è espresso come \\(\\mu_i = \\alpha + \\beta(X_i - \\bar{X})\\), allora possiamo assegnare ai parametri \\(\\alpha\\) e \\(\\beta\\) la seguente interpretazione.Il parametro \\(\\alpha\\) è uguale al valore atteso della \\(Y\\) corrispondenza del valore \\(X\\) medio. Infatti, precedenza abbiamo notato come, dal punto di vista geometrico, \\(\\alpha\\) corrisponde ’ordinata del punto cui la retta di regressione interseca l’asse verticale di un sistema di coordinate cartesiane. Nel caso presente abbiamo espresso la \\(X\\) come scarti (o differenze) dalla media: \\(X_i - \\bar{X}\\). Da ciò segue che la media di \\(X\\) (espressa termini di scarti dalla media) avrà valore zero. Di conseguenza, \\(\\alpha\\) corrisponderà \\(\\mathbb{E}(Y \\mid \\bar{X})\\).Il parametro \\(\\alpha\\) è uguale al valore atteso della \\(Y\\) corrispondenza del valore \\(X\\) medio. Infatti, precedenza abbiamo notato come, dal punto di vista geometrico, \\(\\alpha\\) corrisponde ’ordinata del punto cui la retta di regressione interseca l’asse verticale di un sistema di coordinate cartesiane. Nel caso presente abbiamo espresso la \\(X\\) come scarti (o differenze) dalla media: \\(X_i - \\bar{X}\\). Da ciò segue che la media di \\(X\\) (espressa termini di scarti dalla media) avrà valore zero. Di conseguenza, \\(\\alpha\\) corrisponderà \\(\\mathbb{E}(Y \\mid \\bar{X})\\).Il parametro \\(\\beta\\) ci dice di quanto varia \\(\\mathbb{E}(Y \\mid X)\\) quando \\(X\\) varia di un’unità.Il parametro \\(\\beta\\) ci dice di quanto varia \\(\\mathbb{E}(Y \\mid X)\\) quando \\(X\\) varia di un’unità.Nel modello statistico presentato sopra, la nostra incertezza su \\(\\beta\\) è stata quantificata mediante una distribuzione priori centrata sullo zero e con una deviazione standard pari \\(\\sigma_{\\beta}\\). La nostra incertezza su \\(\\alpha\\) è stata quantificata mediante una distribuzione priori centrata sullo zero e con una deviazione standard pari \\(\\sigma_{\\alpha}\\). Infine, la nostra incertezza su \\(\\sigma\\) (la deviazione standard della dispersione dei dati attorno alla retta di regressione) è stata quantificata mediante una distribuzione uniforme compresa tra 0 e 50.Per ora ci siamo limitati descrivere la formulazione Bayesiana del modello di regressione mediante la sintassi di rethinking, così come fa McElreath (2020). Nelle sezioni seguenti vedremo come sia possibile svolgere l’analisi di regressione termini Bayesiani. Inizieremo considerando il caso più semplice, ovvero quello nel quale la variabile \\(X\\) è una variabile dicotomica; considereremo poi il caso cui \\(X\\) è una variabile continua.","code":""},{"path":"inferenza-bayesiana.html","id":"variabile-indipendente-dicotomica","chapter":"Capitolo 29 Inferenza Bayesiana","heading":"29.4.1 Variabile indipendente dicotomica","text":"Solitamente, un modello di regressione lineare come quello descritto nella sezione precedente, la variabile \\(X\\) è una variabile continua. Tuttavia, è anche possibile considerare una \\(X\\) discreta. Consideriamo qui il caso più semplice, ovvero quello cui \\(X\\) assume solo due valori: 0 e 1. tali circostanze, il modello lineare può essere usato per il confronto tra le medie di due gruppi. Vediamo perché.Se \\(X\\) è una variabile dicotomica (con valori 0 e 1), allora per il modello lineare \\(\\mu_i = \\alpha + \\beta x_i\\) abbiamo quanto segue. Quando \\(X=0\\), il modello diventa\\[\\mu_i = \\alpha\\]\nmentre, quando \\(X=1\\), il modello diventa\\[\\mu_i = \\alpha + \\beta.\\]\nCiò significa che il parametro \\(\\alpha\\) è uguale alla media del gruppo codificato con \\(X=0\\) e il parametro \\(\\beta\\) è uguale alla differenza tra le medie dei due gruppi (essendo la media del secondo gruppo uguale \\(\\alpha + \\beta\\)).tali circostanze, il parametro \\(\\beta\\) risulta particolarmente utile quanto, nel caso di due gruppi, codifica l’effetto di una manipolazione sperimentale o di un trattamento, ovvero esprime la differenza tra le medie di due gruppi. Per “effetto di un trattamento” si intende appunto la differenza tra le medie di due gruppi (per esempio, il gruppo “sperimentale” e il gruppo “di controllo”). L’inferenza su \\(\\beta\\) può dunque aiutarci capire quanto può essere considerato “robusto” l’effetto di un trattamento o di una manipolazione sperimentale.","code":""},{"path":"inferenza-bayesiana.html","id":"un-esempio-pratico","chapter":"Capitolo 29 Inferenza Bayesiana","heading":"29.4.2 Un esempio pratico","text":"Esaminiamo un sottoinsieme di dati tratto dal National Longitudinal Survey Youth quali sono stati discussi da Gelman et al. (2020). soggetti sono bambini di 3 e 4 anni. La variabile dipendente, kid_score, è il punteggio totale del Peabody Individual Achievement Test (PIAT) costituito dalla somma dei punteggi di tre sottoscale (Mathematics, Reading comprehension, Reading recognition). La variabile indipendente, mom_hs, è il livello di istruzione della madre, codificato con due livelli: scuola media superiore completata oppure . La domanda della ricerca è se il QI del figlio (misurato sulla scala PIAT) risulta o meno associato al livello di istruzione della madre.Codifichiamo il livello di istruzione della madre (\\(X\\)) con una variabile indicatrice (ovvero, una variabile che assume solo valori 0 e 1) tale per cui:\\(X=0\\): la madre non ha completato la scuola secondaria di secondo grado (scuola media superiore);\\(X=0\\): la madre non ha completato la scuola secondaria di secondo grado (scuola media superiore);\\(X=1\\): la madre ha completato la scuola media superiore.\\(X=1\\): la madre ha completato la scuola media superiore.Supponiamo che dati siano contenuti nel data.frame df.Calcoliamo le statistiche descrittive per due gruppi:Il punteggio medio PIAT è pari 77.5 per bambini la cui madre non ha il diploma di scuola media superiore e pari 89.3 per bambini la cui madre ha completato la scuola media superiore. Questa differenza suggerisce un’associazione tra le variabili, ma tale differenza potrebbe essere soltanto la conseguenza della variabilità campionaria, senza riflettere una caratteristica generale della popolazione. Come possiamo usare il modello statistico lineare per fare inferenza sulla differenza osservata tra due gruppi?Per rispondere questa domanda specifichiamo il modello statistico che descrive la differenza tra punteggi PIAT dei due gruppi mediante un modello di regressione lineare:Si noti che abbiamo specificato tale modello statistico seguendo la stessa logica descritta precedenza. Ovvero, abbiamo esplicitato:la verosimiglianza dei dati;la verosimiglianza dei dati;il modello statistico della regressione lineare che esprime il valore atteso della variabile dipendente come una funzione lineare della variabile indipendente;il modello statistico della regressione lineare che esprime il valore atteso della variabile dipendente come una funzione lineare della variabile indipendente;la distribuzione priori di ciascuno dei parametri del modello, ovvero \\(\\), \\(b\\) e \\(\\sigma\\).la distribuzione priori di ciascuno dei parametri del modello, ovvero \\(\\), \\(b\\) e \\(\\sigma\\).Nel caso presente, abbiamo specificato due distribuzioni priori “debolmente informative” per parametri \\(\\) e \\(b\\). La distribuzione priori per il parametro \\(\\) è una distribuzione Normale centrata sulla media di tutti dati (calcolata ignorando la suddivisione gruppi), con una deviazione standard relativamente grande. Ciò significa che, priori, per il parametro \\(\\) riteniamo plausibili valori che sono inclusi nell’intervallo \\(86.8 \\pm 2 \\times 100\\) punti PIAT, anche se riteniamo più probabili valori prossimi 86.8. Così facendo esprimiamo una generale incertezza su quello che potrebbe essere il valore della media del gruppo codificato con \\(X = 0\\).maniera simile, caratterizziamo il possibile valore della differenza tra le medie tra due gruppi (ciò cui siamo interessati) maniera molto vaga: affermiamo che potrebbe essere un valore qualsiasi, plausibilmente contenuto nell’intervallo \\(0 \\pm 2 \\times 100\\), assegnando una plausibilità priori maggiore ai valori prossimi allo zero (positivi e negativi). Per il parametro \\(b\\), specifichiamo dunque una distribuzione priori Normale centrata sullo zero. Questa scelta ha l’effetto di non favorire posteriori per \\(b\\) la cui media è positiva o negativa. altri termini, specificando una distribuzione priori per \\(b\\) centrata sullo zero non favoriamo una soluzione (posteriori) che indica che vi è un’associazione positiva tra livello di scolarità della madre e intelligenza del bambino, né l’ipotesi opposta (associazione negativa tra le due variabili).Infine, specifichiamo distribuzione priori uniforme nell’intervallo (0, 100) per il parametro \\(\\sigma\\) che descrive la distribuzione dei dati attorno al loro valore atteso (la retta di regressione).","code":"\nlibrary(\"foreign\")\ndf <- read.dta(here(\"data\", \"kidiq.dta\"))\nhead(df)\n#>   kid_score mom_hs    mom_iq mom_work mom_age\n#> 1        65      1 121.11753        4      27\n#> 2        98      1  89.36188        4      25\n#> 3        85      1 115.44316        4      27\n#> 4        83      1  99.44964        3      25\n#> 5       115      1  92.74571        4      27\n#> 6        98      0 107.90184        1      18\ndf %>% \n  group_by(mom_hs) %>% \n  summarise(\n    mean_kid_score = mean(kid_score),\n    std = sqrt(var(kid_score))\n  )\n#> # A tibble: 2 x 3\n#>   mom_hs mean_kid_score   std\n#>    <dbl>          <dbl> <dbl>\n#> 1      0           77.5  22.6\n#> 2      1           89.3  19.0\nflist <- alist(\n  kid_score ~ dnorm(mu, sigma),\n  mu ~ a + b * mom_hs,\n  a ~ dnorm(86.8, 100),\n  b ~ dnorm(0, 100),\n  sigma ~ dunif(0, 100)\n)"},{"path":"inferenza-bayesiana.html","id":"quale-distribuzione-a-priori-è-corretta","chapter":"Capitolo 29 Inferenza Bayesiana","heading":"Quale distribuzione a priori è corretta?","text":"Un grave problema che è emerso negli anni recenti relativamente ’analisi dei dati psicologici (e non solo) è il cosiddetto “\\(p\\)-hacking,” ovvero la pratica di adattare il modello e dati allo scopo di ottenere il risultato desiderato. Il risultato desiderato è generalmente un valore-\\(p\\) inferiore al 5%. Il problema è che quando il modello statistico viene modificato alla luce dei dati osservati, valori-\\(p\\) non mantengono più il loro significato originario: altre parole, il “\\(p\\)-hacking” aumenta la probabilità di ottenere dei risultati falsi. L’approccio Bayesiano non prevede valori-\\(p\\), ma il rischio rimane se scegliamo le distribuzioni priori base alle proprietà del campione allo scopo di ottenere il risultato desiderato. La procedura che invece deve essere seguita è quella di scegliere le distribuzioni priori sulla base di considerazioni generali, indipendentemente dalle specifiche caratteristiche del campione, come abbiamo fatto sopra utilizzando una distribuzione priori per \\(b\\) centrata sullo zero.","code":""},{"path":"inferenza-bayesiana.html","id":"inferenza-mediante-la-distribuzione-a-posteriori","chapter":"Capitolo 29 Inferenza Bayesiana","heading":"29.4.2.1 Inferenza mediante la distribuzione a posteriori","text":"Adattiamo il modello ai dati utilizzando la funzione quap():Estraiamo alcuni campioni dalla distribuzione posteriori:Esaminiamo la distribuzione posteriori dei parametri mediante le istruzioni seguenti.\nFigura 29.1: Distribuzioni posteriori dei parametri , b e \\(\\sigma\\) del modello statistico lineare che descrive punteggi del Peabody Individual Achievement Test come funzione del gruppo di appartenenza: bambini la cui madre non ha completato la scuola media superiore e bambini la cui madre ha completato la scuola media superiore. dati sono tratti da Gelman et al. (2020).\nCome precedenza, la funzione precis() può essere usata per calcolare la media posteriori per parametri del modello:risultati confermano ciò che ci aspettavamo: il coefficiente \\(\\) corrisponde alla media del gruppo codificato con \\(X = 0\\), ovvero la media dei punteggi PIAT per bambini la cui madre non ha completato la scuola media superiore; il coefficiente \\(b\\) corrisponde alla differenza tra le medie dei due gruppi, ovvero 89.32 - 77.55 = 11.77.Una rappresentazione grafica dell’interpretazione che abbiamo fornito ai parametri del modello lineare è fornita nella figura 29.2.\nFigura 29.2: Distribuzione dei punteggi del Peabody Individual Achievement Test due gruppi di bambini facenti parte del campione discusso da Gelman et al. (2020): bambini la cui madre non hanno completato la scuola media superiore (\\(X\\) = 0) e bambini la cui madre ha completato la scuola media superiore (\\(X\\) = 1).\n","code":"\nm1 <- quap(\n  flist,\n  data = df\n)\npost <- extract.samples(m1)\npost[1:5, ]\n#>          a         b    sigma\n#> 1 80.07328  9.006764 19.73586\n#> 2 77.26278 11.935567 19.77395\n#> 3 76.66754 11.448966 19.31510\n#> 4 77.23189 10.742990 19.97299\n#> 5 80.54546  9.255061 19.83349\npar(mfrow = c(1, 3))\n\ndens(\n  post$a, lwd = 2.5, xlab = \"\",\n  ylab = \"Densità\", main = \"p(a | x, y)\",\n  cex.lab = 1.5, cex.axis = 1.35, cex.main = 1.5,\n  cex.sub = 1.5\n)\ndens(\n  post$b, lwd = 2.5, xlab = \"\",\n  ylab = \"\", main = \"p(b | x, y)\",\n  cex.lab = 1.5, cex.axis = 1.35, cex.main = 1.5,\n  cex.sub = 1.5\n)\ndens(\n  post$sigma, lwd = 2.5, xlab = \"\",\n  ylab = \"\", main = \"p(sigma | x, y)\",\n  cex.lab = 1.5, cex.axis = 1.35, cex.main = 1.5,\n  cex.sub = 1.5\n)\n    \npar(mfrow = c(1, 1))\nprecis(m1, prob = 0.95)\n#>           mean        sd      2.5%    97.5%\n#> a     77.55837 2.0528231 73.534910 81.58183\n#> b     11.75868 2.3158682  7.219661 16.29770\n#> sigma 19.80505 0.6721414 18.487679 21.12243"},{"path":"inferenza-bayesiana.html","id":"inferenza","chapter":"Capitolo 29 Inferenza Bayesiana","heading":"29.4.2.2 Inferenza","text":"Il coefficiente \\(b\\) ci dice che bambini la cui madre ha completato la scuola superiore ottengono media circa 12 punti più rispetto ai bambini la cui madre non ha completato la scuola superiore. L’intervallo di credibilità al 95% calcolato mediante la funzione precis() ci dice che possiamo essere sicuri al 95% che tale differenza è di almeno 7 punti e può arrivare fino ben 16 punti. Possiamo dunque concludere, con un grado di certezza soggettiva del 95%, che c’è un’associazione tra il livello di scolarità della madre e l’intelligenza del bambino: bambini tendono ad avere un livello di intelligenza più elevato se le madri hanno un più alto livello di istruzione.","code":""},{"path":"inferenza-bayesiana.html","id":"una-variabile-indipendente-continua","chapter":"Capitolo 29 Inferenza Bayesiana","heading":"29.5 Una variabile indipendente continua","text":"Continuiamo ora con l’esempio relativo al National Longitudinal Survey Youth discusso da Gelman et al. (2020) ponendoci ora il problema di descrivere l’associazione tra l’intelligenza del bambino, kid_score (ovvero il punteggio totale del Peabody Individual Achievement Test, PIAT), e il quoziente di intelligenza della madre, mom_iq. Si noti che, questo caso, la variabile indipendente è una variabile continua (e non più dicotomica come nell’esempio precedente).Iniziamo esaminando dati, per verificare che un modello lineare sia appropriato per dati considerati.\nFigura 29.3: Punteggio del test PIAT come funzione del QI materno con sovrapposta la retta di regressione. Ogni punto sulla retta di regressione può essere concepito come un punteggio il punteggio predetto per un bambino la cui madri ha il QI corrispondente o come il punteggio PIAT medio per una sottopopolazione di bambini le cui madri hanno tutte quel particolare valore di QI. dati sono tratti da Gelman et al. (2020).)\nIl diagramma dispersione suggerisce che un modello lineare è appropriato per questi dati. Descriviamo dunque termini formali il modello che vogliamo adattare ai dati:\\[\n\\begin{aligned}\nY_i &\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta(X_i - \\bar{X}) \\\\\n\\alpha &\\sim \\mathcal{N}(0, \\sigma_{\\alpha}) \\\\\n\\beta &\\sim \\mathcal{N}(0, \\sigma_{\\beta}) \\\\\n\\sigma &\\sim \\text{Unif}(0, 50) \n\\end{aligned}\n\\]Si noti che abbiamo descritto \\(X\\) nei termini degli scostamenti dalla media (\\(X_i - \\bar{X}\\)). Come precedenza, ciò fa modo che il coefficiente \\(\\alpha\\) corrisponda al valore atteso della \\(Y\\) corrispondenza della media di \\(X\\) (quoziente di intelligenza della madre) – questa è una conseguenza del fatto che la retta di regressione passa per il punto \\((\\bar{X}, \\bar{Y})\\). Infatti, avrebbe poco senso chiederci qual è il valore atteso del punteggio PIAT quando il quoziente d’intelligenza della madre è uguale zero.Specifichiamo dunque il modello statistico lineare con la sintassi richiesta da rethinking:Adattiamo il modello di regressione ai datiEsaminiamo il risultato ottenuto mediante la funzione precis():Troviamo così che\n\\[\n\\mathbb{E}(\\text{kid_score}) = 86 + 0.61 \\cdot x,\n\\]\nladdove \\(x\\) è la variabile kid_score espressa come scostamento rispetto al suo valore medio. Tale retta di regressione stimata è mostrata assieme ai dati nella figura 29.3.Il coefficiente \\(b\\) ci dice che, ’aumentare di un punto del quoziente d’intelligenza della madre, la media dei punteggi PIAT cresce di 0.61 unità. Il parametro \\(\\sigma\\) ci dice che la deviazione standard che quantifica la dispersione dei dati attorno alla retta di regressione è pari 18.22.L’intervallo di credibilità di questo coefficiente ci dice che, con un livello di certezza del 95%, possiamo essere sicuri che, ’aumentare di un punto del quoziente d’intelligenza della madre, la media dei punteggi PIAT crescerà, come minimo, di 0.50 punti e, come massimo, di 0.72 punti. La differenza 0.72 - 0.50 esprime il nostro grado di incertezza rispetto alla stima del parametro, quando vogliamo che la nostra stima sia “credibile” al livello di 0.95. Ma non c’è niente di “magico” o necessario relativamente al livello di 0.95. Infatti, il default della funzione precis() è 0.89. Ciascuno di questi valori è\narbitrario. Sono possibili tantissime soglie per quantificare la nostra incertezza: alcuni ricercatori usano il livello di 0.5. Il nostro obiettivo è quello di descrivere il livello della nostra incertezza relativamente alla stima del parametro. E la nostra incertezza è\ndescritta dall’intera distribuzione posteriori. Per cui il metodo più semplice, più diretto e più completo per descrivere la nostra incertezza rispetto alla stima dei parametri è quello di riportare graficamente tutta la distribuzione posteriori, come indicato per esempio nella figura 29.4.\nFigura 29.4: Distribuzione posteriori dei parametri \\(\\), \\(b\\) e \\(sigma\\) del modello statistico lineare che descrive punteggi del Peabody Individual Achievement Test come funzione del quoziente d’intelligenza della madre espresso come scostamento rispetto al suo valore medio. dati sono tratti da Gelman et al. (2020).\n","code":"\ndf %>% \n  ggplot(aes(x = mom_iq, y = kid_score)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(\n    x = \"QI della madre\",\n    y = \"Peabody Individual Achievement Test\"\n  )\n#> `geom_smooth()` using formula 'y ~ x'\nflist <- alist(\n  kid_score ~ dnorm(mu, sigma),\n  mu ~ a + b * (mom_iq - mean(mom_iq)),\n  a ~ dnorm(mean(kid_score), 100),\n  b ~ dnorm(0, 100),\n  sigma ~ dunif(0, 100)\n)\nm2 <- quap(\n  flist,\n  data = df\n)\nprecis(m2, prob = 0.95)\n#>             mean         sd       2.5%      97.5%\n#> a     86.7973283 0.87475112 85.0828476 88.5118090\n#> b      0.6099751 0.05838627  0.4955402  0.7244101\n#> sigma 18.2240956 0.61857167 17.0117174 19.4364738\npost <- extract.samples(m2)\npar(mfrow = c(1, 3))\n\ndens(\n  post$a, lwd = 2.5, xlab = \"\",\n  ylab = \"Densità\", main = \"p(a | x, y)\",\n  cex.lab = 1.5, cex.axis = 1.35, cex.main = 1.5,\n  cex.sub = 1.5\n)\ndens(\n  post$b, lwd = 2.5, xlab = \"\",\n  ylab = \"\", main = \"p(b | x, y)\",\n  cex.lab = 1.5, cex.axis = 1.35, cex.main = 1.5,\n  cex.sub = 1.5\n)\ndens(\n  post$sigma, lwd = 2.5, xlab = \"\",\n  ylab = \"\", main = \"p(sigma | x, y)\",\n  cex.lab = 1.5, cex.axis = 1.35, cex.main = 1.5,\n  cex.sub = 1.5\n)\n    \npar(mfrow = c(1, 1))"},{"path":"inferenza-bayesiana.html","id":"conclusioni-13","chapter":"Capitolo 29 Inferenza Bayesiana","heading":"Conclusioni","text":"Questo capitolo ha introdotto il modello bivariato di regressione lineare, ovvero un metodo che ci consente di stimare l’associazione tra una variabile indipendente e una variabile dipendente. La distribuzione Normale può essere usata per specificare la funzione di verosimiglianza modelli statistici di questo tipo perché può essere concepita come un\nmodo di contare quanti diversi modi diverse combinazioni di \\(\\mu\\) e \\(\\sigma\\) possono produrre un’osservazione. Per adattare questi modelli ai dati, il presente capitolo ha introdotto un’approssimazione quadratica della distribuzione posteriori tramite la funzione quap(). Sono state inoltre introdotte nuove procedure per visualizzare le distribuzioni posteriori e per descrivere le stime posteriori.Si noti che, per definire la distribuzione priori del parametro \\(p\\) di una distribuzione di Bernoulli, abbiamo usato una distribuzione uniforme (priori non informativa), ovvero una Beta(1, 1). tali circostanze, l’intervallo di credibilità è praticamente identico ’intervallo di confidenza di tipo frequentista. L’intervallo di credibilità, invece, differisce dall’intervallo di confidenza frequentista quando il modello statistico Bayesiano include una distribuzione priori informativa o debolmente informativa. L’analisi dei dati Bayesiana fa quasi sempre uso di distribuzioni priori debolmente informative, mentre le distribuzioni priori informative sono più rare. Le distribuzioni priori debolmente informative hanno quale scopo la regolarizzazione, cioè, l’obiettivo di mantenere le inferenze una gamma ragionevole di valori; ciò contribuisce nel contempo limitare l’influenza eccessiva delle osservazioni estreme (valori anomali).","code":""},{"path":"citazione.html","id":"citazione","chapter":"Citazione","heading":"Citazione","text":"Sentitevi liberi di utilizzare Data Science per psicologi per vostri scopi, ma vi chiedo di riconoscerne la paternità.Per citare Data Science per psicologi potete usare:Caudek Corrado (2021). Data Science per psicologi.\nDipartimento NEUROFARBA, Università degli Studi di Firenze, Italia.\nEstratto da https://github.com/ccaudek/bookdown_psicometria/Gli utenti \\(\\LaTeX\\) possono usare la seguente voce BibTeX:L’URL di Data Science per psicologi è https://github.com/ccaudek/bookdown_psicometria/.","code":"@Manual{caudek_psicometria,\n  title = {Data Science per psicologi},\n  author = {Caudek Corrado},\n  year = {2021},\n  organization = {{Dipartimento NEUROFARBA, Università degli Studi di Firenze}},\n  address = {Firenze, Italia},\n  note = {Textbook},\n  url = {https://github.com/ccaudek/bookdown_psicometria/}\n}"},{"path":"citazione.html","id":"licenza","chapter":"Citazione","heading":"Licenza","text":"Tutto il materiale del testo Data Science per psicologi  di Corrado Caudek è pubblicato sotto una Licenza Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.","code":""},{"path":"un-piccolo-ripasso.html","id":"un-piccolo-ripasso","chapter":"Un piccolo ripasso","heading":"Un piccolo ripasso","text":"","code":""},{"path":"un-piccolo-ripasso.html","id":"simbologia-di-base","chapter":"Un piccolo ripasso","heading":"Simbologia di base","text":"Per una scrittura più sintetica possono essere utilizzati alcuni simboli\nmatematici.L’operatore logico booleano \\(\\land\\) significa “e” (congiunzione\nforte) mentre il connettivo di disgiunzione \\(\\lor\\) significa “o”\n(oppure) (congiunzione debole).L’operatore logico booleano \\(\\land\\) significa “e” (congiunzione\nforte) mentre il connettivo di disgiunzione \\(\\lor\\) significa “o”\n(oppure) (congiunzione debole).Il quantificatore esistenziale \\(\\exists\\) vuol dire “esiste almeno\nun” e indica l’esistenza di almeno una istanza del concetto/oggetto\nindicato. Il quantificatore esistenziale di unicità \\(\\exists!\\)\n(“esiste soltanto un”) indica l’esistenza di esattamente una istanza\ndel concetto/oggetto indicato. Il quantificatore esistenziale\n\\(\\nexists\\) nega l’esistenza del concetto/oggetto indicato.Il quantificatore esistenziale \\(\\exists\\) vuol dire “esiste almeno\nun” e indica l’esistenza di almeno una istanza del concetto/oggetto\nindicato. Il quantificatore esistenziale di unicità \\(\\exists!\\)\n(“esiste soltanto un”) indica l’esistenza di esattamente una istanza\ndel concetto/oggetto indicato. Il quantificatore esistenziale\n\\(\\nexists\\) nega l’esistenza del concetto/oggetto indicato.Il quantificatore universale \\(\\forall\\) vuol dire “per ogni.”Il quantificatore universale \\(\\forall\\) vuol dire “per ogni.”L’implicazione logica “\\(\\Rightarrow\\)” significa “implica” (se\n…allora). \\(P \\Rightarrow Q\\) vuol dire che \\(P\\) è condizione\nsufficiente per la verità di \\(Q\\) e che \\(Q\\) è condizione necessaria\nper la verità di \\(P\\).L’implicazione logica “\\(\\Rightarrow\\)” significa “implica” (se\n…allora). \\(P \\Rightarrow Q\\) vuol dire che \\(P\\) è condizione\nsufficiente per la verità di \\(Q\\) e che \\(Q\\) è condizione necessaria\nper la verità di \\(P\\).L’equivalenza matematica “\\(\\iff\\)” significa “se e solo se” e indica\nuna condizione necessaria e sufficiente, o corrispondenza biunivoca.L’equivalenza matematica “\\(\\iff\\)” significa “se e solo se” e indica\nuna condizione necessaria e sufficiente, o corrispondenza biunivoca.Il simbolo \\(\\vert\\) si legge “tale che.”Il simbolo \\(\\vert\\) si legge “tale che.”Il simbolo \\(\\triangleq\\) (o \\(:=\\)) si legge “uguale per definizione.”Il simbolo \\(\\triangleq\\) (o \\(:=\\)) si legge “uguale per definizione.”Il simbolo \\(\\Delta\\) indica la differenza fra due valori della\nvariabile scritta destra del simbolo.Il simbolo \\(\\Delta\\) indica la differenza fra due valori della\nvariabile scritta destra del simbolo.Il simbolo \\(\\propto\\) si legge “proporzionale .”Il simbolo \\(\\propto\\) si legge “proporzionale .”Il simbolo \\(\\approx\\) si legge “circa.”Il simbolo \\(\\approx\\) si legge “circa.”Il simbolo \\(\\\\) della teoria degli insiemi vuol dire “appartiene” e\nindica l’appartenenza di un elemento ad un insieme. Il simbolo\n\\(\\notin\\) vuol dire “non appartiene.”Il simbolo \\(\\\\) della teoria degli insiemi vuol dire “appartiene” e\nindica l’appartenenza di un elemento ad un insieme. Il simbolo\n\\(\\notin\\) vuol dire “non appartiene.”Il simbolo \\(\\subseteq\\) si legge “è un sottoinsieme di” (può\ncoincidere con l’insieme stesso). Il simbolo \\(\\subset\\) si legge “è\nun sottoinsieme proprio di.”Il simbolo \\(\\subseteq\\) si legge “è un sottoinsieme di” (può\ncoincidere con l’insieme stesso). Il simbolo \\(\\subset\\) si legge “è\nun sottoinsieme proprio di.”Il simbolo \\(\\#\\) indica la cardinalità di un insieme.Il simbolo \\(\\#\\) indica la cardinalità di un insieme.Il simbolo \\(\\cap\\) indica l’intersezione di due insiemi. Il simbolo\n\\(\\cup\\) indica l’unione di due insiemi.Il simbolo \\(\\cap\\) indica l’intersezione di due insiemi. Il simbolo\n\\(\\cup\\) indica l’unione di due insiemi.Il simbolo \\(\\emptyset\\) indica l’insieme vuoto o evento impossibile.Il simbolo \\(\\emptyset\\) indica l’insieme vuoto o evento impossibile.","code":""},{"path":"un-piccolo-ripasso.html","id":"numeri-binari-interi-razionali-irrazionali-e-reali","chapter":"Un piccolo ripasso","heading":"Numeri binari, interi, razionali, irrazionali e reali {-}","text":"","code":""},{"path":"un-piccolo-ripasso.html","id":"numeri-binari","chapter":"Un piccolo ripasso","heading":"Numeri binari","text":"più semplici sono numeri binari, cioè zero o uno. Useremo spesso\nnumeri binari per rappresentare se qualcosa è vero o falso, o presente o\nassente.Supponiamo di chiedere 10 studenti “Ti piacciono mirtilli?” Poniamo\nche le risposte siano le seguenti:Tali risposte possono essere ricodificate nei termini di valori di\nverità, ovvero, vero e falso, generalmente denotati rispettivamente come\n1 e 0. tale ricodifica può essere effettuata mediante l’operatore\n== che è un test per l’uguaglianza e restituisce il valore logico VERO\nse le due cose sono uguali e FALSO se non lo sono:R considera valori di verità e numeri binari modo equivalente, con\nTRUE uguale 1 e FALSE uguale zero. Di conseguenza, possiamo\neffettuare operazioni algebriche sui valori logici VERO e FALSO.\nNell’esempio, possiamo sommare valori di verità, dividere per 10e concludere che 7 risposte su 10 sono positive.","code":"\nopinion <- c('Yes','No','Yes','No','Yes','No','Yes','Yes','Yes','Yes')\nopinion\n#>  [1] \"Yes\" \"No\"  \"Yes\" \"No\"  \"Yes\" \"No\"  \"Yes\" \"Yes\" \"Yes\" \"Yes\"\nopinion <- opinion == \"Yes\"\nopinion\n#>  [1]  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE\nsum(opinion) / length(opinion)\n#> [1] 0.7"},{"path":"un-piccolo-ripasso.html","id":"numeri-interi","chapter":"Un piccolo ripasso","heading":"Numeri interi","text":"Un numero intero è un numero senza decimali. Si dicono naturali \nnumeri che servono contare, come 1, 2, … L’insieme dei numeri\nnaturali si indica con il simbolo \\(\\mathbb{N}\\). È anche necessario\nintrodurre numeri con il segno per poter trattare grandezze negative.\nSi ottengono così l’insieme numerico dei numeri interi relativi:\n\\(\\mathbb{Z} = \\{0, \\pm 1, \\pm 2, \\dots \\}\\)","code":""},{"path":"un-piccolo-ripasso.html","id":"numeri-razionali","chapter":"Un piccolo ripasso","heading":"Numeri razionali","text":"numeri razionali sono numeri frazionari \\(m/n\\), dove \\(m, n \\N\\),\ncon \\(n \\neq 0\\). Si ottengono così numeri razionali:\n\\(\\mathbb{Q} = \\{\\frac{m}{n} \\,\\vert\\, m, n \\\\mathbb{Z}, n \\neq 0\\}\\).\nÈ evidente che \\(\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q}\\).\nAnche questo caso è necessario poter trattare grandezze negative. \nnumeri razionali non negativi sono indicati con\n\\(\\mathbb{Q^+} = \\{q \\\\mathbb{Q} \\,\\vert\\, q \\geq 0\\}\\).","code":""},{"path":"un-piccolo-ripasso.html","id":"numeri-irrazionali","chapter":"Un piccolo ripasso","heading":"Numeri irrazionali","text":"Tuttavia, non tutti punti di una retta \\(r\\) possono essere\nrappresentati mediante numeri interi e razionali. È dunque necessario\nintrodurre un’altra classe di numeri. Si dicono irrazionali, e sono\ndenotati con \\(\\mathbb{R}\\), numeri che possono essere scritti come una\nfrazione \\(/ b\\), con \\(\\) e \\(b\\) interi e \\(b\\) diverso da 0. numeri\nirrazionali sono numeri illimitati e non periodici che quindi non\npossono essere espressi sotto forma di frazione. Per esempio,\n\\(\\sqrt{2}\\), \\(\\sqrt{3}\\) e \\({\\displaystyle \\pi =3,141592\\ldots}\\) sono\nnumeri irrazionali.","code":""},{"path":"un-piccolo-ripasso.html","id":"numeri-reali","chapter":"Un piccolo ripasso","heading":"Numeri reali","text":"punti della retta \\(r\\) sono quindi “di più” dei numeri razionali. Per\npoter rappresentare tutti punti della retta abbiamo dunque bisogno dei\nnumeri reali. numeri reali possono essere positivi, negativi o nulli\ne comprendono, come casi particolari, numeri interi, numeri\nrazionali e numeri irrazionali. Spesso statisticac il numero dei\ndecimali indica il grado di precisione della misurazione.","code":""},{"path":"un-piccolo-ripasso.html","id":"intervalli","chapter":"Un piccolo ripasso","heading":"Intervalli","text":"Un intervallo si dice chiuso se gli estremi sono compresi\nnell’intervallo, aperto se gli estremi non sono compresi. Le\ncaratteristiche degli intervalli sono riportate nella tabella seguente.","code":""},{"path":"un-piccolo-ripasso.html","id":"insiemi","chapter":"Un piccolo ripasso","heading":"Insiemi","text":"Un insieme (o collezione, classe, gruppo, …) è un concetto primitivo,\novvero è un concetto che già possediamo. Georg Cantor l’ha definito nel\nmodo seguente:un insieme è una collezione di oggetti, determinati e distinti, della nostra percezione o del nostro pensiero, concepiti come un tutto unico; tali oggetti si dicono elementi dell’insieme.Mentre non è rilevante la natura degli oggetti che costituiscono\nl’insieme, ciò che importa è distinguere se un dato oggetto appartenga o\nmeno ad un insieme. Deve essere vera una delle due possibilità: il dato\noggetto è un elemento dell’insieme considerato oppure non è elemento\ndell’insieme considerato. Due insiemi \\(\\) e \\(B\\) si dicono uguali se sono\nformati dagli stessi elementi, anche se disposti ordine diverso:\n\\(=B\\). Due insiemi \\(\\) e \\(B\\) si dicono diversi se non contengono gli\nstessi elementi: \\(\\neq B\\). Ad esempio, seguenti insiemi sono uguali:\n\\[\\{1, 2, 3\\} = \\{3, 1, 2\\} = \\{1, 3, 2\\}= \\{1, 1, 1, 2, 3, 3, 3\\}.\\]\nGli insiemi sono denotati da una lettera maiuscola, mentre le lettere\nminuscole, di solito, designano gli elementi di un insieme. Per esempio,\nun generico insieme \\(\\) si indica con\n\\[= \\{a_1, a_2, \\dots, a_n\\}, \\quad \\text{con~} n > 0.\\]La scrittura \\(\\\\) dice che \\(\\) è un elemento di \\(\\). Per dire che\n\\(b\\) non è un elemento di \\(\\) si scrive \\(b \\notin .\\)Per quegli insiemi cui elementi soddisfano una certa proprietà che li\ncaratterizza, tale proprietà può essere usata per descrivere più\nsinteticamente l’insieme:\n\\[\n= \\{x ~\\vert~ \\text{proprietà posseduta da~} x\\},\n\\]\nche si legge come “\\(\\) è l’insieme degli elementi \\(x\\) per cui è vera la proprietà\nindicata.” Per esempio, per indicare l’insieme \\(\\) delle coppie di\nnumeri reali \\((x,y)\\) che appartengono alla parabola \\(y = x^2 + 1\\) si può\nscrivere:\n\\[\n= \\{(x,y) ~\\vert~ y = x^2 + 1\\}.\n\\]\nDati due insiemi \\(\\) e \\(B\\), diremo che \\(\\) è un sottoinsieme di \\(B\\) se\ne solo se tutti gli elementi di \\(\\) sono anche elementi di \\(B\\):\n\\[\\subseteq B \\iff (\\forall x \\\\Rightarrow x \\B).\\] Se esiste\nalmeno un elemento di \\(B\\) che non appartiene ad \\(\\) allora diremo che\n\\(\\) è un sottoinsieme proprio di \\(B\\):\n\\[\n\\subset B \\iff (\\subseteq B, \\exists~ x \\B ~\\vert~ x \\notin ).\n\\]\nUn altro insieme, detto insieme delle parti, o insieme potenza, che si\nassocia ’insieme \\(\\) è l’insieme di tutti sottoinsiemi di \\(\\),\ninclusi l’insieme vuoto e \\(\\) stesso. Per esempio, per l’insieme\n\\(= \\{, b, c\\}\\), l’insieme delle parti è:\n\\[\n\\mathcal{P}() = \\{\n\\emptyset, \\{\\}, \\{b\\}, \\{c\\},\n \\{, b\\}, \\{, c\\}, \\{c, b\\},\n \\{, b, c\\}\n\\}.\n\\]","code":""},{"path":"un-piccolo-ripasso.html","id":"operazioni-tra-insiemi","chapter":"Un piccolo ripasso","heading":"Operazioni tra insiemi","text":"Si definisce intersezione di \\(\\) e \\(B\\) l’insieme \\(\\cap B\\) di tutti\ngli elementi \\(x\\) che appartengono ad \\(\\) e contemporaneamente \\(B\\):\n\\[\\cap B = \\{x ~\\vert~ x \\\\land x \\B\\}.\\]Si definisce unione di \\(\\) e \\(B\\) l’insieme \\(\\cup B\\) di tutti gli\nelementi \\(x\\) che appartengono ad \\(\\) o \\(B\\), cioè\n\\[\n\\cup B = \\{x ~\\vert~ x \\\\lor x \\B\\}.\n\\]Differenza. Si indica con \\(\\setminus B\\) l’insieme degli elementi di\n\\(\\) che non appartengono \\(B\\):\n\\[\\setminus B = \\{x ~\\vert~ x \\\\land x \\notin B\\}.\\]Insieme complementare. Nel caso che sia \\(B \\subseteq \\), l’insieme\ndifferenza \\(\\setminus B\\) è detto insieme complementare di \\(B\\) \\(\\) e\nsi indica con \\(B^C\\).Dato un insieme \\(S\\), una partizione di \\(S\\) è una collezione di\nsottoinsiemi di \\(S\\), \\(S_1, \\dots, S_k\\), tali che\n\\[S = S_1 \\cup S_2 \\cup \\dots S_k\\] e\n\\[S_i \\cap S_j, \\quad \\text{con~} \\neq j.\\]La relazione tra unione, intersezione e insieme complementare è data\ndalle leggi di DeMorgan: \\[(\\cup B)^c = ^c \\cap B^c,\\]\n\\[(\\cap B)^c = ^c \\cup B^c.\\]","code":""},{"path":"un-piccolo-ripasso.html","id":"diagrammi-di-eulero-venn","chapter":"Un piccolo ripasso","heading":"Diagrammi di Eulero-Venn","text":"molte situazioni è utile servirsi dei cosiddetti diagrammi di\nEulero-Venn per rappresentare gli insiemi e verificare le proprietà\ndelle operazioni tra insiemi (si veda la figura 29.5.\ndiagrammi di Venn sono così nominati onore del matematico inglese del diciannovesimo secolo John Venn anche se Leibnitz e Eulero avevano già precedenza utilizzato rappresentazioni simili.\ntale rappresentazione, gli insiemi sono individuati da regioni del piano delimitate da una curva chiusa. Nel caso di insiemi finiti, è possibile evidenziare esplicitamente alcuni elementi di un insieme mediante punti, quando si\npossono anche evidenziare tutti gli elementi degli insiemi considerati.\nFigura 29.5: tutte le figure \\(S\\) è la regione delimitata dal rettangolo, \\(L\\) è la regione ’interno del cerchio di sinistra e \\(R\\) è la regione ’interno del cerchio di destra. La regione evidenziata mostra l’insieme indicato sotto ciascuna figura.\ndiagrammi di Eulero-Venn che forniscono una dimostrazione delle leggi\ndi DeMorgan sono forniti nella figura 29.6.\nFigura 29.6: Dimostrazione delle leggi di DeMorgan.\n","code":""},{"path":"un-piccolo-ripasso.html","id":"coppie-ordinate-e-prodotto-cartesiano","chapter":"Un piccolo ripasso","heading":"Coppie ordinate e prodotto cartesiano","text":"Una coppia ordinata \\((x,y)\\) è l’insieme cui elementi sono \\(x \\\\) e\n\\(y \\B\\) e nella quale \\(x\\) è la prima componente (o prima coordinata),\n\\(y\\) la seconda. L’insieme di tutte le coppie ordinate costruite \npartire dagli insiemi \\(\\) e \\(B\\) viene detto prodotto cartesiano:\n\\[\\times B = \\{(x, y) ~\\vert~ x \\\\land y \\B\\}.\\] Ad esempio,\nsia \\(= \\{1, 2, 3\\}\\) e \\(B = \\{, b\\}\\). Allora,\n\\[\\{1, 2\\} \\times \\{, b, c\\} = \\{(1, ), (1, b), (1, c), (2, ), (2, b), (2, c)\\}.\\]","code":""},{"path":"un-piccolo-ripasso.html","id":"cardinalità","chapter":"Un piccolo ripasso","heading":"Cardinalità","text":"Si definisce cardinalità (o potenza) di un insieme finito il numero\ndegli elementi dell’insieme. Viene indicata con \\(\\vert \\vert, \\#()\\) o\n\\(\\text{c}()\\).","code":""},{"path":"un-piccolo-ripasso.html","id":"proprietà-degli-stimatori-dei-minimi-quadrati-1","chapter":"Un piccolo ripasso","heading":"Proprietà degli stimatori dei minimi quadrati","text":"Il coefficiente dei minimi quadrati \\(b\\) è una combinazione lineare delle\nosservazioni \\(y_i\\). Tale proprietà è importante perché consente di\nderivare la distribuzione di \\(b\\) dalla distribuzione delle \\(y_i\\). Può\nessere dimostrato che la formula per il calcolo di \\(b\\) si può scrivere\nnel modo seguente: \\[\\begin{aligned}\nb &= \\sum_i \\left[\\frac{x_i-\\bar{x}}{\\sum_j(x_j-\\bar{x})^2}\\right]y_i = \\textstyle\\sum m_i y_i,\\end{aligned}\\]\ndove \\(m_i \\triangleq (x_i-\\bar{x}) / \\sum (x_j-\\bar{x})^2\\) è il peso\nassociato ciascun valore \\(y_i\\). Dato che valori \\(x_i\\) sono fissi e\n\\(m_i\\) dipende solo da \\(x_i\\), anche pesi \\(m_i\\) sono fissi.Il valore atteso di \\(b\\) è uguale \\[\\begin{aligned}\nE(b) &= \\textstyle\\sum m_i E(y_i)\\notag\\\\ \n&= \\textstyle\\sum m_i (\\alpha + \\beta x_i)\\notag\\\\ \n&= \\textstyle\\alpha\\sum m_i + \\beta \\sum m_i x_i\\notag\\\\\n&= \\frac{\\alpha \\sum(x_i-\\bar{x})}{\\sum(x_i-\\bar{x})^2} + \\beta \\frac{\\sum(x_i-\\bar{x})x_i}{\\sum(x_i-\\bar{x})^2}\\notag\\\\\n&= 0 + \\beta \\frac{\\sum x_i^2 -\\bar{x}\\sum x_i}{\\sum(x_i-\\bar{x})^2}\\notag\\\\ \n&= \\beta \\frac{\\sum x_i^2 - n\\bar{x}^2}{\\sum(x_i-\\bar{x})^2}\\notag\\\\ \n&= \\beta.\\end{aligned}\\] Il coefficiente dei minimi quadrati \\(b\\) è\ndunque uno stimatore corretto di \\(\\beta\\). maniera equivalente si può\ndimostrare che \\(E() = \\alpha\\).Sotto le ipotesi di omoschedasticità\n\\(\\big[ \\var(y_i) = \\var(\\varepsilon_i)=\\sigma^2_{\\varepsilon}\\big]\\) e\nindipendenza, la varianza di \\(b\\) è \\[\\begin{aligned}\n\\var(b) &= \\textstyle\\var\\big(\\sum m_i y_i\\big)\\notag\\\\\n&= \\textstyle\\mathop{\\sum m_i^2} \\var(y_i)\\notag\\\\ \n&= \\textstyle\\mathop{\\sum m_i^2} \\sigma^2_{\\varepsilon}\\notag\\\\\n&= \\frac{\\mathop{\\sigma^2_{\\varepsilon}} \\textstyle\\sum(x_i-\\bar{x})^2}{\\big[\\textstyle\\sum(x_i-\\bar{x})^2\\big]^2}\\notag\\\\\n&= \\frac{\\sigma^2_{\\varepsilon}}{\\sum(x_i-\\bar{x})^2}.\\end{aligned}\\] \nmaniera simile si dimostra che la varianza di \\(\\) è\n\\[\\var()= \\frac{\\sigma^2_{\\varepsilon} \\textstyle\\sum x_i^2}{n \\textstyle\\sum (x_i-\\bar{x})^2}.\\]Dato che sia \\(\\) che \\(b\\) sono funzioni lineari di \\(y_i\\), se valori\n\\(y_i\\) seguono la distribuzione gaussiana, allora anche \\(\\) e \\(b\\) saranno\ndistribuiti secondo una distribuzione normale. conclusione,\n\\[\n\\begin{aligned}\nb &\\sim \\mathcal{N}\\bigg(\\beta,  \\frac{\\sigma^2_{\\varepsilon}}{\\sum(x_i-\\bar{x})^2}\\bigg),\\\\\n&\\sim \\mathcal{N}\\bigg(\\alpha, \\frac{\\sigma^2_{\\varepsilon}\\textstyle\\sum x_i^2}{n \\textstyle\\sum (x_i-\\bar{x})^2} \\bigg).\n\\end{aligned}\n\\]","code":""},{"path":"bibliografia.html","id":"bibliografia","chapter":"Bibliografia","heading":"Bibliografia","text":"","code":""}]
