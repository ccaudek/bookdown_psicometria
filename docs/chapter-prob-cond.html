<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Capitolo 12 Probabilità condizionata | Data Science per psicologi</title>
<meta name="author" content="Corrado Caudek">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.6.4/header-attrs.js"></script><script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.5.3/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.5.3/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.4/tabs.js"></script><script src="libs/bs3compat-0.2.4/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Data Science per psicologi</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Benvenuti</a></li>
<li class="book-part">Introduzione</li>
<li><a class="" href="obiettivi-formativi.html"><span class="header-section-number">1</span> Obiettivi formativi</a></li>
<li class="book-part">Introduzione al linguaggio R</li>
<li><a class="" href="chapter-pacchetti.html"><span class="header-section-number">2</span> Pacchetti</a></li>
<li><a class="" href="chapter-install-r.html"><span class="header-section-number">3</span> Per cominciare</a></li>
<li><a class="" href="chapter-sintassi.html"><span class="header-section-number">4</span> Sintassi di base</a></li>
<li><a class="" href="chapter-strutture-dati.html"><span class="header-section-number">5</span> Strutture di dati</a></li>
<li><a class="" href="chapter-strut-contr.html"><span class="header-section-number">6</span> Strutture di controllo</a></li>
<li><a class="" href="chapter-input-output.html"><span class="header-section-number">7</span> Input/Output</a></li>
<li class="book-part">Misurazione</li>
<li><a class="" href="chapter-terminologia.html"><span class="header-section-number">8</span> Terminologia</a></li>
<li><a class="" href="chapter-misurazione.html"><span class="header-section-number">9</span> La misurazione in psicologia</a></li>
<li class="book-part">Descrizione</li>
<li><a class="" href="chapter-descript.html"><span class="header-section-number">10</span> Statistica descrittiva</a></li>
<li class="book-part">Elementi di teoria della probabilità</li>
<li><a class="" href="chapter-prob.html"><span class="header-section-number">11</span> Il calcolo delle probabilità</a></li>
<li><a class="active" href="chapter-prob-cond.html"><span class="header-section-number">12</span> Probabilità condizionata</a></li>
<li><a class="" href="chapter-teo-bayes.html"><span class="header-section-number">13</span> Il teorema di Bayes</a></li>
<li><a class="" href="chapter-prob-congiunta.html"><span class="header-section-number">14</span> Probabilità congiunta</a></li>
<li class="book-part">Inferenza frequentista</li>
<li><a class="" href="distribuzione-campionaria-della-media-dei-campioni.html"><span class="header-section-number">15</span> Distribuzione campionaria della media dei campioni</a></li>
<li><a class="" href="significativit%C3%A0-statistica.html"><span class="header-section-number">16</span> Significatività statistica</a></li>
<li><a class="" href="inferenza-sulle-medie.html"><span class="header-section-number">17</span> Inferenza sulle medie</a></li>
<li><a class="" href="critiche-e-difese.html"><span class="header-section-number">18</span> Critiche e difese</a></li>
<li class="book-part">Verosimiglianza</li>
<li><a class="" href="la-funzione-di-verosimiglianza.html"><span class="header-section-number">19</span> La funzione di verosimiglianza</a></li>
<li class="book-part">Statistica Bayesiana</li>
<li><a class="" href="chapter-modellistica-bayesiana.html"><span class="header-section-number">20</span> Modellistica bayesiana</a></li>
<li><a class="" href="chapter-stima-distr-posteriori.html"><span class="header-section-number">21</span> Stima della funzione a posteriori</a></li>
<li><a class="" href="una-breve-introduzione-al-modello-di-regressione.html"><span class="header-section-number">22</span> Una breve introduzione al modello di regressione</a></li>
<li><a class="" href="il-modello-statistico-della-regressione-lineare.html"><span class="header-section-number">23</span> Il modello statistico della regressione lineare</a></li>
<li><a class="" href="inferenza-bayesiana.html"><span class="header-section-number">24</span> Inferenza Bayesiana</a></li>
<li><a class="" href="informazioni-generali.html">Informazioni generali</a></li>
<li><a class="" href="appendici.html">Appendici</a></li>
<li><a class="" href="bibliografia.html">Bibliografia</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="chapter-prob-cond" class="section level1" number="12">
<h1>
<span class="header-section-number">Capitolo 12</span> Probabilità condizionata<a class="anchor" aria-label="anchor" href="#chapter-prob-cond"><i class="fas fa-link"></i></a>
</h1>
<p>L’attribuzione di una probabilità ad un evento è sempre condizionata
dalle conoscenze che abbiamo a disposizione. Per un determinato stato di
conoscenze, attribuiamo ad un dato evento una certa probabilità di
verificarsi; ma se il nostro stato di conoscenze cambia, allora cambierà
anche la probabilità che attribuiamo all’evento in questione. Per
esempio, posiamo chiederci quale sia probabilità che Mario Rossi superi
l’esame di Psicometria nel primo appello del presente anno accademico.
In assenza di altre informazioni, la migliore stima di tale probabilità
è data dalla proporzione di studenti che hanno superato l’esame di
Psicometria nel corrispondente appello dei passati anni accademici. Ma
se sappiamo che Mario Rossi è particolarmente portato per le materie
quantitative, ha un’ottima preparazione di base e ha studiato molto,
allora la probabilità sarà sicuramente più alta.</p>
<div id="probabilità-condizionata-su-altri-eventi" class="section level2" number="12.1">
<h2>
<span class="header-section-number">12.1</span> Probabilità condizionata su altri eventi<a class="anchor" aria-label="anchor" href="#probabilit%C3%A0-condizionata-su-altri-eventi"><i class="fas fa-link"></i></a>
</h2>
<p>La probabilità condizionata è una componente essenziale del ragionamento
scientifico dato che chiarisce come sia possibile incorporare le
evidenze disponibili, in maniera logica e coerente, nella nostra
conoscenza del mondo. Infatti, si può pensare che tutte le probabilità
siano probabilità condizionate, anche se l’evento condizionante non è
sempre esplicitamente menzionato. Consideriamo il seguente problema.</p>
<p><strong>Esercizio.</strong>
Lo screening per la diagnosi precoce del tumore mammario si avvale di
test che sono accurati al 90%, nel senso che il 90% delle donne con
cancro e il 90% delle donne senza cancro saranno classificate
correttamente. Supponiamo che l’1% delle donne sottoposte allo screening
abbia effettivamente il cancro al seno. Ci chiediamo: qual è la
probabilità che una donna scelta casualmente abbia una mammografia
positiva e, se ce l’ha, qual è la probabilità che abbia davvero il
cancro?</p>
<p><em>Soluzione.</em>
Per risolvere questo problema, supponiamo che il test in questione venga
somministrato ad un grande campione di donne, diciamo a 1000 donne. Di
queste 1000 donne, 10 (ovvero, l’1%) hanno il cancro al seno. Per queste
10 donne, il test darà un risultato positivo in 9 casi (ovvero, nel 90%
dei casi). Per le rimanenti 990 donne che non hanno il cancro al seno,
il test darà un risultato positivo in 99 casi (se la probabilità di un
vero positivo è del 90%, la probabilità di un falso positivo è del 10%).
Questa situazione è rappresentata nella figura <a href="chapter-prob-cond.html#fig:mammografia">12.1</a>.
Mettendo insieme questi due risultati, vediamo che il test dà un risultato positivo per 9 donne che hanno effettivamente il cancro al seno e per 99 donne che non ce l’hanno, per un totale di 108 risultati positivi. Dunque, la probabilità di ottenere un risultato positivo al test è <span class="math inline">\(\frac{108}{1000}\)</span> = 11%. Ma delle 108
donne che hanno ottenuto un risultato positivo al test, solo 9 hanno il
cancro al seno. Dunque, la probabilità di avere il cancro, dato un
risultato positivo al test, è pari a <span class="math inline">\(\frac{9}{108}\)</span> = 8%.</p>
<div class="figure" style="text-align: center">
<span id="fig:mammografia"></span>
<img src="images/mammografia.png" alt="Rappresentazione ad albero che riporta le frequenze attese dei risultati di una mammografia in un campione di 1,000 donne" width="90%"><p class="caption">
Figura 12.1: Rappresentazione ad albero che riporta le frequenze attese dei risultati di una mammografia in un campione di 1,000 donne
</p>
</div>
<p>Nell’esercizio precedente, la probabilità dell’evento “ottenere un risultato positivo al test” è una probabilità non condizionata, mentre la probabilità dell’evento “avere il cancro al seno, dato che il test ha dato un risultato positivo” è una probabilità condizionata. In termini generali, la probabilità condizionata <span class="math inline">\(P(A \mid B)\)</span> rappresenta la probabilità che si verifichi l’evento <span class="math inline">\(A\)</span> sapendo che si è verificato
l’evento <span class="math inline">\(B\)</span>; oppure: la probabilità di <span class="math inline">\(A\)</span> in una prova valida solo se
si verifica anche <span class="math inline">\(B\)</span>. Ciò ci conduce alla seguente definizione.</p>

<div class="definition">
<span id="def:prob-cond" class="definition"><strong>Definizione 12.1  </strong></span>Dato un qualsiasi evento <span class="math inline">\(A\)</span>, si chiama <em>probabilità condizionata</em> di
<span class="math inline">\(A\)</span> dato <span class="math inline">\(B\)</span> il numero
<span class="math display" id="eq:probcond">\[\begin{equation}
P(A \mid B) = \frac{P(A \cap B)}{P(B)}, \quad \text{con}\, P(B) &gt; 0,
\tag{12.1}
\end{equation}\]</span>
dove <span class="math inline">\(P(A\cap B)\)</span> è la probabilità congiunta dei
due eventi, ovvero la probabilità che si verifichino entrambi.
</div>
<p>In alcuni casi può essere conveniente leggere al contrario la
formula <a href="chapter-prob-cond.html#def:prob-cond">12.1</a> e utilizzarla per calcolare la probabilità
dell’intersezione di due eventi. Per esempio se conosciamo la
probabilità dell’evento <span class="math inline">\(B\)</span> e la probabilità condizionata di <span class="math inline">\(A\)</span> su <span class="math inline">\(B\)</span>,
otteniamo
<span class="math display" id="eq:probcondinv">\[\begin{equation}
P(A \cap B) = P(B)P(A \mid B),
\tag{12.2}
\end{equation}\]</span>
mentre se conosciamo la probabilità dell’evento <span class="math inline">\(A\)</span> e la probabilità condizionata di <span class="math inline">\(B\)</span> su <span class="math inline">\(A\)</span>, otteniamo <span class="math inline">\(P(A \cap B) = P(A)P(B \mid A)\)</span>.</p>
<p><strong>Esercizio.</strong>
Da un mazzo di 52 carte (13 carte per ciascuno dei 4 semi) ne viene
estratta 1 in modo casuale. Qual è la probabilità che esca una figura di
cuori? Sapendo che la carta estratta ha il seme di cuori, qual è la
probabilità che il valore numerico della carta sia 7, 8 o 9?</p>
<p><em>Soluzione.</em>
Ci sono 13 carte di cuori, dunque la risposta alla prima domanda è 1/4.
Per rispondere alla seconda domanda consideriamo solo le 13 carte di
cuori; la probabilità cercata è dunque 3/13.</p>
</div>
<div id="la-fallacia-del-pubblico-ministero" class="section level2" number="12.2">
<h2>
<span class="header-section-number">12.2</span> La fallacia del pubblico ministero<a class="anchor" aria-label="anchor" href="#la-fallacia-del-pubblico-ministero"><i class="fas fa-link"></i></a>
</h2>
<p>Un errore comune che si commette è quello di credere che <span class="math inline">\(P(A \mid B)\)</span>
sia uguale a <span class="math inline">\(P(B \mid A)\)</span>. Tale fallacia ha particolare risalto in
ambito forense tanto che è conosciuta con il nome di “fallacia del
procuratore” (<em>prosecutor’s fallacy</em>). In essa, una piccola probabilità
dell’evidenza, data l’innocenza, viene erroneamente interpretata come la
probabilità dell’innocenza, data l’evidenza.</p>
<p>Consideriamo il caso di un esame del DNA. Un esperto forense potrebbe
affermare, ad esempio, che “se l’imputato è innocente, c’è solo una
possibilità su un miliardo che vi sia una corrispondenza tra il suo DNA
e il DNA trovato sulla scena del crimine.” Ma talvolta questa
probabilità è erroneamente interpretata come avesse il seguente
significato: “date le prove del DNA, c’è solo una possibilità su un
miliardo che l’imputato sia innocente.”</p>
<p>Le considerazioni precedenti risultano più chiare se facciamo nuovamente
riferimento all’esercizio sul tumore mammario descritto sopra. In tale esercizio abbiamo visto come la probabilità di cancro dato un risultato positivo al test sia uguale a 0.08. Tale probabilità è molto diversa dalla probabilità di un risultato
positivo al test data la presenza del cancro. Infatti, questa seconda
probabilità è uguale a 0.90 ed è descritta nel problema come una delle
caratteristiche del test in questione.</p>
</div>
<div id="legge-della-probabilità-composta" class="section level2" number="12.3">
<h2>
<span class="header-section-number">12.3</span> Legge della probabilità composta<a class="anchor" aria-label="anchor" href="#legge-della-probabilit%C3%A0-composta"><i class="fas fa-link"></i></a>
</h2>
<p>Il teorema della probabilità composta deriva dal concetto di probabilità
condizionata per cui la probabilità che si verifichino due eventi <span class="math inline">\(A_i\)</span>
e <span class="math inline">\(A_j\)</span> è pari alla probabilità di uno dei due eventi moltiplicato con
la probabilità dell’altro evento condizionato al verificarsi del primo.</p>
<p>L’equazione <a href="chapter-prob-cond.html#eq:probcondinv">(12.2)</a> si estende al caso di <span class="math inline">\(n\)</span> eventi <span class="math inline">\(A_1, \dots, A_n\)</span> nella forma seguente:
<span class="math display" id="eq:probcomposte">\[\begin{equation}
\begin{split}
P(A_1 \cap A_2 \cap \dots\cap A_n) = {}&amp; P(A_1)P(A_2 \mid A_1)P(A_3 \mid A_1 \cap A_2) \dots\\
 &amp; P(A_n \mid A_1 \cap A_2 \cap \dots \cap A_{n-1})
\end{split}
\tag{11.1}
\end{equation}\]</span>
la quale esprime in forma generale la legge della probabilità composta.</p>
<p><strong>Esercizio.</strong>
Da un’urna contenente 6 palline bianche e 4 nere si estrae una pallina
per volta, senza reintrodurla nell’urna. Indichiamo con <span class="math inline">\(B_i\)</span> l’evento:
“esce una pallina bianca alla <span class="math inline">\(i\)</span>-esima estrazione” e con <span class="math inline">\(N_i\)</span>
l’estrazione di una pallina nera. L’evento: “escono due palline bianche
nelle prime due estrazioni” è rappresentato dalla intersezione
<span class="math inline">\(\{B_1 \cap B_2\}\)</span> e la sua probabilità vale, per la <a href="chapter-prob-cond.html#eq:probcondinv">(12.2)</a>
<span class="math display">\[
P(B_1 \cap B_2) = P(B_1)P(B_2 \mid B_1).
\]</span>
<span class="math inline">\(P(B_1)\)</span> vale 6/10, perché nella prima estrazione <span class="math inline">\(\Omega\)</span> è costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilità condizionata <span class="math inline">\(P(B_2 \mid B_1)\)</span> vale 5/9, perché nella seconda estrazione, se è verificato l’evento <span class="math inline">\(B_1\)</span>, lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava
pertanto:
<span class="math display">\[
  P(B_1 \cap B_2) = \frac{6}{10} \cdot \frac{5}{9} = \frac{1}{3}.
\]</span>
In modo analogo si ha che
<span class="math display">\[
P(N_1 \cap N_2) = P(N_1)P(N_2 \mid N_1) = \frac{4}{10} \cdot \frac{3}{9} = \frac{4}{30}.
\]</span></p>
<p>Se l’esperimento consiste nell’estrazione successiva di 3 palline, la
probabilità che queste siano tutte bianche vale, per
la <a href="chapter-prob.html#eq:probcomposte">(11.1)</a>:
<span class="math display">\[
P(B_1 \cap B_2 \cap B_3)=P(B_1)P(B_2 \mid B_1)P(B_3 \mid B_1 \cap B_2),
\]</span>
dove la probabilità <span class="math inline">\(P(B_3 \mid B_1 \cap B_2)\)</span> si calcola supponendo che
si sia verificato l’evento condizionante <span class="math inline">\(\{B_1 \cap B_2\}\)</span>. Lo spazio
campionario per questa probabilità condizionata è costituito da 4
palline bianche e 4 nere, per cui <span class="math inline">\(P(B_3 \mid B_1 \cap B_2) = 1/2\)</span> e
quindi:
<span class="math display">\[
P (B_1 \cap B_2 \cap B_3) = \frac{6}{10}\cdot\frac{5}{9} \cdot\frac{4}{8}  = \frac{1}{6}.
\]</span></p>
<p>La probabilità dell’estrazione di tre palline nere è invece:
<span class="math display">\[
\begin{aligned}
P(N_1 \cap N_2 \cap N_3) &amp;= P(N_1)P(N_2 \mid N_1)P(N_3 \mid N_1 \cap N_2)\notag\\ 
&amp;= \frac{4}{10} \cdot \frac{3}{9} \cdot \frac{2}{8} = \frac{1}{30}.\notag
\end{aligned}
\]</span></p>
</div>
<div id="lindipendendenza-stocastica" class="section level2" number="12.4">
<h2>
<span class="header-section-number">12.4</span> L’indipendendenza stocastica<a class="anchor" aria-label="anchor" href="#lindipendendenza-stocastica"><i class="fas fa-link"></i></a>
</h2>
<p>Un concetto molto importante per le applicazioni statistiche della
probabilità è quello dell’indipendenza stocastica. La
definizione <a href="chapter-prob-cond.html#eq:probcond">(12.1)</a> esprime il concetto intuitivo di indipendenza
di un evento da un altro, nel senso che il verificarsi di <span class="math inline">\(A\)</span> non
influisce sulla probabilità del verificarsi di <span class="math inline">\(B\)</span>, ovvero non la
condiziona. Infatti, per la definizione <a href="chapter-prob-cond.html#eq:probcond">(12.1)</a> di probabilità condizionata, si ha che, se <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> sono due eventi indipendenti, risulta:
<span class="math display">\[
P(A \mid B) = \frac{P(A)P(B)}{P(B)} = P(A).\notag
\]</span>
Possiamo dunque dire che due eventi <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> sono indipendenti se
<span class="math display">\[
\begin{split}
P(A \mid B) &amp;= P(A), \\
P(B \mid A) &amp;= P(B).
\end{split}
\]</span></p>
<p><strong>Esercizio.</strong>
Nel lancio di due dadi non truccati, si considerino gli eventi:
<em>A</em> = {esce un 1 o un 2 nel primo lancio} e <em>B</em> = {il punteggio
totale è 8}. Gli eventi <em>A</em> e <em>B</em> sono indipendenti?</p>
<p><em>Soluzione.</em>
Rappresentiamo qui sotto lo spazio campionario dell’esperimento casuale.</p>
<div class="figure" style="text-align: center">
<span id="fig:sampling-space-dice"></span>
<img src="images/sampling-space-dice.png" alt="Rappresentazione dello spazio campionario dei risultati dell'esperimento casuale corrispondente al lancio di due dadi bilanciati. Sono evidenziati gli eventi elementari che costituiscono l'evento A: esce un 1 o un 2 nel primo lancio." width="50%"><p class="caption">
Figura 12.2: Rappresentazione dello spazio campionario dei risultati dell’esperimento casuale corrispondente al lancio di due dadi bilanciati. Sono evidenziati gli eventi elementari che costituiscono l’evento A: esce un 1 o un 2 nel primo lancio.
</p>
</div>
<p>Gli eventi <em>A</em> e <em>B</em> non sono statisticamente indipendenti. Infatti, le
loro probabilità valgono <em>P</em>(A) = 12/36 e <em>P</em>(B) = 5/36 e la probabilità
della loro intersezione è
<span class="math display">\[
P(A \cap B) = 1/36 = 3/108 \neq P(A)P(B) = 5/108.
\]</span>
 </p>
<p>Si noti che il concetto di indipendenza è del tutto differente da quello
di incompatibilità. Due eventi <em>A</em> e <em>B</em> incompatibili (per i quali si
ha <span class="math inline">\(A \cap B = \emptyset\)</span>) sono statisticamente dipendenti, poiché il
verificarsi dell’uno esclude il verificarsi dell’altro:
<span class="math inline">\(P(A \cap B)=0 \neq P(A)P(B)\)</span>.</p>
<p><br></p>
<p>Si noti inoltre che, se due eventi con probabilità non nulla sono statisticamente indipendenti, la legge delle probabilità totali espressa dalla <a href="chapter-prob.html#eq:probunione">(11.2)</a> si modifica nella relazione seguente:</p>
<p><span class="math display">\[\begin{equation}
P(A \cup B) = P(A) + P(B) - P(A)P(B).
\end{equation}\]</span></p>
</div>
<div id="conclusioni-3" class="section level2 unnumbered">
<h2>Conclusioni<a class="anchor" aria-label="anchor" href="#conclusioni-3"><i class="fas fa-link"></i></a>
</h2>
<p>La probabilità condizionata è importante perché ci fornisce uno
strumento per precisare il concetto di indipendenza statistica. Una
delle più importanti domande delle analisi statistiche è infatti quella
che si chiede se due variabili siano o meno associate. In questo
capitolo abbiamo discusso il concetto di indipendenza (come contrapposto
al concetto di associazione); nel capitolo <a href="chapter-descript.html#chapter-descript">Statistica descrittiva</a> abbiamo descritto poi uno dei modi possibili che ci consentono di quantificare l’associazione tra due variabili. In seguito vedremo come sia possibile fare inferenza sull’associazione tra variabili – ovvero, come stabilire il livello di
fiducia nel verificarsi dell’evento esaminato nel campione in un
contesto più ampio, cioè quello della popolazione.</p>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="chapter-prob.html"><span class="header-section-number">11</span> Il calcolo delle probabilità</a></div>
<div class="next"><a href="chapter-teo-bayes.html"><span class="header-section-number">13</span> Il teorema di Bayes</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#chapter-prob-cond"><span class="header-section-number">12</span> Probabilità condizionata</a></li>
<li><a class="nav-link" href="#probabilit%C3%A0-condizionata-su-altri-eventi"><span class="header-section-number">12.1</span> Probabilità condizionata su altri eventi</a></li>
<li><a class="nav-link" href="#la-fallacia-del-pubblico-ministero"><span class="header-section-number">12.2</span> La fallacia del pubblico ministero</a></li>
<li><a class="nav-link" href="#legge-della-probabilit%C3%A0-composta"><span class="header-section-number">12.3</span> Legge della probabilità composta</a></li>
<li><a class="nav-link" href="#lindipendendenza-stocastica"><span class="header-section-number">12.4</span> L’indipendendenza stocastica</a></li>
<li><a class="nav-link" href="#conclusioni-3">Conclusioni</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Data Science per psicologi</strong>" was written by Corrado Caudek. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
