<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capitolo 3 Statistica descrittiva | PSICOMETRIA</title>
  <meta name="description" content="""" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Capitolo 3 Statistica descrittiva | PSICOMETRIA" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="""" />
  <meta name="github-repo" content="ccaudek/bookdown_psicometria" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capitolo 3 Statistica descrittiva | PSICOMETRIA" />
  
  <meta name="twitter:description" content="""" />
  

<meta name="author" content="Corrado Caudek" />


<meta name="date" content="2020-12-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="chapter-misurazione.html"/>
<link rel="next" href="bibliografia.html"/>
<script src="libs/header-attrs-2.5/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A.A. 2020/2021</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefazione</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#perché-tanta-statistica-in-psicologia"><i class="fa fa-check"></i>Perché tanta statistica in psicologia?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#come-studiare"><i class="fa fa-check"></i>Come studiare?</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="chapter-terminologia.html"><a href="chapter-terminologia.html"><i class="fa fa-check"></i><b>1</b> Terminologia</a>
<ul>
<li class="chapter" data-level="1.1" data-path="chapter-terminologia.html"><a href="chapter-terminologia.html#metodi-e-procedure-della-psicologia"><i class="fa fa-check"></i><b>1.1</b> Metodi e procedure della psicologia</a></li>
<li class="chapter" data-level="1.2" data-path="chapter-terminologia.html"><a href="chapter-terminologia.html#variabili-e-costanti"><i class="fa fa-check"></i><b>1.2</b> Variabili e costanti</a></li>
<li class="chapter" data-level="1.3" data-path="chapter-terminologia.html"><a href="chapter-terminologia.html#variabili-indipendenti-e-variabili-dipendenti"><i class="fa fa-check"></i><b>1.3</b> Variabili indipendenti e variabili dipendenti</a></li>
<li class="chapter" data-level="1.4" data-path="chapter-terminologia.html"><a href="chapter-terminologia.html#la-matrice-dei-dati"><i class="fa fa-check"></i><b>1.4</b> La matrice dei dati</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html"><i class="fa fa-check"></i><b>2</b> La misurazione in psicologia</a>
<ul>
<li class="chapter" data-level="2.1" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#le-scale-di-misura"><i class="fa fa-check"></i><b>2.1</b> Le scale di misura</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#scala-nominale"><i class="fa fa-check"></i><b>2.1.1</b> Scala nominale</a></li>
<li class="chapter" data-level="2.1.2" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#scala-ordinale"><i class="fa fa-check"></i><b>2.1.2</b> Scala ordinale</a></li>
<li class="chapter" data-level="2.1.3" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#scala-ad-intervalli"><i class="fa fa-check"></i><b>2.1.3</b> Scala ad intervalli</a></li>
<li class="chapter" data-level="2.1.4" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#scala-di-rapporti"><i class="fa fa-check"></i><b>2.1.4</b> Scala di rapporti</a></li>
<li class="chapter" data-level="2.1.5" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#gerarchia-dei-livelli-di-scala-di-misura"><i class="fa fa-check"></i><b>2.1.5</b> Gerarchia dei livelli di scala di misura</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#sec:DiscreteVsContinuous"><i class="fa fa-check"></i><b>2.2</b> Variabili discrete vs. variabili continue</a></li>
<li class="chapter" data-level="2.3" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#perché-alcune-misurazioni-sono-migliori-di-altre"><i class="fa fa-check"></i><b>2.3</b> Perché alcune misurazioni sono migliori di altre?</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#sec:accuratezza_precisione"><i class="fa fa-check"></i><b>2.3.1</b> Tipologie di errori</a></li>
<li class="chapter" data-level="2.3.2" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#sec:reliability"><i class="fa fa-check"></i><b>2.3.2</b> Attendibilità</a></li>
<li class="chapter" data-level="2.3.3" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#sec:validity"><i class="fa fa-check"></i><b>2.3.3</b> Validità</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#conclusioni"><i class="fa fa-check"></i>Conclusioni</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html"><i class="fa fa-check"></i><b>3</b> Statistica descrittiva</a>
<ul>
<li class="chapter" data-level="3.1" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#perché-riassumere-i-dati"><i class="fa fa-check"></i><b>3.1</b> Perché riassumere i dati?</a></li>
<li class="chapter" data-level="3.2" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#sec:distr_freq"><i class="fa fa-check"></i><b>3.2</b> Distribuzioni di frequenze</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#esercizio-con-r"><i class="fa fa-check"></i><b>3.2.1</b> Esercizio con R</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#istogramma"><i class="fa fa-check"></i><b>3.3</b> Istogramma</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#esercizio-con-r-1"><i class="fa fa-check"></i><b>3.3.1</b> Esercizio con R</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#funzione-di-densità-empirica"><i class="fa fa-check"></i><b>3.4</b> Funzione di densità empirica</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#esercizio-con-r-2"><i class="fa fa-check"></i><b>3.4.1</b> Esercizio con R</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#forma-di-una-distribuzione"><i class="fa fa-check"></i><b>3.5</b> Forma di una distribuzione</a></li>
<li class="chapter" data-level="3.6" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#indici-di-posizione"><i class="fa fa-check"></i><b>3.6</b> Indici di posizione</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#quantili"><i class="fa fa-check"></i><b>3.6.1</b> Quantili</a></li>
<li class="chapter" data-level="3.6.2" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#box-plot"><i class="fa fa-check"></i><b>3.6.2</b> Box-plot</a></li>
<li class="chapter" data-level="3.6.3" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#leccellenza-grafica"><i class="fa fa-check"></i><b>3.6.3</b> L’eccellenza grafica</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#indici-di-tendenza-centrale"><i class="fa fa-check"></i><b>3.7</b> Indici di tendenza centrale</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#media"><i class="fa fa-check"></i><b>3.7.1</b> Media</a></li>
<li class="chapter" data-level="3.7.2" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#media-spuntata"><i class="fa fa-check"></i><b>3.7.2</b> Media spuntata</a></li>
<li class="chapter" data-level="3.7.3" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#moda-e-mediana"><i class="fa fa-check"></i><b>3.7.3</b> Moda e mediana</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#indici-di-dispersione"><i class="fa fa-check"></i><b>3.8</b> Indici di dispersione</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#indici-basati-sullordinamento-dei-dati"><i class="fa fa-check"></i><b>3.8.1</b> Indici basati sull’ordinamento dei dati</a></li>
<li class="chapter" data-level="3.8.2" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#scostamento-medio-semplice-dalla-mediana"><i class="fa fa-check"></i><b>3.8.2</b> Scostamento medio semplice dalla mediana</a></li>
<li class="chapter" data-level="3.8.3" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#varianza"><i class="fa fa-check"></i><b>3.8.3</b> Varianza</a></li>
<li class="chapter" data-level="3.8.4" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#deviazione-standard"><i class="fa fa-check"></i><b>3.8.4</b> Deviazione standard</a></li>
<li class="chapter" data-level="3.8.5" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#indici-di-variabilità-relativi"><i class="fa fa-check"></i><b>3.8.5</b> Indici di variabilità relativi</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#le-relazioni-tra-variabili"><i class="fa fa-check"></i><b>3.9</b> Le relazioni tra variabili</a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#diagramma-a-dispersione"><i class="fa fa-check"></i><b>3.9.1</b> Diagramma a dispersione</a></li>
<li class="chapter" data-level="3.9.2" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#covarianza"><i class="fa fa-check"></i><b>3.9.2</b> Covarianza</a></li>
<li class="chapter" data-level="3.9.3" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#correlazione"><i class="fa fa-check"></i><b>3.9.3</b> Correlazione</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#correlazione-e-causazione"><i class="fa fa-check"></i><b>3.10</b> Correlazione e causazione</a>
<ul>
<li class="chapter" data-level="3.10.1" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#usi-della-correlazione"><i class="fa fa-check"></i><b>3.10.1</b> Usi della correlazione</a></li>
<li class="chapter" data-level="3.10.2" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#correlazione-di-spearman"><i class="fa fa-check"></i><b>3.10.2</b> Correlazione di Spearman</a></li>
<li class="chapter" data-level="3.10.3" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#correlazione-nulla"><i class="fa fa-check"></i><b>3.10.3</b> Correlazione nulla</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#conclusioni"><i class="fa fa-check"></i>Conclusioni</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliografia.html"><a href="bibliografia.html"><i class="fa fa-check"></i>Bibliografia</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">PSICOMETRIA</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chapter:descriptive_stats" class="section level1" number="3">
<h1><span class="header-section-number">Capitolo 3</span> Statistica descrittiva</h1>
<p>Nel 1907 Francis Galton, cugino di Charles Darwin, matematico e
statistico autodidatta, geografo, esploratore, teorico della
dattiloscopia (ovvero, dell’uso delle impronte digitali a fini
identificativi) e dell’eugenetica, scrisse una lettera alla rivista
scientifica Nature sulla sua visita alla <em>Fat Stock and Poultry
Exhibition</em> di Plymouth. Lì vide alcuni membri del pubblico partecipare
ad un gioco il cui scopo era quello di indovinare il peso della carcassa
di un grande bue che era appena stato scuoiato. Galton si procurò i 787
dei biglietti che erano stati compilati dal pubblico e considerò il
valore medio di 547 kg come la “scelta democratica” dei partecipanti, in
quanto “ogni altra stima era stata giudicata troppo alta o troppo bassa
dalla maggioranza dei votanti.” Il punto interessante è che il peso
corretto di 543 kg si dimostrò essere molto simile alla “scelta
democratica” basata sulle stime dei 787 partecipanti. Galton intitolò la
sua lettera a Nature <em>Vox Populi</em> (voce del popolo), ma questo processo
decisionale è ora meglio conosciuto come la “saggezza delle folle”
(<em>wisdom of crowds</em>). Possiamo dire che, nel suo articolo del 1907,
Galton effettuò quello che ora chiamiamo un riepilogo dei dati, ovvero
calcolò un indice sintetico a partire da un insieme di dati. In questo
capitolo esamineremo le tecniche che sono state sviluppate nel secolo
successivo per riassumere le grandi masse di dati con cui sempre più
spesso ci dobbiamo confrontare. Vedremo come calcolare e interpretare
gli indici di posizione e di dispersione, discuteremo le distribuzioni
di frequenze e le relazioni tra variabili. Vedremo inoltre quali sono le
tecniche di visualizzazione che ci consentono di rappresentare questi
sommari dei dati mediante dei grafici. Ma prima di entrare nei dettagli,
prendiamoci un momento per capire perché abbiamo bisogno della
statistica descrittiva.</p>
<div id="perché-riassumere-i-dati" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Perché riassumere i dati?</h2>
<p>Quando riassumiamo i dati, necessariamente buttiamo via delle
informazioni. Ma è una buona idea procedere in questo modo? Non sarebbe
meglio conservare le informazioni specifiche di ciascun soggetto che
partecipa ad un esperimento psicologico, al di là di ciò che viene
trasmesso dagli indici riassuntivi della statistica descrittiva? Che
dire delle informazioni che descrivono come sono stati raccolti i dati,
come l’ora del giorno o l’umore del partecipante? Tutte queste
informazioni vengono perdute quando riassumiamo i dati. La risposta alla
domanda che ci siamo posti è che, in generale, non è una buona idea
conservare tutti i dettagli di ciò che sappiamo. È molto più utile
riassumere le informazioni perché la semplificazione risultante consente
i processi di <strong>generalizzazione</strong>.</p>
<p>In un contesto letterario, l’importanza della generalizzazione è stata
sottolineata da Jorge Luis Borges nel suo racconto “Funes o della
memoria,” che descrive un individuo che perde la capacità di
dimenticare. Borges si concentra sulla relazione tra generalizzazione e
pensiero:</p>
<blockquote>
<p>Pensare è dimenticare una differenza, generalizzare, astrarre. Nel mondo troppo pieno di Funes, c’erano solo dettagli.</p>
</blockquote>
<p>Come possiamo ben capire, la vita di Funes non è facile. Se facciamo
riferimento alla psicologia possiamo dire che gli psicologi hanno
studiato a lungo l’utilità della generalizzazione per il pensiero. Un
esempio è fornito dal fenomeno della formazione dei concetti e lo
psicologo che viene in mente a questo proposito è sicuramente Eleanor
Rosch, la quale ha studiato i principi di base della categorizzazione. I
concetti ci forniscono uno strumento potente per organizzare le
conoscenze. Noi siamo in grado di riconoscere facilmente i diversi
esemplare di un concetto – per esempio, “gli uccelli” – anche se i
singoli esemplari che fanno parte di una categoria sono molto diversi
tra loro (l’aquila, la gallina, il pettirosso). L’uso dei concetti, cioè
la generalizzazione, è utile perché ci consente di fare previsioni sulle
proprietà dei singoli esemplari che appartengono ad una categoria, anche
se non abbiamo mai avuto esperienza diretta con essi – per esempio,
possiamo fare la predizione che tutti gli uccelli possono volare e
mangiare vermi, ma non possono guidare un’automobile o parlare in
inglese. Queste previsioni non sono sempre corrette, ma sono utili.</p>
<p>Le statistiche descrittive, in un certo senso, ci fornisco l’analogo dei
“prototipi” che, secondo Eleanor Rosch, stanno alla base del processo
psicologico di creazione dei concetti. Un prototipo è l’esemplare più
rappresentativo di una categoria. In maniera simile, una statistica
descrittiva come la media, ad esempio, potrebbe essere intesa come
l’osservazione “tipica.”</p>
<p>La statistica descrittiva ci fornisce gli strumenti per riassumere i
dati che abbiamo a disposizione in una forma visiva o numerica. Le
rappresentazioni grafiche più usate della statistica descrittiva sono
gli istogrammi, i diagrammi a dispersione o i box-plot, e gli indici
sintetici più comuni sono la media, la mediana, la varianza e la
deviazione standard.</p>
</div>
<div id="sec:distr_freq" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Distribuzioni di frequenze</h2>
<p>Per introdurre i principali strumenti della statistica descrittiva
considereremo qui i dati raccolti da <span class="citation"><a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">Zetsche, Bürkner, &amp; Renneberg</a> (<a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">2019</a>)</span>. Questi autori
hanno studiato le aspettative negative le quali sono state evidenziate
come un meccanismo chiave nel mantenimento e nella reiterazione della
depressione. <span class="citation"><a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">Zetsche, Bürkner, &amp; Renneberg</a> (<a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">2019</a>)</span> hanno valutato le aspettative di
individui depressi circa il loro umore futuro ed si sono chiesti se
queste aspettative fossero accurate oppure distorte negativamente.</p>
<p>In uno degli studi descritti viene esaminato un campione costituito da 30
soggetti con almeno un episodio depressivo maggiore e da 37 controlli
sani. Gli autori hanno misurato il livello depressivo con il <em>Beck
Depression Inventory</em> (BDI-II). Ma qual è la la gravità della
depressione riportata dai soggetti nel campione esaminato da
<span class="citation"><a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">Zetsche, Bürkner, &amp; Renneberg</a> (<a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">2019</a>)</span>?</p>
<p>Dei 67 soggetti considerati, uno non ha completato il BDI-II e quindi abbiamo a disposizione 66 valori del BDI-II.
I dati sono riportati nella tabella [tab:bdi2_values].
Per semplicità i dati sono stati ordinati in
ordine crescente. È chiaro che i dati grezzi sono di difficile lettura.
Poniamoci dunque il problema di creare una rappresentazione sintetica e
comprensibile di questo insieme di valori.</p>
<p>Uno dei modi che ci consentono di effettuare una sintesi dei dati è
quello di generare una <em>distribuzione di frequenze</em>.
Una distribuzione di frequenze è un riepilogo del conteggio della
frequenza con cui le modalità osservate in un insieme di dati si
verificano in un intervallo di valori.</p>
<p>Per creare una distribuzione di frequenze possiamo procedere effettuando
una partizione delle modalità della variabile di interesse in <span class="math inline">\(m\)</span> classi
(denotate con <span class="math inline">\(\Delta_i\)</span>) tra loro disgiunte. In tale partizione, la
classe <span class="math inline">\(i\)</span>-esima coincide con un intervallo di valori aperto a destra
<span class="math inline">\([a_i, b_i)\)</span> o aperto a sinistra <span class="math inline">\((a_i, b_i]\)</span><a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>. Ad ogni classe
<span class="math inline">\(\Delta_i\)</span> avente <span class="math inline">\(a_i\)</span> e <span class="math inline">\(b_i\)</span> come limite inferiore e superiore
associamo l’ampiezza <span class="math inline">\(b_i - a_i\)</span> (non necessariamente uguale per ogni
classe) e il valore centrale <span class="math inline">\(\bar{x}_i\)</span>. La scelta delle classi è
arbitraria, ma è buona norma non definire classi con un numero troppo
piccolo (&lt; 5) di osservazioni. Poiché ogni elemento dell’insieme
<span class="math inline">\(\{x_i\}_{i=1}^n\)</span> appartiene ad una ed una sola classe <span class="math inline">\(\Delta_i\)</span>,
possiamo calcolare le quantità elencate di seguito.</p>
<ul>
<li><p>La <strong>frequenza assoluta</strong> <span class="math inline">\(n_i\)</span> di ciascuna classe, ovvero il numero di osservazioni che ricadono nella classe <span class="math inline">\(\Delta_i\)</span>.
Proprietà: <span class="math inline">\(n_1 + n_2 + \dots + n_m = n\)</span>.</p></li>
<li><p>La <strong>frequenza relativa</strong> <span class="math inline">\(f_i = n_i/n\)</span> di ciascuna classe. Proprietà: <span class="math inline">\(f_1+f_2+\dots+f_m =1\)</span>.</p></li>
<li><p>La <strong>frequenza cumulata</strong> <span class="math inline">\(N_i\)</span>, ovvero il numero totale delle osservazioni che ricadono nelle classi fino alla <span class="math inline">\(i\)</span>-esima compresa: <span class="math inline">\(N_i = \sum_{i=1}^m n_i.\)</span></p></li>
<li><p>La <strong>frequenza cumulata relativa</strong> <span class="math inline">\(F_i\)</span>, ovvero
<span class="math inline">\(F_i = f_1+f_2+\dots+f_m = \frac{N_i}{n} = \frac{1}{n} \sum_{i=1}^m f_i.\)</span></p></li>
</ul>
<p>Calcoliamo ora la distribuzione di frequenza assoluta e la distribuzione di frequenza relativa per i valori del BDI-II del campione clinico di <span class="citation"><a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">Zetsche, Bürkner, &amp; Renneberg</a> (<a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">2019</a>)</span>.
Per costruire una distribuzione di frequenza è innanzitutto necessario scegliere gli
intervalli delle classi. Facendo riferimento ai cut-off usati per l’interpretazione del BDI-II, definiamo i seguenti <strong>intervalli aperti a destra</strong>:</p>
<ul>
<li>depressione minima: [0, 13.5),</li>
<li>depressione lieve: [13.5, 19.5),</li>
<li>depressione moderata: [19.5, 28.5),</li>
<li>depressione severa: [28.5, 63).</li>
</ul>
<p>La distribuzione di frequenza della variabile <code>bdi2</code> è riportata nella
tabella seguente. Questa distribuzione di frequenza ci aiuta a capire meglio cosa sta succedendo. Se consideriamo la frequenza relativa, ad esempio, possiamo notare che ci sono due valori maggiormente ricorrenti e tali valori corrispondono alle due classi più estreme. Questo ha senso nel caso presente, in quanto il campione esaminato da <span class="citation"><a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">Zetsche, Bürkner, &amp; Renneberg</a> (<a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">2019</a>)</span> includeva due gruppi di
soggetti: soggetti sani (con valori BDI-II bassi) e soggetti depressi
(con valori BDI-II alti). In una distribuzione di frequenza tali valori
tipici vanno sotto il nome di <strong>mode</strong> della distribuzione.</p>
<table>
<thead>
<tr class="header">
<th align="center">Limiti delle classi</th>
<th align="center">Freq. ass.</th>
<th align="center">Freq. rel.</th>
<th align="center">Freq. ass. cum.</th>
<th align="center">Freq. rel. cum.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\([0, 13.5)\)</span></td>
<td align="center">36</td>
<td align="center">36/66</td>
<td align="center">36</td>
<td align="center">36/66</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\([13.5, 19.5)\)</span></td>
<td align="center">1</td>
<td align="center">1/66</td>
<td align="center">37</td>
<td align="center">37/66</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\([19.5, 28.5)\)</span></td>
<td align="center">12</td>
<td align="center">12/66</td>
<td align="center">49</td>
<td align="center">49/66</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\([28.5, 63)\)</span></td>
<td align="center">17</td>
<td align="center">17/66</td>
<td align="center">66</td>
<td align="center">66/66</td>
</tr>
</tbody>
</table>
<div id="esercizio-con-r" class="section level3" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Esercizio con R</h3>
<p>Poniamoci ora il problema di costruire la tabella precedente partendo dai dati grezzi messi a disposizione da <span class="citation"><a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">Zetsche, Bürkner, &amp; Renneberg</a> (<a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">2019</a>)</span>. Iniziamo a caricare i pacchetti che ci servono.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="chapter-descriptive-stats.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>(<span class="fu">library</span>(<span class="st">&quot;here&quot;</span>))</span>
<span id="cb1-2"><a href="chapter-descriptive-stats.html#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>(<span class="fu">library</span>(<span class="st">&quot;tidyverse&quot;</span>))</span>
<span id="cb1-3"><a href="chapter-descriptive-stats.html#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>(<span class="fu">library</span>(<span class="st">&quot;car&quot;</span>))</span></code></pre></div>
<p>Leggiamo i dati.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="chapter-descriptive-stats.html#cb2-1" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(</span>
<span id="cb2-2"><a href="chapter-descriptive-stats.html#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">here</span>(<span class="st">&quot;data&quot;</span>, <span class="st">&quot;data.mood.csv&quot;</span>), </span>
<span id="cb2-3"><a href="chapter-descriptive-stats.html#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">header=</span><span class="cn">TRUE</span></span>
<span id="cb2-4"><a href="chapter-descriptive-stats.html#cb2-4" aria-hidden="true" tabindex="-1"></a>) </span></code></pre></div>
<p>C’è un solo valore di depressione per ciascun soggetto ma tale valore viene ripetuto tante volte quante volte sono le righe del data.frame associate ad ogni soggetto (ciascuna riga corrispondente ad una prova diversa). È dunque necessario trasformare il data.frame in modo tale da avere un’unica riga per ciascun soggetto, ovvero un unico valore BDI-II per soggetto.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="chapter-descriptive-stats.html#cb3-1" aria-hidden="true" tabindex="-1"></a>bysubj <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span> </span>
<span id="cb3-2"><a href="chapter-descriptive-stats.html#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(esm_id) <span class="sc">%&gt;%</span> </span>
<span id="cb3-3"><a href="chapter-descriptive-stats.html#cb3-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(</span>
<span id="cb3-4"><a href="chapter-descriptive-stats.html#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">bdi =</span> <span class="fu">mean</span>(bdi)</span>
<span id="cb3-5"><a href="chapter-descriptive-stats.html#cb3-5" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb3-6"><a href="chapter-descriptive-stats.html#cb3-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">na.omit</span>()</span>
<span id="cb3-7"><a href="chapter-descriptive-stats.html#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; `summarise()` ungrouping output (override with `.groups` argument)</span></span></code></pre></div>
<p>Ci sono dunque 66 soggetti i quali hanno ottenuto i valori sulla scala del BDI-II stampati di seguito (li mostriamo ordinati dal più piccolo al più grande).</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="chapter-descriptive-stats.html#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sort</span>(bysubj<span class="sc">$</span>bdi)</span>
<span id="cb4-2"><a href="chapter-descriptive-stats.html#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  2</span></span>
<span id="cb4-3"><a href="chapter-descriptive-stats.html#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [27]  2  2  2  3  3  3  5  7  9 12 19 22 22 24 25 25 26 26 26 27 27 28 28 30 30 30</span></span>
<span id="cb4-4"><a href="chapter-descriptive-stats.html#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [53] 31 31 33 33 34 35 35 35 36 39 41 43 43 44</span></span></code></pre></div>
<p>Calcoliamo ora le frequenze assolute per i seguenti intervalli aperti a destra: [0, 13.5), [13.5, 19.5), [19.5, 28.5), [28.5, 63). Esaminando i dati, vediamo che 36 soggetti cadono nella prima classe. Dobbiamo però eseguire quest’operazione di conteggio utilizzando R.</p>
<p>Uno dei modi possibili per calcolare le frequenze assolute è quello di usare la funzione <code>cut()</code>. Mediante tal funzione è possibile dividere il <em>campo di variazione</em> (ovvero, la differenza tra il valore massimo di una distribuzione ed il valore minimo) di una variabile continua <code>x</code> in intervalli e codificare ciascun valore <code>x</code> nei termini dell’intervallo a cui appartiene. Tale risultato si ottiene nel modo seguente.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="chapter-descriptive-stats.html#cb5-1" aria-hidden="true" tabindex="-1"></a>bysubj<span class="sc">$</span>bdi_level <span class="ot">&lt;-</span> <span class="fu">cut</span>(</span>
<span id="cb5-2"><a href="chapter-descriptive-stats.html#cb5-2" aria-hidden="true" tabindex="-1"></a>  bysubj<span class="sc">$</span>bdi,</span>
<span id="cb5-3"><a href="chapter-descriptive-stats.html#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">breaks =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">13.5</span>, <span class="fl">19.5</span>, <span class="fl">28.5</span>, <span class="dv">63</span>),</span>
<span id="cb5-4"><a href="chapter-descriptive-stats.html#cb5-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">include.lowest =</span> <span class="cn">TRUE</span>,</span>
<span id="cb5-5"><a href="chapter-descriptive-stats.html#cb5-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">labels =</span> <span class="fu">c</span>(</span>
<span id="cb5-6"><a href="chapter-descriptive-stats.html#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;minimal&quot;</span>, <span class="st">&quot;mild&quot;</span>, <span class="st">&quot;moderate&quot;</span>, <span class="st">&quot;severe&quot;</span></span>
<span id="cb5-7"><a href="chapter-descriptive-stats.html#cb5-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb5-8"><a href="chapter-descriptive-stats.html#cb5-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-9"><a href="chapter-descriptive-stats.html#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="chapter-descriptive-stats.html#cb5-10" aria-hidden="true" tabindex="-1"></a>bysubj<span class="sc">$</span>bdi_level</span>
<span id="cb5-11"><a href="chapter-descriptive-stats.html#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] moderate severe   severe   moderate severe   severe   severe   severe  </span></span>
<span id="cb5-12"><a href="chapter-descriptive-stats.html#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [9] moderate severe   moderate mild     severe   minimal  minimal  minimal </span></span>
<span id="cb5-13"><a href="chapter-descriptive-stats.html#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [17] severe   moderate minimal  minimal  minimal  minimal  minimal  moderate</span></span>
<span id="cb5-14"><a href="chapter-descriptive-stats.html#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [25] minimal  minimal  minimal  minimal  minimal  minimal  minimal  severe  </span></span>
<span id="cb5-15"><a href="chapter-descriptive-stats.html#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [33] minimal  minimal  severe   minimal  moderate minimal  minimal  minimal </span></span>
<span id="cb5-16"><a href="chapter-descriptive-stats.html#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [41] severe   minimal  minimal  severe   severe   moderate severe   severe  </span></span>
<span id="cb5-17"><a href="chapter-descriptive-stats.html#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [49] minimal  moderate minimal  moderate severe   moderate moderate minimal </span></span>
<span id="cb5-18"><a href="chapter-descriptive-stats.html#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [57] minimal  minimal  minimal  minimal  minimal  minimal  minimal  minimal </span></span>
<span id="cb5-19"><a href="chapter-descriptive-stats.html#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [65] minimal  minimal </span></span>
<span id="cb5-20"><a href="chapter-descriptive-stats.html#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Levels: minimal mild moderate severe</span></span></code></pre></div>
<p>Possiamo ora usare la funzione <code>table()</code> la quale ritorna un elenco che associa la frequenza assoluta a ciascuna modalità della variabile in input – ovvero, la distribuzione di frequenza assoluta.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="chapter-descriptive-stats.html#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(bysubj<span class="sc">$</span>bdi_level)</span>
<span id="cb6-2"><a href="chapter-descriptive-stats.html#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb6-3"><a href="chapter-descriptive-stats.html#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  minimal     mild moderate   severe </span></span>
<span id="cb6-4"><a href="chapter-descriptive-stats.html#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       36        1       12       17</span></span></code></pre></div>
<p>Per ottenere la distribuzione di frequenza relativa è sufficiente dividere ciascuna frequenza assoluta per il numero totale di osservazioni:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="chapter-descriptive-stats.html#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(bysubj<span class="sc">$</span>bdi_level) <span class="sc">/</span> <span class="fu">sum</span>(<span class="fu">table</span>(bysubj<span class="sc">$</span>bdi_level))</span>
<span id="cb7-2"><a href="chapter-descriptive-stats.html#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb7-3"><a href="chapter-descriptive-stats.html#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    minimal       mild   moderate     severe </span></span>
<span id="cb7-4"><a href="chapter-descriptive-stats.html#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 0.54545455 0.01515152 0.18181818 0.25757576</span></span></code></pre></div>
<p>In questo modo abbiamo ottenuto le distribuzioni di frequenza assoluta e relativa per i valori del BDI-II dei soggetti di <span class="citation"><a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">Zetsche, Bürkner, &amp; Renneberg</a> (<a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">2019</a>)</span>:</p>
<table>
<thead>
<tr class="header">
<th>Limiti delle classi</th>
<th>Frequenza assoluta</th>
<th>Frequenza relativa</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>[0, 13.5)</td>
<td>36</td>
<td>36/66</td>
</tr>
<tr class="even">
<td>[13.5, 19.5)</td>
<td>1</td>
<td>1/66</td>
</tr>
<tr class="odd">
<td>[19.5, 28.5)</td>
<td>12</td>
<td>12/66</td>
</tr>
<tr class="even">
<td>[28.5, 63]</td>
<td>17</td>
<td>17/66</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="istogramma" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Istogramma</h2>
<p>I dati che sono stati sintetizzati in una distribuzione di frequenze
possono essere rappresentati graficamente in un istogramma.
Un istogramma si costruisce riportando sulle ascisse i limiti delle
classi <span class="math inline">\(\Delta_i\)</span> e sulle ordinate i valori della funzione costante a
tratti
<span class="math display">\[\varphi_n(x)= \frac{f_i}{b_i-a_i}, \quad x\in \Delta_i,\, i=1, \dots, m\]</span>
che misura la <strong>densità della frequenza relativa</strong> della variabile <span class="math inline">\(X\)</span>
nella classe <span class="math inline">\(\Delta_i\)</span>, ovvero il rapporto fra la frequenza relativa
<span class="math inline">\(f_i\)</span> e l’ampiezza (<span class="math inline">\(b_i - a_i\)</span>) della classe. In questo modo il
rettangolo dell’istogramma associato alla classe <span class="math inline">\(\Delta_i\)</span> avrà un’area
proporzionale alla frequenza relativa <span class="math inline">\(f_i\)</span>. Si noti che l’area totale
dell’istogramma delle frequenze relative è data della somma delle aree
dei singoli rettangoli e quindi vale 1.0.</p>
<div id="esercizio-con-r-1" class="section level3" number="3.3.1">
<h3><span class="header-section-number">3.3.1</span> Esercizio con R</h3>
<p>Poniamoci il problema di costruire un istogramma per i dati del BDI-II.
Nell’istogramma viene rappresentata la frequenza relativa delle classi: l’area di ogni barra dell’istogramma è proporzionale alla frequenza relativa della classe che la barra rappresenta.
Come si trova l’altezza delle barre dell’istogramma? Per la classe [0, 13.5), ad esempio, la frequenza relativa è 36/66. Tale valore corrisponde all’<strong>area</strong> del rettangolo. Dato che la base del rettangolo è 13.5, l’altezza sarà 36/66 / 13.5, ovvero {r 36/66 / 13.5}. E così via per le altre barre dell’istogramma.</p>
<p>Una rappresentazione grafica dell’istogramma delle frequenze relative si può ottenere con R utilizzando le funzioni di <code>ggplot2</code>.
Il pacchetto <code>ggplot2</code> è un potente strumento per rappresentare graficamente i dati. Le iniziali del nome, <code>gg</code>, si riferiscono alla ‘’Grammar of Graphics’’, che è un modo di pensare le figure come una serie di layer stratificati. Originariamente descritta da Leland Wilkinson, la grammatica dei grafici è stata aggiornata e applicata in R da Hadley Wickham, il creatore del pacchetto. Per chiarezza, precisiamo che la funzione <code>ggplot()</code> utilizza intervalli aperti a destra.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="chapter-descriptive-stats.html#cb8-1" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> bysubj <span class="sc">%&gt;%</span></span>
<span id="cb8-2"><a href="chapter-descriptive-stats.html#cb8-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> bdi)) <span class="sc">+</span></span>
<span id="cb8-3"><a href="chapter-descriptive-stats.html#cb8-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(</span>
<span id="cb8-4"><a href="chapter-descriptive-stats.html#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">y =</span> ..density..),</span>
<span id="cb8-5"><a href="chapter-descriptive-stats.html#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">breaks =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">13.5</span>, <span class="fl">19.5</span>, <span class="fl">28.5</span>, <span class="fl">44.1</span>) <span class="co"># il valore BDI-II massimo è 44</span></span>
<span id="cb8-6"><a href="chapter-descriptive-stats.html#cb8-6" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb8-7"><a href="chapter-descriptive-stats.html#cb8-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">13.5</span>, <span class="fl">19.5</span>, <span class="fl">28.5</span>, <span class="fl">44.1</span>)) <span class="sc">+</span></span>
<span id="cb8-8"><a href="chapter-descriptive-stats.html#cb8-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb8-9"><a href="chapter-descriptive-stats.html#cb8-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;BDI-II&quot;</span>,</span>
<span id="cb8-10"><a href="chapter-descriptive-stats.html#cb8-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Densità di frequenza&quot;</span></span>
<span id="cb8-11"><a href="chapter-descriptive-stats.html#cb8-11" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb8-12"><a href="chapter-descriptive-stats.html#cb8-12" aria-hidden="true" tabindex="-1"></a>p1</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:hist1zetsche"></span>
<img src="Psicometria_files/figure-html/hist1zetsche-1.png" alt="Istogramma per i valori BDI-II riportati da @zetsche_future_2019." width="70%" />
<p class="caption">
Figura 3.1: Istogramma per i valori BDI-II riportati da <span class="citation"><a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">Zetsche, Bürkner, &amp; Renneberg</a> (<a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">2019</a>)</span>.
</p>
</div>
<p>Con i quattro intervalli individuati dai cut-off del BDI-II otteniamo la
rappresentazione riportata nella figura <a href="chapter-descriptive-stats.html#fig:hist1zetsche">3.1</a>. Nel caso della prima barra dell’istogramma a sinistra, l’ampiezza dell’intervallo è pari a 13.5 e
l’area della barra (ovvero, la frequenza relativa) è uguale a 36/66.
Dunque l’altezza della barra è uguale a (36 / 66) / 13.5 = 0.040. Lo
stesso procedimento si applica per il calcolo dell’altezza degli altri
rettangoli.</p>
<p>Anche se nel caso presente è sensato usare ampiezze diverse per gli intervalli delle classi, in generale gli istogrammi si costruiscono utilizzando intervalli riportati sulle ascisse con un’ampiezza uguale.
Questo è il caso dell’istogramma seguente il quale è stato generato a partire dagli stessi dati.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="chapter-descriptive-stats.html#cb9-1" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> bysubj <span class="sc">%&gt;%</span></span>
<span id="cb9-2"><a href="chapter-descriptive-stats.html#cb9-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> bdi)) <span class="sc">+</span></span>
<span id="cb9-3"><a href="chapter-descriptive-stats.html#cb9-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(</span>
<span id="cb9-4"><a href="chapter-descriptive-stats.html#cb9-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">y =</span> ..density..),</span>
<span id="cb9-5"><a href="chapter-descriptive-stats.html#cb9-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="fl">44.1</span>, <span class="at">length.out =</span> <span class="dv">7</span>)</span>
<span id="cb9-6"><a href="chapter-descriptive-stats.html#cb9-6" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb9-7"><a href="chapter-descriptive-stats.html#cb9-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks=</span><span class="fu">c</span>(<span class="fl">0.00</span>,  <span class="fl">7.35</span>, <span class="fl">14.70</span>, <span class="fl">22.05</span>, <span class="fl">29.40</span>, <span class="fl">36.75</span>, <span class="fl">44.10</span>)) <span class="sc">+</span></span>
<span id="cb9-8"><a href="chapter-descriptive-stats.html#cb9-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb9-9"><a href="chapter-descriptive-stats.html#cb9-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;BDI-II&quot;</span>,</span>
<span id="cb9-10"><a href="chapter-descriptive-stats.html#cb9-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Densità di frequanza&quot;</span></span>
<span id="cb9-11"><a href="chapter-descriptive-stats.html#cb9-11" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb9-12"><a href="chapter-descriptive-stats.html#cb9-12" aria-hidden="true" tabindex="-1"></a>p2</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:hist2zetsche"></span>
<img src="Psicometria_files/figure-html/hist2zetsche-1.png" alt="Una rappresentazione più comune per l'istogramma dei valori BDI-II di @zetsche_future_2019 nella quale gli intervalli delle classi hanno ampiezze uguali." width="70%" />
<p class="caption">
Figura 3.2: Una rappresentazione più comune per l’istogramma dei valori BDI-II di <span class="citation"><a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">Zetsche, Bürkner, &amp; Renneberg</a> (<a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">2019</a>)</span> nella quale gli intervalli delle classi hanno ampiezze uguali.
</p>
</div>
</div>
</div>
<div id="funzione-di-densità-empirica" class="section level2" number="3.4">
<h2><span class="header-section-number">3.4</span> Funzione di densità empirica</h2>
<p>Il confronto tra le figure <a href="chapter-descriptive-stats.html#fig:hist1zetsche">3.1</a> e <a href="chapter-descriptive-stats.html#fig:hist2zetsche">3.2</a> rende chiaro un limite degli istogrammi. È infatti ovvio che il profilo dell’istogramma è arbitrario: a seconda del numero e dei limiti delle classi che vengono scelte,
cambiano sia il numero che la forma delle barre dell’istogramma. Questo rende difficile fornire un’interpretazione alle informazioni fornite da un istogramma.</p>
<p>Il problema precedente può essere alleviato utilizzando una
rappresentazione alternativa della distribuzione di frequenza, ovvero la
stima della densità della frequenza dei dati (detta anche stima <em>kernel
di densità</em>). Un modo semplice per pensare a tale rappresentazione, che
in inglese va sotto il nome di <em>density plot</em>, è quello di immaginare un
grande campione di dati, in modo che diventi possibile definire un
enorme numero di classi di equivalenza di ampiezza molto piccola, le
quali non risultino vuote. In tali circostanze, la funzione di densità
empirica non è altro che il profilo <em>lisciato</em> dell’istogramma. La
stessa idea si applica anche quando il campione è più piccolo.</p>
<div id="esercizio-con-r-2" class="section level3" number="3.4.1">
<h3><span class="header-section-number">3.4.1</span> Esercizio con R</h3>
<p>Nel caso dei dati del BDI-II otteniamo la reppresentazione fornita dalla figura seguente.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="chapter-descriptive-stats.html#cb10-1" aria-hidden="true" tabindex="-1"></a>p3 <span class="ot">&lt;-</span> bysubj <span class="sc">%&gt;%</span> </span>
<span id="cb10-2"><a href="chapter-descriptive-stats.html#cb10-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> bdi)) <span class="sc">+</span></span>
<span id="cb10-3"><a href="chapter-descriptive-stats.html#cb10-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(</span>
<span id="cb10-4"><a href="chapter-descriptive-stats.html#cb10-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">y =</span> ..density..), </span>
<span id="cb10-5"><a href="chapter-descriptive-stats.html#cb10-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="fl">44.1</span>, <span class="at">length.out =</span> <span class="dv">7</span>)</span>
<span id="cb10-6"><a href="chapter-descriptive-stats.html#cb10-6" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb10-7"><a href="chapter-descriptive-stats.html#cb10-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(</span>
<span id="cb10-8"><a href="chapter-descriptive-stats.html#cb10-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">x =</span> bdi), </span>
<span id="cb10-9"><a href="chapter-descriptive-stats.html#cb10-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">adjust =</span> <span class="fl">0.5</span>, </span>
<span id="cb10-10"><a href="chapter-descriptive-stats.html#cb10-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">size =</span> <span class="fl">0.8</span>, </span>
<span id="cb10-11"><a href="chapter-descriptive-stats.html#cb10-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">&quot;steelblue3&quot;</span>, </span>
<span id="cb10-12"><a href="chapter-descriptive-stats.html#cb10-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> <span class="fl">0.5</span></span>
<span id="cb10-13"><a href="chapter-descriptive-stats.html#cb10-13" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb10-14"><a href="chapter-descriptive-stats.html#cb10-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb10-15"><a href="chapter-descriptive-stats.html#cb10-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;BDI-II&quot;</span>,</span>
<span id="cb10-16"><a href="chapter-descriptive-stats.html#cb10-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Densità di frequenza&quot;</span></span>
<span id="cb10-17"><a href="chapter-descriptive-stats.html#cb10-17" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb10-18"><a href="chapter-descriptive-stats.html#cb10-18" aria-hidden="true" tabindex="-1"></a>p3</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:zetschehist3"></span>
<img src="Psicometria_files/figure-html/zetschehist3-1.png" alt="Funzione di densità empirica per i valori BDI-II di @zetsche_future_2019." width="70%" />
<p class="caption">
Figura 3.3: Funzione di densità empirica per i valori BDI-II di <span class="citation"><a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">Zetsche, Bürkner, &amp; Renneberg</a> (<a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">2019</a>)</span>.
</p>
</div>
<p>Che interpretazione possiamo attribuire alla funzione di densità empirica rappresentata nella figura <a href="chapter-descriptive-stats.html#fig:zetschehist3">3.3</a>?
La interpretiamo come abbiamo fatto con gli istogrammi: l’area sottesa al grafico della funzione di densità empirica in un certo intervallo rappresenta la proporzione dei casi della distribuzione che hanno valori compresi nell’intervallo considerato.</p>
</div>
</div>
<div id="forma-di-una-distribuzione" class="section level2" number="3.5">
<h2><span class="header-section-number">3.5</span> Forma di una distribuzione</h2>
<p>In generale, la forma di una distribuzione descrive come i dati si
distribuiscono intorno ai valori centrali. Distinguiamo tra
distribuzioni simmetriche e asimmetriche, e tra distribuzioni unimodali
o multimodali. Un’illustrazione grafica è fornita nella
figura seguente.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-15"></span>
<img src="Psicometria_files/figure-html/unnamed-chunk-15-1.png" alt="1: Asimmetria negativa. 2: Asimmetria positiva. 3: Distribuzione unimodale. 4: Distribuzione bimodale." width="70%" />
<p class="caption">
Figura 3.4: 1: Asimmetria negativa. 2: Asimmetria positiva. 3: Distribuzione unimodale. 4: Distribuzione bimodale.
</p>
</div>
<p>Nel pannello 1 la distribuzione è unimodadle con asimmetria negativa; nel pannello 2 la distribuzione è unimodadle con asimmetria positiva; nel pannello 3 la distribuzione è simmetrica e unimodale; nel pannello 4 la distribuzione è bimodale.</p>
<p>Se consideriamo nuovamente la figura <a href="chapter-descriptive-stats.html#fig:zetschehist3">3.3</a> possiamo dire che la distribuzione dei valori del BDI-II nel campione considerato da <span class="citation"><a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">Zetsche, Bürkner, &amp; Renneberg</a> (<a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">2019</a>)</span> è bimodale.</p>
</div>
<div id="indici-di-posizione" class="section level2" number="3.6">
<h2><span class="header-section-number">3.6</span> Indici di posizione</h2>
<div id="quantili" class="section level3" number="3.6.1">
<h3><span class="header-section-number">3.6.1</span> Quantili</h3>
<p>La descrizione della distribuzione dei valori BDI-II di
<span class="citation"><a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">Zetsche, Bürkner, &amp; Renneberg</a> (<a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">2019</a>)</span> può essere facilitata dalla determinazione di
alcuni valori caratteristici che sintetizzano le informazioni contenute
nella distribuzione di frequenze. Si dicono <em>quantili</em> (o <em>frattili</em>)
quei valori caratteristici che hanno le seguenti proprietà. I <em>quartili</em>
sono quei valori che ripartiscono i dati <span class="math inline">\(x_i\)</span> in quattro parti
ugualmente numerose (pari ciascuna al 25% del totale). Il primo
quartile, <span class="math inline">\(q_1\)</span>, lascia alla sua sinistra il 25% del campione pensato
come una fila ordinata (a destra quindi il 75%). Il secondo quartile
<span class="math inline">\(q_2\)</span> lascia a sinistra il 50% del campione (a destra quindi il 50%).
Esso viene anche chiamato <em>mediana</em>. Il terzo quartile lascia a sinistra
il 75% del campione (a destra quindi il 25%). Secondo lo stesso
criterio, si dicono <em>decili</em> i quantili di ordine <span class="math inline">\(p\)</span> multiplo di 0.10 e
<em>percentili</em> i quantili di ordine <span class="math inline">\(p\)</span> multiplo di 0.01.</p>
<p>Come si calcolano i quantili? Consideriamo la definizione di quantile
<em>non interpolato</em> di ordine <span class="math inline">\(p\)</span> <span class="math inline">\((0 &lt; p &lt; 1)\)</span>. Si procede innanzitutto
ordinando i dati in ordine crescente, <span class="math inline">\(\{x_1, x_2, \dots, x_n\}\)</span>. Ci
sono poi due possibilità. Se il valore <span class="math inline">\(np\)</span> non è intero, sia <span class="math inline">\(k\)</span>
l’intero tale che <span class="math inline">\(k &lt; np &lt; k + 1\)</span> – ovvero, la parte intera di <span class="math inline">\(np\)</span>.
Allora <span class="math inline">\(q_p = x_{k+1}.\)</span> Se <span class="math inline">\(np = k\)</span> con <span class="math inline">\(k\)</span> intero, allora
<span class="math inline">\(q_p = \frac{1}{2}(x_{k} + x_{k+1}).\)</span> Se vogliamo calcolare il primo
quartile <span class="math inline">\(q_1\)</span>, ad esempio, utilizziamo <span class="math inline">\(p = 0.25\)</span>. Dovendo calcolare
gli altri quantili basta sostituire a <span class="math inline">\(p\)</span> il valore appropriato<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>.</p>
<p>Gli indici di posizione, tra le altre cose, hanno un ruolo importante,
ovvero vengono utilizzati per creare una rappresentazione grafica di una
distribuzione di valori che è molto popolare e può essere usata in
alternativa ad un istogramma (in realtà vedremo poi come possa essere
combinata con un istogramma). Tale rappresentazione va sotto il nome di
box-plot.</p>
<p>Per fare un esempio, consideriamo i nove soggetti del campione clinico di <span class="citation"><a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">Zetsche, Bürkner, &amp; Renneberg</a> (<a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">2019</a>)</span> che hanno riportato un unico episodio di depressione maggiore. Per tali soggetti i valori ordinati del BDI-II (per semplicità li chiameremo <span class="math inline">\(x\)</span>) sono i seguenti: 19, 26, 27, 28, 28, 33, 33, 41, 43.
Per il calcolo del secondo quartile (non interpolato), ovvero per il calcolo della mediana, dobbiamo considerare la quantità <span class="math inline">\(np = 9 \cdot 0.5 = 4.5\)</span>, non intero. Quindi, <span class="math inline">\(q_1 = x_{4 + 1} = 27\)</span>.
Per il calcolo del quantile (non interpolato) di ordine <span class="math inline">\(p = 2/3\)</span> dobbiamo considerare la quantità <span class="math inline">\(np = 9 \cdot 2/3 = 6\)</span>, intero. Quindi, <span class="math inline">\(q_{\frac{2}{3}} = \frac{1}{2} (x_{6} + x_{7}) = \frac{1}{2} (33 + 33) = 33\)</span>.</p>
</div>
<div id="box-plot" class="section level3" number="3.6.2">
<h3><span class="header-section-number">3.6.2</span> Box-plot</h3>
<p>Il <em>box-plot</em> (o diagramma a scatola) è uno strumento grafico utile al
fine di ottenere informazioni circa la dispersione e l’eventuale
simmetria o asimmetria di una distribuzione. Per costruire un box-plot
si rappresenta sul piano cartesiano un rettangolo (cioè la “scatola”) di
altezza arbitraria la cui base corrisponde alla dist intanza
interquartile (IQR = <span class="math inline">\(q_{0.75} - q_{0.25}\)</span>). La linea interna alla
scatola rappresenta la mediana <span class="math inline">\(q_{0.5}\)</span>. Si tracciano poi ai lati della
scatola due segmenti di retta i cui estremi sono detti “valore
adiacente” inferiore e superiore. Il valore adiacente inferiore è il
valore più piccolo tra le osservazioni che risulta maggiore o uguale al
primo quartile meno la distanza corrispondente a 1.5 volte la distanza
interquartile (si veda la
figura <a href="#fig:boxplot" reference-type="ref" reference="fig:boxplot"><span class="math display">\[fig:boxplot\]</span></a>). Il valore adiacente superiore è il valore più
grande tra le osservazioni che risulta minore o uguale a <span class="math inline">\(Q_3+1.5\)</span> IQR.
I valori esterni ai valori adiacenti (chiamati <em>valori anomali</em>) vengono
rappresentati individualmente nel box-plot per meglio evidenziarne la
presenza e la posizione.</p>
<p>Consideriamo ora un caso concreto nel quale viene utilizzato un
box-plot. Nel caso dei dati di <span class="citation"><a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">Zetsche, Bürkner, &amp; Renneberg</a> (<a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">2019</a>)</span> riportati nella
tabella <a href="#tab:Zetsche2020" reference-type="ref" reference="tab:Zetsche2020">1.1</a> ci chiediamo in che modo si differenziano
le distribuzioni del BDI-II tra i due gruppi considerati, ovvero tra il
gruppo dei pazienti e il gruppo di controllo. La
figura <a href="chapter-descriptive-stats.html#fig:Zetsche_violin_plot" reference-type="ref" reference="fig:Zetsche_violin_plot">1.3</a> ci fornisce due rappresentazioni
grafiche possibili che possono essere utilizzate per rispondere a questa
domanda.</p>
<div class="figure">
<embed src="Zetsche_violin_plot.pdf" id="fig:Zetsche_violin_plot" />
<p class="caption">Due versioni di un “violin plot” dei valori BDI-II per ciascun gruppo
specificato nella tabella <a href="#tab:Zetsche2020" reference-type="ref" reference="tab:Zetsche2020">1.1</a>.</p>
</div>
<p>Nella figura <a href="chapter-descriptive-stats.html#fig:Zetsche_violin_plot" reference-type="ref" reference="fig:Zetsche_violin_plot">1.3</a> sinistra sono rappresentati i dati
grezzi: questa è la pratica migliore quando il numero di osservazioni è
piccolo. La linea curva che circonda (simmetricamente) le osservazioni è
l’“istogramma lisciato” che abbiamo descritto in precedenza. Nella
figura <a href="chapter-descriptive-stats.html#fig:Zetsche_violin_plot" reference-type="ref" reference="fig:Zetsche_violin_plot">1.3</a> destra sono rappresentanti gli
stessi dati: la funzione di densità empirica è la stessa di prima, ma al
suo interno viene collocato un box-plot. Questa seconda rappresentazione
è da preferirsi quando ci sono molte osservazioni e non è utile
rappresentare singolarmente ciascun dato. Entrambe le rappresentazioni
suggeriscono che la distribuzione dei dati è all’incirca simmetrica nel
gruppo clinico (codificato come “mdd”). Il gruppo di controllo (“ctl”)
mostra invece un’asimmetria positiva, con tre osservazioni evidenziate
nel boxplot come dei “valori anomili,” dato che si discostano dalla
mediana di una quantità maggiore di 1.5 IQR.</p>
</div>
<div id="leccellenza-grafica" class="section level3" number="3.6.3">
<h3><span class="header-section-number">3.6.3</span> L’eccellenza grafica</h3>
<p>Non c’è un modo “corretto” per rappresentare in forma grafica un insieme
di dati. Ciascuno dei grafici che abbiamo discusso ha i suoi pregi e i
suoi difetti. Un ricercatore che ha influenzato molto il modo in cui
viene realizzata la visualizzazione dei dati scientifici è Edward Tufte,
soprannominato dal New York Times il “Leonardo da Vinci dei dati.”
Secondo Tufte, “l’eccellenza nella grafica consiste nel comunicare idee
complesse in modo chiaro, preciso ed efficiente.” Nella visualizzazione
delle informazioni, l’“eccellenza grafica” ha l’obiettivo di comunicare
al lettore il maggior numero di idee nel minor tempo possibile, con meno
inchiostro possibile, usando il minor spazio possibile. Secondo
<span class="citation"><a href="bibliografia.html#ref-tufte_visual_display" role="doc-biblioref">Tufte</a> (<a href="bibliografia.html#ref-tufte_visual_display" role="doc-biblioref">2001</a>)</span>, le rappresentazioni grafiche dovrebbero:</p>
<ol style="list-style-type: decimal">
<li><p>mostrare i dati;</p></li>
<li><p>indurre l’osservatore a riflettere sulla sostanza piuttosto che
sulla progettazione grafica, o qualcos’altro;</p></li>
<li><p>evitare di distorcere quanto i dati stanno comunicando (“integrità
grafica”);</p></li>
<li><p>presentare molte informazioni in forma succinta;</p></li>
<li><p>rivelare la coerenza tra le molte dimensioni dei dati;</p></li>
<li><p>incoraggiare l’osservatore a comparare differenti porzioni di dati;</p></li>
<li><p>rivelare i dati a diversi livelli di dettaglio, da una visione ampia
alla struttura di base;</p></li>
<li><p>servire ad uno scopo preciso (descrizione, esplorazione, o la
risposta a qualche domanda);</p></li>
<li><p>essere fortemente integrate con le descrizioni statistiche e verbali
dei dati fornite nel testo.</p></li>
</ol>
<p>In base a questi principi, la funzione di densità empirica fornisce una
rappresentazione migliore dei dati della
tabella <a href="#tab:Zetsche2020" reference-type="ref" reference="tab:Zetsche2020">1.1</a> di quanto lo faccia un istogramma. Inoltre,
se oltre al grupppo di appartenenza non ci sono altre dimensioni
importanti da mettere in evidenza, allora la nostra scelta dovrebbe
ricadere sul pannello di sinistra della
figura <a href="chapter-descriptive-stats.html#fig:Zetsche_violin_plot" reference-type="ref" reference="fig:Zetsche_violin_plot">1.3</a>.</p>
</div>
</div>
<div id="indici-di-tendenza-centrale" class="section level2" number="3.7">
<h2><span class="header-section-number">3.7</span> Indici di tendenza centrale</h2>
<p>L’analisi grafica, esaminata in precedenza, costituisce la base di
partenza di qualsivoglia analisi quantitativa dei dati. Tramite
l’analisi grafica possiamo capire alcune caratteristiche importanti di
una distribuzione: per esempio, se è simmetrica o asimmetrica; oppure se
è unimodale o multimodale. Successivamente, possiamo calcolare degli
indici numerici che descrivono in modo sintetico le caratteristiche di
base dei dati esaminati. Tra le misure di tendenza centrale, ovvero tra
gli indici che forniscono un’idea dei valori attorno ai quali sono
prevalentemente concentrati i dati di un campione, quella più
comunemente usata è la media.</p>
<div id="media" class="section level3" number="3.7.1">
<h3><span class="header-section-number">3.7.1</span> Media</h3>
<p>Tutti conosciamo la media aritmetica di <span class="math inline">\(\{x_1, x_2, \dots, x_n\}\)</span>,
ovvero il numero reale <span class="math inline">\(\bar{x}\)</span> definito da
<span class="math display">\[\bar{x}=\frac{1}{n}\sum_{i=1}^n x_i.
 \label{eq:media_aritm}\]</span>
Nell’eq. <a href="#eq:media_aritm" reference-type="eqref" reference="eq:media_aritm"><span class="math display">\[eq:media_aritm\]</span></a> abbiamo usato la notazione delle sommatorie
per descrivere una somma di valori. Questa notazione è molto usata in
statistica e viene descritta in Appendice.</p>
<p>La media gode della seguente importante proprietà: la somma degli scarti
tra ciascuna modalità <span class="math inline">\(x_i\)</span> e la media aritmetica <span class="math inline">\(\bar{x}\)</span> è nulla,
cioè <span class="math display">\[\sum_{i=1}^n (x_i - \bar{x}) = 0.\notag
\label{eq:diffmeansumzero}\]</span> Infatti, <span class="math display">\[\begin{aligned}
\sum_{i=1}^n (x_i - \bar{x}) &amp;= \sum_i x_i - \sum_i \bar{x}\notag\\
&amp;= \sum_i x_i - n \bar{x}\notag\\
&amp;= \sum_i x_i - \sum_i x_i = 0.\notag\end{aligned}\]</span> Ciò ci consente di
pensare alla media come al baricentro della distribuzione.</p>
<p>Un’altra proprietà della media è la seguente. La somma dei quadrati
degli scarti tra ciascuna modalità <span class="math inline">\(x_i\)</span> e una costante arbitraria
<span class="math inline">\(a \in \Re\)</span>, cioè <span class="math display">\[\varphi(a) = \sum_{i=1}^n (x_i - a)^2,\notag\]</span> è
minima per <span class="math inline">\(a = \bar{x}\)</span>.</p>
<p>Il concetto statistico di media ha suscitato molte battute. Per esempio,
il fatto che, in media, ciascuno di noi ha un numero di gambe circa pari
a 1.9999999. Oppure, il fatto che, in media, ciascuno di noi ha un
testicolo. Ma la media ha altri problemi, oltre al fatto di ispirare
battute simili alle precedenti. In particolare, dobbiamo notare che la
media non è sempre l’indice che meglio rappresenta la tendenza centrale
di una distribuzione. In particolare, ciò non accade quando la
distribuzione è asimmetrica, o in presenza di valori anomali (<em>outlier</em>)
– si veda il pannello di destra della
figura <a href="chapter-descriptive-stats.html#fig:Zetsche_violin_plot" reference-type="ref" reference="fig:Zetsche_violin_plot">1.3</a>. In tali circostanze, la tendenza
centrale della distribuzione è meglio rappresentata dalla mediana o
dalla media spuntata.</p>
</div>
<div id="media-spuntata" class="section level3" number="3.7.2">
<h3><span class="header-section-number">3.7.2</span> Media spuntata</h3>
<p>La <em>media spuntata</em> <span class="math inline">\(\bar{x}_t\)</span> (<em>trimmed mean</em>) non è altro che la
media dei dati calcolata considerando solo il 90% (o altra percentuale)
dei dati centrali. Per calcolare <span class="math inline">\(\bar{x}_t\)</span> si ordinando i dati secondo
una sequenza crescente, <span class="math inline">\(x_1 \leq x_2 \leq x_3 \leq \dots \leq x_n\)</span>, per
poi eliminare il primo 5% e l’ultimo 5% dei dati della serie così
ordinata. La media spuntata è data dalla media aritmetica
<a href="#eq:media_aritm" reference-type="eqref" reference="eq:media_aritm"><span class="math display">\[eq:media_aritm\]</span></a> dei dati rimanenti.</p>
</div>
<div id="moda-e-mediana" class="section level3" number="3.7.3">
<h3><span class="header-section-number">3.7.3</span> Moda e mediana</h3>
<p>In precedenza abbiamo già incontrato altri due popolari indici di
tendenza centrale: la <em>moda</em> (<em>Mo</em>), ovvero il valore centrale della
classe con la frequenza massima (può succedere che una distribuzione
abbia più mode; in tal caso si dice <em>multimodale</em> e questo operatore
perde il suo significato di indice di tendenza centrale) e la <em>mediana</em>
<span class="math inline">\(\tilde{x}\)</span>.</p>
</div>
</div>
<div id="indici-di-dispersione" class="section level2" number="3.8">
<h2><span class="header-section-number">3.8</span> Indici di dispersione</h2>
<p>Le medie e gli indici di posizione descritti in precedenza forniscono
delle sintesi dei dati che mettono in evidenza la tendenza centrale
delle osservazioni. Tali indici, tuttavia, non considerano un aspetto
importante della distribuzione dei dati, ovvero la variabilità dei
valori numerici della variabile statistica. È dunque necessario
sintetizzare la distribuzione di una variabile statistica oltre che con
le misure di posizione anche tramite l’utilizzo di indicatori che
valutino la dispersione delle unità statistice.</p>
<div id="indici-basati-sullordinamento-dei-dati" class="section level3" number="3.8.1">
<h3><span class="header-section-number">3.8.1</span> Indici basati sull’ordinamento dei dati</h3>
<p>È possibile calcolare degli indici di variabilità basati
sull’ordinamento dei dati. L’indice più ovvio è l’intervallo di
variazione, ovvero la distanza tra il valore massimo e il valore minimo
di una distribuzione di modalità, mentre in precedenza abbiamo già
incontrato la differenza interquartile. Questi due indici, però, hanno
il limite di essere calcolati sulla base di due soli valori della
distribuzione (<span class="math inline">\(x_{\text{max}}\)</span> e <span class="math inline">\(x_{\text{mini}}\)</span>, oppure <span class="math inline">\(x_{0.25}\)</span> e
<span class="math inline">\(x_{0.75}\)</span>). Pertanto non utilizzano tutte le informazioni che sono
disponibili. Inoltre, l’intervallo di variazione ha il limite di essere
pesantemente influenzato dalla presenza di valori anomali.</p>
</div>
<div id="scostamento-medio-semplice-dalla-mediana" class="section level3" number="3.8.2">
<h3><span class="header-section-number">3.8.2</span> Scostamento medio semplice dalla mediana</h3>
<p>Dati i limiti delle statistiche precedenti è più comune misurare la
variabilità di una variabile statistica come la dispersione dei dati
attorno ad un indice di tendenza centrale. Scelto l’indice di tendenza
centrale rispetto al quale si vuole misurare la dispersione, è possibile
poi calcolare la media degli scostamenti dei singoli dati dal valore di
riferimento. Ad esempio, se scegliamo la mediana quale misura di
posizione centrale, è possibile calcolare la media aritmetica della
distribuzione degli scarti in valore assoluto tra ciascuna modalità e la
mediana stessa. Nel caso di una variabile statistica <span class="math inline">\(X\)</span> lo <em>scostamento
medio semplice dalla mediana</em> è la quantità
<span class="math display">\[S_{Me} = \frac{1}{n} \sum_{i=1}^n |x_i - x_{0.5}|.
\label{eq:scostam_medio_sempl}\]</span></p>
</div>
<div id="varianza" class="section level3" number="3.8.3">
<h3><span class="header-section-number">3.8.3</span> Varianza</h3>
<p>Anche se la statistica definita
dall’eq. <a href="#eq:scostam_medio_sempl" reference-type="eqref" reference="eq:scostam_medio_sempl"><span class="math display">\[eq:scostam_medio_sempl\]</span></a> è molto intuitiva, la misura di
variabilità di gran lunga più usata per valutare la variabilità di una
variabile statistica è senza dubbio la varianza. La varianza
<span class="math display">\[s^2 = \frac{1}{n} \sum_{i=1}^n (x_i - \bar{x})^2
\label{eq:var_descr}\]</span> è la media dei quadrati degli scarti
<span class="math inline">\(x_i - \bar{x}\)</span> tra ogni valore e la media della distribuzione. La
varianza è la misura di dispersione più tecnicamente complessa. È
appropriata solo nel caso di distribuzioni simmetriche e, anch’essa, è
fortemente influenzata dai valori anomali. Inoltre, è espressa in
un’unità di misura che è il quadrato dell’unità di misura dei dati
originari e quindi non consente un’interpretazione intuitiva.</p>
</div>
<div id="deviazione-standard" class="section level3" number="3.8.4">
<h3><span class="header-section-number">3.8.4</span> Deviazione standard</h3>
<p>Per tali ragioni la misura più usata della dispersione di una
distribuzione di dati è la <em>deviazione standard</em>, ovvero la radice
quadrata della varianza. A differenza della varianza, dunque, la
deviazione standard è espressa nella stessa unità di misura dei dati.
Come nel caso della varianza, anche la deviazione standard <span class="math inline">\(s\)</span> dovrebbe
essere usata soltanto quando la media è adeguata per misurare il centro
della distribuzione, ovvero, nel caso di distribuzioni simmetriche. Come
nel caso della media <span class="math inline">\(\bar{x}\)</span>, anche la deviazione standard è
fortemente influenzata dai dati anomali (<em>outlier</em>), ovvero dalla
presenza di uno o di pochi dati che sono molto più distanti dalla media
rispetto agli altri valori della distribuzione. Quando tutte le
osservazioni sono uguali, <span class="math inline">\(s=0\)</span>, altrimenti <span class="math inline">\(s &gt; 0\)</span>.</p>
<p>Alla deviazione standard può essere assegnata una semplice
interpretazione: la deviazione standard è <em>simile</em> (anche se non uguale)
alla media del valore assoluto degli scarti di ciascuna osservazione
dalla media. La deviazione standard ci dice, dunque, quanto sono
distanti, in media, le singole osservazioni dal centro della
distribuzione. Nel caso del campione clinico considerato da
<span class="citation"><a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">Zetsche, Bürkner, &amp; Renneberg</a> (<a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">2019</a>)</span>, ciascuna osservazione dista, in media, 5.33 punti
dalla media della distribuzione. Anche se la deviazione standard è pari
a 6.5 e non è uguale a tale valore, facendo un’approssimazione, possiamo
pensare che, all’incirca, essa rappresenti una tale distanza media.</p>
</div>
<div id="indici-di-variabilità-relativi" class="section level3" number="3.8.5">
<h3><span class="header-section-number">3.8.5</span> Indici di variabilità relativi</h3>
<p>A volte può essere interessante effettuare un confronto fra due misure
di variabilità di grandezze incommensurabili, ovvero di caratteri
rilevati mediante differenti unità di misura. In questi casi, le misure
di variabilità precedentemente descritte si rivelano inadeguate in
quanto dipendono dall’unità di misura adottata. Diventa dunque
necessario ricorrere a particolari numeri adimensionali detti indici
relativi di variabilità. Il più importante di tali indici è il
coefficiente di variazione, ovvero il numero puro
<span class="math display">\[C_v = \frac{\sigma}{\bar{x}}\]</span> ottenuto dal rapporto tra la deviazione
standard e la media dei dati. Un altro indice relativo di variabilità è
la differenza interquartile rapportata al primo quartile oppure al terzo
quartile oppure alla mediana, cioè:
<span class="math display">\[\frac{x_{0.75} - x_{0.25}}{x_{0.25}}, \qquad \frac{x_{0.75} - x_{0.25}}{x_{0.75}}, \qquad \frac{x_{0.75} - x_{0.25}}{x_{0.50}}.\notag\]</span></p>
</div>
</div>
<div id="le-relazioni-tra-variabili" class="section level2" number="3.9">
<h2><span class="header-section-number">3.9</span> Le relazioni tra variabili</h2>
<p><span class="citation"><a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">Zetsche, Bürkner, &amp; Renneberg</a> (<a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">2019</a>)</span> hanno misurato il livello di depressione dei
soggetti del loro esperimento utilizzando due scale psicometriche: il
Beck Depression Inventory II (BDI-II) e la Center for Epidemiologic
Studies Depression Scale (CES-D). Il BDI-II è uno strumento self-report
che valutare la presenza e l’intensità di sintomi depressivi in pazienti
adulti e adolescenti di almeno 13 anni di età con diagnosi psichiatrica
mentre la CES-D è una scala self-report progettata per misurare i
sintomi depressivi che sono stati vissuti nella settimana precedente
nella popolazione generale, specialmente quella degli
adolescenti/giovani adulti. La prima domanda ovvia che ci può venire in
mente è: quanto sono simili le misure ottenute mediante queste due
scale?</p>
<p>È chiaro che i numeri prodotti dalle scale BDI-II e CES-D non possono
essere identici, e questo per due motivi: (1) la presenza degli errori
di misurazione e (2) l’unità di misura delle due variabili. L’errore di
misurazione corrompe sempre, almeno in parte, qualunque operazione di
misurazione. E questo è vero specialmente in psicologia dove
l’<em>affidabilità</em> degli strumenti di misurazione è minore che in altre
discipline (quali la fisica, ad esempio). Il secondo motivo per cui i
valori delle scale BDI-II e CES-D non possono essere uguali è che
l’unità di misura delle due scale è arbitraria. Infatti, qual è l’unità
di misura della depressione? Chi può dirlo! Ma, al di là delle
differenze derivanti dall’errore di misurazione e dalla differente unità
di misura, ci aspettiamo che, se le due scale misurano entrambe lo
stesso costrutto<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>, allora i valori prodotti dalle due scale dovranno
essere tra loro <em>linearmente associati</em>. Per capire cosa si intende con
“associazione lineare” iniziamo a guardare i dati. Per fare questo
utilizziamo una rappresentazione grafica che va sotto il nome di
<em>diagramma a dispersione</em>.</p>
<div id="diagramma-a-dispersione" class="section level3" number="3.9.1">
<h3><span class="header-section-number">3.9.1</span> Diagramma a dispersione</h3>
<p>Il diagramma di dispersione è la rappresentazione grafica delle coppie
di punti individuati dalle variabili BDI-II e CES-D, e si ottiene
ponendo, ad esempio, i valori BDI-II sull’asse delle ascisse e quelli
del CES-D sull’asse delle ordinate. In tale grafico, fornito dalla
figura <a href="chapter-descriptive-stats.html#fig:Zetsche_scatterplot" reference-type="ref" reference="fig:Zetsche_scatterplot">1.4</a>, cascun punto corrisponde ad un
individuo del quale, nel caso presente, conosciamo il livello di
depressione misurato dalle due scale psicometriche. A tale grafico sono
state aggiunte le funzioni <em>marginali</em> (ovvero, che si riferiscono a
ciascuna variabile considerata singolarmente) di densità empirica che
abbiamo già incontrato in precedenza.</p>
<div class="figure">
<embed src="Zetsche_scatterplot.pdf" id="fig:Zetsche_scatterplot" style="width:80.0%" />
<p class="caption">Associazione tra le variabili BDI-II e CES-D nel campione esaminato da
<span class="citation"><a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">Zetsche, Bürkner, &amp; Renneberg</a> (<a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">2019</a>)</span>. Ai margini del diagramma a dispersione sono
rappresentate le funzioni di densità empirica delle due
variabili.</p>
</div>
<p>Dalla figura <a href="chapter-descriptive-stats.html#fig:Zetsche_scatterplot" reference-type="ref" reference="fig:Zetsche_scatterplot">1.4</a> possiamo vedere che i dati mostrano
una certa tendenza a disporsi attorno ad una retta – nel gergo
statistico, questo fatto viene espresso dicendo che i punteggi BDI-II
tendono ad essere linearmente associati ai punteggi CES-D. È ovvio,
tuttavia, che tale relazione lineare è lungi dall’essere perfetta – se
fosse perfetta, tutti i punti del diagramma a dispersione si
disporrebbero esattamente lungo una retta.</p>
<p>Il problema che ci poniamo è quello di trovare un indice numerico che
descriva di quanto la nube di punti si discosta da una perfetta
relazione lineare tra le due variabili. Per risolvere tale problema
dobbiamo specificare un indice statistico che descrive la direzione e la
forza della relazione lineare tra le due variabili. Ci sono vari indici
statistici che possiamo utilizzare a questo scopo.</p>
</div>
<div id="covarianza" class="section level3" number="3.9.2">
<h3><span class="header-section-number">3.9.2</span> Covarianza</h3>
<p>Iniziamo a considerare il più importante di tali indici, chiamato
<em>covarianza</em>. In realtà la definizione di questo indice non ci
sorprenderà più di tanto in quanto, in una forma solo apparentemente
diversa, l’abbiamo già incontrato in precedenza. Ci ricordiamo infatti
che la varianza di una generica variabile <span class="math inline">\(X\)</span> è definita come la media
degli scarti quadratici di ciascuna osservazione dalla media:
<span class="math display">\[S_{XX} = \frac{1}{n} \sum_{i=1}^n(X_i - \bar{X}) (X_i - \bar{X}).\]</span>
Infatti, la varianza viene talvolta descritta come la “covarianza di una
variabile con sé stessa.”</p>
<p>Adesso facciamo un passo ulteriore. Invece di valutare la dispersione di
una sola variabile, chiediamoci come due variabili <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> “variano
insieme” (co-variano). È facile capire come una risposta a tale domanda
possa essere fornita da una semplice trasformazione della formula
precedente che diventa:
<span class="math display">\[S_{XY} = \frac{1}{n} \sum_{i=1}^n(X_i - \bar{X}) (Y_i - \bar{Y}).
\label{eq:definition_covariance}\]</span>
L’eq. <a href="#eq:definition_covariance" reference-type="eqref" reference="eq:definition_covariance"><span class="math display">\[eq:definition_covariance\]</span></a> ci fornisce dunque la definizione
della covarianza.</p>
<p>Per capire il significato
dell’eq. <a href="#eq:definition_covariance" reference-type="eqref" reference="eq:definition_covariance"><span class="math display">\[eq:definition_covariance\]</span></a>, supponiamo di dividere il grafico
della figura <a href="chapter-descriptive-stats.html#fig:Zetsche_scatterplot" reference-type="ref" reference="fig:Zetsche_scatterplot">1.4</a> in quattro quadranti definiti da
una retta verticale passante per la media dei valori BDI-II e da una
retta orizzontale passante per la media dei valori CES-D. Numeriamo i
quadranti partendo da quello in basso a sinistra e muovendoci in senso
antiorario.</p>
<p>Se prevalgono punti nel I e III quadrante, allora la nuvola di punti
avrà un andamento crescente (per cui a valori bassi di <span class="math inline">\(X\)</span> tendono ad
associarsi valori bassi di <span class="math inline">\(Y\)</span> e a valori elevati di <span class="math inline">\(X\)</span> tendono ad
associarsi valori elevati di <span class="math inline">\(Y\)</span>) e la covarianza segno positivo. Mentre
se prevalgono punti nel II e IV quadrante la nuvola di punti avrà un
andamento decrescente (per cui a valori bassi di <span class="math inline">\(X\)</span> tendono ad
associarsi valori elevati di <span class="math inline">\(Y\)</span> e a valori elevati di <span class="math inline">\(X\)</span> tendono ad
associarsi valori bassi di <span class="math inline">\(Y\)</span>) e la covarianza segno negativo. Dunque,
il segno della covarianza ci informa sulla direzione della relazione
lineare tra due variabili: l’associazione lineare si dice positiva se la
covarianza è positiva, negativa se la covarianza è negativa.</p>
<p>Il segno della covarianza ci informa sulla direzione della relazione, ma
invece il valore assoluto della covarianza ci dice ben poco. Esso,
infatti, dipende dall’unità di misura delle variabili. Nel caso presente
questo concetto è difficile da comprendere, dato che le due variabili in
esame non hanno un’unità di misura (ovvero, hanno un’unità di misura
arbitraria e priva di significato). Ma quest’idea diventa chiara se
pensiamo alla relazione lineare tra l’altezza e il peso delle persone,
ad esempio. La covarianza tra queste due quantità è certamente positiva,
ma il valore assoluto della covarianza diventa più grande se l’altezza
viene misurata in millimetri e il peso in grammi, e diventa più piccolo
l’altezza viene misurata in metri e il peso in chilogrammi. Dunque, il
valore della covarianza cambia al mutare dell’unità di misura delle
variabili anche se l’associazione tra le variabili resta costante.</p>
</div>
<div id="correlazione" class="section level3" number="3.9.3">
<h3><span class="header-section-number">3.9.3</span> Correlazione</h3>
<p>Dato che il valore assoluto della covarianza è di difficile
interpretazione – in pratica, non viene mai interpretato – è
necessario trasformare la covarianza in modo tale da renderla immune
alle trasformazioni dell’unità di misura delle variabili. Questa
operazione si dice <em>standardizzazione</em> e corrisponde alla divisione
della covarianza per le deviazioni standard (<span class="math inline">\(s_X\)</span>, <span class="math inline">\(s_Y\)</span>) delle due
variabili:</p>
<p><span class="math display">\[r_{XY} = \frac{S_{XY}}{s_X s_Y}.\]</span> La quantià che si ottiene in questo
modo viene chiamata <em>correlazione</em> di Bravais-Pearson (dal nome degli
autori che, indipendentemente l’uno dall’altro, la hanno introdotta).</p>
<p>Il coefficiente di correlazione ha le seguenti proprietà:</p>
<ul>
<li><p>ha lo stesso segno della covarianza, dato che si ottiene dividendo
la covarianza per due numeri positivi;</p></li>
<li><p>è un numero puro, cioè non dipende dall’unità di misura delle
variabili;</p></li>
<li><p>assume valori compresi tra -1 e +1.</p></li>
</ul>
<p>Ad esso possiamo assegnare la seguente interpretazione:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(r_{XY} = -1\)</span> <span class="math inline">\(\rightarrow\)</span> perfetta relazione negativa: tutti i
punti si trovano esattamente su una retta con pendenza negativa (dal
quadrante in alto a sinistra al quadrante in basso a destra);</p></li>
<li><p><span class="math inline">\(r_{XY} = +1\)</span> <span class="math inline">\(\rightarrow\)</span> perfetta relazione positiva: tutti i
punti si trovano esattamente su una retta con pendenza positiva (dal
quadrante in basso a sinistra al quadrante in alto a destra);</p></li>
<li><p><span class="math inline">\(-1 &lt; r_{XY} &lt; +1\)</span> <span class="math inline">\(\rightarrow\)</span> presenza di una relazione lineare
di intensità diversa;</p></li>
<li><p><span class="math inline">\(r_{XY} = 0\)</span> <span class="math inline">\(\rightarrow\)</span> assenza di relazione lineare tra <span class="math inline">\(X\)</span> e
<span class="math inline">\(Y\)</span>.</p></li>
</ol>
<p>Per i dati della
figura <a href="chapter-descriptive-stats.html#fig:Zetsche_scatterplot" reference-type="ref" reference="fig:Zetsche_scatterplot">1.4</a>, la covarianza è 207.426. Il segno
positivo della covarianza ci dice che tra le due variabili c’è
un’associazione lineare positiva. Per capire qual è l’intensità della
relazione lineare tra le due variabili calcoliamo la correlazione.
Essendo le deviazioni standard del BDI-II e del CES-D rispettavamente
uguali a 15.37 e 14.93, la correlazione diventa uguale a
<span class="math inline">\(\frac{207.426}{15.38 \cdot 14.93} = 0.904.\)</span> Tale valore è prossimo a
1.0, il che vuol dire che i punti del diagramma a dispersione non si
discostano troppo da una retta con una pendenza positiva.</p>
</div>
</div>
<div id="correlazione-e-causazione" class="section level2" number="3.10">
<h2><span class="header-section-number">3.10</span> Correlazione e causazione</h2>
<p>Facendo riferimento nuovamente alla
figura <a href="chapter-descriptive-stats.html#fig:Zetsche_scatterplot" reference-type="ref" reference="fig:Zetsche_scatterplot">1.4</a>, possiamo dire che, in molte
applicazioni (ma non nel caso presente!) l’asse <span class="math inline">\(x\)</span> rappresenta una
quantità nota come <em>variabile indipendente</em> e l’interesse si concentra
sulla sua influenza sulla <em>variabile dipendente</em> tracciata sull’asse
<span class="math inline">\(y\)</span>. Ciò presuppone però che sia nota la direzione in cui l’influenza
causale potrebbe risiedere. È importante tenere bene a mente che la
correlazione è soltanto un indice descrittivo della relazione lineare
tra due variabili e in nessun caso può essere usata per inferire
alcunché sulle relazioni <em>causali</em> che legano le variabili. È ben nota
l’espressione: “correlazione non significa causazione.”</p>
<p>Di opinione diversa era invece Karl Pearson (1911), il quale ha
affermato: “Quanto spesso, quando è stato osservato un nuovo fenomeno,
sentiamo che viene posta la domanda: ‘qual è la sua causa?’ Questa è
una domanda a cui potrebbe essere assolutamente impossibile rispondere.
Invece, può essere più facile rispondere alla domanda: ‘in che misura
altri fenomeni sono associati con esso?’ Dalla risposta a questa
seconda domanda possono risultare molte preziose conoscenze.” Che alla
seconda domanda posta da Pearson sia facile rispondere è indubbio. Che
la nostra comprensione di un fenomeno possa aumentare sulla base delle
informazioni fornite dalle correlazioni, invece, è molto dubbio e quasi
certamente falso.</p>
<div id="usi-della-correlazione" class="section level3" number="3.10.1">
<h3><span class="header-section-number">3.10.1</span> Usi della correlazione</h3>
<p>Anche se non può essere usata per studiare le relazioni causali, la
correlazione viene usata per molti altri scopi tra i quali, per esempio,
quello di misurare la <em>validità concorrente</em> di un test psiologico. Se
un test psicologico misura effettivamente ciò che ci si aspetta che
misuri (nel caso dell’esempio presente, la depressione), allora dovremo
aspettarci che fornisca una correlazione alta con risultati di altri
test che misurano lo stesso costrutto (come nel caso dei dati di
<span class="citation">(<a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">Zetsche, Bürkner, &amp; Renneberg, 2019</a>)</span>). Un’altra proprietà desiderabile di un test
psicometrico è la <em>validità divergente</em>: i risultati di test
psicometrici che misurano costrutti diversi dovrebbero essere poco
associati tra loro. In altre parole, in questo secondo caso dovremmo
aspettarci che la correlazione sia bassa.</p>
</div>
<div id="correlazione-di-spearman" class="section level3" number="3.10.2">
<h3><span class="header-section-number">3.10.2</span> Correlazione di Spearman</h3>
<p>Una misura alternativa della relazione lineare tra due variabili è
fornita dal coefficiente di correlazione di Spearman e dipende soltanto
dalla relazione d’ordine dei dati, non dagli specifici valori dei dati.
Tale misura di associazione è appropriata quando, del fenomeno in esame,
gli psicologi sono stati in grado di misurare soltanto le relazioni
d’ordine tra le diverse modalità della risposta dei soggetti, non
l’intensità della risposta. Le variabili psicologiche che hanno questa
proprietà si dicono <em>ordinali</em>. Nel caso di variabili ordinali, non è
possibile sintetizzare i dati mediante le statistiche descrittive che
abbiamo introdotto in questo capitolo, quali ad esempio la media e la
varianza, ma è invece solo possibile riassumere i dati mediante una
distribuzione di frequenze per le varie modalità della risposta.</p>
</div>
<div id="correlazione-nulla" class="section level3" number="3.10.3">
<h3><span class="header-section-number">3.10.3</span> Correlazione nulla</h3>
<p>Un ultimo aspetto da mettere in evidenza a proposito della correlazione
riguarda il fatto che la correlazione descrive la direzione e
l’intensità della relazione lineare tra due variabili. Relazioni non
lineari tra le variabili, anche sono molto forti, non vengono catturate
dalla correlazione. È importante rendersi conto che una correlazione
pari a zero non significa che non c’è relazione tra le due variabili, ma
solo che tra esse non c’è una relazione <em>lineare</em>. Un esempio di questo
fatto è fornito dalla
figura <a href="chapter-descriptive-stats.html#fig:Cairo_zero_corr" reference-type="ref" reference="fig:Cairo_zero_corr">1.5</a>.</p>
<div class="figure">
<img src="Cairo_zero_corr" id="fig:Cairo_zero_corr" style="width:80.0%" alt="" />
<p class="caption">Due insiemi di dati (fittizi) per i quali i coefficienti di
correlazione di Pearson sono entrambi 0. Ma questo non significa che non
vi sia alcuna relazione tra le
variabili.</p>
</div>
</div>
</div>
<div id="conclusioni" class="section level2 unnumbered">
<h2>Conclusioni</h2>
<p>La prima fase dell’analisi dei dati è sicuramente quella che ci porta a
riassumere i dati mediante gli strumenti della statistica descrittiva.
Ci sono diverse domande che vengono affrontate in questa fase: qual è la
distribuzione delle variabili di interesse? Quali relazioni a coppie si
possono osservare nel campione? Ci sono delle osservazioni ‘anomale,’
ovvero estremamente discrepanti rispetto alle altre, sia quando si
esaminano le statistiche descrittive univariate (ovvero, quelle che
riguardano le caratteristiche di una variabile presa singolarmente), sia
quando vengono esaminate le statistiche bivariate (ovvero, le
statistiche che descrivono l’associazione tra le variabili)? È
importante avere ben chiare le idee su questi punti prima di procedere
con qualsiasi procedura statistica di tipo inferenziale. Per rispondere
alle domande che abbiamo elencato sopra, ed ad altre simili, è molto
utile procedere con delle rappresentazioni grafiche dei dati. Dovrebbe
essere chiaro che, quando disponiamo di grandi moli di dati (come è
sempre il caso in psicologia), per fare questo è necessario usare un
software statistico.</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="2">
<li id="fn2"><p>Un intervallo aperto non include i suoi estremi ed è indicato con
le parentesi tonde. Ad esempio, (0,1) significa maggiore di 0 e
minore di 1. Un intervallo chiuso è un intervallo che include i suoi
estremi ed è indicato con le parentesi quadre. Ci possono essere
intervalli aperti, “<span class="math inline">\((a, b)\)</span>,” intervalli chiusi, “<span class="math inline">\([a, b]\)</span>,”
intervalli aperti a sinistra, “<span class="math inline">\((a, b]\)</span>,” e intervalli aperti a
destra, “<span class="math inline">\([a, b)\)</span>.”<a href="chapter-descriptive-stats.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>Si noti che solitamente i software restituiscono un valore
<em>interpolato</em> di <span class="math inline">\(p\)</span>-esimo quantile <span class="math inline">\(q_p\)</span> <span class="math inline">\((0 &lt; p &lt; 1)\)</span>, il quale
viene calcolato mediante specifiche procedure. Il risultato fornito
dai software, dunque, non sarà identico a quello trovato utilizzando
la definizione non interpolata di quantile che abbiamo presentato
sopra. Se, per qualche ragione, vogliamo conoscere l’algoritmo usato
per la determinazione dei quantili interpolati, dobbiamo leggere la
documentazione del software.<a href="chapter-descriptive-stats.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>Per costrutto si intende un concetto astratto non direttamente
osservabile, reso osservabile dalle variabili che vengono
effettivamente misurate.<a href="chapter-descriptive-stats.html#fnref4" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chapter-misurazione.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bibliografia.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/ccaudek/bookdown_psicometria/edit/master/stat_descrittive.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/ccaudek/bookdown_psicometria/blob/master/stat_descrittive.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
