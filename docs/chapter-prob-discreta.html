<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capitolo 5 Che cos’è la probabilità? | PSICOMETRIA</title>
  <meta name="description" content="""" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Capitolo 5 Che cos’è la probabilità? | PSICOMETRIA" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="""" />
  <meta name="github-repo" content="ccaudek/bookdown_psicometria" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capitolo 5 Che cos’è la probabilità? | PSICOMETRIA" />
  <meta name="twitter:site" content="@ccaudek" />
  <meta name="twitter:description" content="""" />
  

<meta name="author" content="Corrado Caudek" />


<meta name="date" content="2020-12-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="chapter-descriptive-stats.html"/>
<link rel="next" href="bibliografia.html"/>
<script src="libs/header-attrs-2.5/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A.A. 2020/2021</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefazione</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#perché-tanta-statistica-in-psicologia"><i class="fa fa-check"></i>Perché tanta statistica in psicologia?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#come-studiare"><i class="fa fa-check"></i>Come studiare?</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="chapter-pacchetti.html"><a href="chapter-pacchetti.html"><i class="fa fa-check"></i><b>1</b> Pacchetti</a></li>
<li class="chapter" data-level="2" data-path="chapter-terminologia.html"><a href="chapter-terminologia.html"><i class="fa fa-check"></i><b>2</b> Terminologia</a>
<ul>
<li class="chapter" data-level="2.1" data-path="chapter-terminologia.html"><a href="chapter-terminologia.html#metodi-e-procedure-della-psicologia"><i class="fa fa-check"></i><b>2.1</b> Metodi e procedure della psicologia</a></li>
<li class="chapter" data-level="2.2" data-path="chapter-terminologia.html"><a href="chapter-terminologia.html#variabili-e-costanti"><i class="fa fa-check"></i><b>2.2</b> Variabili e costanti</a></li>
<li class="chapter" data-level="2.3" data-path="chapter-terminologia.html"><a href="chapter-terminologia.html#variabili-indipendenti-e-variabili-dipendenti"><i class="fa fa-check"></i><b>2.3</b> Variabili indipendenti e variabili dipendenti</a></li>
<li class="chapter" data-level="2.4" data-path="chapter-terminologia.html"><a href="chapter-terminologia.html#la-matrice-dei-dati"><i class="fa fa-check"></i><b>2.4</b> La matrice dei dati</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html"><i class="fa fa-check"></i><b>3</b> La misurazione in psicologia</a>
<ul>
<li class="chapter" data-level="3.1" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#le-scale-di-misura"><i class="fa fa-check"></i><b>3.1</b> Le scale di misura</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#scala-nominale"><i class="fa fa-check"></i><b>3.1.1</b> Scala nominale</a></li>
<li class="chapter" data-level="3.1.2" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#scala-ordinale"><i class="fa fa-check"></i><b>3.1.2</b> Scala ordinale</a></li>
<li class="chapter" data-level="3.1.3" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#scala-ad-intervalli"><i class="fa fa-check"></i><b>3.1.3</b> Scala ad intervalli</a></li>
<li class="chapter" data-level="3.1.4" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#scala-di-rapporti"><i class="fa fa-check"></i><b>3.1.4</b> Scala di rapporti</a></li>
<li class="chapter" data-level="3.1.5" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#gerarchia-dei-livelli-di-scala-di-misura"><i class="fa fa-check"></i><b>3.1.5</b> Gerarchia dei livelli di scala di misura</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#sec:DiscreteVsContinuous"><i class="fa fa-check"></i><b>3.2</b> Variabili discrete vs. variabili continue</a></li>
<li class="chapter" data-level="3.3" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#perché-alcune-misurazioni-sono-migliori-di-altre"><i class="fa fa-check"></i><b>3.3</b> Perché alcune misurazioni sono migliori di altre?</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#sec:accuratezza_precisione"><i class="fa fa-check"></i><b>3.3.1</b> Tipologie di errori</a></li>
<li class="chapter" data-level="3.3.2" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#sec:reliability"><i class="fa fa-check"></i><b>3.3.2</b> Attendibilità</a></li>
<li class="chapter" data-level="3.3.3" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#sec:validity"><i class="fa fa-check"></i><b>3.3.3</b> Validità</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#conclusioni"><i class="fa fa-check"></i>Conclusioni</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html"><i class="fa fa-check"></i><b>4</b> Statistica descrittiva</a>
<ul>
<li class="chapter" data-level="4.1" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#perché-riassumere-i-dati"><i class="fa fa-check"></i><b>4.1</b> Perché riassumere i dati?</a></li>
<li class="chapter" data-level="4.2" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#sec:distr_freq"><i class="fa fa-check"></i><b>4.2</b> Distribuzioni di frequenze</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#esercizio-con-r"><i class="fa fa-check"></i><b>4.2.1</b> Esercizio con R</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#istogramma"><i class="fa fa-check"></i><b>4.3</b> Istogramma</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#esercizio-con-r-1"><i class="fa fa-check"></i><b>4.3.1</b> Esercizio con R</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#funzione-di-densità-empirica"><i class="fa fa-check"></i><b>4.4</b> Funzione di densità empirica</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#esercizio-con-r-2"><i class="fa fa-check"></i><b>4.4.1</b> Esercizio con R</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#forma-di-una-distribuzione"><i class="fa fa-check"></i><b>4.5</b> Forma di una distribuzione</a></li>
<li class="chapter" data-level="4.6" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#indici-di-posizione"><i class="fa fa-check"></i><b>4.6</b> Indici di posizione</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#quantili"><i class="fa fa-check"></i><b>4.6.1</b> Quantili</a></li>
<li class="chapter" data-level="4.6.2" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#box-plot"><i class="fa fa-check"></i><b>4.6.2</b> Box-plot</a></li>
<li class="chapter" data-level="4.6.3" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#leccellenza-grafica"><i class="fa fa-check"></i><b>4.6.3</b> L’eccellenza grafica</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#indici-di-tendenza-centrale"><i class="fa fa-check"></i><b>4.7</b> Indici di tendenza centrale</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#media"><i class="fa fa-check"></i><b>4.7.1</b> Media</a></li>
<li class="chapter" data-level="4.7.2" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#media-spuntata"><i class="fa fa-check"></i><b>4.7.2</b> Media spuntata</a></li>
<li class="chapter" data-level="4.7.3" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#moda-e-mediana"><i class="fa fa-check"></i><b>4.7.3</b> Moda e mediana</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#indici-di-dispersione"><i class="fa fa-check"></i><b>4.8</b> Indici di dispersione</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#indici-basati-sullordinamento-dei-dati"><i class="fa fa-check"></i><b>4.8.1</b> Indici basati sull’ordinamento dei dati</a></li>
<li class="chapter" data-level="4.8.2" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#scostamento-medio-semplice-dalla-media"><i class="fa fa-check"></i><b>4.8.2</b> Scostamento medio semplice dalla media</a></li>
<li class="chapter" data-level="4.8.3" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#varianza"><i class="fa fa-check"></i><b>4.8.3</b> Varianza</a></li>
<li class="chapter" data-level="4.8.4" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#deviazione-standard"><i class="fa fa-check"></i><b>4.8.4</b> Deviazione standard</a></li>
<li class="chapter" data-level="4.8.5" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#indici-di-variabilità-relativi"><i class="fa fa-check"></i><b>4.8.5</b> Indici di variabilità relativi</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#le-relazioni-tra-variabili"><i class="fa fa-check"></i><b>4.9</b> Le relazioni tra variabili</a>
<ul>
<li class="chapter" data-level="4.9.1" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#diagramma-a-dispersione"><i class="fa fa-check"></i><b>4.9.1</b> Diagramma a dispersione</a></li>
<li class="chapter" data-level="4.9.2" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#covarianza"><i class="fa fa-check"></i><b>4.9.2</b> Covarianza</a></li>
<li class="chapter" data-level="4.9.3" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#correlazione"><i class="fa fa-check"></i><b>4.9.3</b> Correlazione</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#correlazione-e-causazione"><i class="fa fa-check"></i><b>4.10</b> Correlazione e causazione</a>
<ul>
<li class="chapter" data-level="4.10.1" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#usi-della-correlazione"><i class="fa fa-check"></i><b>4.10.1</b> Usi della correlazione</a></li>
<li class="chapter" data-level="4.10.2" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#correlazione-di-spearman"><i class="fa fa-check"></i><b>4.10.2</b> Correlazione di Spearman</a></li>
<li class="chapter" data-level="4.10.3" data-path="chapter-descriptive-stats.html"><a href="chapter-descriptive-stats.html#correlazione-nulla"><i class="fa fa-check"></i><b>4.10.3</b> Correlazione nulla</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#conclusioni"><i class="fa fa-check"></i>Conclusioni</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chapter-prob-discreta.html"><a href="chapter-prob-discreta.html"><i class="fa fa-check"></i><b>5</b> Che cos’è la probabilità?</a>
<ul>
<li class="chapter" data-level="5.1" data-path="chapter-prob-discreta.html"><a href="chapter-prob-discreta.html#probabilità-nel-linguaggio-naturale"><i class="fa fa-check"></i><b>5.1</b> Probabilità nel linguaggio naturale</a></li>
<li class="chapter" data-level="5.2" data-path="chapter-prob-discreta.html"><a href="chapter-prob-discreta.html#probabilità-nel-linguaggio-scientifico"><i class="fa fa-check"></i><b>5.2</b> Probabilità nel linguaggio scientifico</a></li>
<li class="chapter" data-level="5.3" data-path="chapter-prob-discreta.html"><a href="chapter-prob-discreta.html#terminologia"><i class="fa fa-check"></i><b>5.3</b> Terminologia</a></li>
<li class="chapter" data-level="5.4" data-path="chapter-prob-discreta.html"><a href="chapter-prob-discreta.html#le-diverse-definizioni-della-probabilità"><i class="fa fa-check"></i><b>5.4</b> Le diverse definizioni della probabilità</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="chapter-prob-discreta.html"><a href="chapter-prob-discreta.html#sec:def_ing_prob"><i class="fa fa-check"></i><b>5.4.1</b> Una definizione “ingenua” della probabilità</a></li>
<li class="chapter" data-level="5.4.2" data-path="chapter-prob-discreta.html"><a href="chapter-prob-discreta.html#una-definizione-non-ingenua-della-probabilità"><i class="fa fa-check"></i><b>5.4.2</b> Una definizione “non ingenua” della probabilità</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="chapter-prob-discreta.html"><a href="chapter-prob-discreta.html#assegnare-le-probabilità-agli-eventi"><i class="fa fa-check"></i><b>5.5</b> Assegnare le probabilità agli eventi</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="chapter-prob-discreta.html"><a href="chapter-prob-discreta.html#approccio-frequentista"><i class="fa fa-check"></i><b>5.5.1</b> Approccio frequentista</a></li>
<li class="chapter" data-level="5.5.2" data-path="chapter-prob-discreta.html"><a href="chapter-prob-discreta.html#approccio-bayesiano"><i class="fa fa-check"></i><b>5.5.2</b> Approccio Bayesiano</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="chapter-prob-discreta.html"><a href="chapter-prob-discreta.html#proprietà-elementari-della-probabilità"><i class="fa fa-check"></i><b>5.6</b> Proprietà elementari della probabilità</a></li>
<li class="chapter" data-level="5.7" data-path="chapter-prob-discreta.html"><a href="chapter-prob-discreta.html#variabili-aleatorie"><i class="fa fa-check"></i><b>5.7</b> Variabili aleatorie</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="chapter-prob-discreta.html"><a href="chapter-prob-discreta.html#a-cosa-servono-le-variabili-aleatorie"><i class="fa fa-check"></i><b>5.7.1</b> A cosa servono le variabili aleatorie?</a></li>
<li class="chapter" data-level="5.7.2" data-path="chapter-prob-discreta.html"><a href="chapter-prob-discreta.html#funzione-di-massa-di-probabilità"><i class="fa fa-check"></i><b>5.7.2</b> Funzione di massa di probabilità</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="chapter-prob-discreta.html"><a href="chapter-prob-discreta.html#notazione"><i class="fa fa-check"></i><b>5.8</b> Notazione</a></li>
<li class="chapter" data-level="" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html#conclusioni"><i class="fa fa-check"></i>Conclusioni</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliografia.html"><a href="bibliografia.html"><i class="fa fa-check"></i>Bibliografia</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">PSICOMETRIA</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chapter:prob_discreta" class="section level1" number="5">
<h1><span class="header-section-number">Capitolo 5</span> Che cos’è la probabilità?</h1>
<p>È normale fare delle congetture rispetto a ciò di cui non siamo sicuri.
Ma perché facciamo questo? Molto spesso perché, anche se sappiamo che le
nostre conoscenze sono incomplete, dobbiamo comunque prendere delle
decisioni. Ad esempio: “non so se tra qualche ora pioverà; devo o non
devo prendere l’ombrello?” In maniera simile, anche se uno psicologo non
sa in maniera certa quali sono i meccanismi che regolano i fenomeni
psicologi, deve comunque decidere tra diverse alternative. Per esempio,
deve fornire un parere, relativamente a chi, tra due genitori, sia più
adatto per ottenere l’affidamento del figlio in caso di divorzio, oppure
quale sia, in un caso specifico, l’approccio più efficace per il
trattamento dei disturbi dell’alimentazione. Ovviamente la qualità delle
congetture varia, così come varia la qualità delle decisioni che
prendiamo. La teoria delle probabilità ci fornisce gli strumenti per
prendere decisioni “razionali” in condizioni di incertezza, ovvero per
formulare le migliori congetture possibili.</p>
<p>La teoria delle probabilità ci consente di descrivere in maniera
quantitativa quei fenomeni che, pur essendo altamente variabili,
rivelano comunque una qualche coerenza a lungo termine. Il lancio
ripetuto di una moneta è uno di questi fenomeni. È anche l’esempio
tipico che viene usato per introdurre una discussione sulle probabilità.
Sapere se una moneta sia onesta o meno, o calcolare la probabilità di
ottenere testa un certo numero di volte può essere interessante nel
mondo delle scommesse, ma nella vita quotidiana non ci capita spesso di
lanciare una moneta per prendere una decisione. Allora perché ci
preoccupiamo di studiare le proprietà statistiche dei lanci di una
moneta? A questa domanda si può rispondere dicendo che l’esperimento
(chiamato “casuale”) che corrisponde al lancio di una moneta è il
surrogato di una molteplicità di eventi che, della vita reale, sono
molto importanti. Per esempio: qual è la probabilità di successo di un
intervento psicologico? Qual è la probabilità che un test per l’HIV dia
esito positivo in una persona che non ha l’HIV? Qual è la probabilità di
essere occupato entro un anno dalla laurea? I lanci di una moneta
costituiscono una rappresentazione generica di molteplici altri eventi
che hanno un grande significato nella nostra vita. Questa è la ragione
per cui studiamo le proprietà statistiche dei fenomeni aleatori usando
il lancio di una moneta quale esempio generico.</p>
<p>La discussione della teoria della probabilità è certamente l’argomento
più impegnativo affrontato in queste dispense. Fare uno sforzo di
comprensione per chiarire i concetti di base della teoria della
probabilità è però necessario per mettersi nelle condizioni di capire le
caratteristiche dell’inferenza statistica che verranno discusse in
seguito.</p>
<div id="probabilità-nel-linguaggio-naturale" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Probabilità nel linguaggio naturale</h2>
<p>In un articolo pubblicato su Harward Business Review nel 2018,
Mauboussin e Mauboussin ci ricordano come, nel marzo del 1951, l’<em>Office
of National Estimates</em> della CIA pubblicò un documento che suggeriva che
un attacco sovietico alla Jugoslavia nel corso dell’anno fosse una
“seria possibilità.” Sherman Kent, un professore di storia a Yale che fu
chiamato a Washington, D.C. per dirigere l’<em>Office of National
Estimates</em>, espresse perplessità sull’esatto significato
dell’espressione “seria possibilità.” Lo interpretò nel senso che la
probabilità di un attacco era di circa il 65%. Ma quando chiese ai
membri del <em>Board of National Estimates</em> cosa ne pensassero, gli furono
riferite cifre che andavano dal 20% all’80%. Una gamma così ampia
rappresentava chiaramente un problema, poiché le implicazioni politiche
di quegli estremi erano nettamente diverse. Kent riconobbe che la
soluzione di tale problema era quella di usare i numeri per esprimere il
nostro grado di certezza, notando mestamente:</p>
<blockquote>
<p>Non abbiamo usato i numeri…e sembra chiaro che abbiamo abusando delle parole.</p>
</blockquote>
<p>Da allora non è cambiato molto. Ancora oggi le persone nel mondo della
politica, degli affari e nella vita quotidiana continuano a usare parole
vaghe per descrivere i possibili risultati degli eventi. Perché? Phil
Tetlock, professore di psicologia all’Università della Pennsylvania, che
ha studiato a fondo il fenomeno psicologico della previsione, suggerisce
che “una vaga verbosità conferisce sicurezza.” Quando usiamo una parola
per descrivere la probabilità di un evento incerto, cerchiamo di porci
nelle condizioni di non essere smentiti dopo che il risultato
dell’evento verrà rivelato. Se si verifica l’evento che abbiamo
previsto, è facile dire: “Ti avevo detto che probabilmente sarebbe
successo questo.” Se la nostra predizione fallisce, possiamo sempre
dire: “Ho solo detto che probabilmente sarebbe successo.” Parole così
ambigue non solo consentono all’oratore di evitare di essere smentito,
ma consentono anche al destinatario di interpretare il messaggio in modo
coerente con le sue nozioni preconcette. Ovviamente, da tale ambiguità
linguistica deriva una cattiva comunicazione. È dunque necessario
procedere in modo diverso nel linguaggio scientifico. Vedremo in questo
capitolo come sia possibile assegnare al termine “probabilità” un
significato preciso.</p>
</div>
<div id="probabilità-nel-linguaggio-scientifico" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Probabilità nel linguaggio scientifico</h2>
<p>La teoria della probabilità nasce nel 1654. Fu infatti in questa data
che Antoine Gombaud Cavalier De Méré, un nobile francese, nonché
accanito giocatore d’azzardo scrisse una lettera al suo amico Pascal per
cercare di comprendere il motivo delle sue continue perdite nel gioco
dei dadi. De Méré descrisse due diverse scommesse:</p>
<dl>
<dt>scommessa A</dt>
<dd><p>si lancia un dado per 4 volte di seguito e si vince se esce almeno
una volta il 6;</p>
</dd>
<dt>scommessa B</dt>
<dd><p>si lanciano due dadi per 24 volte di seguito e si vince se esce
almeno una volta il doppio 6.</p>
</dd>
</dl>
<p>Il cavaliere De Méré pose a Pascal il seguente quesito: le possibilità
di vittoria sono maggiori nella scommessa A o nella scommessa B? Il
problema di De Méré divenne un motivo di scambio epistolare tra Pascal e
Fermat, i due più grandi matematici del tempo, e viene considerato come
la motivazione iniziale dello sviluppo della teoria della probabilità.</p>
<p>Ma come può essere risolto il problema di De Méré? Una strategia
possibile è quella di seguire l’esempio di De Méré, ovvero, giocare
questo gioco molte volte. Così facendo, De Méré si rese conto che le
possibilità di vittoria erano leggermente migliori nel caso della
scommessa A.</p>
<p>Utilizzando una simulazione al computer possiamo facilmente giungere a
questa stessa conclusione senza perdere tutto il tempo che De Méré ha
dedicato a questa materia. Una simulazione al computer ci consente
infatti di ripetere il gioco di De Méré moltissime volte e di annotare
il risultato ottenuto ad ogni ripetizione del gioco. Vedremo in seguito
perché, utilizzando un computer, è possibile ottenere un risultato
diverso ogni volta che si ripete una certa operazione, in modo tale da
rappresentare il grado di casualità che si osserva quando si lancia di
un dado. Per ora ci limitiamo ad esaminare i risultati che vengono
prodotti in questo modo e che sono illustrati nella
figura <a href="chapter-prob-discreta.html#fig:demere" reference-type="ref" reference="fig:demere">1.1</a>.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="chapter-prob-discreta.html#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Game A: Throw a fair die at most four times, and win if you get a six.</span></span>
<span id="cb25-2"><a href="chapter-prob-discreta.html#cb25-2" aria-hidden="true" tabindex="-1"></a>experiment_a <span class="ot">&lt;-</span> <span class="cf">function</span>(){</span>
<span id="cb25-3"><a href="chapter-prob-discreta.html#cb25-3" aria-hidden="true" tabindex="-1"></a>  rolls <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, <span class="at">size =</span> <span class="dv">4</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb25-4"><a href="chapter-prob-discreta.html#cb25-4" aria-hidden="true" tabindex="-1"></a>  condition <span class="ot">&lt;-</span> <span class="fu">sum</span>(rolls <span class="sc">==</span> <span class="dv">6</span>) <span class="sc">&gt;</span> <span class="dv">0</span></span>
<span id="cb25-5"><a href="chapter-prob-discreta.html#cb25-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(condition)</span>
<span id="cb25-6"><a href="chapter-prob-discreta.html#cb25-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb25-7"><a href="chapter-prob-discreta.html#cb25-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-8"><a href="chapter-prob-discreta.html#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Game B: Throw two fair dice at most twenty-four times, and win if you get a double-six.</span></span>
<span id="cb25-9"><a href="chapter-prob-discreta.html#cb25-9" aria-hidden="true" tabindex="-1"></a>experiment_b <span class="ot">&lt;-</span> <span class="cf">function</span>(){</span>
<span id="cb25-10"><a href="chapter-prob-discreta.html#cb25-10" aria-hidden="true" tabindex="-1"></a>  first.die <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, <span class="at">size =</span> <span class="dv">24</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb25-11"><a href="chapter-prob-discreta.html#cb25-11" aria-hidden="true" tabindex="-1"></a>  second.die <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, <span class="at">size =</span> <span class="dv">24</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb25-12"><a href="chapter-prob-discreta.html#cb25-12" aria-hidden="true" tabindex="-1"></a>  condition <span class="ot">&lt;-</span> <span class="fu">sum</span>((first.die <span class="sc">==</span> second.die) <span class="sc">&amp;</span> (first.die <span class="sc">==</span> <span class="dv">6</span>)) <span class="sc">&gt;</span> <span class="dv">0</span></span>
<span id="cb25-13"><a href="chapter-prob-discreta.html#cb25-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(condition)</span>
<span id="cb25-14"><a href="chapter-prob-discreta.html#cb25-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb25-15"><a href="chapter-prob-discreta.html#cb25-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-16"><a href="chapter-prob-discreta.html#cb25-16" aria-hidden="true" tabindex="-1"></a><span class="co"># number of replications</span></span>
<span id="cb25-17"><a href="chapter-prob-discreta.html#cb25-17" aria-hidden="true" tabindex="-1"></a>nrep <span class="ot">&lt;-</span> <span class="fl">1e4</span></span>
<span id="cb25-18"><a href="chapter-prob-discreta.html#cb25-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Play game A nrep times. We get a vector of nrep elements. Eeach element of </span></span>
<span id="cb25-19"><a href="chapter-prob-discreta.html#cb25-19" aria-hidden="true" tabindex="-1"></a><span class="co"># of the simsA vector is the outcome obtained by playing game A once: TRUE if</span></span>
<span id="cb25-20"><a href="chapter-prob-discreta.html#cb25-20" aria-hidden="true" tabindex="-1"></a><span class="co"># the output is a win, FALSE if the output of the game is a loss. Remember than</span></span>
<span id="cb25-21"><a href="chapter-prob-discreta.html#cb25-21" aria-hidden="true" tabindex="-1"></a><span class="co"># TRUE = 1 and FALSE = 0.</span></span>
<span id="cb25-22"><a href="chapter-prob-discreta.html#cb25-22" aria-hidden="true" tabindex="-1"></a>sims_a <span class="ot">&lt;-</span> <span class="fu">replicate</span>(nrep, <span class="fu">experiment_a</span>())</span>
<span id="cb25-23"><a href="chapter-prob-discreta.html#cb25-23" aria-hidden="true" tabindex="-1"></a><span class="co"># The proportion of wins in game A </span></span>
<span id="cb25-24"><a href="chapter-prob-discreta.html#cb25-24" aria-hidden="true" tabindex="-1"></a>prop_wins_a <span class="ot">&lt;-</span> <span class="fu">sum</span>(sims_a)<span class="sc">/</span><span class="fu">length</span>(sims_a)</span>
<span id="cb25-25"><a href="chapter-prob-discreta.html#cb25-25" aria-hidden="true" tabindex="-1"></a>prop_wins_a</span>
<span id="cb25-26"><a href="chapter-prob-discreta.html#cb25-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.5193</span></span>
<span id="cb25-27"><a href="chapter-prob-discreta.html#cb25-27" aria-hidden="true" tabindex="-1"></a><span class="co"># To plot the results, we compute the </span></span>
<span id="cb25-28"><a href="chapter-prob-discreta.html#cb25-28" aria-hidden="true" tabindex="-1"></a>nwins_a <span class="ot">&lt;-</span> <span class="fu">cumsum</span>(sims_a)</span>
<span id="cb25-29"><a href="chapter-prob-discreta.html#cb25-29" aria-hidden="true" tabindex="-1"></a>ntrials <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span>nrep</span>
<span id="cb25-30"><a href="chapter-prob-discreta.html#cb25-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-31"><a href="chapter-prob-discreta.html#cb25-31" aria-hidden="true" tabindex="-1"></a>sims_b <span class="ot">&lt;-</span> <span class="fu">replicate</span>(nrep, <span class="fu">experiment_b</span>())</span>
<span id="cb25-32"><a href="chapter-prob-discreta.html#cb25-32" aria-hidden="true" tabindex="-1"></a>prop_wins_b <span class="ot">&lt;-</span> <span class="fu">sum</span>(sims_b)<span class="sc">/</span><span class="fu">length</span>(sims_b) </span>
<span id="cb25-33"><a href="chapter-prob-discreta.html#cb25-33" aria-hidden="true" tabindex="-1"></a>prop_wins_b</span>
<span id="cb25-34"><a href="chapter-prob-discreta.html#cb25-34" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.493</span></span>
<span id="cb25-35"><a href="chapter-prob-discreta.html#cb25-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-36"><a href="chapter-prob-discreta.html#cb25-36" aria-hidden="true" tabindex="-1"></a>nwins_b <span class="ot">&lt;-</span> <span class="fu">cumsum</span>(sims_b)</span>
<span id="cb25-37"><a href="chapter-prob-discreta.html#cb25-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-38"><a href="chapter-prob-discreta.html#cb25-38" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb25-39"><a href="chapter-prob-discreta.html#cb25-39" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> <span class="fu">c</span>(ntrials, ntrials), </span>
<span id="cb25-40"><a href="chapter-prob-discreta.html#cb25-40" aria-hidden="true" tabindex="-1"></a>  <span class="at">pwin =</span> <span class="fu">c</span>(nwins_a<span class="sc">/</span>ntrials, nwins_b<span class="sc">/</span>ntrials),</span>
<span id="cb25-41"><a href="chapter-prob-discreta.html#cb25-41" aria-hidden="true" tabindex="-1"></a>  <span class="at">game =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">&quot;Scommessa A&quot;</span>, <span class="st">&quot;Scommessa B&quot;</span>), <span class="at">each =</span> nrep)</span>
<span id="cb25-42"><a href="chapter-prob-discreta.html#cb25-42" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-43"><a href="chapter-prob-discreta.html#cb25-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-44"><a href="chapter-prob-discreta.html#cb25-44" aria-hidden="true" tabindex="-1"></a>d <span class="sc">%&gt;%</span> </span>
<span id="cb25-45"><a href="chapter-prob-discreta.html#cb25-45" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(</span>
<span id="cb25-46"><a href="chapter-prob-discreta.html#cb25-46" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">x =</span> n, <span class="at">y =</span> pwin, <span class="at">col =</span> game)</span>
<span id="cb25-47"><a href="chapter-prob-discreta.html#cb25-47" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb25-48"><a href="chapter-prob-discreta.html#cb25-48" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.4</span>) <span class="sc">+</span></span>
<span id="cb25-49"><a href="chapter-prob-discreta.html#cb25-49" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb25-50"><a href="chapter-prob-discreta.html#cb25-50" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_log10</span>(<span class="at">breaks =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">10</span>, <span class="dv">50</span>, <span class="dv">200</span>, <span class="dv">1000</span>, <span class="dv">3000</span>,  <span class="dv">10000</span>)) <span class="sc">+</span></span>
<span id="cb25-51"><a href="chapter-prob-discreta.html#cb25-51" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.title =</span> <span class="fu">element_blank</span>()) <span class="sc">+</span></span>
<span id="cb25-52"><a href="chapter-prob-discreta.html#cb25-52" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb25-53"><a href="chapter-prob-discreta.html#cb25-53" aria-hidden="true" tabindex="-1"></a>    <span class="at">x=</span><span class="st">&quot;Numero di ripetizioni del gioco di De Méré&quot;</span>, </span>
<span id="cb25-54"><a href="chapter-prob-discreta.html#cb25-54" aria-hidden="true" tabindex="-1"></a>    <span class="at">y=</span><span class="st">&quot;Proporzione di vincite&quot;</span>) <span class="sc">+</span></span>
<span id="cb25-55"><a href="chapter-prob-discreta.html#cb25-55" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;gray80&quot;</span>, <span class="st">&quot;skyblue&quot;</span>)) <span class="sc">+</span></span>
<span id="cb25-56"><a href="chapter-prob-discreta.html#cb25-56" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;bottom&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:demere"></span>
<img src="Psicometria_files/figure-html/demere-1.png" alt="Risultati ottenuti da 10000 ripetizioni delle due scommesse di De Méré." width="80%" />
<p class="caption">
Figura 5.1: Risultati ottenuti da 10000 ripetizioni delle due scommesse di De Méré.
</p>
</div>
<p>La figura <a href="chapter-prob-discreta.html#fig:demere">5.1</a> riportata la proporzione di vittorie in funzione
del numero di ripetizioni di ciascuna scommessa e rivela che, a lungo
termine (ovvero, se consideriamo un grande numero di ripetizioni del
gioco di De Méré), la scommessa A risulta più conveniente della
scommessa B. Nel caso di 10000 ripetizioni del gioco di De Méré, la
proporzione di vittorie è risultata essere pari a 0.5182 per la
scommessa A e pari a 0.4909 per la scommessa B. Se ripetiamo la stessa
simulazione altre 10000 volte, otteniamo una proporzione di vittorie
uguale a 0.5180 per la scommessa A e a 0.4878 per la scommessa B.</p>
<p>Vedremo in questo capitolo come ciascuna di queste proporzioni possa
essere considerata come una <em>stima empirica</em> di ciò che chiamiamo
<em>probabilità</em>. Le proporzioni descritte sopra vengono sono delle “stime”
poiché approssimano il vero valore della probabilità; infatti, ripetendo
la simulazione due volte abbiamo ottenuto dei risultati leggermente
diversi. Ma allora qual è il “vero” valore della probabilità? Un modo
semplice per rispondere a questa domanda è quello di dire che,
utilizzando la procedura descritta sopra, il vero valore della
probabilità si otterrebbe se il gioco di De Méré venisse ripetuto
infinite volte. Ma ovviamente, per qualunque applicazione concreta, non
abbiamo bisogno di ripetere la simulazione infinite volte, in quanto un
grande numero di ripetizioni ci fornisce un’approssimazione sufficiente.</p>
<p>In conclusione, le considerazioni precedenti ci fanno capire che il
concetto di probabilità sia legato a quello di incertezza. La
probabilità può infatti essere definita come la quantificazione del
livello di “casualità” di un evento, laddove viene detto casuale ciò che
non è noto o non può essere predetto con certezza.</p>
</div>
<div id="terminologia" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Terminologia</h2>
<p>Come qualsiasi altra branca della matematica, la teoria delle
probabilità fa uso di una specifica terminologia i cui concetti di base
sono descritti di seguito.</p>
<ul>
<li><p>Il calcolo delle probabilità si occupa di un generico <em>esperimento casuale</em>. Si dice <em>esperimento casuale</em> qualsiasi attività che produce un risultato osservabile. L’esecuzione di un esperimento casuale è chiamata <em>prova</em> dell’esperimento. Esempi sono: lanciare una moneta, lanciare un dado a 6 facce, provare un nuovo percorso per andare al lavoro per vedere se è più veloce di quello che usiamo di solito, o giocare al gioco di De Méré.</p></li>
<li><p>Il risultato (o esito) di una prova si indica con <span class="math inline">\(\omega\)</span> ed è detto <em>evento elementare</em>.</p></li>
<li><p>Prima che l’esperimento casuale venga eseguito non sappiamo quale esito verrà prodotto; dopo che l’esperimento casuale è stato eseguito, l’esito dell’esperimento si “cristallizza” nel risultato osservato.</p></li>
<li><p>Si dice <em>spazio campionario</em> <span class="math inline">\(\Omega\)</span> (probability space) l’insieme di tutti i possibili esiti di un esperimento casuale. Lo spazio campionario può essere finito, infinito o infinito numerabile. Eseguire un esperimento casuale significa scegliere in maniera casuale uno dei possibili eventi elementari dello spazio campionario.</p></li>
<li><p>Si dice <em>evento composto</em> (o non-elementare) un sottoinsieme dello spazio campionario, ovvero un insieme che può essere a sua volta scomposto in più eventi elementari. Per esempio, il numero 4 è un evento elementare dello spazio campionario finito <span class="math inline">\(\Omega = \{1, 2, 3, 4, 5, 6\}\)</span> che corrisponde all’esperimento casuale del lancio di un dado. L’evento composto <span class="math inline">\(A\)</span> “il risultato è pari” è <span class="math inline">\(A = \{2, 4, 6\}\)</span>.</p></li>
</ul>
</div>
<div id="le-diverse-definizioni-della-probabilità" class="section level2" number="5.4">
<h2><span class="header-section-number">5.4</span> Le diverse definizioni della probabilità</h2>
<p>Ma, nello specifico, che cos’è la probabilità? A questa domanda si può rispondere in modi diversi.</p>
<div id="sec:def_ing_prob" class="section level3" number="5.4.1">
<h3><span class="header-section-number">5.4.1</span> Una definizione “ingenua” della probabilità</h3>
<p>Storicamente, la prima definizione della probabilità di un evento è
stata quella che richiede di contare il numero di modi nei quali un
evento può manifestarsi e di dividere tale numero per il numero totale
di eventi dello spazio campionario <span class="math inline">\(\Omega\)</span>.</p>

<div class="definition">
<span id="def:def-ing-prob" class="definition"><strong>Definizione 5.1  </strong></span>Dato uno spazio campionario finito, la definizione ingenua della probabilità dell’evento <span class="math inline">\(A\)</span> è <span class="math display">\[
\begin{aligned}
P_{\text{ing}} = \frac{|A|}{|\Omega|}
= \frac{\text{numero eventi elementari favorevoli all&#39;evento }A}{\text{numero totale  eventi elementari dello spazio campionario }\Omega}.\notag\end{aligned}
\]</span>
</div>
<p>La definizione <a href="chapter-prob-discreta.html#def:def-ing-prob">5.1</a> rende chiaro che il calcolo delle probabilità richiede di contare il numero di modi in cui un evento può realizzarsi.
Per esempio, nell’esperimento casuale corrispondente al lancio di due dadi equilibrati, l’evento <span class="math inline">\(A\)</span> = “la somma dei due dati è 5” si può realizzare in 4 modi diversi: <span class="math inline">\(A = \{ (1, 4), (2, 3), (3, 2), (4, 1) \}\)</span>.
Contare il numero di modi in cui un evento può realizzarsi può essere semplice, nel caso di alcuni eventi (come il presente), oppure estremamente complesso, nel caso di altri eventi. In questo secondo caso, per contare il numero di modi in cui un evento può realizzarsi, al fine di calcolare la probabilità definita come indicato sopra, è necessario fare uso del calcolo combinatorio. In queste dispense ci accontenteremo di presentare alcune nozioni di base del calcolo combinatorio, ma non entreremo nei dettagli di questo argomento.</p>
</div>
<div id="una-definizione-non-ingenua-della-probabilità" class="section level3" number="5.4.2">
<h3><span class="header-section-number">5.4.2</span> Una definizione “non ingenua” della probabilità</h3>
<p>Il calcolo combinatorio ci consente di contare il numero di casi nello spazio campionario e di applicare la definizione “ingenua” di probabilità descritta nella
definizione <a href="chapter-prob-discreta.html#def:def-ing-prob">5.1</a>. È però facile rendersi conto che tale definizione di probabilità ha un grosso problema: non può essere applicata al caso di uno spazio campionario infinito. Dobbiamo dunque trovare una definizione che risolva un tale problema. Per fare ciò vengono specificate alcune proprietà che vorremmo potere attribuire alla probabilità – in matematica, tali proprietà sono dette <em>assiomi</em> – per poi definire una funzione di probabilità che soddisfi tali proprietà. Arriviamo in questo modo alla seguente definizione non ingenua della probabilità.</p>

<div class="definition">
<span id="def:def-assiomi-Kolmogorov" class="definition"><strong>Definizione 5.2  </strong></span>Uno spazio di probabilità è una terna (<span class="math inline">\(\Omega\)</span>, <span class="math inline">\(\mathcal{A}\)</span>, <span class="math inline">\(P\)</span>), dove <span class="math inline">\(\Omega\)</span> è l’insieme dei risultati possibili di un esperimento casuale, <span class="math inline">\(\mathcal{A}\)</span> è detta <span class="math inline">\(\sigma\)</span>-algebra, ovvero un insieme di insiemi (gli eventi) per i quali si può calcolare una probabilità, e <span class="math inline">\(P()\)</span> è una misura di probabilità su <span class="math inline">\(\Omega\)</span>, ovvero <span class="math inline">\(P: \Omega \rightarrow [0, 1]\)</span>.
</div>
<p>Per la precisione, una <span class="math inline">\(\sigma\)</span>-algebra è una famiglia di insiemi tali
che <span class="math inline">\(\emptyset \in \mathcal{A}\)</span>; se <span class="math inline">\(A \in \mathcal{A}\)</span> allora anche il suo complementare <span class="math inline">\(A^C\)</span> è in <span class="math inline">\(\mathcal{A}\)</span>; unioni numerabili di elementi di <span class="math inline">\(\mathcal{A}\)</span> appartengono ancora ad <span class="math inline">\(\mathcal{A}\)</span>.</p>
<p>La funzione di probabilità <span class="math inline">\(P()\)</span> deve soddisfare i seguenti assiomi:</p>
<ol style="list-style-type: decimal">
<li>la probabilità <span class="math inline">\(P(\omega)\)</span> soddisfa la disuguaglianza <span class="math inline">\(0 \leq P(\omega) \leq 1;\)</span></li>
<li>la probabilità dell’evento certo (ovvero la probabilità dello spazio
campionario <span class="math inline">\(\Omega\)</span>) è 1: <span class="math inline">\(P(\Omega) = \sum_{\omega \in \Omega} P(\omega) = 1;\)</span></li>
<li>se <span class="math inline">\(A_1, A_2, \dots, A_k\)</span> sono eventi disgiunti, allora la
probabilità che uno di essi si verifichi è pari alla somma delle
loro separate probabilità: <span class="math inline">\(P(A_1 \text{ o } A_1 \dots \text{ o } A_k) = P(A_1) + P(A_2) +\dots + P(A_k).\)</span></li>
</ol>
<p>La definizione <a href="chapter-prob-discreta.html#def:def-assiomi-Kolmogorov">5.2</a> corrisponde al cosiddetto <em>approccio assiomatico</em> messo a punto da Kolmogorov intorno al 1930, il quale è alla base della moderna teoria della probabilità.</p>
<p>Nonostante l’enorme complessità dell’approccio assiomatico alla
probabilità, per gli scopi dell’analisi dei dati psicologici le cose che
dobbiamo capire sono molto semplici. I vincoli della <span class="math inline">\(\sigma\)</span>-algebra
sono necessari per evitare i paradossi che si possono creare quando si
manipolano gli insiemi (ad esempio, l’utilizzo dell’“l’insieme di tutti
gli insiemi” tipicamente conduce ad un paradosso). Questi problemi sono
però molto lontani dalle applicazioni della teoria della probabilità
all’analisi dei dati psicologici. Gli psicologi tipicamente effettuano
partizioni molto semplici dello spazio campionario: il trattamento ha
funzionato oppure no? Per cui le aporie della teoria degli insiemi a cui
la <span class="math inline">\(\sigma\)</span>-algebra vuole porre un freno sono problemi che non ci
riguardano.</p>
<p>Gli altri aspetti della teoria assiomatica della probabilità, invece,
sono molto intuitivi. I primi due assiomi possono essere interpretati
nel modo seguente. Si assegna il valore 0 all’“evento impossibile,”
ovvero all’esito dell’esperimento casuale che non può verificarsi (ad
esempio, il lancio di un dado a sei facce produce 7), e si assegna il
valore 1 all’evento certo (ad esempio, il lancio di un dado a sei facce
produce un numero compreso tra 1 e 6). Di conseguenza, la probabilità è
un numero nell’intervallo <span class="math inline">\([0, 1]\)</span>.</p>
<p>Il terzo assioma può essere compreso interpretando la probabilità come
la frequenza relativa a lungo termine del verificarsi di un evento. Se
due eventi sono incompatibili, allora la frequenza relativa dell’unione
di tali eventi è la somma delle due singole frequenze relative. Lo
stesso si vale per la probabilità.</p>
</div>
</div>
<div id="assegnare-le-probabilità-agli-eventi" class="section level2" number="5.5">
<h2><span class="header-section-number">5.5</span> Assegnare le probabilità agli eventi</h2>
<p>È importante capire che l’approccio assiomatico non ci dice come sia
possibile assegnare un valore di probabilità a un evento definito in
<span class="math inline">\(\Omega\)</span>. A questo proposito esistono due diverse scuole di pensiero.</p>
<div id="approccio-frequentista" class="section level3" number="5.5.1">
<h3><span class="header-section-number">5.5.1</span> Approccio frequentista</h3>
<p>Una prima possibilità è di definire la nozione di probabilità in termini
empirici. La probabilità di un evento <span class="math inline">\(A\)</span> può essere concepita come il
limite cui tende la frequenza relativa dell’evento, al tendere
all’infinito del numero delle prove effettuate, ossia
<span class="math display">\[\begin{equation}
P_A = \lim_{n \to \infty} \frac{n_A}{n}.
\end{equation}\]</span>
Questo è l’approccio che abbiamo utilizzato in precedenza, quando abbiamo discusso il gioco di De Méré.</p>
<p>Tale definizione assume che l’esperimento possa essere ripetuto più
volte, idealmente infinite volte, sotto le medesime condizioni, e
corrisponde alla definizione <em>frequentista</em> di probabilità. Per
l’approccio frequentista, dire che la probabilità di ottenere testa è
0.5 significa affermare che l’evento “testa” verrebbe ottenuto nel 50%
dei casi, se ripetessimo tantissime volte l’esperimento casuale del
lancio di una moneta.</p>
<p>Se non abbiamo a disposizione informazioni empiriche a proposito del
verificarsi di un evento possiamo attribuire le probabilità agli eventi
usando la nostra conoscenza della situazione. Tale approccio è seguito
dalla definizione <em>classica</em> di probabilità in base alla quale la
probabilità di un evento è il rapporto tra il numero di casi favorevoli
e quelli possibili, supposto che tutti gli eventi siano equiprobabili,
ossia <span class="math display">\[P_A = \frac{n_A}{n},\]</span> dove <span class="math inline">\(n\)</span> è il numero di casi possibili e
<span class="math inline">\(n_A\)</span> è il numero di casi favorevoli per l’evento <span class="math inline">\(A\)</span>. L’assunzione di
equiprobabilità degli eventi elementari ha senso soprattutto nel caso
dei giochi d’azzardo.</p>
<p>In base all’approccio frequentista, la probabilità è il limite a cui
tende una frequenza relativa empirica al crescere del numero di
ripetizioni dell’esperimento casuale. È molto facile utilizzare   per
calcolare una tale probabilità. Per esempio, se vogliamo calcolare la
probabilità di ottenere 3 nel lancio di un dado equilibrato, possiamo
eseguire la seguente simulazione.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="chapter-prob-discreta.html#cb26-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fl">1e5</span></span>
<span id="cb26-2"><a href="chapter-prob-discreta.html#cb26-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, n, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb26-3"><a href="chapter-prob-discreta.html#cb26-3" aria-hidden="true" tabindex="-1"></a>x_01 <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(x <span class="sc">==</span> <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb26-4"><a href="chapter-prob-discreta.html#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(x_01)</span>
<span id="cb26-5"><a href="chapter-prob-discreta.html#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.1676</span></span></code></pre></div>
<p>Il risultato è ovviamente molto simile a <span class="math inline">\(1/6\)</span>.</p>
</div>
<div id="approccio-bayesiano" class="section level3" number="5.5.2">
<h3><span class="header-section-number">5.5.2</span> Approccio Bayesiano</h3>
<p>Esistono però degli eventi per i quali non è possibile calcolare una frequenza relativa, ovvero quelli che si verificano una volta soltanto. Che cos’è allora la probabilità in questi casi? In base all’approccio Bayesiano la probabilità è una misura del grado di plausibilità di una proposizione. Questa definizione è applicabile a qualsiasi evento. Ciò consente di assegnare una probabilità anche a proposizioni quali “il candidato <span class="math inline">\(A\)</span> vincerà le elezioni” oppure “l’accusato è innocente,” anche se non è possibile ripetere più volte un’elezione o un evento criminoso.</p>
<p>Per assegnare le probabilità agli eventi, nell’approccio Bayesiano si
utilizzano considerazioni “soggettive” che derivano dalle informazioni
di cui il soggetto è in possesso. Il teorema di Bayes consente di
aggiustare, alla luce dei dati osservati, tali credenze “a priori” per
arrivare alla probabilità a posteriori. Quindi, tramite l’approccio
Bayesiano, si usa una stima del grado di plausibilità di una
proposizione prima dell’osservazione dei dati, al fine di associare un
valore numerico al grado di plausibilità di quella stessa proposizione
successivamente all’osservazione dei dati. Questo processo di
“aggiornamento Bayesiano” corrisponde all’inferenza statistica e verrà
discusso in dettaglio nel seguito delle dispense.</p>
</div>
</div>
<div id="proprietà-elementari-della-probabilità" class="section level2" number="5.6">
<h2><span class="header-section-number">5.6</span> Proprietà elementari della probabilità</h2>
<p>Indipendentemente da come decidiamo di interpretare la probabilità (in
termini frequentisti o Bayesiani), alla probabilità possono essere
assegnate le seguenti proprietà.</p>
<ol style="list-style-type: decimal">
<li><p>La probabilità dell’evento impossibile è zero:
<span class="math display">\[P(\emptyset) = 1 - P(\Omega) = 0.\]</span></p></li>
<li><p>Se consideriamo due eventi <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> tali che <span class="math inline">\(A \subseteq B\)</span>, cioè
che <span class="math inline">\(A\)</span> è contenuto o coincidente con <span class="math inline">\(B\)</span>, da ciò segue che
<span class="math display">\[P(A) \leq P(B).\]</span></p></li>
<li><p>Se <span class="math inline">\(A^c\)</span> è il complementare dell’evento <span class="math inline">\(A\)</span>, allora
<span class="math display">\[P(A^c) = 1 - P(A).\]</span></p></li>
<li><p>Dati <span class="math inline">\(n\)</span> eventi <span class="math inline">\(A_i\)</span> per <span class="math inline">\(i= 1, \cdots, n\)</span>, gli eventi si dicono
<em>indipendenti</em> se risulta
<span class="math display">\[P(A_i \cap A_j \cap \cdots \cap A_k) = P(A_i) P(A_j) \cdots P(A_k).\]</span></p></li>
<li><p>Se due eventi <span class="math inline">\(A\)</span> e <span class="math inline">\(B\)</span> non sono disgiunti, allora quando sommiamo
le loro probabilità dobbiamo evitare che la loro parte comune
<span class="math inline">\(A \cap B\)</span> venga contata due volte. Dati due eventi non
necessariamente disgiunti, dunque, la probabilità dell’unione è pari
alla somma delle singole probabilità dei due eventi meno la
probabilità dell’intersezione:
<span class="math display">\[P(A \text{ o } B) = P(A \cup B) = P(A) + P(B) - P(A \cap B).\]</span></p></li>
</ol>

<div class="exercise">
<span id="exr:ex-parlamento-londra" class="exercise"><strong>Exercizio 5.1  </strong></span>Nel 2012, a 97 deputati al Parlamento di Londra è stato chiesto: “Se lanci una moneta due volte, qual è la probabilità di ottenere due volte testa?” La maggioranza, 60 su 97, non ha saputo dare la risposta corretta. Come possiamo dare a questo problema una risposta migliore di quella fornita da questi politici?
</div>

<div class="solution">
 <span class="solution"><em>Soluzione. </em></span> In base alla regola 4 elencata sopra, la risposta corretta è <span class="math inline">\(0.5 \times 0.5 = 0.25\)</span>.
</div>

<div class="exercise">
<span id="exr:ex-urna-10b-10r-10g" class="exercise"><strong>Exercizio 5.2  </strong></span>Un’urna contiene <span class="math inline">\(30\)</span> palline: <span class="math inline">\(10\)</span> bianche numerate da <span class="math inline">\(1\)</span> a <span class="math inline">\(10\)</span>, <span class="math inline">\(10\)</span>
rosse e <span class="math inline">\(10\)</span> gialle numerate allo stesso modo. Qual è la probabilità
che, estraendo una pallina a caso, venga estratta una pallina gialla o
una pallina pari?
</div>

<div class="solution">
 <span class="solution"><em>Soluzione. </em></span> Il numero totale di palline è <span class="math inline">\(30\)</span>. La probabilità che venga estratta
una gialla è <span class="math inline">\(P(G) = \frac{10}{30} = \frac{1}{3}\)</span>. Le palline con numero
pari sono <span class="math inline">\(5\)</span> per ogni colore, quindi <span class="math inline">\(15\)</span>. La probabilità che venga
estratto un numero pari è <span class="math inline">\(P(P) = \frac{15}{30} = \frac{1}{2}\)</span>. Gli
eventi sono compatibili: i casi favorevoli a entrambi gli eventi
(pallina gialla e pari) sono <span class="math inline">\(5\)</span>. La probabilità dell’evento cercato è
dunque
<span class="math inline">\(P(\text{gialla} \cup \text{pari}) = \frac{1}{3} + \frac{1}{2} - \frac{5}{30} = \frac{2}{3}\)</span>.
</div>
</div>
<div id="variabili-aleatorie" class="section level2" number="5.7">
<h2><span class="header-section-number">5.7</span> Variabili aleatorie</h2>
<p>Il concetto di “variabile aleatoria” è estremamente utile per estendere
la nostra capacità di quantificare l’incertezza e di riassumere i
risultati di un esperimento casuale. Le variabili aleatorie sono un
concetto fondamentale di tutta la teoria statistica; è quindi cruciale
capire quale sia il loro significano. Iniziamo con una definizione.</p>

<div class="definition">
<span id="def:def-var-aleatoria" class="definition"><strong>Definizione 5.3  </strong></span>Una variabile aleatoria è una funzione sullo spazio campionario <span class="math inline">\(\Omega\)</span>
che associa ad ogni evento elementare <span class="math inline">\(\omega_i\)</span> un unico numero
<span class="math inline">\(X(\omega_i) = x_i\)</span>, ovvero <span class="math inline">\(X: \Omega \rightarrow \Re\)</span>.
</div>
<p>Il dominio della variabile aleatoria <span class="math inline">\(X\)</span> (che è una funzione) è dato dai
punti dello spazio campionario <span class="math inline">\(\Omega\)</span>. Ad ogni evento elementare
<span class="math inline">\(\omega_i\)</span> attribuiamo il numero <span class="math inline">\(X(\omega_i)\)</span>, ovvero il valore che la
variabile aleatoria assume sul risultato <span class="math inline">\(\omega_i\)</span> dell’esperimento
casuale. L’attributo “aleatoria” si riferisce al fatto che la variabile
considerata trae origine da un esperimento di cui non siamo in grado di
prevedere l’esito con certezza.</p>
<p>Mediante una variabile aleatoria trasformiamo lo spazio campionario
<span class="math inline">\(\Omega\)</span>, che in genere è complesso, in uno spazio campionario più
semplice formato da un insieme di numeri. Il maggior vantaggio di questa
sostituzione è che molte variabili aleatorie, definite su spazi
campionari anche molto diversi tra loro, danno luogo ad una stessa
“distribuzione” di probabilità sull’asse reale. Le variabili aleatorie
si indicano con le lettere maiuscole ed i valori da esse assunti con le
lettere minuscole.</p>
<p>Ci sono due classi di variabili aleatorie: variabili aleatorie discrete
e variabili aleatorie continue. Consideriamo innanzitutto il caso delle
variabili aleatorie discrete.</p>
<p>Una variabile aleatoria <span class="math inline">\(X\)</span> viene detta discreta se può assumere un
insieme discreto (finito o numerabile) di numeri reali.</p>
<p>Se <span class="math inline">\(X\)</span> è una variabile aleatoria discreta allora l’insieme dei possibili
valori <span class="math inline">\(x\)</span>, tali per cui <span class="math inline">\(P(X = x) &gt; 0\)</span>, viene detto “supporto” di <span class="math inline">\(X\)</span>.</p>
<p>Alcuni esempi di variabili aleatorie discrete sono i seguenti: il numero
di intrusioni di pensieri, immagini, impulsi indesiderabili in un
paziente OCD, il voto all’esame di Psicometria, la durata di vita di un
individuo, il numero dei punti che si osservano nel lancio di due dadi e
il guadagno (la perdita) che un giocatore realizzerà in <span class="math inline">\(n\)</span> partite. Si
noti che, in tutti questi casi, la variabile aleatoria considerata viene
rappresentata mediante un numero.</p>
<div id="a-cosa-servono-le-variabili-aleatorie" class="section level3" number="5.7.1">
<h3><span class="header-section-number">5.7.1</span> A cosa servono le variabili aleatorie?</h3>
<p>Facendo riferimento agli esempi elencati sopra, possiamo chiederci
perché questi numeri vengono considerati come “aleatori.” È ovvio che
noi non conosciamo, ad esempio, il voto di Psicometria di Mario Rossi
prima del momento in cui Mario Rossi avrà fatto l’esame. Le variabili
aleatorie si pongono il seguente problema: come possiamo descrivere le
nostre opinioni rispetto al voto (possibile) di Mario Rossi, prima che
lui abbia fatto l’esame. Prima dell’esame, il voto di Psicometria di
Mario Rossi si può solo descrivere facendo riferimento ad un insieme di
valori possibili. Inoltre, molto spesso, possiamo anche dire che tali
valori possibili non sono tutti egualmente verosimili: ci aspettiamo di
osservare più spesso alcuni di questi valori rispetto agli altri. Le
proprietà delle variabili aleatorie ci consentono di sistematizzare
questo tipo di opinioni. Ovviamente, una volta che Mario Rossi avrà
fatto l’esame, questa materia non avrà più alcuna componente aleatoria.</p>
</div>
<div id="funzione-di-massa-di-probabilità" class="section level3" number="5.7.2">
<h3><span class="header-section-number">5.7.2</span> Funzione di massa di probabilità</h3>
<p>Per entrare nel merito di questa discussione, chiediamoci ora come sia
possibile associare delle probabilità ai valori che vengono assunti
dalle variabili aleatorie. Ad esempio, qual è la probabilità che Mario
Rossi ottenga 29 all’esame? Ci occuperemo qui del caso delle variabili
aleatorie discrete.</p>
<p>Alle variabili aleatorie discrete vengono assegnale le probabilità
mediante le cosiddette “distribuzioni di probabilità.” Una distribuzione
di probabilità è un modello matematico che collega ciascun valore di una
variabile aleatoria discreta alla probabilità di osservare un tale
valore in un esperimento casuale. In pratica, ad ognuno dei valori che
possono essere assunti da una variabile aleatoria discreta viene
associata una determinata probabilità. La funzione che associa ad ogni
valore della variabile aleatoria una probabilità corrispondente si
chiama “distribuzione di probabilità” oppure “legge di probabilità.”</p>
<p>Una descrizione intuitiva del concetto di distribuzione di probabilità
può essere formulata nei termini seguenti. Possiamo pensare alla
probabilità come ad una quantità positiva che viene “distribuita”
sull’insieme dei valori della variabile aleatoria. Tale “distribuzione”
(suddivisione, spartizione) viene scalata in maniera tale che ciascun
elemento di essa corrisponda ad una proporzione del totale, nel senso
che il valore totale della distribuzione è sempre pari a 1. Una
distribuzione di probabilità non è dunque altro che un modo per
suddividere la nostra certezza (cioè 1) tra i valori che la variabile
aleatoria può assumere. In modo più formale, possiamo dire quanto segue.</p>
<p>Se <span class="math inline">\(X\)</span> è una variabile aleatoria discreta, una distribuzione di
probabilità può essere rappresentata mediante una funzione di massa di
probabilità che associa a ciascuno dei valori <span class="math inline">\(x\)</span> che la variabile
aleatoria <span class="math inline">\(X\)</span> può assumere la corrispondente probabilità <span class="math inline">\(P_{\pi}(X=x)\)</span>.</p>
<p>In maniera più semplice, una distribuzione di (massa) di probabilità è
formata dall’elenco di tutti i valori possibili di una variabile
aleatoria discreta e dalle probabilità loro associate. Si noti che
<span class="math inline">\(P_{\pi}(X=x)\)</span> è un numero positivo se il valore <span class="math inline">\(x\)</span> è compreso nel
supporto di <span class="math inline">\(X\)</span>, altrimenti vale 0.</p>
<p>Se <span class="math inline">\(A\)</span> è un sottoinsieme della variabile aleatoria <span class="math inline">\(X\)</span>, allora denotiamo
con <span class="math inline">\(P_{\pi}(A)\)</span> la probabilità assegnata ad <span class="math inline">\(A\)</span> dalla distribuzione
<span class="math inline">\(P_{\pi}\)</span>. Mediante una distribuzione di probabilità <span class="math inline">\(P_{\pi}\)</span> è
possibile determinare la probabilità di ciascun sottoinsieme
<span class="math inline">\(A \subset X\)</span> come <span class="math display">\[P_{\pi}(A) = \sum_{x \in A} P_{\pi}(x).\]</span> Qui non
facciamo altro che applicare il terzo assioma di Kolmogorov – si veda
l’eq. <a href="#eq:kolmogorov_3" reference-type="eqref" reference="eq:kolmogorov_3"><span class="math display">\[eq:kolmogorov_3\]</span></a>.</p>
<p><span id="exercise:prob_distr_2dice" label="exercise:prob_distr_2dice"><span class="math display">\[exercise:prob_distr_2dice\]</span></span> Consideriamo nuovamente lo spazio
campionario <span class="math inline">\(\Omega\)</span>
dell’esercizio <a href="#exercise:sampling_space_2dice" reference-type="ref" reference="exercise:sampling_space_2dice"><span class="math display">\[exercise:sampling_space_2dice\]</span></a> e definiamo la variabile
aleatoria <span class="math inline">\(S(\omega)\)</span> come la somma dei puntini che si ottengono dal
lancio di due dadi. Per esempio,
<span class="math inline">\(S\big(\epsdice{6}\epsdice{3}\big) = 6+3=9\)</span>. Iniziamo a chiederci qual è
la probabilità dell’evento <span class="math inline">\(S = 7\)</span>.</p>
<p>Per risolvere tale problema iniziamo a considerare il fatto che l’evento
<span class="math inline">\(S = 7\)</span> si verifica in corrispondenza di sei punti elementari dello
spazio campionario <span class="math inline">\(\Omega\)</span>: <span class="math inline">\(\epsdice{1}\epsdice{6}\)</span>,
<span class="math inline">\(\epsdice{2}\epsdice{5}\)</span>, <span class="math inline">\(\epsdice{3}\epsdice{4}\)</span>,
<span class="math inline">\(\epsdice{4}\epsdice{3}\)</span>, <span class="math inline">\(\epsdice{5}\epsdice{2}\)</span>,
<span class="math inline">\(\epsdice{6}\epsdice{1}\)</span>. Dunque,
<span class="math display">\[P(S = 7) = P\big(\epsdice{1}\epsdice{6}\big) + P\big(\epsdice{2}\epsdice{5}\big) + P\big(\epsdice{3}\epsdice{4}\big) + P\big(\epsdice{4}\epsdice{3}\big) + P\big(\epsdice{5}\epsdice{2}\big) + P\big(\epsdice{6}\epsdice{1}\big).\]</span>
Se possiamo assumere che i due dadi sono bilanciati, allora ciascun
evento elementare dello spazio campionario ha probabilità <span class="math inline">\(\frac{1}{36}\)</span>
e la probabilità cercata diventa <span class="math inline">\(\frac{1}{6}\)</span>. È facile estendere il
ragionamento fatto sopra a tutti i valori che <span class="math inline">\(S\)</span> può assumere. In
questo modo giungiamo alla funzione di massa di probabilità <span class="math inline">\(P_0\)</span>
riportata nella prima riga della
tabella <a href="chapter-prob-discreta.html#tab:massa_prob_due_dadi_on_tr" reference-type="ref" reference="tab:massa_prob_due_dadi_on_tr">1.1</a>.</p>
::: {#tab:massa_prob_due_dadi_on_tr}
<table>
<caption>
Distribuzione di massa di probabilità per la somma dei punti prodotti dal lancio di due dadi bilanciati (<span class="math inline"><em>P</em><sub>0</sub></span>) e di due dadi truccati (<span class="math inline"><em>P</em><sub>1</sub></span>).
</caption>
<thead>
<tr class="header">
<th style="text-align: center;">
s
</th>
<th style="text-align: center;">
2
</th>
<th style="text-align: center;">
3
</th>
<th style="text-align: center;">
4
</th>
<th style="text-align: center;">
5
</th>
<th style="text-align: center;">
6
</th>
<th style="text-align: center;">
7
</th>
<th style="text-align: center;">
8
</th>
<th style="text-align: center;">
9
</th>
<th style="text-align: center;">
10
</th>
<th style="text-align: center;">
11
</th>
<th style="text-align: center;">
12
</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">
<span class="math inline"><em>P</em><sub>0</sub>(<em>S</em> = <em>s</em>)</span>
</td>
<td style="text-align: center;">
<span class="math inline"><span class="math inline">\(\frac{1}{36}\)</span></span>
</td>
<td style="text-align: center;">
<span class="math inline"><span class="math inline">\(\frac{2}{36}\)</span></span>
</td>
<td style="text-align: center;">
<span class="math inline"><span class="math inline">\(\frac{3}{36}\)</span></span>
</td>
<td style="text-align: center;">
<span class="math inline"><span class="math inline">\(\frac{4}{36}\)</span></span>
</td>
<td style="text-align: center;">
<span class="math inline"><span class="math inline">\(\frac{5}{36}\)</span></span>
</td>
<td style="text-align: center;">
<span class="math inline"><span class="math inline">\(\frac{6}{36}\)</span></span>
</td>
<td style="text-align: center;">
<span class="math inline"><span class="math inline">\(\frac{5}{36}\)</span></span>
</td>
<td style="text-align: center;">
<span class="math inline"><span class="math inline">\(\frac{4}{36}\)</span></span>
</td>
<td style="text-align: center;">
<span class="math inline"><span class="math inline">\(\frac{3}{36}\)</span></span>
</td>
<td style="text-align: center;">
<span class="math inline"><span class="math inline">\(\frac{2}{36}\)</span></span>
</td>
<td style="text-align: center;">
<span class="math inline"><span class="math inline">\(\frac{1}{36}\)</span></span>
</td>
</tr>
<tr class="even">
<td style="text-align: center;">
<hr />
<p>
<span class="math inline"><em>P</em><sub>1</sub>(<em>S</em> = <em>s</em>)</span>
</p>
</td>
<td style="text-align: center;">
<span class="math inline"><span class="math inline">\(\frac{4}{64}\)</span></span>
</td>
<td style="text-align: center;">
<span class="math inline"><span class="math inline">\(\frac{4}{64}\)</span></span>
</td>
<td style="text-align: center;">
<span class="math inline"><span class="math inline">\(\frac{5}{64}\)</span></span>
</td>
<td style="text-align: center;">
<span class="math inline"><span class="math inline">\(\frac{6}{64}\)</span></span>
</td>
<td style="text-align: center;">
<span class="math inline"><span class="math inline">\(\frac{7}{64}\)</span></span>
</td>
<td style="text-align: center;">
<span class="math inline"><span class="math inline">\(\frac{12}{64}\)</span></span>
</td>
<td style="text-align: center;">
<span class="math inline"><span class="math inline">\(\frac{7}{64}\)</span></span>
</td>
<td style="text-align: center;">
<span class="math inline"><span class="math inline">\(\frac{6}{64}\)</span></span>
</td>
<td style="text-align: center;">
<span class="math inline"><span class="math inline">\(\frac{5}{64}\)</span></span>
</td>
<td style="text-align: center;">
<span class="math inline"><span class="math inline">\(\frac{4}{64}\)</span></span>
</td>
<td style="text-align: center;">
<span class="math inline"><span class="math inline">\(\frac{4}{64}\)</span></span>
</td>
</tr>
</tbody>
</table>
<p>: Distribuzione di massa di probabilità per la somma dei punti prodotti
dal lancio di due dadi bilanciati (<span class="math inline">\(P_0\)</span>) e di due dadi truccati
(<span class="math inline">\(P_1\)</span>).
:::</p>
<p><span id="tab:massa_prob_due_dadi_on_tr" label="tab:massa_prob_due_dadi_on_tr"><span class="math display">\[tab:massa_prob_due_dadi_on_tr\]</span></span></p>
<p>Per considerare un caso più generale, poniamoci ora il problema di
trovare la funzione di massa di probabilità di <span class="math inline">\(S\)</span> nel caso di due dadi
truccati aventi la seguente distribuzione di probabilità:
<span class="math display">\[\begin{aligned}
P\big(\epsdice{1}\big) &amp;= P\big(\epsdice{6}\big) = \frac{1}{4};\notag\\
P\big(\epsdice{2}\big) &amp;= P\big(\epsdice{3}\big) = P\big(\epsdice{4}\big) = P\big(\epsdice{5}\big) = \frac{1}{8}\notag.
\label{eq:loaded_dice}\end{aligned}\]</span> Nel caso dei due dadi truccati, la
probabilità dell’evento elementare <span class="math inline">\(\epsdice{1}\epsdice{1}\)</span> è
<span class="math inline">\(\frac{1}{4}\frac{1}{4}\)</span>. Dunque, <span class="math inline">\(P(S=2) = \frac{4}{64}\)</span>. La
probabilità dell’evento elementare <span class="math inline">\(\epsdice{1}\epsdice{2}\)</span> è
<span class="math inline">\(\frac{1}{4}\frac{1}{8}\)</span>. Tale valore è uguale alla probabilità
dell’evento elementare <span class="math inline">\(\epsdice{2}\epsdice{1}\)</span>. Dunque, la probabilità
che <span class="math inline">\(S\)</span> sia uguale a 3 è
<span class="math inline">\(\frac{1}{4}\frac{1}{8} + \frac{1}{8}\frac{1}{4} = \frac{4}{64}\)</span>, e così
via. Svolgendo i calcoli per tutti i possibili valori di <span class="math inline">\(S\)</span> otteniamo
la funzione di massa di probabilità <span class="math inline">\(P_1\)</span> riportata nella seconda riga
della tabella <a href="chapter-prob-discreta.html#tab:massa_prob_due_dadi_on_tr" reference-type="ref" reference="tab:massa_prob_due_dadi_on_tr">1.1</a>.</p>
<p>Si noti che, a partire dalla funzione di massa di probabilità di <span class="math inline">\(S\)</span>, è
possibile calcolare la probabilità di altri eventi. Per esempio,
possiamo dire che l’evento <span class="math inline">\(S &gt; 10\)</span> ha una probabilità minore nel caso
dei dadi bilanciati, <span class="math inline">\(P_0(S &gt; 10) = \frac{3}{36} = \frac{1}{12}\)</span>,
rispetto al caso dei dadi truccati considerati in precedenza,
<span class="math inline">\(P_1(S &gt; 10) = \frac{8}{64} = \frac{1}{8}\)</span>.</p>
</div>
</div>
<div id="notazione" class="section level2" number="5.8">
<h2><span class="header-section-number">5.8</span> Notazione</h2>
<p>Qui sotto è riportata la notazione che verrà usata per fare riferimento
ad eventi e probabilità, nel caso discreto e continuo, in maniera tale
che queste convenzioni siano elencate tutte in un posto solo.</p>
<ul>
<li><p>Gli eventi sono denotati da lettere maiuscole, es. <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span>, <span class="math inline">\(C\)</span>.</p></li>
<li><p>Una variabile aleatoria è denotata da una lettera maiuscola, ad
esempio <span class="math inline">\(X\)</span>, e assume valori denotati dalla stessa lettera
minuscola, ad esempio <span class="math inline">\(x\)</span>.</p></li>
<li><p>La connessione tra eventi e valori viene espressa nei termini
seguenti: “<span class="math inline">\(X = x\)</span>” significa che l’evento <span class="math inline">\(X\)</span> assume il valore <span class="math inline">\(x\)</span>.</p></li>
<li><p>La probabilità di un evento è denotata con <span class="math inline">\(P(A)\)</span>.</p></li>
<li><p>Una variabile aleatoria discreta ha una funzione di massa di
probabilità denotata con <span class="math inline">\(p(x)\)</span>. La relazione tra <span class="math inline">\(P\)</span> e <span class="math inline">\(p\)</span> è che
<span class="math inline">\(P(X=x) = p(x)\)</span>.</p></li>
</ul>
</div>
<div id="conclusioni" class="section level2 unnumbered">
<h2>Conclusioni</h2>
<p>In questo capitolo abbiamo visto come si costruisce lo spazio
campionario di un esperimento casuale, quali sono le proprietà di base
della probabilità e come si assegnano le probabilità agli eventi
definiti sopra uno spazio campionario discreto. Abbiamo anche introdotto
le nozioni di “variabile aleatoria” e di “funzione di massa di
probabilità.” Le procedure di analisi dei dati psicologici che
discuteremo in seguito faranno un grande uso di questi concetti e della
notazione qui introdotta.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chapter-descriptive-stats.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bibliografia.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/ccaudek/bookdown_psicometria/edit/master/05_prob_intro.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/ccaudek/bookdown_psicometria/blob/master/05_prob_intro.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"facebook": false,
"twitter": true,
"github": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
