[["index.html", "PSICOMETRIA Prefazione", " PSICOMETRIA Corrado Caudek 2021-01-10 Prefazione Questo WORK-IN-PROGRESS è stato aggiornato il giorno: 10 Gen 2021. Le presenti dispense contengono il materiale delle lezioni dell’insegnamento Psicometria B000286 (A.A. 2020/2021) rivolto agli studenti del primo anno del Corso di Laurea in Scienze e Tecniche Psicologiche dell’Università di Firenze. "],["obiettivi.html", "Obiettivi", " Obiettivi L’insegnamento di Psicometria si propone di fornire agli studenti un’introduzione all’analisi dei dati in psicologia. Alcuni degli argomenti trattati richiedono delle conoscenze pregresse, soprattutto di tipo matematico. Tali conoscenze sono state aggiunte delle appendici di queste dispense. La lettura di tale materiale è consigliata a tutti, sia a chi sta studiando gli argomenti proposti per la prima volta, sia a chi deve ripassare per colmare eventuali lacune pregresse. "],["perché-tanta-statistica-in-psicologia.html", "Perché tanta statistica in psicologia?", " Perché tanta statistica in psicologia? Sembra sensato spendere due parole su un tema che è importante per gli studenti: quello indicato dal titolo di questa sezione. È ovvio che agli studenti di psicologia la statistica non piace. Se piacesse, forse studierebbero statistica e non psicologia; ma non lo fanno. Di conseguenza, gli studenti di psicologia si chiedono: ``perché dobbiamo perdere tanto tempo a studiare queste cose quando in realtà quello che ci interessa è tutt’altro?’’ Questa è una bella domanda. Per cercare di rispondere a questa domanda introduco il paradosso di Simpson. Consideriamo un fenomeno sociale che ha suscitato un enorme interesse in tempi recenti: la brutalità della polizia e le diseguaglianze razziali messe in evidenza dalle uccisioni da parte della polizia statunitense. Per affrontare questo tema, esaminiamo l’analisi statistica descritta in un articolo di Ross et al. (2020). La logica di tale analisi statistica può essere descritta nel modo seguente. Immaginiamo due gruppi di individui: Montechi e Capuleti. Il 10% dei Montechi e il 20% dei Capuleti commette crimini violenti (ovvero, sono dei criminali). In un anno, il 14% dei Montechi viene ucciso dalla polizia contro il 26% dei Capuleti. Come si fa a capire se c’è un pregiudizio verso uno dei due gruppi? Cesario et al. (2019) sostengono che è necessario dividere la frequenza relativa di uccisioni da parte della polizia per la percentuale di criminali in ciascun gruppo. Quindi, secondo questa logica, il tasso di uccisioni da parte della polizia è di 14/10 = 1.4% per i Capuleti e di 26/20 = 1.3% per i Montechi. Questo indica una discriminazione contro i Capuleti e ci fornisce la risposta alla nostra domanda. Ma le cose stanno effettivamente così? Forse no. Se decomponiamo il numero di uccisioni da parte della polizia in ciascuna delle modalità della variabile criminalità (ovvero, criminali vs. non criminali), scopriamo che, per i Capuleti, i 14 morti possono essere suddivisi in 5 morti di criminali e 9 morti di non criminali. Per Montechi, i 26 morti si suddividono in 10 morti di criminali e 16 morti di non criminali. Quindi, i criminali Capuleti vengono uccisi dalla polizia ad un tasso del 5/10 = 50% e i criminali Montechi vengono uccisi ad un tasso del 10/20 = 50% – lo stesso tasso nei due gruppi. Ma i non criminali Capuleti vengono uccisi dalla polizia ad un tasso del 9/90 = 10%, mentre i non criminali Montechi vengono uccisi ad un tasso del 16/80 = 20%. Ciò significa che i criminali di entrambi i gruppi hanno la stessa probabilità di essere uccisi dalla polizia, ma i non criminali Montechi hanno due volte la probabilità di essere uccisi dalla polizia dei non criminali Capuleti. Questo indica un’enorme discriminazione contro i Montechi! Eppure, l’analisi precedente aveva prodotto il risultato opposto. Lasciando perdere Shakespeare, Ross et al. (2020) hanno dimostrato che questo è esattamente ciò che sta succedendo con i dati reali sulle sparatorie della polizia negli Stati Uniti: i neri disarmati negli Stati Uniti vengono uccisi a tassi molto più alti rispetto ai bianchi disarmati, sebbene i tassi siano simili nei due gruppi quando si considerano solo le sparatorie con individui armati; se tuttavia si riassumono i dati considerando solo la frequenza totale dei morti scalata per il tasso di criminalità questo fatto viene oscurato. L’articolo di ci fa vedere come sia necessario stare molto attenti con l’uso della statistica, specialmente quando gli errori statistici possono avere un impatto enorme sulla percezione pubblica – e, nella psicologia, sulla pratica dello psicologo. Le analisi statistiche precedenti sono un esempio di ciò che viene chiamato il paradosso di Simpson, ovvero il fatto che, alle volte, quando si riassumono i dati in un modo apparentemente ragionevole, si finisce per giungere ad una conclusione del tutto sbagliata. Il paradosso di Simpson illustra il fatto che non è semplice neppure i dati, figurarsi poi fare delle inferenze! Queste considerazioni ci fanno capire che, senza un certo livello di consapevolezza metodologica, lo psicologo (e non solo) si espone al rischio di fare errori gravissimi. Ma c’è un’altra ragione ancora più semplice che dovrebbe farci capire perché la statistica è così importante per la psicologia. Infatti, a ben pensarci, la psicologia è una disciplina intrinsecamente statistica, se per statistica intendiamo quella disciplina che studia la variazione delle caratteristiche degli individui nella popolazione. La psicologia studia gli individui ed è proprio la variabilità inter- e intra-individuale ciò che vogliamo descrivere e, in certi casi, predire. In questo senso, la psicologia è molto diversa dall’ingegneria, per esempio. Le proprietà di un determinato ponte, sotto certe condizioni, sono molto simili a quelle di un altro ponte, sotto le medesime condizioni. Quindi, per un ingegnere la statistica è poco importante: le proprietà dei materiali sono unicamente dipendenti dalla loro composizione e restano costanti. Ma lo stesso non si può dire degli individui: ogni individuo è unico e cambia nel tempo. E le variazioni tra gli individui, e di un individuo nel tempo, sono l’oggetto di studio proprio della psicologia: è dunque chiaro che i problemi che la psicologia si pone sono molto diversi da quelli affrontati, per esempio, dagli ingegneri. Questa è la ragione per cui abbiamo tanto bisogno della statistica in psicologia: perché la statistica ci consente di descrivere la variazione e il cambiamento. E queste sono appunto le caratteristiche di base dei fenomeni psicologici. Sono sicuro che, leggendo queste righe, a molti studenti sarà venuta in mente la seguente domanda: perché non chiediamo a qualche esperto di fare il “lavoro sporco” (ovvero le analisi statistiche) per noi, mentre noi (psicologi) ci occupiamo solo di ciò che ci interessa, ovvero dei problemi psicologici slegati dai dettagli `tecnici’ della statistica? La risposta a questa domanda è che non è possibile progettare uno studio psicologico sensato senza avere almeno una comprensione rudimentale della teoria statistica. Ma non possiamo liberarci della statistica anche se non vogliamo diventare dei ricercatori e ci accontentiamo di svolgere la professione di psicologo. Infatti, anche in questo secondo caso, non possiamo fare a meno di leggere la letteratura psicologica più recente: il continuo aggiornamento delle nostre conoscenze è infatti richiesto dalla deontologia della professione. Ma è necessario conoscere un bel po’ di statistica per potere fare questo. Per rendersi conto di quanto ciò sia vero basta aprire a caso una rivista specialistica di psicologia: gli articoli che riportano i risultati delle ricerche psicologiche sono zeppi di analisi statistiche e di modelli formali. E la comprensione della letteratura psicologica è proprio uno dei requisiti minimi del bagaglio professionale dello psicologo. Le considerazioni precedenti cercano di chiarire il seguente punto: la statistica non è qualcosa che, in un singolo insegnamento universitario, dobbiamo studiare a malincuore, per poi potercela tranquillamente dimenticare. Nel bene e nel male, gli psicologi usano strumenti statistici in tantissime fasi della loro attività professionale: in particolare quando costruiscono, somministrano e interpretano i test psicometrici. È dunque chiaro che possedere delle solide basi di statistica è un tassello imprescindibile del bagaglio professionale dello psicologo. "],["come-studiare.html", "Come studiare?", " Come studiare? Il giusto metodo di studio per prepararsi all’esame di Psicometria è quello di seguire attivamente le lezioni, assimilare i concetti via via che essi vengono presentati e verificare in autonomia le procedure presentate a lezione. È importante fare domande a lezione per sviluppare la capacità di mettere in relazione tra loro i diversi argomenti trattati, prendere parte alle esercitazioni organizzate dai Peer Tutor, utilizzare i forum attivi su Moodle e, soprattutto, svolgere gli esercizi proposti su Moodle. I problemi forniti su Moodle rappresentano la difficoltà richiesta per superare l’esame e consentono allo studente di capire se le competenze sviluppate risultino essere sufficienti rispetto alle richieste dell’insegnamento. Incoraggio inoltre gli studenti a venire a ricevimento e parlare con me per per chiarire ciò che non si è capito appieno. "],["chapter-pacchetti.html", "Capitolo 1 Pacchetti", " Capitolo 1 Pacchetti Riporto qui tutti i pacchetti che verranno usati in queste dispense. suppressPackageStartupMessages(library(&quot;here&quot;)) suppressPackageStartupMessages(library(&quot;tidyverse&quot;)) suppressPackageStartupMessages(library(&quot;ggpubr&quot;)) suppressPackageStartupMessages(library(&quot;ggExtra&quot;)) suppressPackageStartupMessages(library(&quot;car&quot;)) suppressPackageStartupMessages(library(&quot;cowplot&quot;)) suppressPackageStartupMessages(library(&quot;tidybayes&quot;)) suppressPackageStartupMessages(library(&quot;datasauRus&quot;)) suppressPackageStartupMessages(library(&quot;RColorBrewer&quot;)) suppressPackageStartupMessages(library(&quot;rio&quot;)) suppressPackageStartupMessages(library(&quot;papaja&quot;)) library(&quot;patchwork&quot;) set.seed(12345) sessionInfo() #&gt; R version 3.6.3 (2020-02-29) #&gt; Platform: x86_64-apple-darwin15.6.0 (64-bit) #&gt; Running under: macOS Mojave 10.14.6 #&gt; #&gt; Matrix products: default #&gt; BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib #&gt; LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib #&gt; #&gt; locale: #&gt; [1] it_IT.UTF-8/it_IT.UTF-8/it_IT.UTF-8/C/it_IT.UTF-8/it_IT.UTF-8 #&gt; #&gt; attached base packages: #&gt; [1] parallel stats graphics grDevices utils datasets methods base #&gt; #&gt; other attached packages: #&gt; [1] foreign_0.8-75 rethinking_2.01 dagitty_0.3-0 rstan_2.21.2 #&gt; [5] StanHeaders_2.21.0-7 ggfortify_0.4.11 rio_0.5.16 RColorBrewer_1.1-2 #&gt; [9] tidybayes_2.3.1 cowplot_1.1.1 car_3.0-10 carData_3.0-4 #&gt; [13] ggExtra_0.9 ggpubr_0.4.0 datasauRus_0.1.4 patchwork_1.1.1 #&gt; [17] here_1.0.1 papaja_0.1.0.9997 forcats_0.5.0 stringr_1.4.0 #&gt; [21] dplyr_1.0.2 purrr_0.3.4 readr_1.4.0 tidyr_1.1.2 #&gt; [25] tibble_3.0.4 ggplot2_3.3.3 tidyverse_1.3.0 goodshirt_0.2.2 #&gt; #&gt; loaded via a namespace (and not attached): #&gt; [1] readxl_1.3.1 backports_1.2.1 plyr_1.8.6 splines_3.6.3 #&gt; [5] svUnit_1.0.3 inline_0.3.17 digest_0.6.27 htmltools_0.5.0 #&gt; [9] magick_2.5.2 fansi_0.4.1 magrittr_2.0.1 openxlsx_4.2.3 #&gt; [13] modelr_0.1.8 RcppParallel_5.0.2 matrixStats_0.57.0 askpass_1.1 #&gt; [17] prettyunits_1.1.1 colorspace_2.0-0 rvest_0.3.6 ggdist_2.4.0 #&gt; [21] haven_2.3.1 xfun_0.20 callr_3.5.1 crayon_1.3.4 #&gt; [25] jsonlite_1.7.2 glue_1.4.2 gtable_0.3.0 V8_3.4.0 #&gt; [29] distributional_0.2.1 pkgbuild_1.2.0 shape_1.4.5 abind_1.4-5 #&gt; [33] scales_1.1.1 mvtnorm_1.1-1 qpdf_1.1 DBI_1.1.0 #&gt; [37] rstatix_0.6.0 miniUI_0.1.1.1 Rcpp_1.0.5 xtable_1.8-4 #&gt; [41] stats4_3.6.3 pdftools_2.3.1 httr_1.4.2 arrayhelpers_1.1-0 #&gt; [45] ellipsis_0.3.1 pkgconfig_2.0.3 loo_2.4.1 farver_2.0.3 #&gt; [49] dbplyr_2.0.0 utf8_1.1.4 cowsay_0.8.0 tidyselect_1.1.0 #&gt; [53] labeling_0.4.2 rlang_0.4.10 later_1.1.0.1 munsell_0.5.0 #&gt; [57] cellranger_1.1.0 tools_3.6.3 fortunes_1.5-4 cli_2.2.0 #&gt; [61] generics_0.1.0 broom_0.7.3 evaluate_0.14 fastmap_1.0.1 #&gt; [65] yaml_2.2.1 processx_3.4.5 knitr_1.30.2 fs_1.5.0 #&gt; [69] zip_2.1.1 nlme_3.1-151 mime_0.9 xml2_1.3.2 #&gt; [73] compiler_3.6.3 rstudioapi_0.13 curl_4.3 ggsignif_0.6.0 #&gt; [77] reprex_0.3.0 stringi_1.5.3 highr_0.8 ps_1.5.0 #&gt; [81] lattice_0.20-41 Matrix_1.3-2 vctrs_0.3.6 pillar_1.4.7 #&gt; [85] lifecycle_0.2.0 rmsfact_0.0.3 data.table_1.13.6 httpuv_1.5.4 #&gt; [89] R6_2.5.0 bookdown_0.21.4 promises_1.1.1 gridExtra_2.3 #&gt; [93] codetools_0.2-18 boot_1.3-25 MASS_7.3-53 assertthat_0.2.1 #&gt; [97] rprojroot_2.0.2 withr_2.3.0 mgcv_1.8-33 hms_0.5.3 #&gt; [101] grid_3.6.3 coda_0.19-4 rmarkdown_2.6.4 shiny_1.5.0 #&gt; [105] lubridate_1.7.9.2 tinytex_0.28 "],["cha-install.html", "Capitolo 2 Per cominciare Obiettivi di apprendimento Motivazione 2.1 Installare R e RStudio 2.2 Utilizzare RStudio per semplificare il lavoro", " Capitolo 2 Per cominciare Obiettivi di apprendimento Lo studio di questo capitolo dovrebbe insegnare allo studente come: Installare R e RStudio. Motivazione Al fine di utilizzare R è necessario eseguire le seguenti tre operazioni nell’ordine dato: Installare R; Installare RStudio; Installare R-Packages (se necessario). Vedremo qui come installare R e RStudio. 2.1 Installare R e RStudio R è disponibile gratuitamente ed è scaricabile dal sito http://www.rproject.org/. Dalla pagina principale del sito r-project.org andiamo sulla sezione Download e scegliamo un server a piacimento per scaricare il software d’installazione. Una volta scaricato l’installer, lo installiamo come un qualsiasi software, cliccando due volte sul file d’istallazione. Esistono versioni di per tutti i più diffusi sistemi operativi (Windows, Mac OS X e Linux). Il R Core Development Team lavora continuamente per migliorare le prestazioni di R, per correggere errori e per consentire l’uso di con nuove tecnologie. Di conseguenza, periodicamente vengono rilasciate nuove versioni di R. Informazioni a questo proposito sono fornite sulla pagina web https://www.r-project.org/. Per installare una nuova versione di R si segue la stessa procedura che è stata seguita per la prima installazione.1 Dopo avere installato R è opportuno installare anche RStudio. RStudio si può scaricare da https://www.rstudio.com/. Anche RStudio è disponibile per tutti i più diffusi sistemi operativi. 2.2 Utilizzare RStudio per semplificare il lavoro Possiamo pensare ad R come al motore di un automobile e a RStudio come al cruscotto di un automobile. Più precisamente, R è un linguaggio di programmazione che esegue calcoli mentre RStudio è un ambiente di sviluppo integrato (IDE) che fornisce un’interfaccia grafica aggiungendo una serie di strumenti che facilitano la fase di sviluppo e di esecuzione del codice. Utilizzeremo dunque R mediante RStudio. In altre parole, non aprite aprite invece L’ambiente di lavoro di RStudio è costituito da quattro finestre: la finestra del codice (scrivere-eseguire script), la finestra della console (riga di comando - output), la finestra degli oggetti (elenco oggetti-cronologia dei comandi) e la finestra dei pacchetti-dei grafici-dell’aiuto in linea. La console di RStudio. 2.2.1 Eseguire il codice Mediante il menu a tendina di RStudio, scegliendo il percorso File &gt; New File &gt; R Notebook oppure File &gt; New File &gt; R Script l’utente può aprire nella finestra del codice (in alto a destra) un R Notebook o un R script dove inserire le istruzioni da eseguire. In un R script, un blocco di codice viene eseguito selezionando un insieme di righe di istruzioni e digitando la sequenza di tasti Command + Invio sul Mac, oppure Control + Invio su Windows. In un R Notebook, un blocco di codice viene eseguito schiacciando il bottone con l’icona \\(\\color{red}\\blacktriangleright\\) (“Run current chunk”) posizionata a destra rispetto al codice. In seguito, quest’idea è stata completamente screditata.↩︎ "],["chapter-sintassi-R.html", "Capitolo 3 Sintassi di base Obiettivi di apprendimento Motivazione 3.1 Utilizzare la console R come calcolatrice 3.2 Le parentesi 3.3 I nomi degli oggetti 3.4 Permanenza dei dati e rimozione di oggetti 3.5 Chiudere R 3.6 Creare ed eseguire uno script R con un editore 3.7 Cambiare la cartella di lavoro 3.8 L’oggetto base di : il vettore 3.9 Funzioni 3.10 Pacchetti", " Capitolo 3 Sintassi di base Obiettivi di apprendimento Lo studio di questo capitolo dovrebbe insegnare allo studente come: Conoscere e sapere usare alcune delle funzioni di base di R. Motivazione R è un linguaggio di programmazione orientato all’analisi dei dati, il calcolo e la visualizzazione grafica. È disponibile su Internet una vasta gamma di materiali utile per avvicinarsi all’ambiente R e aiutare l’utente nell’apprendimento di questo software statistico. Cercheremo qui di fornire alcune indicazioni e una breve descrizione delle risorse di base di R. 3.1 Utilizzare la console R come calcolatrice La console di RStudio contiene un cursore rappresentato dal simbolo “&gt;” (linea di comando) dove si possono inserire i comandi e le funzioni – in realtà è sempre meglio utilizzare un R Notebook anziché la console, ma per ora esaminiamo il funzionamento di quest’ultima. La console di RStudio può essere utilizzata come semplice calcolatrice. I comandi elementari consistono di espressioni o di assegnazioni. Le operazioni aritmetiche vengono eseguite mediante simboli “standard:” +, *, -, /, sqrt(), log(), exp(), … I comandi sono separati da un carattere di nuova linea (si immette un carattere di nuova linea digitando il tasto Invio). Se un comando non è completo alla fine della linea, R darà un prompt differente che per default è il carattere + sulla linea seguente e continuerà a leggere l’input finché il comando non è sintatticamente completo. Ad esempio, 4 - + + 1 #&gt; [1] 3 R è un ambiente interattivo, ossia i comandi producono una risposta immediata. Se scriviamo 2 + 2 e premiamo il tasto di invio, comparirà nella riga successiva il risultato: 2 + 2 #&gt; [1] 4 Il risultato è preceduto da [1], il che significa che il risultato dell’operazione che abbiamo appena eseguito è il primo valore di questa linea. Alcune funzioni ritornano più di un singolo numero e, in quel caso, l’informazione fornita da R è più utile. Per esempio, l’istruzione 100:130 ritorna \\(31\\) valori, ovvero i numeri da \\(100\\) a \\(130\\): 100:130 #&gt; [1] 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 #&gt; [23] 122 123 124 125 126 127 128 129 130 In questo caso, [24] indica che il valore \\(123\\) è il ventiquattresimo numero che è stato stampato sulla console. R è un linguaggio di programmazione a oggetti, quindi si basa sulla creazione di oggetti e sulla possibilità di salvarli nella memoria del programma. Quando creiamo un oggetto gli attribuiamo un nome usando il simbolo &lt;-. Ad esempio, per creare un oggetto che contiene il risultato dell’operazione 2 + 2 procediamo nel modo seguente: res_sum &lt;- 2 + 2 res_sum #&gt; [1] 4 L’operazione di assegnazione (&lt;-) copia il contenuto dell’operando destro (detto r-value) nell’operando sinistro detto (l-value). Il valore dell’espressione assegnazione è r-value. Nell’esempio precedente, res_sum (l-value) assume il valore di \\(4\\). La console di RStudio fornisce la possibilità di richiamare e rieseguire i comandi. I tasti freccia verticale, \\(\\uparrow\\) e \\(\\downarrow\\), sulla tastiera possono essere utilizzati per scorrere avanti e indietro i comandi già immessi. Appena trovato il comando che interessa, lo si può modificare, ad esempio, con i tasti freccia orizzontali, immettendo nuovi caratteri o cancellandone altri. Se viene digitato un comando che R non riconosce, sulla console viene visualizzato un messaggio di errore; ad esempio, 3 % 9 Errore: unexpected input in &quot;3 % 9&quot; 3.2 Le parentesi Le parentesi in R (come in generale in ogni linguaggio di programmazione) assegnano un significato diverso alle porzioni di codice che delimitano. Le parentesi tonde funzionano come nell’algebra. Per esempio 2 + 3 * 4 #&gt; [1] 14 non è equivalente a (2 + 3) * 4 #&gt; [1] 20 Le due istruzioni precedenti producono risultati diversi perché, se la sequenza delle operazioni algebriche non viene specificata dalle parentesi, R assegna alle operazioni algebriche il seguente ordine di priorità decrescente: esponenziazione, moltiplicazione / divisione, addizione / sottrazione, confronti logici (&lt;, &gt;, &lt;=, &gt;=, ==, !=). È sempre una buona idea rendere esplicito l’ordine delle operazioni algebriche che si vuole eseguire mediante l’uso delle parentesi tonde. Le parentesi tonde vengono anche utilizzate per le funzioni, come vedremo nei prossimi paragrafi. Tra le parentesi tonde avremo dunque l’oggetto a cui vogliamo applicare la funzione e gli argomenti passati alla funzione. Le parentesi graffe sono destinate alla programmazione. Un blocco tra le parentesi graffe viene letto come un oggetto unico che può contenere una o più istruzioni. Le parentesi quadre vengono utilizzate per selezionare degli elementi, per esempio all’interno di un vettore, o di una matrice, o di un data.frame. L’argomento entro le parentesi quadre può essere generato da espressioni logiche. 3.3 I nomi degli oggetti Le entità create e manipolate da R si chiamano ‘oggetti.’ Tali oggetti possono essere variabili, array di numeri, caratteri, stringhe, funzioni, o più in generale strutture costruite a partire da tali componenti. Durante una sessione di R gli oggetti sono creati e memorizzati attraverso opportuni nomi. I nomi possono contenere un qualunque carattere alfanumerico e come carattere speciale il trattino basso (_) o il punto. R fornisce i seguenti vincoli per i nomi degli oggetti: i nomi degli oggetti non possono mai iniziare con un carattere numerico e non possono contenere i seguenti simboli: $, @, !, ^, +, -, /, *. È buona pratica usare nomi come ratio_of_sums. È fortemente sconsigliato utilizzare nei nomi degli oggetti caratteri accentati o, ancora peggio, apostrofi. Per questa ragione è sensato creare i nomi degli oggetti utilizzando la lingua inglese. È anche bene che i nomi degli oggetti non coincidano con nomi di funzioni. Si noti che R è case sensitive, cioè A e a sono due simboli diversi e identificano due oggetti differenti. 3.4 Permanenza dei dati e rimozione di oggetti Gli oggetti vengono salvati nello “spazio di lavoro” (workspace). Il comando ls() può essere utilizzato per visualizzare i nomi degli oggetti che sono in quel momento memorizzati in R. Per eliminare oggetti dallo spazio di lavoro è disponibile la funzione rm(); ad esempio rm(x, y, z, ink, junk, temp, foo, bar) cancella tutti gli oggetti indicati entro parentesi. Per eliminare tutti gli oggetti presenti nello spazio di lavoro si può utilizzare la seguente istruzione: rm(list = ls()) 3.5 Chiudere R Quando si chiude RStudio il programma ci chiederà se si desidera salvare l’area di lavoro sul computer. Tale operazione è da evitare in quanto gli oggetti così salvati andranno ad interferire con gli oggetti creati in un lavoro futuro. Si consiglia dunque di rispondere negativamente a questa domanda. In RStudio, selezionare Preferences dal menu a tendina e, in R General Workspace, deselezionare l’opzione Restore .RData into workspace at start- up e scegliere l’opzione Never nella finestra di dialogo Save workspace to .RData on exit. In R, selezionare Preferences dal menu a tendina e, in Startup, selezionare l’opzione No in corrispondenza dell’item Save workspace on exit from R. 3.6 Creare ed eseguire uno script R con un editore È molto più facile interagire con manipolando uno script con un editore piuttosto che inserendo direttamente le istruzioni nella console. R fornisce il Text Editor dove è possibile inserire il codice (File \\(\\to\\) New Script). Per salvare il file basta utilizzare l’apposito menù a tendina (estensione .R). Tale file potrà poi essere riaperto ed utilizzato in un momento successivo. L’editore comunica con R nel modo seguente: dopo avere selezionato la porzione di codice che si vuole eseguire, si digita un’apposita sequenza di tasti (Command + Enter su Mac OS X e ctrl + r in Windows)2. Così facendo, R eseguirà le istruzioni selezionate e l’output verrà stampato sulla console. Il Text Editor fornito da R è piuttosto primitivo: è fortemente consigliato utilizzare RStudio. 3.6.1 Commentare il codice I commenti sono parole in linguaggio naturale (nel nostro caso l’italiano), che permettono agli utilizzatori di capire il flusso logico del codice e a chi lo ha scritto di ricordare il perché di determinate istruzioni. In R, le parole dopo il simbolo # sono considerate commenti e sono ignorate; ad esempio: # Questo e&#39; un commento 3.7 Cambiare la cartella di lavoro Quando si inizia una sessione di lavoro, sceglie una cartella quale “working directory.” Sarà in tale cartella che andrà a cercare gli script definiti dall’utilizzatore e i file dei dati. È possibile determinare quale sia la corrente “working directory” digitando sulla console di RStudio l’istruzione: getwd() Per cambiare la cartella di lavoro (in maniera tale che corrisponda alla cartella nella quale sono stati salvati i dati e gli script da eseguire) si sceglie la voce Set Working Directory sul menù a tendina di RStudio e si selezione la voce Choose Directory… Nella finestra che compare, si cambia la cartella con quella che si vuole. 3.8 L’oggetto base di : il vettore R opera su strutture di dati; la più semplice di tali strutture è il vettore numerico, che consiste in un insieme ordinato di numeri; ad esempio: x &lt;- c(7.0, 10.2, -2.9, 21.4) Nell’istruzione precedente, c() è una funzione. In gli argomenti sono passati alle funzioni inserendoli all’interno delle parentesi tonde. Si noti che gli argomenti (in questo caso, i numeri \\(7.0, 10.2, -2.9, 21.4\\)) sono separati a virgole. La funzione c() può prendere un numero arbitrario di argomenti e genera un vettore concatenando i suoi argomenti. L’operatore &lt;- assegna un nome al vettore che è stato creato. Nel caso presente, digitando x possiamo visualizzare il vettore che abbiamo creato: x #&gt; [1] 7.0 10.2 -2.9 21.4 Se invece eseguiamo l’istruzione c(7.0, 10.2, -2.9, 21.4) #&gt; [1] 7.0 10.2 -2.9 21.4 senza assegnazione, il valore dell’espressione sarà visualizzato nella console, ma il vettore non potrà essere utilizzato in nessun altro modo. 3.8.1 Operazioni vettorializzate Molte operazioni in sono vettorializzate, il che significa che esse sono eseguite in parallelo in determinati oggetti . Ciò consente di scrivere codice che sia efficiente, conciso e più facile da leggere rispetto al codice che contiene istruzioni non vettorializzate. 3.8.2 Vettori aritmetici L’esempio più semplice che illustra come si svolgono le operazioni vettorializzate riguarda le operazioni algebriche applicate ai vettori. I vettori, infatti, possono essere utilizzati in espressioni numeriche nelle quali le operazioni algebriche vengono eseguite “elemento per elemento.” Per illustrare questo concetto, definiamo il vettore die che contiene i possibili risultati del lancio di un dado: die &lt;- c(1, 2, 3, 4, 5, 6) die #&gt; [1] 1 2 3 4 5 6 Supponiamo di volere sommare \\(10\\) a ciascun elemento del vettore die. Dato che le operazioni sui vettori sono eseguite elemento per elemento, per ottenere questo risultato è sufficiente eseguire l’istruzione: die + 10 #&gt; [1] 11 12 13 14 15 16 Si noti come la costante \\(10\\) sia stata sommata a ciascun elemento del vettore. In maniera corrispondente, l’istruzione die - 1 #&gt; [1] 0 1 2 3 4 5 sottrarrà un’unità da ciascuno degli elementi del vettore die. Se l’operazione aritmetica coinvolge due o più vettori, allinea i vettori ed esegue una sequenza di operazioni elemento per elemento. Per esempio, l’istruzione die * die #&gt; [1] 1 4 9 16 25 36 fa sì che i due vettori vengano disposti l’uno di fianco all’altro per poi moltiplicare gli elementi corrispondenti: il primo elemento del primo vettore per il primo elemento del secondo vettore e così via. Il vettore risultante avrà la stessa dimensione dei due vettori che sono stati moltiplicati, come indicato qui sotto: \\[\\begin{array}{ccccc} 1 &amp; \\times &amp; 1 &amp; \\to &amp; 1 \\\\ 2 &amp; \\times &amp; 2 &amp; \\to &amp; 4 \\\\ 3 &amp; \\times &amp; 3 &amp; \\to &amp; 9 \\\\ 4 &amp; \\times &amp; 4 &amp; \\to &amp; 16 \\\\ 5 &amp; \\times &amp; 5 &amp; \\to &amp; 25 \\\\ 6 &amp; \\times &amp; 6 &amp; \\to &amp; 36 \\\\ \\hline \\verb+die+ &amp; * &amp; \\verb+die+ &amp; = &amp; \\end{array}\\] Oltre agli operatori aritmetici elementari +, -, *, /, e ^ per l’elevamento a potenza, sono disponibili le più comuni funzioni matematiche: log(), exp(), sin(), cos(), tan(), sqrt(), max(), min() e così via. Altre funzioni di uso comune sono: range() che restituisce un vettore c(min(x), max(x)); sort() che restituisce un vettore ordinato; length(x) che restituisce il numero di elementi di x; sum(x) che dà la somma degli elementi di x, mentre prod(x) dà il loro prodotto. Due funzioni statistiche di uso comune sono mean(x), la media aritmetica, e var(x), la varianza. 3.8.3 Generazione di sequenze regolari R possiede un ampio numero di funzioni per generare sequenze di numeri. Ad esempio, c(1:10) è il vettore c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10). L’espressione c(30:1) può essere utilizzata per generare una sequenza all’indietro. La funzione seq() genera un vettore che contiene una sequenza regolare di numeri, generata in base a determinate regole. Può avere 5 argomenti: i primi due rappresentano l’inizio (from) e la fine (to) della sequenza, il terzo specifica l’ampiezza del passo (by), il quarto la lunghezza della sequenza (length.out) e infine il quinto (along.with), che se utilizzato deve essere l’unico parametro presente, è il nome di un vettore, ad esempio x, creando in tal modo la sequenza 1, 2, …, length(x). Esempi di utilizzo della funzione seq() sono i seguenti: seq(from = 1, to = 10) #&gt; [1] 1 2 3 4 5 6 7 8 9 10 seq(-5, 5, by = 2.5) #&gt; [1] -5.0 -2.5 0.0 2.5 5.0 seq(from = 1, to = 7, length.out = 4) #&gt; [1] 1 3 5 7 seq(along.with = die) #&gt; [1] 1 2 3 4 5 6 Altra funzione utilizzata per generare sequenze è rep() che può essere utilizzata per replicare un oggetto in vari modi. Ad esempio: die3 &lt;- rep(die, times = 3) die3 #&gt; [1] 1 2 3 4 5 6 1 2 3 4 5 6 1 2 3 4 5 6 metterà tre copie di die nell’oggetto die3. 3.8.4 Generazione di numeri casuali La funzione sample() è una delle tante funzioni che possono essere usate per generare numeri casuali. Per esempio, la seguente istruzione simula dieci lanci di un dado a sei facce: roll &lt;- sample(1:6, 10, replace = TRUE) roll #&gt; [1] 5 4 5 6 4 6 1 5 5 5 Il primo argomento di sample() è il vettore da cui la funzione estrarrà degli elementi a caso; il secondo argomento specifica che dovranno essere effettuate 10 estrazioni casuali; il terzo argomento specifica che le estrazioni sono con rimessa (cioè, lo stesso elemento può essere estratto più di una volta). Scegliere un elemento a caso dal vettore \\(\\{1, 2, 3, 4, 5, 6\\}\\) è equivalente a lanciare un dado e osservare la faccia che si presenta. L’istruzione precedente corrisponde dunque alla simulazione di dieci lanci di un dado a sei facce. 3.8.5 Vettori logici Quando si manipolano i vettori, talvolta si vogliono trovare gli elementi che soddisfano determinate condizioni logiche. Per esempio, in dieci lanci di un dado, quante volte è uscito \\(5\\)? Per rispondere a questa domanda si possono usare gli operatori logici &lt;, &gt; e == per le operazioni di “minore di,” “maggiore di” e “uguale a.” Se scriviamo roll == 5 #&gt; [1] TRUE FALSE TRUE FALSE FALSE FALSE FALSE TRUE TRUE TRUE creiamo un vettore costituito da elementi TRUE/FALSE i quali identificano gli elementi del vettore che soddisfano la condizione logica specificata. Possiamo trattare tale vettore come se fosse costituito da elementi di valore \\(0\\) e \\(1\\). Sommando gli elementi di tale vettore, infatti, possiamo contare il numero di “5”: sum(roll == 5) #&gt; [1] 5 3.8.6 Dati mancanti Quando si è in presenza di un dato mancante, assegna il valore speciale NA, che sta per Not Available. In generale, un’operazione su un NA dà come risultato un NA. Nell’uso delle funzioni che operano sui dati sarà dunque necessario specificare che, qualunque operazione venga effettuata, gli NA devono essere esclusi. 3.8.7 Vettori di caratteri e fattori I vettori di caratteri si creano formando una sequenza di caratteri delimitati da doppie virgolette e possono essere concatenati in un vettore attraverso la funzione c(). Successivamente, si può applicare la funzione factor(), che definisce automaticamente le modalità della variabile categoriale. Ad esempio, soc_status &lt;- factor( c(&quot;low&quot;, &quot;high&quot;, &quot;medium&quot;, &quot;high&quot;, &quot;low&quot;, &quot;medium&quot;, &quot;high&quot;) ) levels(soc_status) #&gt; [1] &quot;high&quot; &quot;low&quot; &quot;medium&quot; Talvolta l’ordine dei livelli del fattore non importa, mentre altre volte l’ordine è importante, per esempio, quando una variable categoriale viene rappresentata in un grafico. Per specificare l’ordine dei livelli del fattore si usa la seguente sintassi: soc_status &lt;- factor(soc_status, levels = c(&quot;low&quot;, &quot;medium&quot;, &quot;high&quot;)) levels(soc_status) #&gt; [1] &quot;low&quot; &quot;medium&quot; &quot;high&quot; 3.9 Funzioni offre la possibilità di utilizzare un’enorme libreria di funzioni che permettono di svolgere operazioni complicate, quali ad esempio, il campionamento casuale. Esaminiamo ora con più attenzione le proprietà delle funzioni di R utilizzando ancora l’esempio del lancio di un dado. Abbiamo visto in precedenza come il lancio di un dado possa essere simulato da R con la funzione sample(). La funzione sample() prende tre argomenti: il nome di un vettore, un numero chiamato size e un argomento chiamato replace. La funzione sample() ritorna un numero di elementi del vettore pari a size. Ad esempio sample(die, 2, replace = TRUE) #&gt; [1] 2 6 Assegnando TRUE all’argomento replace specifichiamo che vogliamo un campionamento con rimessa. Se volgiamo eseguire una serie di lanci indipendenti di un dado, eseguiamo ripetutamente la funzione sample() ponendo size uguale a 1: sample(die, 1, replace = TRUE) #&gt; [1] 3 sample(die, 1, replace = TRUE) #&gt; [1] 6 sample(die, 1, replace = TRUE) #&gt; [1] 3 Come si fa a sapere quanti e quali argomenti sono richiesti da una funzione? Tale informazione viene fornita dalla funzione args(). Nel nostro caso args(sample) #&gt; function (x, size, replace = FALSE, prob = NULL) #&gt; NULL ci informa che il primo argomento è un vettore chiamato x, il secondo argomento è chiamato size ed ha il significato descritto sopra, il terzo argomento, replace, specifica se il campionamento è eseguito con o senza reimmissione, e il quarto argomento, prob, assegna delle probabilità agli elementi del vettore. Il significato degli argomenti viene spiegato nel file di help della funzione. Si noti che agli ultimi due argomenti sono stati assegnati dei valori, detti di default. Ciò significa che, se l’utilizzatore non li cambia, verranno usati da . La specificazione replace = FALSE significa che il campionamento viene eseguito senza reimmissione. Se desideriamo un campionamento con reimmissione, basta specificare replace = TRUE (nel caso di una singola estrazione è ovviamente irrilevante). Ad esempio, l’istruzione seguente simula i risultati di 10 lanci indipendenti di un dado: sample(die, 10, replace = TRUE) #&gt; [1] 5 5 4 5 2 6 4 2 3 1 Infine, prob = NULL specifica che non viene alterata la probabilità di estrazione degli elementi del vettore. In generale, gli argomenti di una funzione possono essere oggetti come vettori, matrici, altre funzioni, parametri o operatori logici. R ha un sistema di help interno in formato HTML che si richiama con help.start(). Per avere informazioni su qualche funzione specifica, per esempio la funzione sample(), il comando da utilizzare è help(sample) oppure ?sample. 3.9.1 Scrivere proprie funzioni Abbiamo visto in precedenza come sia possibile simulare i risultati prodotti da dieci lanci di un dado o, in maniera equivalente, dal singolo lancio di dieci dadi. Possiamo replicare questo processo digitando ripetutamente le stesse istruzioni nella console. Otterremo ogni volta risultati diversi perché, ad ogni ripetizione, il generatore di numeri pseudo-casuali di dipende dal valore ottenuto dal clock interno della macchina. La funzione set.seed() ci permette di replicare esattamente i risultati della generazione di numeri casuali. Per ottenere questo risultato, basta assegnare al seed un numero arbitrario, es. set.seed(12345). Tuttavia, questa procedura è praticamente difficile da perseguire se il numero di ripetizioni è alto. In tal caso è vantaggioso scrivere una funzione contenente il codice che specifica il numero di ripetizioni. In questo modo, per trovare il risultato cercato basterà chiamare la funzione una sola volta. Le funzioni di R sono costituite da tre elementi: il nome, il blocco del codice e una serie di argomenti. Per creare una funzione è necessario immagazzinare in R questi tre elementi e function() consente di ottenere tale risultato usando la sintassi seguente: nome_funzione &lt;- function(arg1, arg2, ...) { espressione1 espressione2 return(risultato) } Una chiamata di funzione è poi eseguita nel seguente modo: nome_funzione(arg1, arg2, ...) Per potere essere utilizzata, una funzione deve essere presente nella memoria di lavoro di R. Le funzioni salvate in un file possono essere richiamate utilizzando la funzione source(), ad esempio, source(\"file_funzioni.R\"). Consideriamo ora la funzione two_rolls() che ritorna la somma dei punti prodotti dal lancio di due dadi non truccati: two_rolls &lt;- function() { die &lt;- 1:6 res &lt;- sample(die, size = 2, replace = TRUE) sum_res &lt;- sum(res) return(sum_res) } La funzione two_rolls() inizia con il creare il vettore die che contiene sei elementi: i numeri da \\(1\\) a \\(6\\). Viene poi utilizzata la funzione sample() con gli gli argomenti, die, size = 2 e replace = TRUE. Tale funzione restituisce il risultato del lancio di due dadi. Il risultato fornito da sample(die, size = 2, replace = TRUE) viene assegnato all’oggetto res. L’oggetto res corrisponde dunque ad un vettore di due elementi. L’istruzione sum(res) somma gli elementi del vettore res e attribuisce il risultato di questa operazione a sum_res. Infine, la funzione return() ritorna il contenuto dell’oggetto sum_res. Invocando la funzione two_rolls() si ottiene dunque la somma del lancio di due dadi. In generale, la funzione two_rolls() produrrà un risultato diverso ogni volta che viene usata: two_rolls() #&gt; [1] 9 two_rolls() #&gt; [1] 11 two_rolls() #&gt; [1] 7 La formattazione del codice mediante l’uso di spazi e rientri non è necessaria ma è altamente raccomandata per minimizzare la probabilità di compiere errori. 3.10 Pacchetti Le funzioni di R sono organizzate in pacchetti, i più importanti dei quali sono già disponibili quando si accede al programma. 3.10.1 Istallazione e upgrade dei pacchetti Alcuni pacchetti non sono presenti nella release di base di R. Per installare un pacchetto non presente è sufficiente scrivere nella console: install.packages(&quot;nome_pacchetto&quot;) Ad esempio, install.packages(&quot;ggplot2&quot;) La prima volta che si usa questa funzione durante una sessione di lavoro si dovrà anche selezionare da una lista il sito mirror da cui scaricare il pacchetto. Gli autori dei pacchetti periodicamente rilasciano nuove versioni dei loro pacchetti che contengono miglioramenti di varia natura. Per eseguire l’upgrade dei pacchetti ggplot2 e dplyr, ad esempio, si usa la seguente istruzione: update.packages(c(&quot;ggplot2&quot;, &quot;dplyr&quot;)) Per eseguire l’upgrade di tutti i pacchetti l’istruzione è update.packages() 3.10.2 Caricare un pacchetto in R L’istallazione dei pacchetti non rende immediatamente disponibili le funzioni in essi contenute. L’istallazione di un pacchetto semplicemente copia il codice sul disco rigido della macchina in uso. Per potere usare le funzioni contenute in un pacchetto installato è necessario caricare il pacchetto in . Ciò si ottiene con il comando: library(&quot;ggplot2&quot;) se si vuole caricare il pacchetto ggplot2. A questo punto diventa possibile usare le funzioni contenute in ggplot2. Queste operazioni si possono anche eseguire usando dal menu a tendina di RStudio. Per sapere quali sono i pacchetti già presenti nella release di R con cui si sta lavorando, basta scrivere: library() In seguito, quest’idea è stata completamente screditata.↩︎ "],["chapter-strutture-dati-R.html", "Capitolo 4 Strutture di dati Obiettivi di apprendimento Motivazione 4.1 Classi e modi degli oggetti 4.2 Matrici 4.3 Array 4.4 Operazioni aritmetiche su vettori, matrici e array 4.5 Liste 4.6 Data frame", " Capitolo 4 Strutture di dati Obiettivi di apprendimento Lo studio di questo capitolo dovrebbe insegnare allo studente come: Distinguere tra classi e modi degli oggetti di R. Creare un data.frame in cui inserire i dati da analizzare. Estrarre un sottoinsieme di dati da un data.frame. Motivazione Solitamente gli psicologi raccolgono grandi quantità di dati. Tali dati vengono codificati in R all’interno di oggetti aventi proprietà diverse. Intuitivamente, in R un oggetto è qualsiasi cosa a cui è possibile assegnare un valore. I dati possono essere di tipo numerico o alfanumerico. Di conseguenza, R distingue tra oggetti aventi ‘modi’ diversi. Inoltre, i dati possono essere organizzati in righe e colonne in base a diversi tipi di strutture che R chiama ‘classi.’ 4.1 Classi e modi degli oggetti Gli oggetti R si distinguono a seconda della loro classe (class) e del loro modo (mode). La classe definisce il tipo di oggetto. In R, vengono utilizzate cinque strutture di dati che corrispondono a cinque classi differenti: vector, matrix, array, list e data.frame. Un’altra classe di oggetti R è function (ad essa appartengono le funzioni). La classe di appartenenza di un oggetto si stabilisce usando le funzioni class(), oppure is.list(), is.function(), is.logical(), e così via. Queste funzioni restituisco TRUE e FALSE in base all’appartenenza o meno dell’argomento a quella determinata classe. Gli oggetti R possono anche essere classificati in base al loro ‘modo.’ I modi ‘atomici’ degli oggetti sono: numeric, complex, character e logical. Per esempio, x &lt;- c(4, 9) mode(x) #&gt; [1] &quot;numeric&quot; cards &lt;- c(&quot;9 of clubs&quot;, &quot;10 of hearts&quot;, &quot;jack of hearts&quot;) mode(cards) #&gt; [1] &quot;character&quot; Nel seguito verranno esaminate le cinque strutture di dati utilizzate da R. 4.1.1 Vettori I vettori sono la classe di oggetto più importante in R. Un vettore può essere creato usando la funzione c(): y &lt;- c(2, 1, 6, -3, 9) y #&gt; [1] 2 1 6 -3 9 Le dimensioni di un vettore presente nella memoria di lavoro possono essere trovare con la funzione length(); ad esempio, length(y) #&gt; [1] 5 ci dice che y è un vettore costituito da cinque elementi. La somma, il minimo e il massimo degli elementi contenuti in un vettore si trovano con le seguenti istruzioni: sum(y) #&gt; [1] 15 min(y) #&gt; [1] -3 max(y) #&gt; [1] 9 Mentre ci sono sei ‘tipi’ di vettori ‘atomici’ in R, noi ci focalizzeremo sui tipi seguenti: ‘numeric’ (‘integer’: e.g., 5; ‘double’: e.g., 5.5), ‘character’ (e.g., ‘pippo’) e ‘logical’ (e.g., TRUE, FALSE). Usiamo la funzione typeof() per determinare il ‘tipo’ di un vettore atomico. Tutti gli elementi di un vettore atomico devono essere dello stesso tipo. La funzione str() rende visibile in maniera compatta la struttura interna di un oggetto. 4.2 Matrici Una matrice è una collezione di vettori. Il comando per generare una matrice è matrix(): X &lt;- matrix(1:20, nrow = 4, byrow = FALSE) X #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 1 5 9 13 17 #&gt; [2,] 2 6 10 14 18 #&gt; [3,] 3 7 11 15 19 #&gt; [4,] 4 8 12 16 20 Il primo argomento è il vettore i cui elementi andranno a disporsi all’interno della matrice. È poi necessario specificare le dimensioni della matrice e il modo in cui R dovrà riempire la matrice. Date le dimensioni del vettore, la specificazione del numero di righe (secondo argomento) è sufficiente per determinare le dimensioni della matrice. L’argomento byrow = FALSE è il default. In tal caso, R riempie la matrice per colonne. Se vogliamo che R riempia la matrice per righe, usiamo byrow = TRUE: Y &lt;- matrix(1:20, nrow = 4, byrow = TRUE) Y #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 1 2 3 4 5 #&gt; [2,] 6 7 8 9 10 #&gt; [3,] 11 12 13 14 15 #&gt; [4,] 16 17 18 19 20 Le dimensioni di una matrice presente nella memoria di lavoro possono essere trovare con la funzione dim(); ad esempio, dim(Y) #&gt; [1] 4 5 ci dice che Y è una matrice con quattro righe e cinque colonne. 4.3 Array Un array è una collezione di matrici (si veda la Figura 1.1). Per costruire un array con la funzione array() è necessario specificare un vettore come primo argomento e un vettore di dimensioni, chiamato dim, quale secondo argomento: ar &lt;- array( c(11:14, 21:24, 31:34), dim = c(2, 2, 3) ) Un sottoinsieme di questi dati può essere selezionato, per esempio, nel modo seguente: ar[, , 3] #&gt; [,1] [,2] #&gt; [1,] 31 33 #&gt; [2,] 32 34 4.4 Operazioni aritmetiche su vettori, matrici e array 4.4.1 Operazioni aritmetiche su vettori I vettori e le matrici (o gli array) possono essere utilizzati in espressioni aritmetiche. Il risultato è un vettore o una matrice (o un array) formato dalle operazioni fatte elemento per elemento sui vettori o sulle matrici. Ad esempio, y + 3 #&gt; [1] 5 4 9 0 12 restituisce un vettore di dimensioni uguali alle dimensioni di y, i cui elementi sono dati dalla somma tra ciascuno degli elementi originari di y e la costante “3.” Ovviamente, ad un vettore possono essere applicate tutte le altre operazioni algebriche, sempre elemento per elemento. Ad esempio, 3 * y #&gt; [1] 6 3 18 -9 27 restituisce un vettore i cui elementi sono uguali agli elementi di y moltiplicati per 3. Se sono costituiti dallo stesso numero di elementi, due vettori possono essere sommati, sottratti, moltiplicati e divisi, laddove queste operazioni algebriche vengono eseguite elemento per elemento. Per esempio, x &lt;- c(1, 1, 2, 1, 3) y &lt;- c(2, 1, 6, 3, 9) x + y #&gt; [1] 3 2 8 4 12 x - y #&gt; [1] -1 0 -4 -2 -6 x * y #&gt; [1] 2 1 12 3 27 x / y #&gt; [1] 0.5000000 1.0000000 0.3333333 0.3333333 0.3333333 4.4.2 Operazioni aritmetiche su matrici Le operazioni algebriche elemento per elemento si possono estendere al caso delle matrici. Per esempio, se X, Y sono entrambe matrici di dimensioni \\(4 \\times 5\\), allora la seguente operazione M &lt;- 2 * (X + Y) - 3 crea una matrice D anch’essa di dimensioni \\(4 \\times 5\\) i cui elementi sono ottenuti dalle operazioni fatte elemento per elemento sulle matrici e sugli scalari: M #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] 1 11 21 31 41 #&gt; [2,] 13 23 33 43 53 #&gt; [3,] 25 35 45 55 65 #&gt; [4,] 37 47 57 67 77 4.4.3 Operazioni aritmetiche su array Le stesse considerazioni si estendono al caso degli array. 4.5 Liste Le liste assomigliano ai vettori perché raggruppano i dati in un insieme unidimensionale. Tuttavia, le liste non raggruppano elementi individuali ma bensì oggetti di R, quali vettori e altre liste. Per esempio, list1 &lt;- list(&quot;R&quot;, list(TRUE, FALSE), 20:24) list1 #&gt; [[1]] #&gt; [1] &quot;R&quot; #&gt; #&gt; [[2]] #&gt; [[2]][[1]] #&gt; [1] TRUE #&gt; #&gt; [[2]][[2]] #&gt; [1] FALSE #&gt; #&gt; #&gt; [[3]] #&gt; [1] 20 21 22 23 24 Le doppie parentesi quadre identificano l’elemento della lista a cui vogliamo fare riferimento. Per esempio, list1[[3]] #&gt; [1] 20 21 22 23 24 list1[[3]][2] #&gt; [1] 21 4.6 Data frame I data.frame sono strutture tipo matrice, in cui le colonne possono essere vettori di tipi differenti (si veda la Figura 1.1). La funzione usata per generare un data frame è data.frame(), che permette di unire più vettori di uguale lunghezza come colonne del data frame, ognuno dei quali si riferisce ad una diversa variabile. Ad esempio, df &lt;- data.frame( face = c(&quot;ace&quot;, &quot;two&quot;, &quot;six&quot;), suit = c(&quot;clubs&quot;, &quot;clubs&quot;, &quot;clubs&quot;), value = c(1, 2, 3) ) df #&gt; face suit value #&gt; 1 ace clubs 1 #&gt; 2 two clubs 2 #&gt; 3 six clubs 3 L’estrazione di dati da un data.frame può essere effettuata in maniera simile a quanto avviene per i vettori. Ad esempio, per estrarre la variabile value dal data.frame df si può indicare l’indice della terza colonna: df[, 3] #&gt; [1] 1 2 3 Dal momento che le colonne sono delle variabili, è possibile estrarle anche indicando nome della variabile, scrivendo nome_data_frame$nome_variabile: df$value #&gt; [1] 1 2 3 Per fare un esempio, creiamo un data.frame che contenga tutte le informazioni di un mazzo di carte da poker (Grolemund, 2014). In tale data.frame, ciascuna riga corrisponde ad una carta – in un mazzo da poker ci sono 52 carte, perciò il data.frame avrà 52 righe. Il vettore face indica con una stringa di caratteri il valore di ciascuna carta, il vettore suit indica il seme e il vettore value indica con un numero intero il valore di ciascuna carta. Quindi, il data.frame avrà 3 colonne. deck &lt;- data.frame( face = c(&quot;king&quot;, &quot;queen&quot;, &quot;jack&quot;, &quot;ten&quot;, &quot;nine&quot;, &quot;eight&quot;, &quot;seven&quot;, &quot;six&quot;, &quot;five&quot;, &quot;four&quot;, &quot;three&quot;, &quot;two&quot;, &quot;ace&quot;, &quot;king&quot;, &quot;queen&quot;, &quot;jack&quot;, &quot;ten&quot;, &quot;nine&quot;, &quot;eight&quot;, &quot;seven&quot;, &quot;six&quot;, &quot;five&quot;, &quot;four&quot;, &quot;three&quot;, &quot;two&quot;, &quot;ace&quot;, &quot;king&quot;, &quot;queen&quot;, &quot;jack&quot;, &quot;ten&quot;, &quot;nine&quot;, &quot;eight&quot;, &quot;seven&quot;, &quot;six&quot;, &quot;five&quot;, &quot;four&quot;, &quot;three&quot;, &quot;two&quot;, &quot;ace&quot;, &quot;king&quot;, &quot;queen&quot;, &quot;jack&quot;, &quot;ten&quot;, &quot;nine&quot;, &quot;eight&quot;, &quot;seven&quot;, &quot;six&quot;, &quot;five&quot;, &quot;four&quot;, &quot;three&quot;, &quot;two&quot;, &quot;ace&quot;), suit = c(&quot;spades&quot;, &quot;spades&quot;, &quot;spades&quot;, &quot;spades&quot;, &quot;spades&quot;, &quot;spades&quot;, &quot;spades&quot;, &quot;spades&quot;, &quot;spades&quot;, &quot;spades&quot;, &quot;spades&quot;, &quot;spades&quot;, &quot;spades&quot;, &quot;clubs&quot;, &quot;clubs&quot;, &quot;clubs&quot;, &quot;clubs&quot;, &quot;clubs&quot;, &quot;clubs&quot;, &quot;clubs&quot;, &quot;clubs&quot;, &quot;clubs&quot;, &quot;clubs&quot;, &quot;clubs&quot;, &quot;clubs&quot;, &quot;clubs&quot;, &quot;diamonds&quot;, &quot;diamonds&quot;, &quot;diamonds&quot;, &quot;diamonds&quot;, &quot;diamonds&quot;, &quot;diamonds&quot;, &quot;diamonds&quot;, &quot;diamonds&quot;, &quot;diamonds&quot;, &quot;diamonds&quot;, &quot;diamonds&quot;, &quot;diamonds&quot;, &quot;diamonds&quot;, &quot;hearts&quot;, &quot;hearts&quot;, &quot;hearts&quot;, &quot;hearts&quot;, &quot;hearts&quot;, &quot;hearts&quot;, &quot;hearts&quot;, &quot;hearts&quot;, &quot;hearts&quot;, &quot;hearts&quot;, &quot;hearts&quot;, &quot;hearts&quot;, &quot;hearts&quot;), value = c(13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1) ) Avendo salvato tutte queste informazioni nell’oggetto deck, possiamo stamparle sullo schermo semplicemente digitando il nome dell’oggetto che le contiene: deck #&gt; face suit value #&gt; 1 king spades 13 #&gt; 2 queen spades 12 #&gt; 3 jack spades 11 #&gt; 4 ten spades 10 #&gt; 5 nine spades 9 #&gt; 6 eight spades 8 #&gt; 7 seven spades 7 #&gt; 8 six spades 6 #&gt; 9 five spades 5 #&gt; 10 four spades 4 #&gt; 11 three spades 3 #&gt; 12 two spades 2 #&gt; 13 ace spades 1 #&gt; 14 king clubs 13 #&gt; 15 queen clubs 12 #&gt; 16 jack clubs 11 #&gt; 17 ten clubs 10 #&gt; 18 nine clubs 9 #&gt; 19 eight clubs 8 #&gt; 20 seven clubs 7 #&gt; 21 six clubs 6 #&gt; 22 five clubs 5 #&gt; 23 four clubs 4 #&gt; 24 three clubs 3 #&gt; 25 two clubs 2 #&gt; 26 ace clubs 1 #&gt; 27 king diamonds 13 #&gt; 28 queen diamonds 12 #&gt; 29 jack diamonds 11 #&gt; 30 ten diamonds 10 #&gt; 31 nine diamonds 9 #&gt; 32 eight diamonds 8 #&gt; 33 seven diamonds 7 #&gt; 34 six diamonds 6 #&gt; 35 five diamonds 5 #&gt; 36 four diamonds 4 #&gt; 37 three diamonds 3 #&gt; 38 two diamonds 2 #&gt; 39 ace diamonds 1 #&gt; 40 king hearts 13 #&gt; 41 queen hearts 12 #&gt; 42 jack hearts 11 #&gt; 43 ten hearts 10 #&gt; 44 nine hearts 9 #&gt; 45 eight hearts 8 #&gt; 46 seven hearts 7 #&gt; 47 six hearts 6 #&gt; 48 five hearts 5 #&gt; 49 four hearts 4 #&gt; 50 three hearts 3 #&gt; 51 two hearts 2 #&gt; 52 ace hearts 1 Si noti che, a schermo, R stampa un numero progressivo che corrisponde al numero della riga. 4.6.1 Selezione di elementi Una volta creato un data.frame, ad esempio quello che contiene un mazzo virtuale di carte (si veda l’esempio \\[exmp:deck_of_cards\\]), è necessario sapere come manipolarlo. La funzione head() mostra le prime sei righe del data.frame: head(deck) #&gt; face suit value #&gt; 1 king spades 13 #&gt; 2 queen spades 12 #&gt; 3 jack spades 11 #&gt; 4 ten spades 10 #&gt; 5 nine spades 9 #&gt; 6 eight spades 8 Poniamoci ora il problema di mescolare il mazzo di carte e di estrarre alcune carte dal mazzo. Queste operazioni possono essere eseguite usando il sistema notazionale di R. Il sistema di notazione di R consente di estrarre singoli elementi dagli oggetti definiti da R. Per estrarre un valore da un data.frame, per esempio, dobbiamo scrivere il nome del data.frame seguito da una coppia di parentesi quadre: deck[ , ] All’interno delle parentesi quadre ci sono due indici separati da una virgola. R usa il primo indice per selezionare un sottoinsieme di righe del data.frame e il secondo indice per selezionare un sottoinsieme di colonne. Per esempio, deck[9, 2] #&gt; [1] spades #&gt; Levels: clubs diamonds hearts spades restituisce l’elemento che si trova nella nella nona riga della seconda colonna di deck. In R ci sono sei modi diversi per specificare gli indici di un oggetto: interi positivi, interi negativi, zero, spazi vuoti, valori logici e nomi. Esaminiamoli qui di seguito. 4.6.1.1 Interi positivi Gli indici \\(i, j\\) possono essere degli interi positivi che identificano l’elemento nella \\(i\\)-esima riga e nella \\(j\\)-esima colonna del data.frame. Per l’esempio relativo al mazzo di carte, l’istruzione deck[1, 1] #&gt; [1] king #&gt; Levels: ace eight five four jack king nine queen seven six ten three two ritorna il valore nella prima riga e nella prima colonna. Per estrarre più di un valore, usiamo un vettore di interi positivi. Per esempio, la prima riga di deck si trova con deck[1, c(1:3)] #&gt; face suit value #&gt; 1 king spades 13 Tale sistema notazionale non si applica solo ai data.frame ma può essere usato anche per gli altri oggetti di R. L’indice usato da R inizia da 1. In altri linguaggi di programmazione, per esempio C, inizia da 0. 4.6.1.2 Interi negativi Gli interi negativi fanno l’esatto contrario degli interi positivi: R ritornerà tutti gli elementi tranne quelli specificati dagli interi negativi. Per esempio, la prima riga del data.frame può essere specificata nel modo seguente deck[-(2:52), 1:3] #&gt; face suit value #&gt; 1 king spades 13 ovvero, escludendo tutte le righe seguenti. 4.6.1.3 Zero Quando lo zero viene usato come indice, R non ritorna nulla dalla dimensione a cui lo zero si riferisce. L’istruzione deck[0, 0] #&gt; data frame with 0 columns and 0 rows ritorna un data.frame vuoto. Non molto utile. 4.6.1.4 Spazio ’ ’ Uno spazio viene usato quale indice per comunicare a R di estrarre tutti i valori in quella dimensione. Questo è utile per estrarre intere colonne o intere righe da un data.frame. Per esempio, l’istruzione deck[3, ] #&gt; face suit value #&gt; 3 jack spades 11 ritorna la terza riga del data.frame deck. 4.6.1.5 Valori booleani Se viene fornito un vettore di stringhe TRUE, FALSE, R selezionerà gli elementi riga o colonna corrispondenti ai valori booleani TRUE usati quali indici. Per esempio, l’istruzione deck[3, c(TRUE, TRUE, FALSE)] #&gt; face suit #&gt; 3 jack spades ritorna i valori delle prime due colonne della terza riga di deck. 4.6.1.6 Nomi È possibile selezionare gli elementi del data.frame usando i loro nomi. Per esempio, deck[1, c(&quot;face&quot;, &quot;suit&quot;, &quot;value&quot;)] #&gt; face suit value #&gt; 1 king spades 13 deck[ , &quot;value&quot;] #&gt; [1] 13 12 11 10 9 8 7 6 5 4 3 2 1 13 12 11 10 9 8 7 6 5 4 3 2 1 13 12 11 #&gt; [30] 10 9 8 7 6 5 4 3 2 1 13 12 11 10 9 8 7 6 5 4 3 2 1 4.6.2 Giochi di carte Avendo presentato le nozioni base del sistema di notazione di R, utilizziamo tali conoscenze per manipolare il data.frame. L’istruzione deck[1:52, ] ritorna tutte le righe e tutte e le colonne del data.frame deck. Le righe sono identificate dal primo indice, che va da 1 a 52. Permutare in modo casuale l’indice delle righe equivale a mescolare il mazzo di carte. Per fare questo, utilizziamo la funzione sample() ponendo replace=FALSE e size uguale alla dimensione del vettore che contiene gli indici da 1 a 52: random &lt;- sample(1:52, size = 52, replace = FALSE) random #&gt; [1] 10 32 34 17 22 31 1 6 50 46 25 37 8 33 51 19 28 36 11 26 3 2 23 52 38 45 4 29 43 #&gt; [30] 7 27 41 47 40 24 18 30 12 48 9 42 20 14 16 39 44 21 5 35 15 13 49 Utilizzando il vettore random di indici permutati otteniamo il risultato cercato: deck_shuffled &lt;- deck[random, ] head(deck_shuffled) #&gt; face suit value #&gt; 10 four spades 4 #&gt; 32 eight diamonds 8 #&gt; 34 six diamonds 6 #&gt; 17 ten clubs 10 #&gt; 22 five clubs 5 #&gt; 31 nine diamonds 9 Possiamo ora scrivere una funzione che include le precedenti istruzioni: shuffle &lt;- function(cards) { random &lt;- sample(1:52, size = 52, replace = FALSE) return(cards[random, ]) } Invocando la funzione shuffle() possiamo generare un data.frame che rappresenta un mazzo di carte mescolato: deck_shuffled &lt;- shuffle(deck) Se immaginiamo di distribuire le carte di questo mazzo a due giocatori di poker, per il primo giocatore avremo: deck_shuffled[c(1, 3, 5, 7, 9), ] #&gt; face suit value #&gt; 37 three diamonds 3 #&gt; 13 ace spades 1 #&gt; 33 seven diamonds 7 #&gt; 50 three hearts 3 #&gt; 32 eight diamonds 8 e per il secondo: deck_shuffled[c(2, 4, 6, 8, 10), ] #&gt; face suit value #&gt; 17 ten clubs 10 #&gt; 38 two diamonds 2 #&gt; 48 five hearts 5 #&gt; 18 nine clubs 9 #&gt; 5 nine spades 9 4.6.3 Variabili locali Si noti che, nell’esempio precedente, abbiamo passato l’argomento deck alla funzione shuffle(), perché questo è il nome del data.frame che volevamo manipolare. Nella definizione della funzione shuffle(), però, l’argomento della funzione era chiamato cards. Il nome degli argomenti è diverso nei due casi. Allora perché l’istruzione shuffle(deck) non dà un messaggio d’errore? La risposta a questa domanda è che nelle funzioni le variabili nascono quando la funzione entra in esecuzione e muoiono al termine dell’esecuzione della funzione. Per questa ragione, sono dette ‘locali.’ La variabile cards, in questo esempio, esiste soltanto all’interno della funzione. Dunque non deve (necessariamente) avere lo stesso nome di un altro oggetto che esiste al di fuori della funzione, nello spazio di lavoro di R (anzi, è meglio se il nome degli oggetti usati all’interno delle funzioni è diverso da quello degli oggetti che esistono fuori dalle funzioni). R sa che l’oggetto deck passato a shuffle() corrisponde a cards all’interno della funzione perché assegna il nome cards a qualunque oggetto venga passato alla funzione shuffle() come primo (e, in questo caso, unico) argomento. "],["chapter-strutture-controllo.html", "Capitolo 5 Strutture di controllo Obiettivi di apprendimento Motivazione 5.1 Il ciclo for", " Capitolo 5 Strutture di controllo Obiettivi di apprendimento Lo studio di questo capitolo dovrebbe insegnare allo studente come: Sapere usare un ciclo for in R. Motivazione In R esistono strutture di controllo specifiche per regolare il flusso di esecuzione di un programma. I loop permettono di ripetere ciclicamente blocchi di istruzioni per un numero prefissato di volte o fino a che una determinata condizione logica viene soddisfatta. Questo li rende utili per la programmazione di simulazioni. 5.1 Il ciclo for Il ciclo for è una struttura di controllo iterativa che determina l’esecuzione di una porzione di programma ripetuta per un certo numero noto di volte. Il linguaggio R usa la seguente sintassi per il ciclo for: for (indice in valori_indice) { operazioni } il che significa “esegui le operazioni operazioni per i diversi valori di indice compresi nel vettore valori_indice.” Per esempio, il seguente ciclo for non fa altro che stampare il valore della variabile contatore in ciascuna esecuzione del ciclo: for (i in 1:3) { print(i) } #&gt; [1] 1 #&gt; [1] 2 #&gt; [1] 3 Un esempio (leggermente) più complicato è il seguente: x_list &lt;- seq(1, 9, by = 2) x_list #&gt; [1] 1 3 5 7 9 sum_x &lt;- 0 for (x in x_list) { sum_x &lt;- sum_x + x cat(&quot;L&#39;indice corrente e&#39;&quot;, x, &quot;\\n&quot;) cat(&quot;La frequenza cumulata e&#39;&quot;, sum_x, &quot;\\n&quot;) } #&gt; L&#39;indice corrente e&#39; 1 #&gt; La frequenza cumulata e&#39; 1 #&gt; L&#39;indice corrente e&#39; 3 #&gt; La frequenza cumulata e&#39; 4 #&gt; L&#39;indice corrente e&#39; 5 #&gt; La frequenza cumulata e&#39; 9 #&gt; L&#39;indice corrente e&#39; 7 #&gt; La frequenza cumulata e&#39; 16 #&gt; L&#39;indice corrente e&#39; 9 #&gt; La frequenza cumulata e&#39; 25 Per esempio, quanti numeri pari sono contenuti in un vettore? La risposta a questa domanda viene fornita dalla funzione countEvenNumbers() che possiamo definire come indicato qui sotto: countEvenNumbers &lt;- function(x) { count &lt;- 0 for (i in 1:length(x)) { if (x[i] %% 2 == 0) count = count + 1 } count } Nella funzione countEvenNumbers() abbiamo inizializzato la variabile count a zero. Prima dell’esecuzione del ciclo for, dunque, count vale zero. Il ciclo for viene eseguito tante volte quanti sono gli elementi che costituiscono il vettore x. L’indice i dunque assume valori compresi tra 1 e il valore che corrisponde al numero di elementi di x. L’operazione modulo, indicato con %% dà come risultato il resto della divisione euclidea del primo numero per il secondo. Per esempio, 9 %% 2 dà come risultato \\(1\\) perché questo è il resto della divisione \\(9/2\\). L’operazione modulo dà come risultato \\(0\\) per tutti i numeri pari. In ciascuna esecuzione del ciclo for l’operazione modulo viene eseguita, successivamente, su uno degli elementi di x. Se l’operazione modulo dà \\(0\\) come risultato, ovvero se il valore considerato è un numero pari, allora la variabile count viene incrementata di un’unità. L’istruzione return() ritorna dunque il numero di valori pari contenuti nel vettore di input alla funzione. Per esempio: x &lt;- c(1, 2, 1, 4, 6, 3, 9, 12) countEvenNumbers(x) #&gt; [1] 4 "],["chapter-input-output-R.html", "Capitolo 6 Input/Output Obiettivi di apprendimento Motivazione 6.1 La funzione read.table() 6.2 File di dati forniti da R 6.3 Esportazione di un file 6.4 Pacchetto rio 6.5 Dove sono i miei file?", " Capitolo 6 Input/Output Obiettivi di apprendimento Lo studio di questo capitolo dovrebbe insegnare allo studente come: Importare i dati da un file esterno in R. Motivazione I dati raccolti dallo psicologo sono contenuti in file aventi formati diversi: solo testo, CSV, Excel, eccetera. R prevede diverse funzioni di importazione dei dati. Esamineremo qui la funzione read.table() per l’importazione di dati in formato solo testo, ma funzioni analoghe possono essere usate per molti altri formati possibili. 6.1 La funzione read.table() Ci sono tanti modi per importare un file dal nostro computer. R permette di utilizzare delle funzioni che sono già nella libreria di base, oppure possiamo utilizzare delle funzioni specifiche, a seconda del tipo di file da importare, che sono contenute in pacchetti aggiuntivi. Per leggere i dati da file in R è conveniente preliminarmente generare un file di dati in formato ASCII, disponendoli come si farebbe in una matrice di dati, e mettere questo file nella cartella di lavoro corrente. Fatto questo, si può utilizzare la funzione read.table() presente nella libreria di base per leggere l’intero dataset. Se la prima riga del file contiene l’intestazione delle variabili, allora read.table(\"my_file.txt\", header = TRUE) interpreterà la prima riga del file come una riga dove sono contenuti i nomi delle variabili, assegnando ciascun nome alle variabili del data frame: mydata &lt;- read.table(&quot;my_file.txt&quot;, header = TRUE) In alternativa, si può impiegare la funzione read.csv(), che è adatta a leggere dati salvati in .csv. Utilizzando altre funzioni, si possono leggere in R i dati contenuti in file aventi formati diversi da quelli considerati qui, quali Excel, SPSS, ecc. 6.2 File di dati forniti da R In R esistono comunque oltre 50 insiemi di dati contenuti nel package base e altri sono disponibili in altri packages. Per vedere l’elenco degli insiemi di dati disponibili nel package base basta usare l’istruzione data(); per caricare un particolare insieme di dati, ad esempio cars, basta utilizzare l’istruzione data(cars) Nella maggior parte dei casi questo corrisponde a caricare un oggetto, solitamente un data.frame dello stesso nome: per l’esempio considerato si avrebbe un data frame di nome cars. 6.3 Esportazione di un file Per esportare un data.frame in formato .csv possiamo scrivere il seguente codice write.csv(df_esempio, file = &quot;esempio.csv&quot;, row.names = FALSE) dove df_esempio è il data.frame da salvare e esempio.csv è il file che verrà salvato all’interno della nostra cartellla di lavoro. 6.4 Pacchetto rio Un’alternativa più semplice è fornita dalle funzioni fornite dal pacchetto rio. Per importare i dati da un file in qualsiasi formato si usa my_data_frame &lt;- rio::import(&quot;my_file.csv&quot;) Per esportare i dati in un file avente qualsiasi formato si usa invece rio::export(my_data_frame, &quot;my_file.csv&quot;) 6.5 Dove sono i miei file? Quello che abbiamo detto finora, a proposito dell’importazione ed esportazione dei file, si riferisce a file che si trovano nella cartella di lavoro (working directory). Ma non sempre ci troviamo in questa situazione, il che è anche una buona cosa, perché se dobbiamo gestire un progetto anche leggermente complesso è sempre una buona idea salvare i file che usiamo in cartelle diverse. Per esempio, possiamo usare una cartella chiamata psicometria dove salviamo tutto il materiale di questo insegnamento. Nella cartella psicometria ci potrà essere una cartella chiamata scripts dove salveremo gli script con il codice R utilizzato per i vari esercizi, e una cartella chiamata data dove possiamo salvare i dati. Questa organizzazione minimale ci pone, però, difronte ad un problema: i dati che vogliamo caricare in R non si trovano più nella cartella dove sono contenuti gli script. Quando importiamo un file di dati dobbiamo dunque specificare il percorso che identifica la posizione sul nostro computer del file che ci interessa. Questo problema può essere risolto in due modi: speficicando l’inridizzo del file in modo assoluto o relativo. Specificare l’indirizzo di un file in modo assoluto ha una serie di limiti. Il più grande è che non sarà possibile utilizzare quell’istruzione su una macchina diversa. Dunque, è molto più conveniente specificare l’indirizzo dei file in modo relativo. Ma relativo rispetto a cosa? Rispetto alla working directory che definirà l’origine del nostro percorso. Ma è facile immaginare che progetti diversi possano avere diverse working directory. Infatti le cose stanno proprio in questo modo: per ciascun progetto dobbiamo specificare una diversa working directory. Per esempio, potremmo avere un progetto relativo all’insegnamento di Psicometria e un progetto relativo alla prova finale. Per organizzaere il lavoro in questo modo, si procede come segue. Supponiamo di creare una cartella chiamata psicometria che contiene, al suo interno, le cartelle scripts e data: psicometria/ ├── data ├── scripts Queste cartelle conterranno i file che ho specificato sopra. Chiudiamo RStudio, se è aperto e lo riapriamo di nuovo. Dal menu selezioniamo File -&gt; New Project… Questo aprirà un altro menu che ci chiederà, tra le altre cose se vogliamo creare un nuovo progetto (New project). Selezioniamo quell’opzione e navighiamo fino alla cartella psicometria e selezioniamo open. Questo creerà un file chiamato psicometria.Rproj nella cartella psicometria. Chiudiamo RStudio. Se vogliamo accedere al progetto “psicometria” dobbiamo cliccare sul file psicometria.Rproj. Questo aprirà RStudio e farà in modo che la working directory coincida con la cartalla psicometria. Ogni volta che vogliamo lavorare sui dati del progetto “psicometria” dobbiamo chiudere RStudio (se è già aperto) e riaprirlo cliccando sul file psicometria.Rproj. A questo punto possiamo definire l’indirizzo dei file in modo relativo – relativo alla cartella psicometria. Per fare questo usiamo le funzionalità del pacchetto here. Supponiamo di volere caricare un file di dati che si chiama dati_depressione.txt e si trova nella cartella data contenuta nella cartella psicometria. Per importare questi dati (dopo avere caricato i pacchetti rio e here) useremo l’istruzione seguente: rio::import(here(&quot;data&quot;, &quot;dati_depressione.txt&quot;)) In altre parole, così facendo specifichiamo il percorso relativo del file dati_depressione.txt. L’istruzione precedente significa che, partendo dalla cartella che coincide con la working directory dobbiamo spostarci nella cartella data e lì dentro troviamo il file chiamato dati_depressione.txt. "],["chapter-terminologia.html", "Capitolo 7 Terminologia 7.1 Metodi e procedure della psicologia 7.2 Variabili e costanti 7.3 Variabili indipendenti e variabili dipendenti 7.4 La matrice dei dati", " Capitolo 7 Terminologia 7.1 Metodi e procedure della psicologia Una teoria psicologica di un qualche aspetto del comportamento umano o della mente ha le seguenti proprietà: descrive le caratteristiche del comportamento in questione, formula predizioni sulle caratteristiche future del comportamento, è sostenuta da evidenze empiriche, deve essere falsificabile (ovvero, in linea di principio, deve potere fare delle predizioni su aspetti del fenomeno considerato che non sono ancora noti e che, se venissero indagati, potrebbero portare a rigettare la teoria, se si dimostrassero incompatibili con essa). L’analisi dei dati si riferisce al punto 3 indicato sopra e, nelle sue fasi distinte, ovvero la misurazione, l’analisi descrittiva, l’inferenza causale, ha un ruolo centrale nello sviluppo delle teorie psicologiche. Prima di affrontare il primo degli ambiti in cui abbiamo articolato l’analisi dei dati, ovvero quello della misurazione, prenderemo qui in esame la terminologia che viene utilizzata. 7.2 Variabili e costanti L’analisi dei dati inizia con l’individuazione delle unità portatrici di informazioni circa il fenomeno di interesse. Si dice popolazione (o universo) l’insieme \\(\\Omega\\) delle entità capaci di fornire informazioni sul fenomeno oggetto dell’indagine statistica. Possiamo dunque scrivere \\(\\Omega = \\{\\omega_i\\}_{i=1, \\dots, n}= \\{\\omega_1, \\omega_2, \\dots, \\omega_n\\}\\) oppure \\(\\Omega = \\{\\omega_1, \\omega_2, \\dots \\}\\) nel caso di popolazioni finite o infinite, rispettivamente. Gli elementi \\(\\omega_i\\) dell’insieme \\(\\Omega\\) sono detti unità statistiche. Un sottoinsieme della popolazione viene chiamato campione. Ciascuna unità statistica \\(\\omega_i\\) (abbreviata con u.s.) è portatrice dell’informazione che verrà rilevata mediante un’operazione di misurazione. Definiamo variabile statistica la proprietà (o grandezza) che è oggetto di studio nell’analisi dei dati. Una variabile è una proprietà di un fenomeno che può essere espressa in più valori sia numerici sia categoriali. Il termine “variabile” si contrappone al termine “costante” che descrive una proprietà invariante di tutte le unità statistiche. Si dice modalità ciascuna delle varianti con cui una variabile statistica può presentarsi. Definiamo insieme delle modalità di una variabile statistica l’insieme \\(M\\) di tutte le possibili espressioni con cui la variabile può manifestarsi. Le modalità osservate e facenti parte del campione si chiamano dati (si veda la Tabella 1.1). Proprietà oggetto di studio, variabile e modalità. Fenomeno studiato Popolazione Variabile Modalità Tipo Intelligenza Tutti gli italiani WAIS-IV \\(112\\), \\(92\\), \\(121\\), … Quantitativo discreto Velocità di esecuzione nel compito Stroop Bambini dai 6 agli 8 anni Reciproco dei tempi di reazione \\(1/2.36\\) s, \\(1/4.72\\) s, \\(1/3.81\\) s, … Quantitativo continuo Disturbo di personalità Detenuti nelle carceri italiane Assessment del disturbo di personalità tramite interviste cliniche strutturate Cluster A, Cluster B, Cluster C proposti dal DSM-V Qualitativo 7.3 Variabili indipendenti e variabili dipendenti È importante distinguere il concetto di variabile indipendente, che descrive ciò che viene manipolato dallo sperimentatore o che è già presente nel campione, dalla variabile dipendente, che descrive ciò che varia al variare della variabile indipendente e che viene misurato nel campione. Exercizio 7.1 Uno psicologo convoca 120 studenti universitari per un test di memoria. Prima di iniziare l’esperimento, a metà dei soggetti viene detto che si tratta di un compito particolarmente difficile; agli altri soggetti non viene data alcuna indicazione. Lo psicologo misura il punteggio nella prova di memoria di ciascun soggetto. Si individuino la variabile indipendente e la variabile dipendente di questo esperimento. Soluzione. La variabile indipendente è l’informazione sulla difficoltà della prova. La variabile indipendente viene manipolata dallo sperimentatore assegnando i soggetti (di solito in maniera causale) o alla condizione (modalità) “informazione assegnata” o “informazione non data.” La variabile dipendente è ciò che viene misurato nell’esperimento, ovvero il punteggio nella prova di memoria di ciascun soggetto. 7.4 La matrice dei dati Le realizzazioni delle variabili esaminate in una rilevazione statistica vengono organizzate in una matrice dei dati. Le colonne della matrice dei dati contengono gli insiemi dei dati individuali di ciascuna variabile statistica considerata. Ogni riga della matrice contiene tutte le informazioni relative alla stessa unità statistica. Una generica matrice dei dati ha l’aspetto seguente: \\[D_{m,n} = \\begin{pmatrix} \\omega_1 &amp; a_{1} &amp; b_{1} &amp; \\cdots &amp; x_{1} &amp; y_{1}\\\\ \\omega_2 &amp; a_{2} &amp; b_{2} &amp; \\cdots &amp; x_{2} &amp; y_{2}\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots \\\\ \\omega_n &amp; a_{n} &amp; b_{n} &amp; \\cdots &amp; x_{n} &amp; y_{n} \\end{pmatrix}\\] dove, nel caso presente, la prima colonna contiene il nome delle unità statistiche, la seconda e la terza colonna si riferiscono a due mutabili statistiche (variabili categoriali; \\(A\\) e \\(B\\)) e ne presentano le modalità osservate nel campione mentre le ultime due colonne si riferiscono a due variabili statistiche (\\(X\\) e \\(Y\\)) e ne presentano le modalità osservate nel campione. Generalmente, tra le unità statistiche \\(\\omega_i\\) non esiste un ordine progressivo; l’indice attribuito alle unità statistiche nella matrice dei dati si riferisce semplicemente alla riga che esse occupano. "],["chapter-misurazione.html", "Capitolo 8 La misurazione in psicologia 8.1 Le scale di misura 8.2 Variabili discrete vs. variabili continue 8.3 Perché alcune misurazioni sono migliori di altre? Conclusioni", " Capitolo 8 La misurazione in psicologia Le osservazioni empiriche – osservazioni sul campo, sondaggi o risultati di esperimenti – forniscono il materiale che viene utilizzato in un’indagine statistica e sono chiamate dati. Quando parliamo di dati dobbiamo chiederci: in che misura i dati che sono stati raccolti sono in grado di rappresentare in maniera veritiera le caratteristiche del fenomeno esaminato? C’è un’intera disciplina che cerca di rispondere alla domanda precedente: la “teoria della misurazione.” Senza entrare nei dettagli, il presente capitolo intende fornire un’introduzione generale alle tematiche della misurazione in psicologia. 8.1 Le scale di misura I risultati delle misurazioni, ovvero le variabili, devono avere almeno due valori possibili (altrimenti sarebbero delle costanti). È importante notare che le modalità delle variabili sono in grado di descrivere l’intensità del fenomeno misurato con livelli diversi di precisione. La capacità delle variabili di “catturare” in forma numerica le proprietà del fenomeno che esse rappresentano viene descritta dalla teoria delle scale di misura di Stevens (1946). Secondo tale teoria, possiamo distinguere quattro scale di misura aventi proprietà diverse: le scale nominali (nominal scales), ordinali (ordinal scales), a intervalli (interval scales), di rapporti (ratio scales). 8.1.1 Scala nominale La scala nominale raggruppa i dati in categorie qualitative mutuamente esclusive (cioè nessun dato si può collocare in più di una categoria). Esiste la sola relazione di equivalenza tra le misure delle u.s., cioè nella scala nominale gli elementi del campione appartenenti a classi diverse sono differenti, mentre tutti quelli della stessa classe sono tra loro equivalenti: \\(x_i = x_j\\) oppure \\(x_i \\neq x_j\\). È ammessa l’operazione del conteggio delle u.s. presenti in ogni categoria e il conteggio delle classi di equivalenze, dunque la descrizione dei dati avviene tramite le frequenze assolute e le frequenze relative. A partire da una scala nominale è possibile costruire altre scale equivalenti trasformando i valori della scala di partenza in modo tale da cambiare i nomi delle modalità ma lasciando però inalterata la suddivisione u.s. nelle medesime classi di equivalenza. Questo significa che prendendo una variabile misurata su scala nominale e cambiando i nomi delle sue categorie otteniamo una nuova variabile esattamente corrispondente alla prima. 8.1.2 Scala ordinale La scala ordinale conserva la proprietà della scala nominale di classificare ciascun dato all’interno di una sola categoria, ma alla relazione di equivalenza tra elementi di una stessa classe aggiunge la relazione di ordinamento tra le varie classi di equivalenza. Essendo basata su una relazione d’ordine, una scala ordinale descrive soltanto l’ordine di rango tra le modalità, ma non dà alcuna informazione su quanto una modalità sia più grande di un’altra. Non ci dice, per esempio, se la distanza tra le modalità \\(a\\) e \\(b\\) sia uguale, maggiore o minore della distanza tra le modalità \\(b\\) e \\(c\\). Esempio 8.1 (Scala Mohs) Un esempio classico di scala ordinale è quello della scala Mohs per la determinazione della durezza dei minerali. Per stabilire la durezza dei minerali si usa il criterio empirico della scalfittura. Vengono stabiliti livelli di durezza crescente da 1 a 10 con riferimento a dieci minerali: talco, gesso, calcite, fluorite, apatite, ortoclasio, quarzo, topazio, corindone e diamante. Un minerale appartenente ad uno di questi livelli se scalfisce quello di livello inferiore ed è scalfito da quello di livello superiore. 8.1.3 Scala ad intervalli La scala ad intervalli include le proprietà di quella nominale e di quella ordinale, e in più consente di misurare le distanze tra le coppie di u.s. nei termini di un intervallo costante, chiamato unità di misura, a cui viene attribuito il valore “1.” La posizione dell’origine della scala, cioè il punto zero, è scelta arbitrariamente, nel senso che non indica l’assenza della quantità che si sta misurando. Avendo uno zero arbitrario, questa scala di misura consente valori negativi. Lo zero, infatti, non viene attribuito all’u.s. in cui la proprietà misurata risulta assente. La scala a intervalli equivalenti ci consente di effettuare operazioni algebriche basate sulla differenza tra i numeri associati ai diversi punti della scala, operazioni algebriche non era possibile eseguire nel caso di misure a livello di scala ordinale o nominale. Il limite della scala ad intervalli è quello di non consentire il calcolo del rapporto tra coppie di misure. Possiamo dire, per esempio, che la distanza tra \\(a\\) e \\(b\\) è la metà della distanza tra \\(c\\) e \\(d\\). Oppure che la distanza tra \\(a\\) e \\(b\\) è uguale alla distanza tra \\(c\\) e \\(d\\). Non possiamo dire, però, che \\(a\\) possiede la proprietà misurata in quantità doppia rispetto \\(b\\). Non possiamo cioè stabilire dei rapporti diretti tra le misure ottenute. Solo per le differenze tra le modalità sono dunque permesse tutte le operazioni aritmetiche: le differenze possono essere tra loro sommate, elevate a potenza oppure divise, determinando così le quantità che stanno alla base della statistica inferenziale. Nelle scale ad intervalli equivalenti, l’unità di misura è arbitraria, ovvero può essere cambiata attraverso una dilatazione, operazione che consiste nel moltiplicare tutti i valori della scala per una costante positiva. Poiché l’aggiunta di una costante non altera le differenze tra i valori della scala, è anche ammessa la traslazione, operazione che consiste nel sommare una costante a tutti i valori della scala. Essendo la scala invariate rispetto alla traslazione e alla dilatazione, le trasformazioni ammissibili sono le trasformazioni lineari: \\[y&#39; = a + by, \\quad b &gt; 0.\\] L’aspetto che rimane invariante a seguito di una trasformazione lineare è l’uguaglianza dei rapporti fra intervalli. Esempio 8.2 (Temperatura) Esempio di scala ad intervalli è la temperatura misurata in gradi Celsius o Fahrenheit, ma non Kelvin. Come per la scala nominale, è possibile stabilire se due modalità sono uguali o diverse: 30\\(^\\circ\\)C \\(\\neq\\) 20\\(^\\circ\\)C. Come per la scala ordinale è possibile mettere due modalità in una relazione d’ordine: 30\\(^\\circ\\)C \\(&gt;\\) 20\\(^\\circ\\)C. In aggiunta ai casi precedenti, però, è possibile definire una unità di misura per cui è possibile dire che tra 30\\(^\\circ\\)C e 20\\(^\\circ\\)C c’è una differenza di 30\\(^\\circ\\) - 20\\(^\\circ\\) = 10\\(^\\circ\\)C. I valori di temperatura, oltre a poter essere ordinati secondo l’intensità del fenomeno, godono della proprietà che le differenze tra loro sono direttamente confrontabili e quantificabili. Il limite della scala ad intervalli è quello di non consentire il calcolo del rapporto tra coppie di misure. Ad esempio, una temperatura di 80\\(^\\circ\\)C non è il doppio di una di 40\\(^\\circ\\)C. Se infatti esprimiamo le stesse temperature nei termini della scala Fahrenheit, allora i due valori non saranno in rapporto di 1 a 2 tra loro. Infatti, 20\\(^\\circ\\)C = 68\\(^\\circ\\)F e 40\\(^\\circ\\)C = 104\\(^\\circ\\)F. Questo significa che la relazione “il doppio di” che avevamo individuato in precedenza si applicava ai numeri della scala centigrada, ma non alla proprietà misurata (cioè la temperatura). La decisione di che scala usare (Centigrada vs. Fahrenheit) è arbitraria. Ma questa arbitrarietà non deve influenzare le inferenze che traiamo dai dati. Queste inferenze, infatti, devono dirci qualcosa a proposito della realtà empirica e non possono in nessun modo essere condizionate dalle nostre scelte arbitrarie che ci portano a scegliere la scala Centigrada piuttosto che quella Fahrenheit. Consideriamo ora l’aspetto invariante di una trasformazione lineare, ovvero l’uguaglianza dei rapporti fra intervalli. Prendiamo in esame, ad esempio, tre temperature: \\(20^\\circ C = 68^\\circ F\\), \\(15^\\circ C = 59^\\circ F\\), \\(10^\\circ C = 50 ^\\circ F\\). È facile rendersi conto del fatto che i rapporti fra intervalli restano costanti indipendentemente dall’unità di misura che è stata scelta: \\[ \\frac{20^\\circ C - 10^\\circ C}{20^\\circ C - 15^\\circ C} = \\frac{68^\\circ F - 50^\\circ F}{68^\\circ F-59^\\circ F} = 2. \\] 8.1.4 Scala di rapporti Nella scala a rapporti equivalenti la posizione dello zero non è arbitraria, ma corrisponde all’elemento dotato di intensità nulla rispetto alla proprietà misurata. Una scala a rapporti equivalenti si costruisce associando il numero 0 all’elemento con intensità nulla; viene poi scelta un’unità di misura \\(u\\) e, ad ogni elemento, si assegna un numero \\(a\\) definito come: \\[a = \\frac{d}{u}\\] dove \\(d\\) rappresenta la distanza dall’origine. Alle u.s. vengono dunque assegnati dei numeri tali per cui le differenze e i rapporti tra i numeri riflettono le differenze e i rapporti tra le intensità della proprietà misurata. Operazioni aritmetiche sono possibili non solo sulle differenze tra i valori della scala (come per la scala a intervalli equivalenti), ma anche sui valori stessi della scala. L’unica arbitrarietà riguarda l’unità di misura che si utilizza. L’unità di misura può cambiare, ma qualsiasi unità di misura si scelga, lo zero deve sempre indicare l’intensità nulla della proprietà considerata. Le trasformazioni ammissibili a questo livello di scala sono dette trasformazioni di similarità: \\[y&#39; = by, \\quad b &gt; 0.\\] A questo livello di scala, a seguito delle trasformazioni ammissibili, rimangono invariati anche i rapporti: \\[\\frac{y_i}{y_j} = \\frac{y&#39;_i}{y&#39;_j}.\\] 8.1.5 Gerarchia dei livelli di scala di misura Stevens (1946) parla di livelli di scala poiché i quattro tipi di scala di misura stanno in una precisa gerarchia: la scala nominale rappresenta il livello più basso della misurazione, la scala a rapporti equivalenti è invece il livello più alto. Scale di modalità Operazioni aritmetiche nominali enumerare le classi di equivalenza e/o le frequenze per ciascuna classe di equivalenza ordinali enumerare le classi di equivalenza e/o le frequenze per ciascuna classe di equivalenza intervallari differenze (rapporti tra differenze) di rapporti rapporti diretti tra le misure Passando da un livello di misurazione ad uno più alto aumenta il numero di operazioni aritmetiche che possono essere compiute sui valori della scala, come indicato nella figura seguente. Figura 8.1: I quattro livelli di scala secondo Stevens (1946). Per ciò che riguarda le trasformazioni ammissibili, più il livello di scala è basso, più le funzioni sono generali (sono minori cioè i vincoli per passare da una rappresentazione numerica ad un’altra equivalente). Salendo la gerarchia, la natura delle funzioni di trasformazione si fa più restrittiva. 8.2 Variabili discrete vs. variabili continue Le variabili a livello di intervalli e di rapporti possono essere discrete o continue. Le variabili discrete possono assumere alcuni valori ma non altri. Una volta che l’elenco di valori accettabili è stato specificato, non ci sono casi che cadono tra questi valori. Le variabili discrete di solito assumono valori interi. Quando una variabile può assumere qualsiasi valore entro un intervallo specificato, allora si dice che la variabile è continua. In teoria, ciò significa che frazioni e decimali possono essere utilizzati per raggiungere un livello di precisione qualsiasi. In pratica, a un certo punto dobbiamo arrotondare i numeri, rendendo tecnicamente la variabile discreta. In variabili veramente discrete, tuttavia, non è possibile aumentare a piacimento il livello di precisione della misurazione. Figura 8.2: Le variabili continue possono assumere un insieme continuo di valori, al contrario delle variabili discrete, per le quali l’insieme dei possibili valori ha cardinalità al più numerabile. Esempio 8.3 Il numero di biciclette possedute da una persona è una variabile discreta poiché tale variabile può assumere come modalità solo i numeri interi non negativi. Le frazioni di biciclette non sono sensate. 8.3 Perché alcune misurazioni sono migliori di altre? In psicologia, ciò che vogliamo misurare non è una caratteristica fisica, ma invece è un concetto teorico inosservabile, ovvero un costrutto. Ad esempio, supponiamo che un docente voglia valutare quanto bene uno studente comprenda la distinzione tra le quattro diverse scale di misura che sono state descritte sopra. Il docente potrebbe predisporre un test costituito da un insieme di domande e potrebbe contare a quante domande lo studente risponde correttamente. Questo test, però, può o può non essere una buona misura del costrutto relativo alla conoscenza effettiva delle quattro scale di misura. Per esempio, se il docente scrive le domande del test in modo ambiguo o se usa una linguaggio troppo tecnico che lo studente non conosce, allora i risultati del test potrebbero suggerire che lo studente non conosce la materia in questione anche se in realtà questo non è vero. D’altra parte, se il docente prepara un test a scelta multipla con risposte errate molto ovvie, allora lo studente può ottenere dei buoni risultati al test anche senza essere in grado di comprendere adeguatamente le proprietà delle quattro scale di misura. In generale non è possibile misurare un costrutto senza una certa quantità di errore. Poniamoci dunque il problema di determinare in che modo una misurazione possa dirsi adeguata. 8.3.1 Tipologie di errori L’errore è, per definizione, la differenza tra il valore vero e il valore misurato della grandezza in esame. Gli errori sono classificati come sistematici (o determinati) e casuali (o indeterminati). Gli errori casuali sono fluttuazioni, in eccesso o in difetto rispetto al valore reale, delle singole determinazioni e sono dovuti alle molte variabili incontrollabili che influenzano ogni misura psicologica. Gli errori sistematici, invece, influiscono sulla misurazione sempre nello stesso senso e, solitamente, per una stessa quantità (possono essere additivi o proporzionali). Le differenze tra le due tipologie di errori, sistematici e casuali, introducono i concetti di accuratezza e di precisione della misura. Una misura viene definita: accurata, quando vi è un accordo tra la misura effettuata ed il valore reale; precisa quando, ripetendo più volte la misura, i risultati ottenuti sono concordanti, cioè differiscono in maniera irrilevante tra loro. La metafora del tiro a bersaglio illustra la relazione tra precisione e accuratezza. Figura 8.3: Illustrazione dei concetti di precisione e accuratezza: (a) bassa precisione e bassa accuratezza, (b) bassa precisione e alta accuratezza, (c) alta precisione e bassa accuratezza, (d) alta precisione e alta accuratezza. Per tenere sotto controllo l’incidenza degli errori, sono stati introdotti in psicologia i concetti di attendibilità e validità: l’attendibilità esprime il grado di accordo o coerenza tra misurazioni indipendenti dello stesso costrutto psicologico3; la validità descrive il grado in cui uno strumento misura ciò che dice di misurare. 8.3.2 Attendibilità Uno strumento si dice attendibile quando valuta in modo coerente e stabile la stessa variabile: i risultati ottenuti si mantengono costanti dopo ripetute somministrazione ed in assenza di variazioni psicologiche e fisiche dei soggetti sottoposti al test o cambiamenti dell’ambiente in cui ha luogo la somministrazione. 8.3.3 Validità L’attendibilità di uno strumento non è sufficiente: in primo luogo uno strumento di misura deve essere valido, laddove la validità rappresenta il grado in cui uno strumento misura effettivamente ciò che dovrebbe misurare. In genere, si fa riferimento ad almeno quattro tipi di validità. La validità di costrutto riguarda il grado in cui un test misura ciò per cui è stato costruito. Essa si suddivide in: validità convergente e validità divergente. La validità convergente fa riferimento alla concordanza tra uno strumento e un altro che misura lo stesso costrutto. La validità divergente, al contrario, valuta il grado di discriminazione tra strumenti che misurano costrutti differenti. Senza validità di costrutto le altre forme di validità non hanno senso. In base alla validità di contenuto, un test fornisce una misura valida di un attributo psicologico se il dominio dell’attributo è rappresentato in maniera adeguata dagli item del test. Un requisito di base della validità di contenuto è la rilevanza e la rappresentatività del contenuto degli item in riferimento all’attributo che il test intende misurare. La validità di criterio valuta il grado di concordanza tra i risultati dello strumento considerato e i risultati ottenuti da altri strumenti che misurano lo stesso costrutto, o tra i risultati dello strumento considerato e un criterio esterno. Nella validità concorrente, costrutto e criterio vengono misurati contestualmente, consentendo un confronto immediato. Nella validità predittiva, il costrutto viene misurato prima e il criterio in un momento successivo, consentendo la valutazione della capacità dello strumento di predire un evento futuro. Infine, la validità di facciata fa riferimento al grado in cui il test appare valido ai soggetti a cui esso è diretto. La validità di facciata è importante in ambiti particolari, quali ad esempio la selezione del personale per una determinata occupazione. In questo caso è ovviamente importante che chi si sottopone al test ritenga che il test vada a misurare quegli aspetti che sono importanti per le mansioni lavorative che dovranno essere svolte, piuttosto che altre cose. In generale, la validità di facciata non è utile, tranne in casi particolari. Conclusioni Una domanda che uno psicologo spesso si pone è: “sulla base delle evidenze osservate, possiamo concludere dicendo che l’intervento psicologico è efficace nel trattamento e nella cura del disturbo?” Le considerazioni svolte in questo capitolo dovrebbero farci capire che, prima di cercare di rispondere a questa domanda con l’analisi statistica dei dati, devono essere affrontati i problemi della validità e dell’attendibilità delle misure (oltre a stabilire l’appropriato livello di scala di misura delle osservazioni). L’attendibilità è un prerequisito della validità. Se gli errori di misurazione sono troppo grandi, i dati sono inutili. Inoltre, uno strumento di misurazione può essere preciso ma non valido. La validità e l’attendibilità delle misurazioni sono dunque entrambe necessarie. In generale, l’attendibilità e la validità delle misure devono essere valutate per capire se i dati raccolti da un ricercatore siano adeguati (1) per fornire una risposta alla domanda della ricerca, e (2) per giungere alla conclusione proposta dal ricercatore alla luce dei risultati dell’analisi statistica che è stata eseguita. È chiaro che le informazioni fornite in questo capitolo si limitano a scalfire la superficie di questi problemi. I concetti qui introdotti, però, devono sempre essere tenuti a mente e costituiscono il fondamento di quanto verrà esposto nei capitoli successivi. In seguito, quest’idea è stata completamente screditata.↩︎ "],["chapter-descriptive-stats.html", "Capitolo 9 Statistica descrittiva 9.1 Perché riassumere i dati? 9.2 Distribuzioni di frequenze 9.3 Istogramma 9.4 Funzione di densità empirica 9.5 Forma di una distribuzione 9.6 Indici di posizione 9.7 Indici di tendenza centrale 9.8 Indici di dispersione 9.9 Le relazioni tra variabili 9.10 Correlazione e causazione Conclusioni 9.11 Esercizi", " Capitolo 9 Statistica descrittiva Nel 1907 Francis Galton, cugino di Charles Darwin, matematico e statistico autodidatta, geografo, esploratore, teorico della dattiloscopia (ovvero, dell’uso delle impronte digitali a fini identificativi) e dell’eugenetica, scrisse una lettera alla rivista scientifica Nature sulla sua visita alla Fat Stock and Poultry Exhibition di Plymouth. Lì vide alcuni membri del pubblico partecipare ad un gioco il cui scopo era quello di indovinare il peso della carcassa di un grande bue che era appena stato scuoiato. Galton si procurò i 787 dei biglietti che erano stati compilati dal pubblico e considerò il valore medio di 547 kg come la “scelta democratica” dei partecipanti, in quanto “ogni altra stima era stata giudicata troppo alta o troppo bassa dalla maggioranza dei votanti.” Il punto interessante è che il peso corretto di 543 kg si dimostrò essere molto simile alla “scelta democratica” basata sulle stime dei 787 partecipanti. Galton intitolò la sua lettera a Nature Vox Populi (voce del popolo), ma questo processo decisionale è ora meglio conosciuto come la “saggezza delle folle” (wisdom of crowds). Possiamo dire che, nel suo articolo del 1907, Galton effettuò quello che ora chiamiamo un riepilogo dei dati, ovvero calcolò un indice sintetico a partire da un insieme di dati. In questo capitolo esamineremo le tecniche che sono state sviluppate nel secolo successivo per riassumere le grandi masse di dati con cui sempre più spesso ci dobbiamo confrontare. Vedremo come calcolare e interpretare gli indici di posizione e di dispersione, discuteremo le distribuzioni di frequenze e le relazioni tra variabili. Vedremo inoltre quali sono le tecniche di visualizzazione che ci consentono di rappresentare questi sommari dei dati mediante dei grafici. Ma prima di entrare nei dettagli, prendiamoci un momento per capire perché abbiamo bisogno della statistica descrittiva. 9.1 Perché riassumere i dati? Quando riassumiamo i dati, necessariamente buttiamo via delle informazioni. Ma è una buona idea procedere in questo modo? Non sarebbe meglio conservare le informazioni specifiche di ciascun soggetto che partecipa ad un esperimento psicologico, al di là di ciò che viene trasmesso dagli indici riassuntivi della statistica descrittiva? Che dire delle informazioni che descrivono come sono stati raccolti i dati, come l’ora del giorno o l’umore del partecipante? Tutte queste informazioni vengono perdute quando riassumiamo i dati. La risposta alla domanda che ci siamo posti è che, in generale, non è una buona idea conservare tutti i dettagli di ciò che sappiamo. È molto più utile riassumere le informazioni perché la semplificazione risultante consente i processi di generalizzazione. In un contesto letterario, l’importanza della generalizzazione è stata sottolineata da Jorge Luis Borges nel suo racconto “Funes o della memoria,” che descrive un individuo che perde la capacità di dimenticare. Borges si concentra sulla relazione tra generalizzazione e pensiero: Pensare è dimenticare una differenza, generalizzare, astrarre. Nel mondo troppo pieno di Funes, c’erano solo dettagli. Come possiamo ben capire, la vita di Funes non è facile. Se facciamo riferimento alla psicologia possiamo dire che gli psicologi hanno studiato a lungo l’utilità della generalizzazione per il pensiero. Un esempio è fornito dal fenomeno della formazione dei concetti e lo psicologo che viene in mente a questo proposito è sicuramente Eleanor Rosch, la quale ha studiato i principi di base della categorizzazione. I concetti ci forniscono uno strumento potente per organizzare le conoscenze. Noi siamo in grado di riconoscere facilmente i diversi esemplare di un concetto – per esempio, “gli uccelli” – anche se i singoli esemplari che fanno parte di una categoria sono molto diversi tra loro (l’aquila, la gallina, il pettirosso). L’uso dei concetti, cioè la generalizzazione, è utile perché ci consente di fare previsioni sulle proprietà dei singoli esemplari che appartengono ad una categoria, anche se non abbiamo mai avuto esperienza diretta con essi – per esempio, possiamo fare la predizione che tutti gli uccelli possono volare e mangiare vermi, ma non possono guidare un’automobile o parlare in inglese. Queste previsioni non sono sempre corrette, ma sono utili. Le statistiche descrittive, in un certo senso, ci fornisco l’analogo dei “prototipi” che, secondo Eleanor Rosch, stanno alla base del processo psicologico di creazione dei concetti. Un prototipo è l’esemplare più rappresentativo di una categoria. In maniera simile, una statistica descrittiva come la media, ad esempio, potrebbe essere intesa come l’osservazione “tipica.” La statistica descrittiva ci fornisce gli strumenti per riassumere i dati che abbiamo a disposizione in una forma visiva o numerica. Le rappresentazioni grafiche più usate della statistica descrittiva sono gli istogrammi, i diagrammi a dispersione o i box-plot, e gli indici sintetici più comuni sono la media, la mediana, la varianza e la deviazione standard. 9.2 Distribuzioni di frequenze Per introdurre i principali strumenti della statistica descrittiva considereremo qui i dati raccolti da Zetsche et al. (2019). Questi autori hanno studiato le aspettative negative le quali sono state evidenziate come un meccanismo chiave nel mantenimento e nella reiterazione della depressione. Zetsche et al. (2019) hanno valutato le aspettative di individui depressi circa il loro umore futuro ed si sono chiesti se queste aspettative fossero accurate oppure distorte negativamente. In uno degli studi descritti viene esaminato un campione costituito da 30 soggetti con almeno un episodio depressivo maggiore e da 37 controlli sani. Gli autori hanno misurato il livello depressivo con il Beck Depression Inventory (BDI-II). Ma qual è la la gravità della depressione riportata dai soggetti nel campione esaminato da Zetsche et al. (2019)? Dei 67 soggetti considerati, uno non ha completato il BDI-II e quindi abbiamo a disposizione 66 valori del BDI-II. I dati sono riportati nella tabella [tab:bdi2_values]. Per semplicità i dati sono stati ordinati in ordine crescente. È chiaro che i dati grezzi sono di difficile lettura. Poniamoci dunque il problema di creare una rappresentazione sintetica e comprensibile di questo insieme di valori. Uno dei modi che ci consentono di effettuare una sintesi dei dati è quello di generare una distribuzione di frequenze. Una distribuzione di frequenze è un riepilogo del conteggio della frequenza con cui le modalità osservate in un insieme di dati si verificano in un intervallo di valori. Per creare una distribuzione di frequenze possiamo procedere effettuando una partizione delle modalità della variabile di interesse in \\(m\\) classi (denotate con \\(\\Delta_i\\)) tra loro disgiunte. In tale partizione, la classe \\(i\\)-esima coincide con un intervallo di valori aperto a destra \\([a_i, b_i)\\) o aperto a sinistra \\((a_i, b_i]\\). Ad ogni classe \\(\\Delta_i\\) avente \\(a_i\\) e \\(b_i\\) come limite inferiore e superiore associamo l’ampiezza \\(b_i - a_i\\) (non necessariamente uguale per ogni classe) e il valore centrale \\(\\bar{x}_i\\). La scelta delle classi è arbitraria, ma è buona norma non definire classi con un numero troppo piccolo (&lt; 5) di osservazioni. Poiché ogni elemento dell’insieme \\(\\{x_i\\}_{i=1}^n\\) appartiene ad una ed una sola classe \\(\\Delta_i\\), possiamo calcolare le quantità elencate di seguito. La frequenza assoluta \\(n_i\\) di ciascuna classe, ovvero il numero di osservazioni che ricadono nella classe \\(\\Delta_i\\). Proprietà: \\(n_1 + n_2 + \\dots + n_m = n\\). La frequenza relativa \\(f_i = n_i/n\\) di ciascuna classe. Proprietà: \\(f_1+f_2+\\dots+f_m =1\\). La frequenza cumulata \\(N_i\\), ovvero il numero totale delle osservazioni che ricadono nelle classi fino alla \\(i\\)-esima compresa: \\(N_i = \\sum_{i=1}^m n_i.\\) La frequenza cumulata relativa \\(F_i\\), ovvero \\(F_i = f_1+f_2+\\dots+f_m = \\frac{N_i}{n} = \\frac{1}{n} \\sum_{i=1}^m f_i.\\) Calcoliamo ora la distribuzione di frequenza assoluta e la distribuzione di frequenza relativa per i valori del BDI-II del campione clinico di Zetsche et al. (2019). Per costruire una distribuzione di frequenza è innanzitutto necessario scegliere gli intervalli delle classi. Facendo riferimento ai cut-off usati per l’interpretazione del BDI-II, definiamo i seguenti intervalli aperti a destra: depressione minima: [0, 13.5), depressione lieve: [13.5, 19.5), depressione moderata: [19.5, 28.5), depressione severa: [28.5, 63). La distribuzione di frequenza della variabile bdi2 è riportata nella tabella seguente. Questa distribuzione di frequenza ci aiuta a capire meglio cosa sta succedendo. Se consideriamo la frequenza relativa, ad esempio, possiamo notare che ci sono due valori maggiormente ricorrenti e tali valori corrispondono alle due classi più estreme. Questo ha senso nel caso presente, in quanto il campione esaminato da Zetsche et al. (2019) includeva due gruppi di soggetti: soggetti sani (con valori BDI-II bassi) e soggetti depressi (con valori BDI-II alti). In una distribuzione di frequenza tali valori tipici vanno sotto il nome di mode della distribuzione. Limiti delle classi Freq. ass. Freq. rel. Freq. ass. cum. Freq. rel. cum. \\([0, 13.5)\\) 36 36/66 36 36/66 \\([13.5, 19.5)\\) 1 1/66 37 37/66 \\([19.5, 28.5)\\) 12 12/66 49 49/66 \\([28.5, 63)\\) 17 17/66 66 66/66 9.2.1 Esercizio con R Poniamoci ora il problema di costruire la tabella precedente partendo dai dati grezzi messi a disposizione da Zetsche et al. (2019). Leggiamo i dati assumendo che il file data.mood.csv si trovi nella cartella data contenuta nella working directory. df &lt;- read.csv( here(&quot;data&quot;, &quot;data.mood.csv&quot;), header=TRUE ) C’è un solo valore di depressione per ciascun soggetto ma tale valore viene ripetuto tante volte quante volte sono le righe del data.frame associate ad ogni soggetto (ciascuna riga corrispondente ad una prova diversa). È dunque necessario trasformare il data.frame in modo tale da avere un’unica riga per ciascun soggetto, ovvero un unico valore BDI-II per soggetto. bysubj &lt;- df %&gt;% group_by(esm_id) %&gt;% summarise( bdi = mean(bdi) ) %&gt;% na.omit() #&gt; `summarise()` ungrouping output (override with `.groups` argument) Ci sono dunque 66 soggetti i quali hanno ottenuto i valori sulla scala del BDI-II stampati di seguito (li presento ordinati dal più piccolo al più grande). sort(bysubj$bdi) #&gt; [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 2 2 2 #&gt; [30] 3 3 3 5 7 9 12 19 22 22 24 25 25 26 26 26 27 27 28 28 30 30 30 31 31 33 33 34 35 #&gt; [59] 35 35 36 39 41 43 43 44 Calcolo ora le frequenze assolute per i seguenti intervalli aperti a destra: [0, 13.5), [13.5, 19.5), [19.5, 28.5), [28.5, 63). Esaminando i dati, possiamo notare che 36 soggetti cadono nella prima classe. È però necessario eseguire quest’operazione di conteggio utilizzando R. Uno dei modi possibili per calcolare le frequenze assolute è quello di usare la funzione cut(). Mediante tal funzione è possibile dividere il campo di variazione (ovvero, la differenza tra il valore massimo di una distribuzione ed il valore minimo) di una variabile continua x in intervalli e codificare ciascun valore x nei termini dell’intervallo a cui appartiene. Tale risultato si ottiene nel modo seguente. bysubj$bdi_level &lt;- cut( bysubj$bdi, breaks = c(0, 13.5, 19.5, 28.5, 63), include.lowest = TRUE, labels = c( &quot;minimal&quot;, &quot;mild&quot;, &quot;moderate&quot;, &quot;severe&quot; ) ) bysubj$bdi_level #&gt; [1] moderate severe severe moderate severe severe severe severe moderate #&gt; [10] severe moderate mild severe minimal minimal minimal severe moderate #&gt; [19] minimal minimal minimal minimal minimal moderate minimal minimal minimal #&gt; [28] minimal minimal minimal minimal severe minimal minimal severe minimal #&gt; [37] moderate minimal minimal minimal severe minimal minimal severe severe #&gt; [46] moderate severe severe minimal moderate minimal moderate severe moderate #&gt; [55] moderate minimal minimal minimal minimal minimal minimal minimal minimal #&gt; [64] minimal minimal minimal #&gt; Levels: minimal mild moderate severe Possiamo ora usare la funzione table() la quale ritorna un elenco che associa la frequenza assoluta a ciascuna modalità della variabile in input – ovvero, la distribuzione di frequenza assoluta. table(bysubj$bdi_level) #&gt; #&gt; minimal mild moderate severe #&gt; 36 1 12 17 Per ottenere la distribuzione di frequenza relativa è sufficiente dividere ciascuna frequenza assoluta per il numero totale di osservazioni: table(bysubj$bdi_level) / sum(table(bysubj$bdi_level)) #&gt; #&gt; minimal mild moderate severe #&gt; 0.54545455 0.01515152 0.18181818 0.25757576 In questo modo abbiamo ottenuto le distribuzioni di frequenza assoluta e relativa per i valori del BDI-II dei soggetti di Zetsche et al. (2019): Limiti delle classi Frequenza assoluta Frequenza relativa [0, 13.5) 36 36/66 [13.5, 19.5) 1 1/66 [19.5, 28.5) 12 12/66 [28.5, 63] 17 17/66 9.3 Istogramma I dati che sono stati sintetizzati in una distribuzione di frequenze possono essere rappresentati graficamente in un istogramma. Un istogramma si costruisce riportando sulle ascisse i limiti delle classi \\(\\Delta_i\\) e sulle ordinate i valori della funzione costante a tratti \\[\\varphi_n(x)= \\frac{f_i}{b_i-a_i}, \\quad x\\in \\Delta_i,\\, i=1, \\dots, m\\] che misura la densità della frequenza relativa della variabile \\(X\\) nella classe \\(\\Delta_i\\), ovvero il rapporto fra la frequenza relativa \\(f_i\\) e l’ampiezza (\\(b_i - a_i\\)) della classe. In questo modo il rettangolo dell’istogramma associato alla classe \\(\\Delta_i\\) avrà un’area proporzionale alla frequenza relativa \\(f_i\\). Si noti che l’area totale dell’istogramma delle frequenze relative è data della somma delle aree dei singoli rettangoli e quindi vale 1.0. 9.3.1 Esercizio con R Poniamoci il problema di costruire un istogramma per i dati del BDI-II. Nell’istogramma viene rappresentata la frequenza relativa delle classi: l’area di ogni barra dell’istogramma è proporzionale alla frequenza relativa della classe che la barra rappresenta. Come si trova l’altezza delle barre dell’istogramma? Per la classe [0, 13.5), ad esempio, la frequenza relativa è 36/66. Tale valore corrisponde all’area del rettangolo. Dato che la base del rettangolo è 13.5, l’altezza sarà 36/66 / 13.5, ovvero {r 36/66 / 13.5}. E così via per le altre barre dell’istogramma. Una rappresentazione grafica dell’istogramma delle frequenze relative si può ottenere con R utilizzando le funzioni di ggplot2. Il pacchetto ggplot2 è un potente strumento per rappresentare graficamente i dati. Le iniziali del nome, gg, si riferiscono alla ‘’Grammar of Graphics’’, che è un modo di pensare le figure come una serie di layer stratificati. Originariamente descritta da Leland Wilkinson, la grammatica dei grafici è stata aggiornata e applicata in R da Hadley Wickham, il creatore del pacchetto. Per chiarezza, precisiamo che la funzione ggplot() utilizza intervalli aperti a destra. p1 &lt;- bysubj %&gt;% ggplot(aes(x = bdi)) + geom_histogram( aes(y = ..density..), breaks = c(0, 13.5, 19.5, 28.5, 44.1) # il valore BDI-II massimo è 44 ) + scale_x_continuous(breaks=c(0, 13.5, 19.5, 28.5, 44.1)) + labs( x = &quot;BDI-II&quot;, y = &quot;Densità di frequenza&quot; ) + theme_apa() p1 Figura 9.1: Istogramma per i valori BDI-II riportati da Zetsche et al. (2019). Con i quattro intervalli individuati dai cut-off del BDI-II otteniamo la rappresentazione riportata nella figura 9.1. Nel caso della prima barra dell’istogramma a sinistra, l’ampiezza dell’intervallo è pari a 13.5 e l’area della barra (ovvero, la frequenza relativa) è uguale a 36/66. Dunque l’altezza della barra è uguale a (36 / 66) / 13.5 = 0.040. Lo stesso procedimento si applica per il calcolo dell’altezza degli altri rettangoli. Anche se nel caso presente è sensato usare ampiezze diverse per gli intervalli delle classi, in generale gli istogrammi si costruiscono utilizzando intervalli riportati sulle ascisse con un’ampiezza uguale. Questo è il caso dell’istogramma seguente il quale è stato generato a partire dagli stessi dati. p2 &lt;- bysubj %&gt;% ggplot(aes(x = bdi)) + geom_histogram( aes(y = ..density..), breaks = seq(0, 44.1, length.out = 7) ) + scale_x_continuous(breaks=c(0.00, 7.35, 14.70, 22.05, 29.40, 36.75, 44.10)) + labs( x = &quot;BDI-II&quot;, y = &quot;Densità di frequanza&quot; ) + theme_apa() p2 Figura 9.2: Una rappresentazione più comune per l’istogramma dei valori BDI-II di Zetsche et al. (2019) nella quale gli intervalli delle classi hanno ampiezze uguali. 9.4 Funzione di densità empirica Il confronto tra le figure 9.1 e 9.2 rende chiaro un limite degli istogrammi. È infatti ovvio che il profilo dell’istogramma è arbitrario: a seconda del numero e dei limiti delle classi che vengono scelte, cambiano sia il numero che la forma delle barre dell’istogramma. Questo rende difficile fornire un’interpretazione alle informazioni fornite da un istogramma. Il problema precedente può essere alleviato utilizzando una rappresentazione alternativa della distribuzione di frequenza, ovvero la stima della densità della frequenza dei dati (detta anche stima kernel di densità). Un modo semplice per pensare a tale rappresentazione, che in inglese va sotto il nome di density plot, è quello di immaginare un grande campione di dati, in modo che diventi possibile definire un enorme numero di classi di equivalenza di ampiezza molto piccola, le quali non risultino vuote. In tali circostanze, la funzione di densità empirica non è altro che il profilo lisciato dell’istogramma. La stessa idea si applica anche quando il campione è più piccolo. 9.4.1 Esercizio con R Nel caso dei dati del BDI-II otteniamo la reppresentazione fornita dalla figura seguente. p3 &lt;- bysubj %&gt;% ggplot(aes(x = bdi)) + geom_histogram( aes(y = ..density..), breaks = seq(0, 44.1, length.out = 7) ) + geom_density( aes(x = bdi), adjust = 0.5, size = 0.8, fill = &quot;steelblue3&quot;, alpha = 0.5 ) + labs( x = &quot;BDI-II&quot;, y = &quot;Densità di frequenza&quot; ) + theme_apa() p3 Figura 9.3: Funzione di densità empirica per i valori BDI-II di Zetsche et al. (2019). Che interpretazione possiamo attribuire alla funzione di densità empirica rappresentata nella figura 9.3? La interpretiamo come abbiamo fatto con gli istogrammi: l’area sottesa al grafico della funzione di densità empirica in un certo intervallo rappresenta la proporzione dei casi della distribuzione che hanno valori compresi nell’intervallo considerato. 9.5 Forma di una distribuzione In generale, la forma di una distribuzione descrive come i dati si distribuiscono intorno ai valori centrali. Distinguiamo tra distribuzioni simmetriche e asimmetriche, e tra distribuzioni unimodali o multimodali. Un’illustrazione grafica è fornita nella figura seguente. Figura 9.4: 1: Asimmetria negativa. 2: Asimmetria positiva. 3: Distribuzione unimodale. 4: Distribuzione bimodale. Nel pannello 1 la distribuzione è unimodadle con asimmetria negativa; nel pannello 2 la distribuzione è unimodadle con asimmetria positiva; nel pannello 3 la distribuzione è simmetrica e unimodale; nel pannello 4 la distribuzione è bimodale. Se consideriamo nuovamente la figura 9.3 possiamo dire che la distribuzione dei valori del BDI-II nel campione considerato da Zetsche et al. (2019) è bimodale. 9.6 Indici di posizione 9.6.1 Quantili La descrizione della distribuzione dei valori BDI-II di Zetsche et al. (2019) può essere facilitata dalla determinazione di alcuni valori caratteristici che sintetizzano le informazioni contenute nella distribuzione di frequenze. Si dicono quantili (o frattili) quei valori caratteristici che hanno le seguenti proprietà. I quartili sono quei valori che ripartiscono i dati \\(x_i\\) in quattro parti ugualmente numerose (pari ciascuna al 25% del totale). Il primo quartile, \\(q_1\\), lascia alla sua sinistra il 25% del campione pensato come una fila ordinata (a destra quindi il 75%). Il secondo quartile \\(q_2\\) lascia a sinistra il 50% del campione (a destra quindi il 50%). Esso viene anche chiamato mediana. Il terzo quartile lascia a sinistra il 75% del campione (a destra quindi il 25%). Secondo lo stesso criterio, si dicono decili i quantili di ordine \\(p\\) multiplo di 0.10 e percentili i quantili di ordine \\(p\\) multiplo di 0.01. Come si calcolano i quantili? Consideriamo la definizione di quantile non interpolato di ordine \\(p\\) \\((0 &lt; p &lt; 1)\\). Si procede innanzitutto ordinando i dati in ordine crescente, \\(\\{x_1, x_2, \\dots, x_n\\}\\). Ci sono poi due possibilità. Se il valore \\(np\\) non è intero, sia \\(k\\) l’intero tale che \\(k &lt; np &lt; k + 1\\) – ovvero, la parte intera di \\(np\\). Allora \\(q_p = x_{k+1}.\\) Se \\(np = k\\) con \\(k\\) intero, allora \\(q_p = \\frac{1}{2}(x_{k} + x_{k+1}).\\) Se vogliamo calcolare il primo quartile \\(q_1\\), ad esempio, utilizziamo \\(p = 0.25\\). Dovendo calcolare gli altri quantili basta sostituire a \\(p\\) il valore appropriato4. Gli indici di posizione, tra le altre cose, hanno un ruolo importante, ovvero vengono utilizzati per creare una rappresentazione grafica di una distribuzione di valori che è molto popolare e può essere usata in alternativa ad un istogramma (in realtà vedremo poi come possa essere combinata con un istogramma). Tale rappresentazione va sotto il nome di box-plot. Per fare un esempio, consideriamo i nove soggetti del campione clinico di Zetsche et al. (2019) che hanno riportato un unico episodio di depressione maggiore. Per tali soggetti i valori ordinati del BDI-II (per semplicità li chiameremo \\(x\\)) sono i seguenti: 19, 26, 27, 28, 28, 33, 33, 41, 43. Per il calcolo del secondo quartile (non interpolato), ovvero per il calcolo della mediana, dobbiamo considerare la quantità \\(np = 9 \\cdot 0.5 = 4.5\\), non intero. Quindi, \\(q_1 = x_{4 + 1} = 27\\). Per il calcolo del quantile (non interpolato) di ordine \\(p = 2/3\\) dobbiamo considerare la quantità \\(np = 9 \\cdot 2/3 = 6\\), intero. Quindi, \\(q_{\\frac{2}{3}} = \\frac{1}{2} (x_{6} + x_{7}) = \\frac{1}{2} (33 + 33) = 33\\). 9.6.2 Box-plot Il box-plot (o diagramma a scatola) è uno strumento grafico utile al fine di ottenere informazioni circa la dispersione e l’eventuale simmetria o asimmetria di una distribuzione. Per costruire un box-plot si rappresenta sul piano cartesiano un rettangolo (cioè la “scatola”) di altezza arbitraria la cui base corrisponde alla dist intanza interquartile (IQR = \\(q_{0.75} - q_{0.25}\\)). La linea interna alla scatola rappresenta la mediana \\(q_{0.5}\\). Si tracciano poi ai lati della scatola due segmenti di retta i cui estremi sono detti “valore adiacente” inferiore e superiore. Il valore adiacente inferiore è il valore più piccolo tra le osservazioni che risulta maggiore o uguale al primo quartile meno la distanza corrispondente a 1.5 volte la distanza interquartile. Il valore adiacente superiore è il valore più grande tra le osservazioni che risulta minore o uguale a \\(Q_3+1.5\\) IQR. I valori esterni ai valori adiacenti (chiamati valori anomali) vengono rappresentati individualmente nel box-plot per meglio evidenziarne la presenza e la posizione. Figura 9.5: Box-plot: \\(M\\) è la mediana, \\(\\bar{x}\\) è la media aritmetica e IQR è la distanza interquartile (\\(Q_3 - Q_1\\)). Consideriamo ora un caso concreto nel quale viene utilizzato un box-plot. Nel caso dei dati di Zetsche et al. (2019) ci chiediamo in che modo si differenziano le distribuzioni del BDI-II tra i due gruppi considerati, ovvero tra il gruppo dei pazienti e il gruppo di controllo. bysubj &lt;- df %&gt;% group_by(esm_id, group) %&gt;% summarise( bdi = mean(bdi), nr_of_episodes = mean(nr_of_episodes, na.rm = TRUE) ) %&gt;% na.omit() #&gt; `summarise()` regrouping output by &#39;esm_id&#39; (override with `.groups` argument) bysubj %&gt;% ggplot(aes(x=group, y=bdi)) + geom_boxplot() + labs( x = &quot;Gruppo&quot;, y = &quot;BDI-II&quot; ) + theme_apa() La figura 9.6 fornisce due rappresentazioni grafiche che possono essere utilizzate per rispondere a questa domanda. library(&quot;patchwork&quot;) bysubj &lt;- df %&gt;% group_by(esm_id, group) %&gt;% summarise( bdi = mean(bdi), nr_of_episodes = mean(nr_of_episodes, na.rm = TRUE) ) %&gt;% na.omit() #&gt; `summarise()` regrouping output by &#39;esm_id&#39; (override with `.groups` argument) p1 &lt;- bysubj %&gt;% ggplot(aes(x=group, y=bdi)) + geom_violin(trim=FALSE) + geom_dotplot(binaxis=&#39;y&#39;, stackdir=&#39;center&#39;, dotsize=0.7) + labs( x = &quot;Gruppo&quot;, y = &quot;BDI-II&quot; #, caption = &quot;Fonte: Zetsche, Buerkner, &amp; Renneberg (2020)&quot; ) p2 &lt;- bysubj %&gt;% ggplot(aes(x=group, y=bdi)) + geom_violin(trim=FALSE) + geom_boxplot(width=0.05) + labs( x = &quot;Gruppo&quot;, y = &quot;BDI-II&quot; #, caption = &quot;Fonte: Zetsche, Buerkner, &amp; Renneberg (2020)&quot; ) p1 + p2 #&gt; `stat_bindot()` using `bins = 30`. Pick better value with `binwidth`. Figura 9.6: Due versioni di un violin plot per i valori BDI-II di ciascuno dei due gruppi di soggetti esaminati da Zetsche et al. (2019). Nella figura 9.6 sinistra sono rappresentati i dati grezzi: questa è la pratica migliore quando il numero di osservazioni è piccolo. La linea curva che circonda (simmetricamente) le osservazioni è l’istogramma lisciato che abbiamo descritto in precedenza. Nella figura 9.6 destra sono rappresentanti gli stessi dati: la funzione di densità empirica è la stessa di prima, ma al suo interno viene collocato un box-plot. Questa seconda rappresentazione è da preferirsi quando ci sono molte osservazioni e non è utile rappresentare singolarmente ciascun dato. Entrambe le rappresentazioni suggeriscono che la distribuzione dei dati è all’incirca simmetrica nel gruppo clinico (codificato come mdd). Il gruppo di controllo (ctl) mostra invece un’asimmetria positiva, con tre osservazioni evidenziate nel boxplot come dei “valori anomali,” dato che si discostano dalla mediana di una quantità maggiore di 1.5 IQR. 9.6.3 L’eccellenza grafica Non c’è un modo “corretto” per rappresentare in forma grafica un insieme di dati. Ciascuno dei grafici che abbiamo discusso ha i suoi pregi e i suoi difetti. Un ricercatore che ha influenzato molto il modo in cui viene realizzata la visualizzazione dei dati scientifici è Edward Tufte, soprannominato dal New York Times il “Leonardo da Vinci dei dati.” Secondo Tufte, “l’eccellenza nella grafica consiste nel comunicare idee complesse in modo chiaro, preciso ed efficiente.” Nella visualizzazione delle informazioni, l’“eccellenza grafica” ha l’obiettivo di comunicare al lettore il maggior numero di idee nel minor tempo possibile, con meno inchiostro possibile, usando il minor spazio possibile. Secondo Tufte (2001), le rappresentazioni grafiche dovrebbero: mostrare i dati; indurre l’osservatore a riflettere sulla sostanza piuttosto che sulla progettazione grafica, o qualcos’altro; evitare di distorcere quanto i dati stanno comunicando (“integrità grafica”); presentare molte informazioni in forma succinta; rivelare la coerenza tra le molte dimensioni dei dati; incoraggiare l’osservatore a comparare differenti porzioni di dati; rivelare i dati a diversi livelli di dettaglio, da una visione ampia alla struttura di base; servire ad uno scopo preciso (descrizione, esplorazione, o la risposta a qualche domanda); essere fortemente integrate con le descrizioni statistiche e verbali dei dati fornite nel testo. In base a questi principi, la funzione di densità empirica fornisce una rappresentazione migliore dei dati di Zetsche et al. (2019) di quanto lo faccia un istogramma. Inoltre, se oltre al grupppo di appartenenza non ci sono altre dimensioni importanti da mettere in evidenza, allora la nostra scelta dovrebbe ricadere sul pannello di sinistra della figura 9.6. 9.7 Indici di tendenza centrale L’analisi grafica, esaminata in precedenza, costituisce la base di partenza di qualsivoglia analisi quantitativa dei dati. Tramite l’analisi grafica possiamo capire alcune caratteristiche importanti di una distribuzione: per esempio, se è simmetrica o asimmetrica; oppure se è unimodale o multimodale. Successivamente, possiamo calcolare degli indici numerici che descrivono in modo sintetico le caratteristiche di base dei dati esaminati. Tra le misure di tendenza centrale, ovvero tra gli indici che forniscono un’idea dei valori attorno ai quali sono prevalentemente concentrati i dati di un campione, quella più comunemente usata è la media. 9.7.1 Media Tutti conosciamo la media aritmetica di \\(\\{x_1, x_2, \\dots, x_n\\}\\), ovvero il numero reale \\(\\bar{x}\\) definito da \\[\\begin{equation} \\bar{x}=\\frac{1}{n}\\sum_{i=1}^n x_i. \\tag{9.1} \\end{equation}\\] Nell’eq. (9.1) abbiamo usato la notazione delle sommatorie per descrivere una somma di valori. Questa notazione è molto usata in statistica e viene descritta in Appendice. La media gode della seguente importante proprietà: la somma degli scarti tra ciascuna modalità \\(x_i\\) e la media aritmetica \\(\\bar{x}\\) è nulla, cioè \\[ \\sum_{i=1}^n (x_i - \\bar{x}) = 0.\\notag \\label{eq:diffmeansumzero}\\] Infatti, \\[\\begin{aligned} \\sum_{i=1}^n (x_i - \\bar{x}) &amp;= \\sum_i x_i - \\sum_i \\bar{x}\\notag\\\\ &amp;= \\sum_i x_i - n \\bar{x}\\notag\\\\ &amp;= \\sum_i x_i - \\sum_i x_i = 0.\\notag\\end{aligned} \\] Ciò ci consente di pensare alla media come al baricentro della distribuzione. Un’altra proprietà della media è la seguente. La somma dei quadrati degli scarti tra ciascuna modalità \\(x_i\\) e una costante arbitraria \\(a \\in \\Re\\), cioè \\[\\varphi(a) = \\sum_{i=1}^n (x_i - a)^2,\\notag\\] è minima per \\(a = \\bar{x}\\). Il concetto statistico di media ha suscitato molte battute. Per esempio, il fatto che, in media, ciascuno di noi ha un numero di gambe circa pari a 1.9999999. Oppure, il fatto che, in media, ciascuno di noi ha un testicolo. Ma la media ha altri problemi, oltre al fatto di ispirare battute simili alle precedenti. In particolare, dobbiamo notare che la media non è sempre l’indice che meglio rappresenta la tendenza centrale di una distribuzione. In particolare, ciò non accade quando la distribuzione è asimmetrica, o in presenza di valori anomali (outlier) – si veda il pannello di destra della figura 9.6. In tali circostanze, la tendenza centrale della distribuzione è meglio rappresentata dalla mediana o dalla media spuntata. 9.7.1.1 Esercizio con R Calcoliamo la media dei valori BDI-II per i due gruppi di soggetti di Zetsche et al. (2019). bysubj %&gt;% group_by(group) %&gt;% summarise( avg_bdi = mean(bdi) ) #&gt; `summarise()` ungrouping output (override with `.groups` argument) #&gt; # A tibble: 2 x 2 #&gt; group avg_bdi #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 ctl 1.69 #&gt; 2 mdd 30.9 9.7.2 Media spuntata La media spuntata \\(\\bar{x}_t\\) (trimmed mean) non è altro che la media dei dati calcolata considerando solo il 90% (o altra percentuale) dei dati centrali. Per calcolare \\(\\bar{x}_t\\) si ordinando i dati secondo una sequenza crescente, \\(x_1 \\leq x_2 \\leq x_3 \\leq \\dots \\leq x_n\\), per poi eliminare il primo 5% e l’ultimo 5% dei dati della serie così ordinata. La media spuntata è data dalla media aritmetica dei dati rimanenti. 9.7.2.1 Esercizio con R Calcoliamo la media spuntata dei valori BDI-II per i due gruppi di soggetti di Zetsche et al. (2019) escludendo il 10% dei valori più estremi in ciascun gruppo. bysubj %&gt;% group_by(group) %&gt;% summarise( avg_trim_bdi = mean(bdi, trim = 0.1) ) #&gt; `summarise()` ungrouping output (override with `.groups` argument) #&gt; # A tibble: 2 x 2 #&gt; group avg_trim_bdi #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 ctl 1 #&gt; 2 mdd 30.6 9.7.3 Moda e mediana In precedenza abbiamo già incontrato altri due popolari indici di tendenza centrale: la moda (Mo), ovvero il valore centrale della classe con la frequenza massima (può succedere che una distribuzione abbia più mode; in tal caso si dice multimodale e questo operatore perde il suo significato di indice di tendenza centrale) e la mediana \\(\\tilde{x}\\). 9.7.3.1 Esercizio con R Calcoliamo i quantili di ordine 0.25, 0.5 e 0.75 dei valori BDI-II per i due gruppi di soggetti di Zetsche et al. (2019). bysubj %&gt;% group_by(group) %&gt;% summarise( q25 = quantile(bdi, probs = 0.25), q50 = quantile(bdi, probs = 0.50), q75 = quantile(bdi, probs = 0.75) ) #&gt; `summarise()` ungrouping output (override with `.groups` argument) #&gt; # A tibble: 2 x 4 #&gt; group q25 q50 q75 #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 ctl 0 1 2 #&gt; 2 mdd 26 30 35 Osservazione. Si noti che solitamente i software restituiscono un valore interpolato del \\(p\\)-esimo quantile \\(q_p\\) \\((0 &lt; p &lt; 1)\\), il quale viene calcolato mediante specifiche procedure. Il risultato fornito dai software, dunque, non sarà identico a quello trovato utilizzando la definizione non interpolata di quantile che abbiamo presentato qui. Se, per qualche ragione, vogliamo conoscere l’algoritmo usato per la determinazione dei quantili interpolati, dobbiamo leggere la documentazione del software. 9.8 Indici di dispersione Le medie e gli indici di posizione descritti in precedenza forniscono delle sintesi dei dati che mettono in evidenza la tendenza centrale delle osservazioni. Tali indici, tuttavia, non considerano un aspetto importante della distribuzione dei dati, ovvero la variabilità dei valori numerici della variabile statistica. È dunque necessario sintetizzare la distribuzione di una variabile statistica oltre che con le misure di posizione anche tramite l’utilizzo di indicatori che valutino la dispersione delle unità statistice. 9.8.1 Indici basati sull’ordinamento dei dati È possibile calcolare degli indici di variabilità basati sull’ordinamento dei dati. L’indice più ovvio è l’intervallo di variazione, ovvero la distanza tra il valore massimo e il valore minimo di una distribuzione di modalità, mentre in precedenza abbiamo già incontrato la differenza interquartile. Questi due indici, però, hanno il limite di essere calcolati sulla base di due soli valori della distribuzione (\\(x_{\\text{max}}\\) e \\(x_{\\text{mini}}\\), oppure \\(x_{0.25}\\) e \\(x_{0.75}\\)). Pertanto non utilizzano tutte le informazioni che sono disponibili. Inoltre, l’intervallo di variazione ha il limite di essere pesantemente influenzato dalla presenza di valori anomali. 9.8.2 Scostamento medio semplice dalla media Dati i limiti delle statistiche precedenti è più comune misurare la variabilità di una variabile statistica come la dispersione dei dati attorno ad un indice di tendenza centrale. Scelto l’indice di tendenza centrale rispetto al quale si vuole misurare la dispersione, è possibile poi calcolare la media degli scostamenti dei singoli dati dal valore di riferimento. Ad esempio, se scegliamo la mediana quale misura di posizione centrale, è possibile calcolare la media aritmetica della distribuzione degli scarti in valore assoluto tra ciascuna modalità e la mediana stessa. Nel caso di una variabile statistica \\(X\\) lo scostamento medio semplice dalla media è la quantità \\[\\begin{equation} S_{Me} = \\frac{1}{n} \\sum_{i=1}^n |x_i - x_{0.5}|. \\tag{9.2} \\end{equation}\\] 9.8.2.1 Esercizio con R Calcoliamo lo scostamento medio semplice dalla media per il BDI-II dei due gruppi di soggetti di Zetsche et al. (2019). mean(abs(bysubj$bdi - median(bysubj$bdi))) #&gt; [1] 14.48387 Oppure, per i due gruppi: mean_abs_dev &lt;- function(x){ mean(abs(x - median(x))) } bysubj %&gt;% group_by(group) %&gt;% summarise( Mean_abs_dev = mean_abs_dev(bdi) ) #&gt; `summarise()` ungrouping output (override with `.groups` argument) #&gt; # A tibble: 2 x 2 #&gt; group Mean_abs_dev #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 ctl 1.62 #&gt; 2 mdd 5.27 La deviazione mediana assoluta è una misura robusta della dispersione statistica di un campione. Per un insieme \\(x_1, x_2, \\dots, x_n\\), il valore di MAD è definito come la mediana del valore assoluto delle deviazioni dei dati dalla mediana, ovvero: \\[\\begin{equation} MAD = \\text{med} (|x_i - \\text{med}(x_i)|). \\tag{9.3} \\end{equation}\\] Per i dati di Zetsche et al. (2019) abbiamo: bysubj %&gt;% group_by(group) %&gt;% summarise( MAD = mad(bdi) ) #&gt; `summarise()` ungrouping output (override with `.groups` argument) #&gt; # A tibble: 2 x 2 #&gt; group MAD #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 ctl 1.48 #&gt; 2 mdd 6.67 9.8.3 Varianza Anche se la statistica definita dall’eq. (9.2) è molto intuitiva, la misura di variabilità di gran lunga più usata per valutare la variabilità di una variabile statistica è senza dubbio la varianza. La varianza \\[\\begin{equation} s^2 = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2 \\tag{9.4} \\end{equation}\\] è la media dei quadrati degli scarti \\(x_i - \\bar{x}\\) tra ogni valore e la media della distribuzione. La varianza è una misura di dispersione più complessa di quelle esaminate in precedenza. È appropriata solo nel caso di distribuzioni simmetriche e, anch’essa, è fortemente influenzata dai valori anomali. Inoltre, è espressa in un’unità di misura che è il quadrato dell’unità di misura dei dati originari e quindi ad essa non può essere assegnata un’interpretazione intuitiva. 9.8.3.1 Esercizio con R Calcoliamo la varianza dei punteggi BDI-II nei due gruppi di soggetti di Zetsche et al. (2019). bysubj %&gt;% group_by(group) %&gt;% summarise( variance = var(bdi) ) #&gt; `summarise()` ungrouping output (override with `.groups` argument) #&gt; # A tibble: 2 x 2 #&gt; group variance #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 ctl 8.03 #&gt; 2 mdd 43.7 9.8.4 Deviazione standard Per le ragioni espresse sopra, la misura più usata della dispersione di una distribuzione di dati è la deviazione standard, ovvero la radice quadrata della varianza. A differenza della varianza, dunque, la deviazione standard è espressa nella stessa unità di misura dei dati. Come nel caso della varianza, anche la deviazione standard \\(s\\) dovrebbe essere usata soltanto quando la media è adeguata per misurare il centro della distribuzione, ovvero, nel caso di distribuzioni simmetriche. Come nel caso della media \\(\\bar{x}\\), anche la deviazione standard è fortemente influenzata dai dati anomali (outlier), ovvero dalla presenza di uno o di pochi dati che sono molto più distanti dalla media rispetto agli altri valori della distribuzione. Quando tutte le osservazioni sono uguali, \\(s=0\\), altrimenti \\(s &gt; 0\\). Alla deviazione standard può essere assegnata una semplice interpretazione: la deviazione standard è simile (ma non identica) allo scostamento medio semplice dalla media. La deviazione standard ci dice, dunque, quanto sono distanti, in media, le singole osservazioni dal centro della distribuzione. 9.8.4.1 Esercizio con R Calcoliamo la deviazione standard per il BDI-II dei due gruppi di soggetti di Zetsche et al. (2019). bysubj %&gt;% group_by(group) %&gt;% summarise( stdev = sd(bdi) ) #&gt; `summarise()` ungrouping output (override with `.groups` argument) #&gt; # A tibble: 2 x 2 #&gt; group stdev #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 ctl 2.83 #&gt; 2 mdd 6.61 9.8.5 Indici di variabilità relativi A volte può essere interessante effettuare un confronto fra due misure di variabilità di grandezze incommensurabili, ovvero di caratteri rilevati mediante differenti unità di misura. In questi casi, le misure di variabilità precedentemente descritte si rivelano inadeguate in quanto dipendono dall’unità di misura adottata. Diventa dunque necessario ricorrere a particolari numeri adimensionali detti indici relativi di variabilità. Il più importante di tali indici è il coefficiente di variazione, ovvero il numero puro \\[C_v = \\frac{\\sigma}{\\bar{x}}\\] ottenuto dal rapporto tra la deviazione standard e la media dei dati. Un altro indice relativo di variabilità è la differenza interquartile rapportata al primo quartile oppure al terzo quartile oppure alla mediana, cioè: \\[\\frac{x_{0.75} - x_{0.25}}{x_{0.25}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.75}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.50}}.\\notag\\] 9.9 Le relazioni tra variabili Zetsche et al. (2019) hanno misurato il livello di depressione dei soggetti del loro esperimento utilizzando due scale psicometriche: il Beck Depression Inventory II (BDI-II) e la Center for Epidemiologic Studies Depression Scale (CES-D). Il BDI-II è uno strumento self-report che valutare la presenza e l’intensità di sintomi depressivi in pazienti adulti e adolescenti di almeno 13 anni di età con diagnosi psichiatrica mentre la CES-D è una scala self-report progettata per misurare i sintomi depressivi che sono stati vissuti nella settimana precedente nella popolazione generale, specialmente quella degli adolescenti/giovani adulti. Una domanda ovvia che ci può venire in mente è: quanto sono simili le misure ottenute mediante queste due scale? È chiaro che i numeri prodotti dalle scale BDI-II e CES-D non possono essere identici, e questo per due motivi: (1) la presenza degli errori di misurazione e (2) l’unità di misura delle due variabili. L’errore di misurazione corrompe sempre, almeno in parte, qualunque operazione di misurazione. E questo è vero specialmente in psicologia dove l’attendibilità degli strumenti di misurazione è minore che in altre discipline (quali la fisica, ad esempio). Il secondo motivo per cui i valori delle scale BDI-II e CES-D non possono essere uguali è che l’unità di misura delle due scale è arbitraria. Infatti, qual è l’unità di misura della depressione? Chi può dirlo! Ma, al di là delle differenze derivanti dall’errore di misurazione e dalla differente unità di misura, ci aspettiamo che, se le due scale misurano entrambe lo stesso costrutto, allora i valori prodotti dalle due scale dovranno essere tra loro linearmente associati. Per capire cosa si intende con “associazione lineare” iniziamo a guardare i dati. Per fare questo utilizziamo una rappresentazione grafica che va sotto il nome di diagramma a dispersione. 9.9.1 Diagramma a dispersione Il diagramma di dispersione è la rappresentazione grafica delle coppie di punti individuati dalle variabili BDI-II e CES-D, e si ottiene ponendo, ad esempio, i valori BDI-II sull’asse delle ascisse e quelli del CES-D sull’asse delle ordinate. In tale grafico, fornito dalla figura 9.7, cascun punto corrisponde ad un individuo del quale, nel caso presente, conosciamo il livello di depressione misurato dalle due scale psicometriche. bysubj &lt;- df %&gt;% group_by(esm_id, group) %&gt;% summarise( bdi = mean(bdi), cesd = mean(cesd_sum) ) %&gt;% na.omit() %&gt;% ungroup() #&gt; `summarise()` regrouping output by &#39;esm_id&#39; (override with `.groups` argument) m_cesd &lt;- mean(bysubj$cesd) m_bdi &lt;- mean(bysubj$bdi) FONT_SIZE &lt;- 10 p &lt;- bysubj %&gt;% ggplot( aes(x=bdi, y=cesd, color=group)) + geom_point(size=1) + geom_hline(yintercept= m_cesd, linetype=&quot;dashed&quot;, color = &quot;gray&quot;) + geom_vline(xintercept = m_bdi, linetype=&quot;dashed&quot;, color = &quot;gray&quot;) + geom_text(x=-1, y=16, label=&quot;I&quot;, color = &quot;gray&quot;, size=FONT_SIZE) + geom_text(x=0, y=46, label=&quot;IV&quot;, color = &quot;gray&quot;, size=FONT_SIZE) + geom_text(x=18, y=46, label=&quot;III&quot;, color = &quot;gray&quot;, size=FONT_SIZE) + geom_text(x=18, y=16, label=&quot;II&quot;, color = &quot;gray&quot;, size=FONT_SIZE) + labs( x = &quot;BDI-II&quot;, y = &quot;CESD&quot; ) + theme_apa() + theme(legend.position=&quot;none&quot;) p Figura 9.7: Associazione tra le variabili BDI-II e CES-D nello studio di Zetsche et al. (2019). In rosso sono rappresentate le osservazioni del gruppo di controllo; in blu quelle dei pazienti. Dalla figura 9.7 possiamo vedere che i dati mostrano una certa tendenza a disporsi attorno ad una retta – nel gergo statistico, questo fatto viene espresso dicendo che i punteggi CES-D tendono ad essere linearmente associati ai punteggi BDI-II. È ovvio, tuttavia, che tale relazione lineare è lungi dall’essere perfetta – se fosse perfetta, tutti i punti del diagramma a dispersione si disporrebbero esattamente lungo una retta. Il problema che ci poniamo è quello di trovare un indice numerico che descriva di quanto la nube di punti si discosta da una perfetta relazione lineare tra le due variabili. Per risolvere tale problema dobbiamo specificare un indice statistico che descriva la direzione e la forza della relazione lineare tra le due variabili. Ci sono vari indici statistici che possiamo utilizzare a questo scopo. 9.9.2 Covarianza Iniziamo a considerare il più importante di tali indici, chiamato covarianza. In realtà la definizione di questo indice non ci sorprenderà più di tanto in quanto, in una forma solo apparentemente diversa, l’abbiamo già incontrato in precedenza. Ci ricordiamo infatti che la varianza di una generica variabile \\(X\\) è definita come la media degli scarti quadratici di ciascuna osservazione dalla media: \\[\\begin{equation} S_{XX} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (X_i - \\bar{X}). \\tag{9.5} \\end{equation}\\] Infatti, la varianza viene talvolta descritta come la “covarianza di una variabile con sé stessa.” Adesso facciamo un passo ulteriore. Invece di valutare la dispersione di una sola variabile, chiediamoci come due variabili \\(X\\) e \\(Y\\) “variano insieme” (co-variano). È facile capire come una risposta a tale domanda possa essere fornita da una semplice trasformazione della formula precedente che diventa: \\[\\begin{equation} S_{XY} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (Y_i - \\bar{Y}). \\tag{9.6} \\end{equation}\\] L’eq. (9.6) ci fornisce dunque la definizione della covarianza. Per capire il significato dell’eq. (9.6), supponiamo di dividere il grafico della figura 9.7 in quattro quadranti definiti da una retta verticale passante per la media dei valori BDI-II e da una retta orizzontale passante per la media dei valori CES-D. Numeriamo i quadranti partendo da quello in basso a sinistra e muovendoci in senso antiorario. Se prevalgono punti nel I e III quadrante, allora la nuvola di punti avrà un andamento crescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\)) e la covarianza segno positivo. Mentre se prevalgono punti nel II e IV quadrante la nuvola di punti avrà un andamento decrescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\)) e la covarianza segno negativo. Dunque, il segno della covarianza ci informa sulla direzione della relazione lineare tra due variabili: l’associazione lineare si dice positiva se la covarianza è positiva, negativa se la covarianza è negativa. Il segno della covarianza ci informa sulla direzione della relazione, ma invece il valore assoluto della covarianza ci dice ben poco. Esso, infatti, dipende dall’unità di misura delle variabili. Nel caso presente questo concetto è difficile da comprendere, dato che le due variabili in esame non hanno un’unità di misura (ovvero, hanno un’unità di misura arbitraria e priva di significato). Ma quest’idea diventa chiara se pensiamo alla relazione lineare tra l’altezza e il peso delle persone, ad esempio. La covarianza tra queste due quantità è certamente positiva, ma il valore assoluto della covarianza diventa più grande se l’altezza viene misurata in millimetri e il peso in grammi, e diventa più piccolo l’altezza viene misurata in metri e il peso in chilogrammi. Dunque, il valore della covarianza cambia al mutare dell’unità di misura delle variabili anche se l’associazione tra le variabili resta costante. 9.9.3 Correlazione Dato che il valore assoluto della covarianza è di difficile interpretazione – in pratica, non viene mai interpretato – è necessario trasformare la covarianza in modo tale da renderla immune alle trasformazioni dell’unità di misura delle variabili. Questa operazione si dice standardizzazione e corrisponde alla divisione della covarianza per le deviazioni standard (\\(s_X\\), \\(s_Y\\)) delle due variabili: \\[\\begin{equation} r_{XY} = \\frac{S_{XY}}{s_X s_Y}. \\tag{9.7} \\end{equation}\\] La quantià che si ottiene in questo modo viene chiamata correlazione di Bravais-Pearson (dal nome degli autori che, indipendentemente l’uno dall’altro, la hanno introdotta). Il coefficiente di correlazione ha le seguenti proprietà: ha lo stesso segno della covarianza, dato che si ottiene dividendo la covarianza per due numeri positivi; è un numero puro, cioè non dipende dall’unità di misura delle variabili; assume valori compresi tra -1 e +1. Ad esso possiamo assegnare la seguente interpretazione: \\(r_{XY} = -1\\) \\(\\rightarrow\\) perfetta relazione negativa: tutti i punti si trovano esattamente su una retta con pendenza negativa (dal quadrante in alto a sinistra al quadrante in basso a destra); \\(r_{XY} = +1\\) \\(\\rightarrow\\) perfetta relazione positiva: tutti i punti si trovano esattamente su una retta con pendenza positiva (dal quadrante in basso a sinistra al quadrante in alto a destra); \\(-1 &lt; r_{XY} &lt; +1\\) \\(\\rightarrow\\) presenza di una relazione lineare di intensità diversa; \\(r_{XY} = 0\\) \\(\\rightarrow\\) assenza di relazione lineare tra \\(X\\) e \\(Y\\). Per i dati della figura 9.7, la covarianza è 207.426. Il segno positivo della covarianza ci dice che tra le due variabili c’è un’associazione lineare positiva. Per capire qual è l’intensità della relazione lineare tra le due variabili calcoliamo la correlazione. Essendo le deviazioni standard del BDI-II e del CES-D rispettavamente uguali a 15.37 e 14.93, la correlazione diventa uguale a \\(\\frac{207.426}{15.38 \\cdot 14.93} = 0.904.\\) Tale valore è prossimo a 1.0, il che vuol dire che i punti del diagramma a dispersione non si discostano troppo da una retta con una pendenza positiva. 9.10 Correlazione e causazione Facendo riferimento nuovamente alla figura 9.7, possiamo dire che, in molte applicazioni (ma non nel caso presente!) l’asse \\(x\\) rappresenta una quantità nota come variabile indipendente e l’interesse si concentra sulla sua influenza sulla variabile dipendente tracciata sull’asse \\(y\\). Ciò presuppone però che sia nota la direzione in cui l’influenza causale potrebbe risiedere. È importante tenere bene a mente che la correlazione è soltanto un indice descrittivo della relazione lineare tra due variabili e in nessun caso può essere usata per inferire alcunché sulle relazioni causali che legano le variabili. È ben nota l’espressione: “correlazione non significa causazione.” Di opinione diversa era invece Karl Pearson (1911), il quale ha affermato: Quanto spesso, quando è stato osservato un nuovo fenomeno, sentiamo che viene posta la domanda: ‘qual è la sua causa?’ Questa è una domanda a cui potrebbe essere assolutamente impossibile rispondere. Invece, può essere più facile rispondere alla domanda: ‘in che misura altri fenomeni sono associati con esso?’ Dalla risposta a questa seconda domanda possono risultare molte preziose conoscenze. Che alla seconda domanda posta da Pearson sia facile rispondere è indubbio. Che la nostra comprensione di un fenomeno possa aumentare sulla base delle informazioni fornite dalle correlazioni, invece, è molto dubbio e quasi certamente falso. 9.10.1 Usi della correlazione Anche se non può essere usata per studiare le relazioni causali, la correlazione viene usata per molti altri scopi tra i quali, per esempio, quello di misurare la validità concorrente di un test psiologico. Se un test psicologico misura effettivamente ciò che ci si aspetta che misuri (nel caso dell’esempio presente, la depressione), allora dovremo aspettarci che fornisca una correlazione alta con risultati di altri test che misurano lo stesso costrutto – come nel caso dei dati di (Zetsche et al., 2019). Un’altra proprietà desiderabile di un test psicometrico è la validità divergente: i risultati di test psicometrici che misurano costrutti diversi dovrebbero essere poco associati tra loro. In altre parole, in questo secondo caso dovremmo aspettarci che la correlazione sia bassa. 9.10.2 Correlazione di Spearman Una misura alternativa della relazione lineare tra due variabili è fornita dal coefficiente di correlazione di Spearman e dipende soltanto dalla relazione d’ordine dei dati, non dagli specifici valori dei dati. Tale misura di associazione è appropriata quando, del fenomeno in esame, gli psicologi sono stati in grado di misurare soltanto le relazioni d’ordine tra le diverse modalità della risposta dei soggetti, non l’intensità della risposta. Le variabili psicologiche che hanno questa proprietà si dicono ordinali. Nel caso di variabili ordinali, non è possibile sintetizzare i dati mediante le statistiche descrittive che abbiamo introdotto in questo capitolo, quali ad esempio la media e la varianza, ma è invece solo possibile riassumere i dati mediante una distribuzione di frequenze per le varie modalità della risposta. 9.10.3 Correlazione nulla Un ultimo aspetto da mettere in evidenza a proposito della correlazione riguarda il fatto che la correlazione descrive la direzione e l’intensità della relazione lineare tra due variabili. Relazioni non lineari tra le variabili, anche sono molto forti, non vengono catturate dalla correlazione. È importante rendersi conto che una correlazione pari a zero non significa che non c’è relazione tra le due variabili, ma solo che tra esse non c’è una relazione lineare. Un esempio di questo fatto è fornito dalla figura 9.8. library(&quot;datasauRus&quot;) slant &lt;- ggplot(datasaurus_dozen_wide, aes(x=slant_down_x,y=slant_down_y), colour=dataset) # loads slant-pattern dataset of datasauRus package into data frame slant slant &lt;- slant + geom_point() # as a scatter type geom slant &lt;- slant + theme_void() # eliminates unwanted axis labels slant &lt;- slant + theme(legend.position = &quot;none&quot;, panel.border = element_rect(colour = &quot;black&quot;, fill=NA, size = 1), plot.margin = margin(0,2,0,2), aspect.ratio = 1) # removes legend, adds a border, adds margin space below, and specifies # required aspect ratio dino &lt;- ggplot(datasaurus_dozen_wide, aes(x=dino_x,y=dino_y), colour=dataset) + geom_point() # loads dino-figure dataset of datasauRus package into data #frame dino as a scatter type geom dino &lt;- dino +theme_void() # eliminates unwanted axis labels dino &lt;- dino + theme(legend.position = &quot;none&quot;, panel.border = element_rect(colour = &quot;black&quot;, fill=NA, size = 1), plot.margin = margin(0,2,0,2), aspect.ratio = 1) # removes legend, adds a border, adds margin space below, specifies # required aspect ratio slant + dino Figura 9.8: Due insiemi di dati (fittizi) per i quali i coefficienti di correlazione di Pearson sono entrambi 0. Ma questo non significa che non vi sia alcuna relazione tra le variabili. Conclusioni La prima fase dell’analisi dei dati è sicuramente quella che ci porta a riassumere i dati mediante gli strumenti della statistica descrittiva. Ci sono diverse domande che vengono affrontate in questa fase: qual è la distribuzione delle variabili di interesse? Quali relazioni a coppie si possono osservare nel campione? Ci sono delle osservazioni ‘anomale,’ ovvero estremamente discrepanti rispetto alle altre, sia quando si esaminano le statistiche descrittive univariate (ovvero, quelle che riguardano le caratteristiche di una variabile presa singolarmente), sia quando vengono esaminate le statistiche bivariate (ovvero, le statistiche che descrivono l’associazione tra le variabili)? È importante avere ben chiare le idee su questi punti prima di procedere con qualsiasi procedura statistica di tipo inferenziale. Per rispondere alle domande che abbiamo elencato sopra, ed ad altre simili, è molto utile procedere con delle rappresentazioni grafiche dei dati. Dovrebbe essere chiaro che, quando disponiamo di grandi moli di dati (come è sempre il caso in psicologia), per fare questo è necessario usare un software statistico. 9.11 Esercizi Scarica gli esercizi: Download 14_descr_exercises.Rmd Guarda le risposte solo dopo avere provato a rispondere a tutte le domande: Download 14_descr_answers.Rmd I metodi di stima MCMC costituiscono la modalità usuale per generare la distribuzione a posteriori nell’analisi Bayesiana. In queste dispense, però, ci limitiamo ai metodi di stima basati sull’approssimazione quadratica. Abbiamo deciso di svolgere gli esercizi mediante l’approssimazione quadratica piuttosto che con il metodo MCMC perché l’installazione sul proprio computer del software necessario per le analisi MCMC costituisce un problema di tipo informatico che esula dagli scopi di questo insegnamento.↩︎ "],["chapter-prob-discreta.html", "Capitolo 10 Che cos’è la probabilità? 10.1 Probabilità nel linguaggio naturale 10.2 Probabilità nel linguaggio scientifico 10.3 Terminologia 10.4 Le diverse definizioni della probabilità 10.5 Assegnare le probabilità agli eventi 10.6 Proprietà elementari della probabilità 10.7 Variabili aleatorie 10.8 Notazione Conclusioni", " Capitolo 10 Che cos’è la probabilità? È normale fare delle congetture rispetto a ciò di cui non siamo sicuri. Ma perché facciamo questo? Molto spesso perché, anche se sappiamo che le nostre conoscenze sono incomplete, dobbiamo comunque prendere delle decisioni. Ad esempio: “non so se tra qualche ora pioverà; devo o non devo prendere l’ombrello?” In maniera simile, anche se uno psicologo non sa in maniera certa quali sono i meccanismi che regolano i fenomeni psicologi, deve comunque decidere tra diverse alternative. Per esempio, deve fornire un parere, relativamente a chi, tra due genitori, sia più adatto per ottenere l’affidamento del figlio in caso di divorzio, oppure quale sia, in un caso specifico, l’approccio più efficace per il trattamento dei disturbi dell’alimentazione. Ovviamente la qualità delle congetture varia, così come varia la qualità delle decisioni che prendiamo. La teoria delle probabilità ci fornisce gli strumenti per prendere decisioni “razionali” in condizioni di incertezza, ovvero per formulare le migliori congetture possibili. La teoria delle probabilità ci consente di descrivere in maniera quantitativa quei fenomeni che, pur essendo altamente variabili, rivelano comunque una qualche coerenza a lungo termine. Il lancio ripetuto di una moneta è uno di questi fenomeni. È anche l’esempio tipico che viene usato per introdurre una discussione sulle probabilità. Sapere se una moneta sia onesta o meno, o calcolare la probabilità di ottenere testa un certo numero di volte può essere interessante nel mondo delle scommesse, ma nella vita quotidiana non ci capita spesso di lanciare una moneta per prendere una decisione. Allora perché ci preoccupiamo di studiare le proprietà statistiche dei lanci di una moneta? A questa domanda si può rispondere dicendo che l’esperimento (chiamato “casuale”) che corrisponde al lancio di una moneta è il surrogato di una molteplicità di eventi che, della vita reale, sono molto importanti. Per esempio: qual è la probabilità di successo di un intervento psicologico? Qual è la probabilità che un test per l’HIV dia esito positivo in una persona che non ha l’HIV? Qual è la probabilità di essere occupato entro un anno dalla laurea? I lanci di una moneta costituiscono una rappresentazione generica di molteplici altri eventi che hanno un grande significato nella nostra vita. Questa è la ragione per cui studiamo le proprietà statistiche dei fenomeni aleatori usando il lancio di una moneta quale esempio generico. La discussione della teoria della probabilità è certamente l’argomento più impegnativo affrontato in queste dispense. Fare uno sforzo di comprensione per chiarire i concetti di base della teoria della probabilità è però necessario per mettersi nelle condizioni di capire le caratteristiche dell’inferenza statistica che verranno discusse in seguito. 10.1 Probabilità nel linguaggio naturale In un articolo pubblicato su Harward Business Review nel 2018, Mauboussin e Mauboussin ci ricordano come, nel marzo del 1951, l’Office of National Estimates della CIA pubblicò un documento che suggeriva che un attacco sovietico alla Jugoslavia nel corso dell’anno fosse una “seria possibilità.” Sherman Kent, un professore di storia a Yale che fu chiamato a Washington, D.C. per dirigere l’Office of National Estimates, espresse perplessità sull’esatto significato dell’espressione “seria possibilità.” Lo interpretò nel senso che la probabilità di un attacco era di circa il 65%. Ma quando chiese ai membri del Board of National Estimates cosa ne pensassero, gli furono riferite cifre che andavano dal 20% all’80%. Una gamma così ampia rappresentava chiaramente un problema, poiché le implicazioni politiche di quegli estremi erano nettamente diverse. Kent riconobbe che la soluzione di tale problema era quella di usare i numeri per esprimere il nostro grado di certezza, notando mestamente: Non abbiamo usato i numeri… e sembra chiaro che abbiamo abusando delle parole. Da allora non è cambiato molto. Ancora oggi le persone nel mondo della politica, degli affari e nella vita quotidiana continuano a usare parole vaghe per descrivere i possibili risultati degli eventi. Perché? Phil Tetlock, professore di psicologia all’Università della Pennsylvania, che ha studiato a fondo il fenomeno psicologico della previsione, suggerisce che “una vaga verbosità conferisce sicurezza.” Quando usiamo una parola per descrivere la probabilità di un evento incerto, cerchiamo di porci nelle condizioni di non essere smentiti dopo che il risultato dell’evento verrà rivelato. Se si verifica l’evento che abbiamo previsto, è facile dire: “Ti avevo detto che probabilmente sarebbe successo questo.” Se la nostra predizione fallisce, possiamo sempre dire: “Ho solo detto che probabilmente sarebbe successo.” Parole così ambigue non solo consentono all’oratore di evitare di essere smentito, ma consentono anche al destinatario di interpretare il messaggio in modo coerente con le sue nozioni preconcette. Ovviamente, da tale ambiguità linguistica deriva una cattiva comunicazione. È dunque necessario procedere in modo diverso nel linguaggio scientifico. Vedremo in questo capitolo come sia possibile assegnare al termine “probabilità” un significato preciso. 10.2 Probabilità nel linguaggio scientifico La teoria della probabilità nasce nel 1654. Fu infatti in questa data che Antoine Gombaud Cavalier De Méré, un nobile francese, nonché accanito giocatore d’azzardo scrisse una lettera al suo amico Pascal per cercare di comprendere il motivo delle sue continue perdite nel gioco dei dadi. De Méré descrisse due diverse scommesse: scommessa A si lancia un dado per 4 volte di seguito e si vince se esce almeno una volta il 6; scommessa B si lanciano due dadi per 24 volte di seguito e si vince se esce almeno una volta il doppio 6. Il cavaliere De Méré pose a Pascal il seguente quesito: le possibilità di vittoria sono maggiori nella scommessa A o nella scommessa B? Il problema di De Méré divenne un motivo di scambio epistolare tra Pascal e Fermat, i due più grandi matematici del tempo, e viene considerato come la motivazione iniziale dello sviluppo della teoria della probabilità. Ma come può essere risolto il problema di De Méré? Una strategia possibile è quella di seguire l’esempio di De Méré, ovvero, giocare questo gioco molte volte. Così facendo, De Méré si rese conto che le possibilità di vittoria erano leggermente migliori nel caso della scommessa A. Utilizzando una simulazione al computer possiamo facilmente giungere a questa stessa conclusione senza perdere tutto il tempo che De Méré ha dedicato a questa materia. Una simulazione al computer ci consente infatti di ripetere il gioco di De Méré moltissime volte e di annotare il risultato ottenuto ad ogni ripetizione del gioco. Vedremo in seguito perché, utilizzando un computer, è possibile ottenere un risultato diverso ogni volta che si ripete una certa operazione, in modo tale da rappresentare il grado di casualità che si osserva quando si lancia di un dado. Per ora ci limitiamo ad esaminare i risultati che vengono prodotti in questo modo e che sono illustrati nella figura 10.1. # Game A: Throw a fair die at most four times, and win if you get a six. experiment_a &lt;- function(){ rolls &lt;- sample(1:6, size = 4, replace = TRUE) condition &lt;- sum(rolls == 6) &gt; 0 return(condition) } # Game B: Throw two fair dice at most twenty-four times, and win if you get a double-six. experiment_b &lt;- function(){ first.die &lt;- sample(1:6, size = 24, replace = TRUE) second.die &lt;- sample(1:6, size = 24, replace = TRUE) condition &lt;- sum((first.die == second.die) &amp; (first.die == 6)) &gt; 0 return(condition) } # number of replications nrep &lt;- 1e4 # Play game A nrep times. We get a vector of nrep elements. Eeach element of # of the simsA vector is the outcome obtained by playing game A once: TRUE if # the output is a win, FALSE if the output of the game is a loss. Remember than # TRUE = 1 and FALSE = 0. sims_a &lt;- replicate(nrep, experiment_a()) # The proportion of wins in game A prop_wins_a &lt;- sum(sims_a)/length(sims_a) prop_wins_a #&gt; [1] 0.5193 # To plot the results, we compute the nwins_a &lt;- cumsum(sims_a) ntrials &lt;- 1:nrep sims_b &lt;- replicate(nrep, experiment_b()) prop_wins_b &lt;- sum(sims_b)/length(sims_b) prop_wins_b #&gt; [1] 0.493 nwins_b &lt;- cumsum(sims_b) d &lt;- data.frame( n = c(ntrials, ntrials), pwin = c(nwins_a/ntrials, nwins_b/ntrials), game = rep(c(&quot;Scommessa A&quot;, &quot;Scommessa B&quot;), each = nrep) ) d %&gt;% ggplot( aes(x = n, y = pwin, col = game) ) + geom_point(alpha = 0.4) + geom_line() + scale_x_log10(breaks = c(1, 3, 10, 50, 200, 1000, 3000, 10000)) + theme(legend.title = element_blank()) + labs( x=&quot;Numero di ripetizioni del gioco di De Méré&quot;, y=&quot;Proporzione di vincite&quot;) + scale_color_manual(values = c(&quot;gray80&quot;, &quot;skyblue&quot;)) + theme(legend.position = &quot;bottom&quot;) Figura 10.1: Risultati ottenuti da 10000 ripetizioni delle due scommesse di De Méré. La figura 10.1 riportata la proporzione di vittorie in funzione del numero di ripetizioni di ciascuna scommessa e rivela che, a lungo termine (ovvero, se consideriamo un grande numero di ripetizioni del gioco di De Méré), la scommessa A risulta più conveniente della scommessa B. Nel caso di 10000 ripetizioni del gioco di De Méré, la proporzione di vittorie è risultata essere pari a 0.5182 per la scommessa A e pari a 0.4909 per la scommessa B. Se ripetiamo la stessa simulazione altre 10000 volte, otteniamo una proporzione di vittorie uguale a 0.5180 per la scommessa A e a 0.4878 per la scommessa B. Vedremo in questo capitolo come ciascuna di queste proporzioni possa essere considerata come una stima empirica di ciò che chiamiamo probabilità. Le proporzioni descritte sopra vengono sono delle “stime” poiché approssimano il vero valore della probabilità; infatti, ripetendo la simulazione due volte abbiamo ottenuto dei risultati leggermente diversi. Ma allora qual è il “vero” valore della probabilità? Un modo semplice per rispondere a questa domanda è quello di dire che, utilizzando la procedura descritta sopra, il vero valore della probabilità si otterrebbe se il gioco di De Méré venisse ripetuto infinite volte. Ma ovviamente, per qualunque applicazione concreta, non abbiamo bisogno di ripetere la simulazione infinite volte, in quanto un grande numero di ripetizioni ci fornisce un’approssimazione sufficiente. In conclusione, le considerazioni precedenti ci fanno capire che il concetto di probabilità sia legato a quello di incertezza. La probabilità può infatti essere definita come la quantificazione del livello di “casualità” di un evento, laddove viene detto casuale ciò che non è noto o non può essere predetto con certezza. 10.3 Terminologia Come qualsiasi altra branca della matematica, la teoria delle probabilità fa uso di una specifica terminologia i cui concetti di base sono descritti di seguito. Il calcolo delle probabilità si occupa di un generico esperimento casuale. Si dice esperimento casuale qualsiasi attività che produce un risultato osservabile. L’esecuzione di un esperimento casuale è chiamata prova dell’esperimento. Esempi sono: lanciare una moneta, lanciare un dado a 6 facce, provare un nuovo percorso per andare al lavoro per vedere se è più veloce di quello che usiamo di solito, o giocare al gioco di De Méré. Il risultato (o esito) di una prova si indica con \\(\\omega\\) ed è detto evento elementare. Prima che l’esperimento casuale venga eseguito non sappiamo quale esito verrà prodotto; dopo che l’esperimento casuale è stato eseguito, l’esito dell’esperimento si “cristallizza” nel risultato osservato. Si dice spazio campionario \\(\\Omega\\) (probability space) l’insieme di tutti i possibili esiti di un esperimento casuale. Lo spazio campionario può essere finito, infinito o infinito numerabile. Eseguire un esperimento casuale significa scegliere in maniera casuale uno dei possibili eventi elementari dello spazio campionario. Si dice evento composto (o non-elementare) un sottoinsieme dello spazio campionario, ovvero un insieme che può essere a sua volta scomposto in più eventi elementari. Per esempio, il numero 4 è un evento elementare dello spazio campionario finito \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\) che corrisponde all’esperimento casuale del lancio di un dado. L’evento composto \\(A\\) “il risultato è pari” è \\(A = \\{2, 4, 6\\}\\). 10.4 Le diverse definizioni della probabilità Ma, nello specifico, che cos’è la probabilità? A questa domanda si può rispondere in modi diversi. 10.4.1 Una definizione “ingenua” della probabilità Storicamente, la prima definizione della probabilità di un evento è stata quella che richiede di contare il numero di modi nei quali un evento può manifestarsi e di dividere tale numero per il numero totale di eventi dello spazio campionario \\(\\Omega\\). Definizione 10.1 Dato uno spazio campionario finito, la definizione ingenua della probabilità dell’evento \\(A\\) è \\[ \\begin{aligned} P_{\\text{ing}} = \\frac{|A|}{|\\Omega|} = \\frac{\\text{numero eventi elementari favorevoli all&#39;evento }A}{\\text{numero totale eventi elementari dello spazio campionario }\\Omega}.\\notag\\end{aligned} \\] La definizione 10.1 rende chiaro che il calcolo delle probabilità richiede di contare il numero di modi in cui un evento può realizzarsi. Per esempio, nell’esperimento casuale corrispondente al lancio di due dadi equilibrati, l’evento \\(A\\) = “la somma dei due dati è 5” si può realizzare in 4 modi diversi: \\(A = \\{ (1, 4), (2, 3), (3, 2), (4, 1) \\}\\). Contare il numero di modi in cui un evento può realizzarsi può essere semplice, nel caso di alcuni eventi (come il presente), oppure estremamente complesso, nel caso di altri eventi. In questo secondo caso, per contare il numero di modi in cui un evento può realizzarsi, al fine di calcolare la probabilità definita come indicato sopra, è necessario fare uso del calcolo combinatorio. In queste dispense ci accontenteremo di presentare alcune nozioni di base del calcolo combinatorio, ma non entreremo nei dettagli di questo argomento. 10.4.2 Una definizione “non ingenua” della probabilità Il calcolo combinatorio ci consente di contare il numero di casi nello spazio campionario e di applicare la definizione “ingenua” di probabilità descritta nella definizione 10.1. È però facile rendersi conto che tale definizione di probabilità ha un grosso problema: non può essere applicata al caso di uno spazio campionario infinito. Dobbiamo dunque trovare una definizione che risolva un tale problema. Per fare ciò vengono specificate alcune proprietà che vorremmo potere attribuire alla probabilità – in matematica, tali proprietà sono dette assiomi – per poi definire una funzione di probabilità che soddisfi tali proprietà. Arriviamo in questo modo alla seguente definizione non ingenua della probabilità. Definizione 10.2 Uno spazio di probabilità è una terna (\\(\\Omega\\), \\(\\mathcal{A}\\), \\(P\\)), dove \\(\\Omega\\) è l’insieme dei risultati possibili di un esperimento casuale, \\(\\mathcal{A}\\) è detta \\(\\sigma\\)-algebra, ovvero un insieme di insiemi (gli eventi) per i quali si può calcolare una probabilità, e \\(P()\\) è una misura di probabilità su \\(\\Omega\\), ovvero \\(P: \\Omega \\rightarrow [0, 1]\\). Per la precisione, una \\(\\sigma\\)-algebra è una famiglia di insiemi tali che \\(\\emptyset \\in \\mathcal{A}\\); se \\(A \\in \\mathcal{A}\\) allora anche il suo complementare \\(A^C\\) è in \\(\\mathcal{A}\\); unioni numerabili di elementi di \\(\\mathcal{A}\\) appartengono ancora ad \\(\\mathcal{A}\\). La funzione di probabilità \\(P()\\) deve soddisfare i seguenti assiomi: la probabilità \\(P(\\omega)\\) soddisfa la disuguaglianza \\(0 \\leq P(\\omega) \\leq 1;\\) la probabilità dell’evento certo (ovvero la probabilità dello spazio campionario \\(\\Omega\\)) è 1: \\(P(\\Omega) = \\sum_{\\omega \\in \\Omega} P(\\omega) = 1;\\) se \\(A_1, A_2, \\dots, A_k\\) sono eventi disgiunti, allora la probabilità che uno di essi si verifichi è pari alla somma delle loro separate probabilità: \\[\\begin{equation} P(A_1 \\text{ o } A_1 \\dots \\text{ o } A_k) = P(A_1) + P(A_2) +\\dots + P(A_k). \\tag{10.1} \\end{equation}\\] La definizione 10.2 corrisponde al cosiddetto approccio assiomatico messo a punto da Kolmogorov intorno al 1930, il quale è alla base della moderna teoria della probabilità. Nonostante l’enorme complessità dell’approccio assiomatico alla probabilità, per gli scopi dell’analisi dei dati psicologici le cose che dobbiamo capire sono molto semplici. I vincoli della \\(\\sigma\\)-algebra sono necessari per evitare i paradossi che si possono creare quando si manipolano gli insiemi (ad esempio, l’utilizzo dell’“l’insieme di tutti gli insiemi” tipicamente conduce ad un paradosso). Questi problemi sono però molto lontani dalle applicazioni della teoria della probabilità all’analisi dei dati psicologici. Gli psicologi tipicamente effettuano partizioni molto semplici dello spazio campionario: il trattamento ha funzionato oppure no? Per cui le aporie della teoria degli insiemi a cui la \\(\\sigma\\)-algebra vuole porre un freno sono problemi che non ci riguardano. Gli altri aspetti della teoria assiomatica della probabilità, invece, sono molto intuitivi. I primi due assiomi possono essere interpretati nel modo seguente. Si assegna il valore 0 all’“evento impossibile,” ovvero all’esito dell’esperimento casuale che non può verificarsi (ad esempio, il lancio di un dado a sei facce produce 7), e si assegna il valore 1 all’evento certo (ad esempio, il lancio di un dado a sei facce produce un numero compreso tra 1 e 6). Di conseguenza, la probabilità è un numero nell’intervallo \\([0, 1]\\). Il terzo assioma può essere compreso interpretando la probabilità come la frequenza relativa a lungo termine del verificarsi di un evento. Se due eventi sono incompatibili, allora la frequenza relativa dell’unione di tali eventi è la somma delle due singole frequenze relative. Lo stesso si vale per la probabilità. 10.5 Assegnare le probabilità agli eventi È importante capire che l’approccio assiomatico non ci dice come sia possibile assegnare un valore di probabilità a un evento definito in \\(\\Omega\\). A questo proposito esistono due diverse scuole di pensiero. 10.5.1 Approccio frequentista Una prima possibilità è di definire la nozione di probabilità in termini empirici. La probabilità di un evento \\(A\\) può essere concepita come il limite cui tende la frequenza relativa dell’evento, al tendere all’infinito del numero delle prove effettuate, ossia \\[\\begin{equation} P_A = \\lim_{n \\to \\infty} \\frac{n_A}{n}. \\end{equation}\\] Questo è l’approccio che abbiamo utilizzato in precedenza, quando abbiamo discusso il gioco di De Méré. Tale definizione assume che l’esperimento possa essere ripetuto più volte, idealmente infinite volte, sotto le medesime condizioni, e corrisponde alla definizione frequentista di probabilità. Per l’approccio frequentista, dire che la probabilità di ottenere testa è 0.5 significa affermare che l’evento “testa” verrebbe ottenuto nel 50% dei casi, se ripetessimo tantissime volte l’esperimento casuale del lancio di una moneta. Se non abbiamo a disposizione informazioni empiriche a proposito del verificarsi di un evento possiamo attribuire le probabilità agli eventi usando la nostra conoscenza della situazione. Tale approccio è seguito dalla definizione classica di probabilità in base alla quale la probabilità di un evento è il rapporto tra il numero di casi favorevoli e quelli possibili, supposto che tutti gli eventi siano equiprobabili, ossia \\[P_A = \\frac{n_A}{n},\\] dove \\(n\\) è il numero di casi possibili e \\(n_A\\) è il numero di casi favorevoli per l’evento \\(A\\). L’assunzione di equiprobabilità degli eventi elementari ha senso soprattutto nel caso dei giochi d’azzardo. In base all’approccio frequentista, la probabilità è il limite a cui tende una frequenza relativa empirica al crescere del numero di ripetizioni dell’esperimento casuale. È molto facile utilizzare per calcolare una tale probabilità. Per esempio, se vogliamo calcolare la probabilità di ottenere 3 nel lancio di un dado equilibrato, possiamo eseguire la seguente simulazione. n &lt;- 1e5 x &lt;- sample(1:6, n, replace = TRUE) x_01 &lt;- ifelse(x == 3, 1, 0) mean(x_01) #&gt; [1] 0.1676 Il risultato è ovviamente molto simile a \\(1/6\\). 10.5.2 Approccio Bayesiano Esistono però degli eventi per i quali non è possibile calcolare una frequenza relativa, ovvero quelli che si verificano una volta soltanto. Che cos’è allora la probabilità in questi casi? In base all’approccio Bayesiano la probabilità è una misura del grado di plausibilità di una proposizione. Questa definizione è applicabile a qualsiasi evento. Ciò consente di assegnare una probabilità anche a proposizioni quali “il candidato \\(A\\) vincerà le elezioni” oppure “l’accusato è innocente,” anche se non è possibile ripetere più volte un’elezione o un evento criminoso. Per assegnare le probabilità agli eventi, nell’approccio Bayesiano si utilizzano considerazioni “soggettive” che derivano dalle informazioni di cui il soggetto è in possesso. Il teorema di Bayes consente di aggiustare, alla luce dei dati osservati, tali credenze “a priori” per arrivare alla probabilità a posteriori. Quindi, tramite l’approccio Bayesiano, si usa una stima del grado di plausibilità di una proposizione prima dell’osservazione dei dati, al fine di associare un valore numerico al grado di plausibilità di quella stessa proposizione successivamente all’osservazione dei dati. Questo processo di “aggiornamento Bayesiano” corrisponde all’inferenza statistica e verrà discusso in dettaglio nel seguito delle dispense. 10.6 Proprietà elementari della probabilità Indipendentemente da come decidiamo di interpretare la probabilità (in termini frequentisti o Bayesiani), alla probabilità possono essere assegnate le seguenti proprietà. La probabilità dell’evento impossibile è zero: \\[P(\\emptyset) = 1 - P(\\Omega) = 0.\\] Se consideriamo due eventi \\(A\\) e \\(B\\) tali che \\(A \\subseteq B\\), cioè che \\(A\\) è contenuto o coincidente con \\(B\\), da ciò segue che \\[P(A) \\leq P(B).\\] Se \\(A^c\\) è il complementare dell’evento \\(A\\), allora \\[P(A^c) = 1 - P(A).\\] Dati \\(n\\) eventi \\(A_i\\) per \\(i= 1, \\cdots, n\\), gli eventi si dicono indipendenti se risulta \\[P(A_i \\cap A_j \\cap \\cdots \\cap A_k) = P(A_i) P(A_j) \\cdots P(A_k).\\] Se due eventi \\(A\\) e \\(B\\) non sono disgiunti, allora quando sommiamo le loro probabilità dobbiamo evitare che la loro parte comune \\(A \\cap B\\) venga contata due volte. Dati due eventi non necessariamente disgiunti, dunque, la probabilità dell’unione è pari alla somma delle singole probabilità dei due eventi meno la probabilità dell’intersezione: \\[\\begin{equation} P(A \\text{ o } B) = P(A \\cup B) = P(A) + P(B) - P(A \\cap B). \\tag{10.2} \\end{equation}\\] Exercizio 10.1 Nel 2012, a 97 deputati al Parlamento di Londra è stato chiesto: “Se lanci una moneta due volte, qual è la probabilità di ottenere due volte testa?” La maggioranza, 60 su 97, non ha saputo dare la risposta corretta. Come possiamo dare a questo problema una risposta migliore di quella fornita da questi politici? Soluzione. In base alla regola 4 elencata sopra, la risposta corretta è \\(0.5 \\times 0.5 = 0.25\\). Exercizio 10.2 Un’urna contiene \\(30\\) palline: \\(10\\) bianche numerate da \\(1\\) a \\(10\\), \\(10\\) rosse e \\(10\\) gialle numerate allo stesso modo. Qual è la probabilità che, estraendo una pallina a caso, venga estratta una pallina gialla o una pallina pari? Soluzione. Il numero totale di palline è \\(30\\). La probabilità che venga estratta una gialla è \\(P(G) = \\frac{10}{30} = \\frac{1}{3}\\). Le palline con numero pari sono \\(5\\) per ogni colore, quindi \\(15\\). La probabilità che venga estratto un numero pari è \\(P(P) = \\frac{15}{30} = \\frac{1}{2}\\). Gli eventi sono compatibili: i casi favorevoli a entrambi gli eventi (pallina gialla e pari) sono \\(5\\). La probabilità dell’evento cercato è dunque \\(P(\\text{gialla} \\cup \\text{pari}) = \\frac{1}{3} + \\frac{1}{2} - \\frac{5}{30} = \\frac{2}{3}\\). 10.7 Variabili aleatorie Il concetto di “variabile aleatoria” è estremamente utile per estendere la nostra capacità di quantificare l’incertezza e di riassumere i risultati di un esperimento casuale. Le variabili aleatorie sono un concetto fondamentale di tutta la teoria statistica; è quindi cruciale capire quale sia il loro significano. Iniziamo con una definizione. Definizione 10.3 Una variabile aleatoria è una funzione sullo spazio campionario \\(\\Omega\\) che associa ad ogni evento elementare \\(\\omega_i\\) un unico numero \\(X(\\omega_i) = x_i\\), ovvero \\(X: \\Omega \\rightarrow \\Re\\). Il dominio della variabile aleatoria \\(X\\) (che è una funzione) è dato dai punti dello spazio campionario \\(\\Omega\\). Ad ogni evento elementare \\(\\omega_i\\) attribuiamo il numero \\(X(\\omega_i)\\), ovvero il valore che la variabile aleatoria assume sul risultato \\(\\omega_i\\) dell’esperimento casuale. L’attributo “aleatoria” si riferisce al fatto che la variabile considerata trae origine da un esperimento di cui non siamo in grado di prevedere l’esito con certezza. Mediante una variabile aleatoria trasformiamo lo spazio campionario \\(\\Omega\\), che in genere è complesso, in uno spazio campionario più semplice formato da un insieme di numeri. Il maggior vantaggio di questa sostituzione è che molte variabili aleatorie, definite su spazi campionari anche molto diversi tra loro, danno luogo ad una stessa “distribuzione” di probabilità sull’asse reale. Le variabili aleatorie si indicano con le lettere maiuscole ed i valori da esse assunti con le lettere minuscole. Ci sono due classi di variabili aleatorie: variabili aleatorie discrete e variabili aleatorie continue. Consideriamo innanzitutto il caso delle variabili aleatorie discrete. Definizione 10.4 Una variabile aleatoria \\(X\\) viene detta discreta se può assumere un insieme discreto (finito o numerabile) di numeri reali. Se \\(X\\) è una variabile aleatoria discreta allora l’insieme dei possibili valori \\(x\\), tali per cui \\(P(X = x) &gt; 0\\), viene detto “supporto” di \\(X\\). Alcuni esempi di variabili aleatorie discrete sono i seguenti: il numero di intrusioni di pensieri, immagini, impulsi indesiderabili in un paziente OCD, il voto all’esame di Psicometria, la durata di vita di un individuo, il numero dei punti che si osservano nel lancio di due dadi e il guadagno (la perdita) che un giocatore realizzerà in \\(n\\) partite. Si noti che, in tutti questi casi, la variabile aleatoria considerata viene rappresentata mediante un numero. 10.7.1 A cosa servono le variabili aleatorie? Facendo riferimento agli esempi elencati sopra, possiamo chiederci perché questi numeri vengono considerati come “aleatori.” È ovvio che noi non conosciamo, ad esempio, il voto di Psicometria di Mario Rossi prima del momento in cui Mario Rossi avrà fatto l’esame. Le variabili aleatorie si pongono il seguente problema: come possiamo descrivere le nostre opinioni rispetto al voto (possibile) di Mario Rossi, prima che lui abbia fatto l’esame. Prima dell’esame, il voto di Psicometria di Mario Rossi si può solo descrivere facendo riferimento ad un insieme di valori possibili. Inoltre, molto spesso, possiamo anche dire che tali valori possibili non sono tutti egualmente verosimili: ci aspettiamo di osservare più spesso alcuni di questi valori rispetto agli altri. Le proprietà delle variabili aleatorie ci consentono di sistematizzare questo tipo di opinioni. Ovviamente, una volta che Mario Rossi avrà fatto l’esame, questa materia non avrà più alcuna componente aleatoria. 10.7.2 Funzione di massa di probabilità Per entrare nel merito di questa discussione, chiediamoci ora come sia possibile associare delle probabilità ai valori che vengono assunti dalle variabili aleatorie. Ad esempio, qual è la probabilità che Mario Rossi ottenga 29 all’esame? Ci occuperemo qui del caso delle variabili aleatorie discrete. Alle variabili aleatorie discrete vengono assegnale le probabilità mediante le cosiddette “distribuzioni di probabilità.” Una distribuzione di probabilità è un modello matematico che collega ciascun valore di una variabile aleatoria discreta alla probabilità di osservare un tale valore in un esperimento casuale. In pratica, ad ognuno dei valori che possono essere assunti da una variabile aleatoria discreta viene associata una determinata probabilità. La funzione che associa ad ogni valore della variabile aleatoria una probabilità corrispondente si chiama “distribuzione di probabilità” oppure “legge di probabilità.” Una descrizione intuitiva del concetto di distribuzione di probabilità può essere formulata nei termini seguenti. Possiamo pensare alla probabilità come ad una quantità positiva che viene “distribuita” sull’insieme dei valori della variabile aleatoria. Tale “distribuzione” (suddivisione, spartizione) viene scalata in maniera tale che ciascun elemento di essa corrisponda ad una proporzione del totale, nel senso che il valore totale della distribuzione è sempre pari a 1. Una distribuzione di probabilità non è dunque altro che un modo per suddividere la nostra certezza (cioè 1) tra i valori che la variabile aleatoria può assumere. In modo più formale, possiamo dire quanto segue. Definizione 10.5 Se \\(X\\) è una variabile aleatoria discreta, una distribuzione di probabilità può essere rappresentata mediante una funzione di massa di probabilità che associa a ciascuno dei valori \\(x\\) che la variabile aleatoria \\(X\\) può assumere la corrispondente probabilità \\(P_{\\pi}(X=x)\\). In maniera più semplice, una distribuzione di (massa) di probabilità è formata dall’elenco di tutti i valori possibili di una variabile aleatoria discreta e dalle probabilità loro associate. Si noti che \\(P_{\\pi}(X=x)\\) è un numero positivo se il valore \\(x\\) è compreso nel supporto di \\(X\\), altrimenti vale 0. Se \\(A\\) è un sottoinsieme della variabile aleatoria \\(X\\), allora denotiamo con \\(P_{\\pi}(A)\\) la probabilità assegnata ad \\(A\\) dalla distribuzione \\(P_{\\pi}\\). Mediante una distribuzione di probabilità \\(P_{\\pi}\\) è possibile determinare la probabilità di ciascun sottoinsieme \\(A \\subset X\\) come \\[P_{\\pi}(A) = \\sum_{x \\in A} P_{\\pi}(x).\\] Qui non facciamo altro che applicare il terzo assioma di Kolmogorov. Exercizio 10.3 Consideriamo nuovamente lo spazio campionario \\(\\Omega\\) dell’esercizio precedente e definiamo la variabile aleatoria \\(S(\\omega)\\) come la somma dei puntini che si ottengono dal lancio di due dadi. Per esempio, \\(S(\\{(6, 3)\\}) = 6 + 3 = 9\\). Iniziamo a chiederci qual è la probabilità dell’evento \\(S = 7\\). Soluzione. Per risolvere tale problema iniziamo a considerare il fatto che l’evento \\(S = 7\\) si verifica in corrispondenza di sei punti elementari dello spazio campionario \\(\\Omega\\): {(1, 6), (2, 5), (3, 4), (4, 3), (2, 5), (6, 1)}. Dunque, \\[\\begin{equation} P(S = 7) = P\\{(1, 6)\\} + P\\{(2, 5)\\} + P\\{(3, 4)\\} + P\\{(4, 3)\\} + P\\{(2, 5)\\} + P\\{(6, 1)\\}. \\end{equation}\\] Se possiamo assumere che i due dadi sono bilanciati, allora ciascun evento elementare dello spazio campionario ha probabilità \\(\\frac{1}{36}\\) e la probabilità cercata diventa \\(\\frac{1}{6}\\). È facile estendere il ragionamento fatto sopra a tutti i valori che \\(S\\) può assumere. In questo modo giungiamo alla funzione di massa di probabilità \\(P_0\\) riportata nella prima riga della tabella seguente. Distribuzione di massa di probabilità per la somma dei punti prodotti dal lancio di due dadi bilanciati (\\(P_0\\)) e di due dadi truccati (\\(P_1\\)). s 2 3 4 5 6 7 8 9 10 11 12 \\(P_0(S = s)\\) \\(\\frac{1}{36}\\) \\(\\frac{2}{36}\\) \\(\\frac{3}{36}\\) \\(\\frac{4}{36}\\) \\(\\frac{5}{36}\\) \\(\\frac{6}{36}\\) \\(\\frac{5}{36}\\) \\(\\frac{4}{36}\\) \\(\\frac{3}{36}\\) \\(\\frac{2}{36}\\) \\(\\frac{1}{36}\\) \\(P_1(S = s)\\) \\(\\frac{4}{64}\\) \\(\\frac{4}{64}\\) \\(\\frac{5}{64}\\) \\(\\frac{6}{64}\\) \\(\\frac{7}{64}\\) \\(\\frac{12}{64}\\) \\(\\frac{7}{64}\\) \\(\\frac{6}{64}\\) \\(\\frac{5}{64}\\) \\(\\frac{4}{64}\\) \\(\\frac{4}{64}\\) Per considerare un caso più generale, poniamoci ora il problema di trovare la funzione di massa di probabilità di \\(S\\) nel caso di due dadi truccati aventi la seguente distribuzione di probabilità: \\[ \\begin{aligned} P(\\{(1, 6)\\}) = \\frac{1}{4};\\notag\\\\ P(\\{(2, 3)\\}) = P(\\{4\\}) = P(\\{5\\}) = \\frac{1}{8}\\notag. \\label{eq:loaded_dice} \\end{aligned} \\] Nel caso dei due dadi truccati, la probabilità dell’evento elementare (1, 1) è 1/4 1/4. Dunque, P(S = 2) = 4/64. La probabilità dell’evento elementare (1, 2) è 1/4 1/8. Tale valore è uguale alla probabilità dell’evento elementare (2, 1). La probabilità che S sia uguale a 3 è 1/4 1/8 + 1/8 1/4 = 4/64, e così via. Svolgendo i calcoli per tutti i possibili valori di S otteniamo la funzione di massa di probabilità \\(P_1\\) riportata nella seconda riga della tabella precedente. Si noti che, a partire dalla funzione di massa di probabilità di S, è possibile calcolare la probabilità di altri eventi. Per esempio, possiamo dire che l’evento S &gt; 10 ha una probabilità minore nel caso dei dadi bilanciati, ovvero 3/36 = 1/12, rispetto al caso dei dadi truccati considerati in precedenza dove, per lo stesso evento, abbiamo una probabilità di 8/64 = 1/8. 10.8 Notazione Qui sotto è riportata la notazione che verrà usata per fare riferimento ad eventi e probabilità, nel caso discreto e continuo, in maniera tale che queste convenzioni siano elencate tutte in un posto solo. Gli eventi sono denotati da lettere maiuscole, es. \\(A\\), \\(B\\), \\(C\\). Una variabile aleatoria è denotata da una lettera maiuscola, ad esempio \\(X\\), e assume valori denotati dalla stessa lettera minuscola, ad esempio \\(x\\). La connessione tra eventi e valori viene espressa nei termini seguenti: “\\(X = x\\)” significa che l’evento \\(X\\) assume il valore \\(x\\). La probabilità di un evento è denotata con \\(P(A)\\). Una variabile aleatoria discreta ha una funzione di massa di probabilità denotata con \\(p(x)\\). La relazione tra \\(P\\) e \\(p\\) è che \\(P(X=x) = p(x)\\). Conclusioni In questo capitolo abbiamo visto come si costruisce lo spazio campionario di un esperimento casuale, quali sono le proprietà di base della probabilità e come si assegnano le probabilità agli eventi definiti sopra uno spazio campionario discreto. Abbiamo anche introdotto le nozioni di “variabile aleatoria” e di “funzione di massa di probabilità.” Le procedure di analisi dei dati psicologici che discuteremo in seguito faranno un grande uso di questi concetti e della notazione qui introdotta. "],["chapter-prob-cond.html", "Capitolo 11 Probabilità condizionata 11.1 Probabilità condizionata su altri eventi 11.2 Legge della probabilità composta 11.3 L’indipendendenza stocastica Conclusioni", " Capitolo 11 Probabilità condizionata L’attribuzione di una probabilità ad un evento è sempre condizionata dalle conoscenze che abbiamo a disposizione. Per un determinato stato di conoscenze, attribuiamo ad un dato evento una certa probabilità di verificarsi; ma se il nostro stato di conoscenze cambia, allora cambierà anche la probabilità che attribuiamo all’evento in questione. Per esempio, posiamo chiederci quale sia probabilità che Mario Rossi superi l’esame di Psicometria nel primo appello del presente anno accademico. In assenza di altre informazioni, la migliore stima di tale probabilità è data dalla proporzione di studenti che hanno superato l’esame di Psicometria nel corrispondente appello dei passati anni accademici. Ma se sappiamo che Mario Rossi è particolarmente portato per le materie quantitative, ha un’ottima preparazione di base e ha studiato molto, allora la probabilità sarà sicuramente più alta. 11.1 Probabilità condizionata su altri eventi La probabilità condizionata è una componente essenziale del ragionamento scientifico dato che chiarisce come sia possibile incorporare le evidenze disponibili, in maniera logica e coerente, nella nostra conoscenza del mondo. Infatti, si può pensare che tutte le probabilità siano probabilità condizionate, anche se l’evento condizionante non è sempre esplicitamente menzionato. Consideriamo il seguente problema. Exercizio 11.1 Lo screening per la diagnosi precoce del tumore mammario si avvale di test che sono accurati al 90%, nel senso che il 90% delle donne con cancro e il 90% delle donne senza cancro saranno classificate correttamente. Supponiamo che l’1% delle donne sottoposte allo screening abbia effettivamente il cancro al seno. Ci chiediamo: qual è la probabilità che una donna scelta casualmente abbia una mammografia positiva e, se ce l’ha, qual è la probabilità che abbia davvero il cancro? Soluzione. Per risolvere questo problema, supponiamo che il test in questione venga somministrato ad un grande campione di donne, diciamo a 1000 donne. Di queste 1000 donne, 10 (ovvero, l’1%) hanno il cancro al seno. Per queste 10 donne, il test darà un risultato positivo in 9 casi (ovvero, nel 90% dei casi). Per le rimanenti 990 donne che non hanno il cancro al seno, il test darà un risultato positivo in 99 casi (se la probabilità di un vero positivo è del 90%, la probabilità di un falso positivo è del 10%). Questa situazione è rappresentata nella figura 11.1. Mettendo insieme questi due risultati, vediamo che il test dà un risultato positivo per 9 donne che hanno effettivamente il cancro al seno e per 99 donne che non ce l’hanno, per un totale di 108 risultati positivi. Dunque, la probabilità di ottenere un risultato positivo al test è \\(\\frac{108}{1000}\\) = 11%. Ma delle 108 donne che hanno ottenuto un risultato positivo al test, solo 9 hanno il cancro al seno. Dunque, la probabilità di avere il cancro, dato un risultato positivo al test, è pari a \\(\\frac{9}{108}\\) = 8%. Figura 11.1: Rappresentazione ad albero che riporta le frequenze attese dei risultati di una mammografia in un campione di 1,000 donne Nell’esercizio 11.1 la probabilità dell’evento “ottenere un risultato positivo al test” è una probabilità non condizionata, mentre la probabilità dell’evento “avere il cancro al seno, dato che il test ha dato un risultato positivo” è una probabilità condizionata. In termini generali, la probabilità condizionata \\(P(A \\mid B)\\) rappresenta la probabilità che si verifichi l’evento \\(A\\) sapendo che si è verificato l’evento \\(B\\); oppure: la probabilità di \\(A\\) in una prova valida solo se si verifica anche \\(B\\). Ciò ci conduce alla seguente definizione. Definizione 11.1 (Probabilità condizionata) Dato un qualsiasi evento \\(A\\), si chiama probabilità condizionata di \\(A\\) dato \\(B\\) il numero \\[\\begin{equation} P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}, \\quad \\text{con}\\, P(B) &gt; 0, \\tag{11.1} \\end{equation}\\] dove \\(P(A\\cap B)\\) è la probabilità congiunta dei due eventi, ovvero la probabilità che si verifichino entrambi. In alcuni casi può essere conveniente leggere al contrario la formula 11.1 e utilizzarla per calcolare la probabilità dell’intersezione di due eventi. Per esempio se conosciamo la probabilità dell’evento \\(B\\) e la probabilità condizionata di \\(A\\) su \\(B\\), otteniamo \\[\\begin{equation} P(A \\cap B) = P(B)P(A \\mid B), \\tag{11.2} \\end{equation}\\] mentre se conosciamo la probabilità dell’evento \\(A\\) e la probabilità condizionata di \\(B\\) su \\(A\\), otteniamo \\(P(A \\cap B) = P(A)P(B \\mid A)\\). Exercizio 11.2 Da un mazzo di 52 carte (13 carte per ciascuno dei 4 semi) ne viene estratta 1 in modo casuale. Qual è la probabilità che esca una figura di cuori? Sapendo che la carta estratta ha il seme di cuori, qual è la probabilità che il valore numerico della carta sia 7, 8 o 9? Soluzione. Ci sono 13 carte di cuori, dunque la risposta alla prima domanda è 1/4. Per rispondere alla seconda domanda consideriamo solo le 13 carte di cuori; la probabilità cercata è dunque 3/13. 11.1.1 La fallacia del pubblico ministero Un errore comune che si commette è quello di credere che \\(P(A \\mid B)\\) sia uguale a \\(P(B \\mid A)\\). Tale fallacia ha particolare risalto in ambito forense tanto che è conosciuta con il nome di “fallacia del procuratore” (prosecutor’s fallacy). In essa, una piccola probabilità dell’evidenza, data l’innocenza, viene erroneamente interpretata come la probabilità dell’innocenza, data l’evidenza. Consideriamo il caso di un esame del DNA. Un esperto forense potrebbe affermare, ad esempio, che “se l’imputato è innocente, c’è solo una possibilità su un miliardo che vi sia una corrispondenza tra il suo DNA e il DNA trovato sulla scena del crimine.” Ma talvolta questa probabilità è erroneamente interpretata come avesse il seguente significato: “date le prove del DNA, c’è solo una possibilità su un miliardo che l’imputato sia innocente.” Le considerazioni precedenti risultano più chiare se facciamo nuovamente riferimento all’esercizio 11.1. In tale esercizio abbiamo visto come la probabilità di cancro dato un risultato positivo al test sia uguale a 0.08. Tale probabilità è molto diversa dalla probabilità di un risultato positivo al test data la presenza del cancro. Infatti, questa seconda probabilità è uguale a 0.90 ed è descritta nel problema come una delle caratteristiche del test in questione. 11.2 Legge della probabilità composta Il teorema della probabilità composta deriva dal concetto di probabilità condizionata per cui la probabilità che si verifichino due eventi \\(A_i\\) e \\(A_j\\) è pari alla probabilità di uno dei due eventi moltiplicato con la probabilità dell’altro evento condizionato al verificarsi del primo. L’equazione (11.2) si estende al caso di \\(n\\) eventi \\(A_1, \\dots, A_n\\) nella forma seguente: \\[\\begin{equation} \\begin{split} P(A_1 \\cap A_2 \\cap \\dots\\cap A_n) = {}&amp; P(A_1)P(A_2 \\mid A_1)P(A_3 \\mid A_1 \\cap A_2) \\dots\\\\ &amp; P(A_n \\mid A_1 \\cap A_2 \\cap \\dots \\cap A_{n-1}) \\end{split} \\tag{10.1} \\end{equation}\\] la quale esprime in forma generale la legge della probabilità composta. Exercizio 11.3 Da un’urna contenente 6 palline bianche e 4 nere si estrae una pallina per volta, senza reintrodurla nell’urna. Indichiamo con \\(B_i\\) l’evento: “esce una pallina bianca alla \\(i\\)-esima estrazione” e con \\(N_i\\) l’estrazione di una pallina nera. L’evento: “escono due palline bianche nelle prime due estrazioni” è rappresentato dalla intersezione \\(\\{B_1 \\cap B_2\\}\\) e la sua probabilità vale, per la (11.2) \\[ P(B_1 \\cap B_2) = P(B_1)P(B_2 \\mid B_1). \\] \\(P(B_1)\\) vale 6/10, perché nella prima estrazione \\(\\Omega\\) è costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilità condizionata \\(P(B_2 \\mid B_1)\\) vale 5/9, perché nella seconda estrazione, se è verificato l’evento \\(B_1\\), lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava pertanto: \\[ P(B_1 \\cap B_2) = \\frac{6}{10} \\cdot \\frac{5}{9} = \\frac{1}{3}. \\] In modo analogo si ha che \\[ P(N_1 \\cap N_2) = P(N_1)P(N_2 \\mid N_1) = \\frac{4}{10} \\cdot \\frac{3}{9} = \\frac{4}{30}. \\] Se l’esperimento consiste nell’estrazione successiva di 3 palline, la probabilità che queste siano tutte bianche vale, per la (10.1): \\[ P(B_1 \\cap B_2 \\cap B_3)=P(B_1)P(B_2 \\mid B_1)P(B_3 \\mid B_1 \\cap B_2), \\] dove la probabilità \\(P(B_3 \\mid B_1 \\cap B_2)\\) si calcola supponendo che si sia verificato l’evento condizionante \\(\\{B_1 \\cap B_2\\}\\). Lo spazio campionario per questa probabilità condizionata è costituito da 4 palline bianche e 4 nere, per cui \\(P(B_3 \\mid B_1 \\cap B_2) = 1/2\\) e quindi: \\[ P (B_1 \\cap B_2 \\cap B_3) = \\frac{6}{10}\\cdot\\frac{5}{9} \\cdot\\frac{4}{8} = \\frac{1}{6}. \\] La probabilità dell’estrazione di tre palline nere è invece: \\[ \\begin{aligned} P(N_1 \\cap N_2 \\cap N_3) &amp;= P(N_1)P(N_2 \\mid N_1)P(N_3 \\mid N_1 \\cap N_2)\\notag\\\\ &amp;= \\frac{4}{10} \\cdot \\frac{3}{9} \\cdot \\frac{2}{8} = \\frac{1}{30}.\\notag \\end{aligned} \\] 11.3 L’indipendendenza stocastica Un concetto molto importante per le applicazioni statistiche della probabilità è quello dell’indipendenza stocastica. La definizione (11.1) esprime il concetto intuitivo di indipendenza di un evento da un altro, nel senso che il verificarsi di \\(A\\) non influisce sulla probabilità del verificarsi di \\(B\\), ovvero non la condiziona. Infatti, per la definizione (11.1) di probabilità condizionata, si ha che, se \\(A\\) e \\(B\\) sono due eventi indipendenti, risulta: \\[ P(A \\mid B) = \\frac{P(A)P(B)}{P(B)} = P(A).\\notag \\] Possiamo dunque dire che due eventi \\(A\\) e \\(B\\) sono indipendenti se \\[ \\begin{split} P(A \\mid B) &amp;= P(A), \\\\ P(B \\mid A) &amp;= P(B). \\end{split} \\] Exercizio 11.4 Nel lancio di due dadi non truccati, si considerino gli eventi: A = {esce un 1 o un 2 nel primo lancio} e B = {il punteggio totale è 8}. Gli eventi A e B sono indipendenti? Soluzione. Rappresentiamo qui sotto lo spazio campionario dell’esperimento casuale. Figura 11.2: Rappresentazione dello spazio campionario dei risultati dell’esperimento casuale corrispondente al lancio di due dadi bilanciati. Sono evidenziati gli eventi elementari che costituiscono l’evento A: esce un 1 o un 2 nel primo lancio. Gli eventi A e B non sono statisticamente indipendenti. Infatti, le loro probabilità valgono P(A) = 12/36 e P(B) = 5/36 e la probabilità della loro intersezione è \\[ P(A \\cap B) = 1/36 = 3/108 \\neq P(A)P(B) = 5/108. \\] Osservazione. Si noti che il concetto di indipendenza è del tutto differente da quello di incompatibilità. Due eventi A e B incompatibili (per i quali si ha \\(A \\cap B = \\emptyset\\)) sono statisticamente dipendenti, poiché il verificarsi dell’uno esclude il verificarsi dell’altro: \\(P(A \\cap B)=0 \\neq P(A)P(B)\\). Osservazione. Se due eventi con probabilità non nulla sono statisticamente indipendenti, la legge delle probabilità totali espressa dalla (10.2) si modifica nella relazione seguente: \\[\\begin{equation} P(A \\cup B) = P(A) + P(B) - P(A)P(B). \\end{equation}\\] Conclusioni La probabilità condizionata è importante perché ci fornisce uno strumento per precisare il concetto di indipendenza statistica. Una delle più importanti domande delle analisi statistiche è infatti quella che si chiede se due variabili siano o meno associate. In questo capitolo abbiamo discusso il concetto di indipendenza (come contrapposto al concetto di associazione); nel capitolo 9 abbiamo descritto poi uno dei modi possibili che ci consentono di quantificare l’associazione tra due variabili. In seguito vedremo come sia possibile fare inferenza sull’associazione tra variabili – ovvero, come stabilire il livello di fiducia nel verificarsi dell’evento esaminato nel campione in un contesto più ampio, cioè quello della popolazione. "],["chapter-bayes-theo.html", "Capitolo 12 Il teorema di Bayes 12.1 Il teorema della probabilità totale 12.2 Il teorema della probabilità delle cause Conclusioni", " Capitolo 12 Il teorema di Bayes Il teorema di Bayes ha un ruolo centrale nella statistica Bayesiana, anche se viene utilizzato anche dall’approccio frequentista. Prima di esaminare il teorema di Bayes introdurremo una sua componente, ovvero il teorema della probabilità totale. 12.1 Il teorema della probabilità totale Il teorema della probabilità totale fa uso della legge della probabilità composta (10.1) per calcolare le probabilità di casi più complessi di quelli considerati fino ad ora. La notazione sembra complessa, ma l’idea sottostante è semplice. Discutiamo qui il teorema della probabilità totale considerando il caso di una partizione dello spazio campionario in tre sottoinsiemi. È facile estendere tale situazione al caso di una partizione in un qualunque numero di sottoinsiemi. Teorema 12.1 Sia \\(\\{A_1, A_2, A_3\\}\\) una partizione dello spazio campionario \\(\\Omega\\). Se \\(E\\) è un qualunque altro evento, allora: \\[\\begin{equation} P(E) = P(E \\cap A_1) + P(E \\cap A_2) + P(E \\cap A_3) \\notag \\tag{12.1} \\end{equation}\\] ovvero \\[\\begin{equation} P(E) = P(E \\mid A_1) P(A_1) + P (E \\mid A_2) P(A_2) + P(E \\mid A_3) P(A_3). \\tag{12.2} \\end{equation}\\] Il teorema della probabilità totale afferma che, se l’evento \\(E\\) è costituito da tutti gli eventi elementari in \\(E \\cap A_1\\), \\(E \\cap A_2\\) e \\(E \\cap A_3\\), allora la probabilità \\(P(E)\\) è data dalla somma delle probabilità di queti tre eventi. Ciò è illustrato nella figura seguente. Exercizio 12.1 Si considerino tre urne, ciascuna delle quali contiene 100 palline: Urna 1: 75 palline rosse e 25 palline blu, Urna 2: 60 palline rosse e 40 palline blu, Urna 3: 45 palline rosse e 55 palline blu. Una pallina viene estratta a caso da un’urna anch’essa scelta a caso. Qual è la probabilità che la pallina estratta sia di colore rosso? Soluzione. Sia \\(R\\) l’evento “la pallina estratta è rossa” e sia \\(U_i\\) l’evento che corrisponde alla scelta dell’\\(i\\)-esima urna. Sappiamo che \\[ P(R \\mid U_1) = 0.75, \\qquad P(R \\mid U_2) = 0.60, \\qquad P(R \\mid U_3) = 0.45. \\] Gli eventi \\(U_1\\), \\(U_2\\) e \\(U_3\\) costituiscono una partizione dello spazio campionario in quanto \\(U_1\\), \\(U_2\\) e \\(U_3\\) sono eventi mutualmente esclusivi ed esaustivi, \\(P(U_1 \\cup U_2 \\cup U_3) = 1.0\\). In base al teorema della probabilità totale, la probabilità di estrarre una pallina rossa è \\[ \\begin{aligned} P(R) &amp;= P(R \\mid U_1)P(U_1)+P(R \\mid U_2)P(U_2)+P(R \\mid U_3)P(U_3)\\notag\\\\ &amp;= 0.75 \\cdot \\frac{1}{3}+0.60 \\cdot \\frac{1}{3}+0.45 \\cdot \\frac{1}{3} =0.60.\\notag \\end{aligned} \\] Exercizio 12.2 Consideriamo un’urna che contiene 5 palline rosse e 2 palline verdi. Due palline vengono estratte, una dopo l’altra. Vogliamo sapere la probabilità dell’evento “la seconda pallina estratta è rossa.” Soluzione. Lo spazio campionario è \\(\\Omega = \\{RR, RV, VR, VV\\}\\). Chiamiamo \\(R_1\\) l’evento “la prima pallina estratta è rossa,” \\(V_1\\) l’evento “la prima pallina estratta è verde,” \\(R_2\\) l’evento “la seconda pallina estratta è rossa” e \\(V_2\\) l’evento “la seconda pallina estratta è verde.” Dobbiamo trovare \\(P(R_2)\\) e possiamo risolvere il problema usando il teorema della probabilità totale (12.2): \\[\\begin{equation} \\begin{aligned} P(R_2) &amp;= P(R_2 \\mid R_1) P(R_1) + P(R_2 \\mid V_1)P(V_1)\\notag\\\\ &amp;= \\frac{4}{6} \\cdot \\frac{5}{7} + \\frac{5}{6} \\cdot \\frac{2}{7} = \\frac{30}{42} = \\frac{5}{7}.\\notag \\end{aligned} \\end{equation}\\] Se la prima estrazione è quella di una pallina rossa, nell’urna restano 4 palline rosse e due verdi, dunque, la probabilità che la seconda estrazione produca una pallina rossa è uguale a 4/6. La probabilità di una pallina rossa nella prima estrazione è 5/7. Se la prima estrazione è quella di una pallina verde, nell’urna restano 5 palline rosse e una pallina verde, dunque, la probabilità che la seconda estrazione produca una pallina rossa è uguale a 5/6. La probabilità di una pallina verde nella prima estrazione è 2/7. 12.2 Il teorema della probabilità delle cause Il teorema di Bayes rappresenta uno dei fondamenti della teoria della probabilità e della statistica. Lo presentiamo qui considerando prima un caso specifico per poi descriverlo nella sua forma più generale. Sia \\(\\{A_1, A_2\\}\\) una partizione dello spazio campionario \\(\\Omega\\). Consideriamo un terzo evento \\(E \\subset \\Omega\\) con probabilità non nulla di cui si conoscono le probabilità condizionate rispetto ad \\(A_1\\) e a \\(A_2\\), ovvero \\(P(E \\mid A_1)\\) e \\(P(E \\mid A_2)\\). È chiaro per le ipotesi fatte che se si verifica \\(E\\) deve anche essersi verificato almeno uno degli eventi \\(A_1\\) e \\(A_2\\). Supponendo che si sia verificato l’evento \\(E\\), ci chiediamo: qual è la probabilità che si sia verificato \\(A_1\\) piuttosto che \\(A_2\\)? Per rispondere alla domanda precedente scriviamo: \\[\\begin{equation} \\begin{aligned} P(A_1 \\mid E) &amp;= \\frac{P(E \\cap A_1)}{P(E)}\\notag\\\\ &amp;= \\frac{P(E \\mid A_1)P(A_1)}{P(E)}\\notag.\\end{aligned} \\end{equation}\\] Sapendo che \\(E = (E \\cap A_1) \\cup (E \\cap A_2)\\) e che \\(A_1\\) e \\(A_2\\) sono eventi disgiunti, ovvero \\(A_1 \\cap A_2 = \\emptyset\\), ne segue che possiamo calcolare \\(P(E)\\) utilizzando il teorema della probabilità totale: \\[\\begin{equation} \\begin{aligned} P(E) &amp;= P(E \\cap A_1) + P(E \\cap A_2)\\notag\\\\ &amp;= P(E \\mid A_1)P(A_1) + P(E \\mid A_2)P(A_2).\\notag \\end{aligned} \\end{equation}\\] Sostituendo il risultato precedente nella formula della probabilità condizionata \\(P(A_1 \\mid E)\\) otteniamo: \\[\\begin{equation} P(A_1 \\mid E) = \\frac{P(E \\mid A_1)P(A_1)}{P(E \\mid A_1)P(A_1) + P(E \\mid A_2)P(A_2)}. \\tag{12.3} \\end{equation}\\] La (12.3) si generalizza facilmente al caso di più di due eventi disgiunti, come indicato di seguito. Teorema 12.2 (Teorema di Bayes) Siano \\(A_1\\), \\(A_2,\\) …, \\(A_n\\) \\(n\\) eventi disgiunti con \\(P(A_i) &gt; 0\\) e tali che \\(\\bigcup_{i=1}^{n} A_i = \\Omega\\). Per l’evento \\(E \\subset \\Omega\\) con \\(P(E) &gt; 0\\), abbiamo \\[\\begin{equation} P(A_j \\mid E) = \\frac{P(E \\mid A_j)P(A_j)}{\\sum_{i=1}^{n}P(E \\mid A_i)P(A_i)}. \\tag{12.4} \\end{equation}\\] La formula (12.4) prende il nome di Teorema di Bayes e mostra che la conoscenza del verificarsi dell’evento \\(E\\) modifica la probabilità che abbiamo attribuito all’evento \\(A_j\\). 12.2.1 Aggiornamento Bayesiano Consideriamo ora un’altra applicazione del teorema di Bayes che ci fa capire come l’applicazione di questo teorema ci consente di modificare una credenza a priori in maniera dinamica, via via che nuove evidenze vengono raccolta, in modo tale da formulare una credenza a posteriori la quale non è mai definitiva, ma può essere sempre aggiornata in base alle nuove evidenze disponibili. Questo processo si chiama aggiornamento Bayesiano. Supponiamo che, per qualche strano errore di produzione, una fabbrica produca due tipi di monete. Il primo tipo di monete ha la caratteristica che, quando una moneta viene lanciata, la probabilità di osservare l’esito “testa” è 0.6. Per semplicità, sia \\(\\theta\\) la probabilità di osservare l’esito “testa.” Per una moneta del primo tipo, dunque, \\(\\theta = 0.6\\). Per una moneta del secondo tipo, invece, la probabilità di produrre l’esito “testa” è 0.4. Ovvero, \\(\\theta = 0.4\\). Noi possediamo una moneta, ma non sappiamo se è del primo tipo o del secondo tipo. Sappiamo solo che il 75% delle monete sono del primo tipo e il 25% sono del secondo tipo. Sulla base di questa conoscenza a priori – ovvero sulla base di una conoscenza ottenuta senza avere eseguito l’esperimento che consiste nel lanciare la moneta una serie di volte per osservare gli esiti prodotti – possiamo dire che la probabilità di una prima ipotesi, secondo la quale \\(\\theta = 0.6\\), è 3 volte più grande della probabilità di una seconda ipotesi, secondo la quale \\(\\theta = 0.4\\). Senza avere eseguito alcun esperimento casuale con la moneta, questo è quello che sappiamo. Ora immaginiamo di lanciare una moneta due volte e di ottenere il risultato seguente: \\(\\{T, C\\}\\). Quello che ci chiediamo è: sulla base di questa evidenza, come cambiano le probabilità che associamo alle due ipotesi? In altre parole, ci chiediamo qual è la probabilità di ciascuna ipotesi alla luce dei dati che sono stati osservati: \\(P(H \\mid x)\\), laddove \\(x\\) sono i dati osservati. Tale probabilità si chiama probabilità a posteriori. Inoltre, se confrontiamo le due ipotesi, ci chiediamo quale valore assuma il rapporto \\(\\frac{P(H_1 \\mid x)}{P(H_2 \\mid x)}\\). Tale rapporto ci dice quanto è più probabile \\(H_1\\) rispetto ad \\(H_2\\), alla luce dei dati osservati. Infine, ci chiediamo come cambia il rapporto definito sopra, quando osserviamo via via nuovi risultati prodotti dal lancio della moneta. Definiamo il problema in maniera più chiara. Conosciamo le probabilità a priori, ovvero \\(P(H_1) = 0.75\\) e \\(P(H_1) = 0.25\\). Quello che vogliamo conoscere sono le probabilità a posteriori \\(P(H_1 \\mid x)\\) e \\(P(H_2 \\mid x)\\). Per trovare le probabilità a posteriori applichiamo il teorema di Bayes: \\[P(H_1 \\mid x) = \\frac{P(x \\mid H_1) P(H_1)}{P(x)} = \\frac{P(x \\mid H_1) P(H_1)}{P(x \\mid H_1) P(H_1) + P(x \\mid H_2) P(H_2)},\\] laddove lo sviluppo del denominatore deriva da un’applicazione del teorema della probabilità totale. Inoltre, \\[P(H_2 \\mid x) = \\frac{P(x \\mid H_2) P(H_2)}{P(x \\mid H_1) P(H_1) + P(x \\mid H_2) P(H_2)}.\\] La probabilità \\(P(x \\mid H_1)\\) si chiama verosimiglianza e descrive la plausibilità dei dati osservati in base all’ipotesi considerata. Se consideriamo l’ipotesi \\(H_1\\) = “la probabilità di testa è 0.6,” allora la verosimiglianza dei dati \\(\\{T, C\\}\\) è \\(0.6 \\times 0.4 = 0.24.\\) Dunque, \\(P(x \\mid H_1) = 0.24\\). Se invece consideriamo l’ipotesi \\(H_2\\) = “la probabilità di testa è 0.4,” allora la verosimiglianza dei dati \\(\\{T, C\\}\\) è \\(0.4 \\times 0.6 = 0.24\\), ovvero, \\(P(x \\mid H_2) = 0.24\\). In base alle due ipotesi \\(H_1\\) e \\(H_2\\), dunque, i dati osservati hanno la medesima plausibilità. Per semplicità, calcoliamo anche \\[\\begin{aligned} P(x) &amp;= P(x \\mid H_1) P(H_1) + P(x \\mid H_2) P(H_2) = 0.24 \\cdot 0.75 + 0.24 \\cdot 0.25 = 0.24.\\notag\\end{aligned}\\] Le probabilità a posteriori diventano: \\[\\begin{aligned} P(H_1 \\mid x) &amp;= \\frac{P(x \\mid H_1) P(H_1)}{P(x)} = \\frac{0.24 \\cdot 0.75}{0.24} = 0.75,\\notag\\end{aligned}\\] \\[\\begin{aligned} P(H_2 \\mid x) &amp;= \\frac{P(x \\mid H_2) P(H_2)}{P(x)} = \\frac{0.24 \\cdot 0.25}{0.24} = 0.25.\\notag\\end{aligned}\\] Possiamo dunque concludere dicendo che, sulla base dei dati osservati, l’ipotesi \\(H_1\\) ha una probabilità 3 volte maggiore di essere vera dell’ipotesi \\(H_2\\). È tuttavia possibile raccogliere più evidenze e, sulla base di esse, le probabilità a posteriori cambieranno. Supponiamo di lanciare la moneta una terza volta e di osservare croce. I nostri dati saranno dunque \\(\\{T, C, C\\}\\). Di conseguenza, \\(P(x \\mid H_1) = 0.6 \\cdot 0.4 \\cdot 0.4 = 0.096\\) e \\(P(x \\mid H_2) = 0.4 \\cdot 0.6 \\cdot 0.6 = 0.144\\). Ne segue che le probabilità a posteriori diventano: \\[\\begin{aligned} P(H_1 \\mid x) &amp;= \\frac{P(x \\mid H_1) P(H_1)}{P(x)} = \\frac{0.096 \\cdot 0.75}{0.096 \\cdot 0.75 + 0.144 \\cdot 0.25} = 0.667,\\notag\\end{aligned}\\] \\[\\begin{aligned} P(H_2 \\mid x) &amp;= \\frac{P(x \\mid H_2) P(H_2)}{P(x)} = \\frac{0.144 \\cdot 0.25}{0.096 \\cdot 0.75 + 0.144 \\cdot 0.25} = 0.333.\\notag\\end{aligned}\\] In queste circostanze, le evidenze che favoriscono \\(H_1\\) nei confronti di \\(H_2\\) sono pari solo ad un fattore di 2. Se otteniamo ancora croce in un quarto lancio della moneta, i nostri dati saranno: \\(\\{T, C, C, C\\}\\). Ripetendo il ragionamento fatto sopra, \\(P(x \\mid H_1) = 0.6 \\cdot 0.4 \\cdot 0.4 \\cdot 0.4 = 0.0384\\) e \\(P(x \\mid H_2) = 0.4 \\cdot 0.6 \\cdot 0.6 \\cdot 0.6 = 0.0864\\). Dunque \\[\\begin{aligned} P(H_1 \\mid x) &amp;= \\frac{0.0384 \\cdot 0.75}{0.0384 \\cdot 0.75 + 0.0864 \\cdot 0.25} = 0.571,\\notag\\end{aligned}\\] \\[\\begin{aligned} P(H_2 \\mid x) &amp;= \\frac{0.0864 \\cdot 0.25}{0.0384 \\cdot 0.75 + 0.0864 \\cdot 0.25} = 0.429.\\notag\\end{aligned}\\] e le evidenze a favore di \\(H_1\\) si riducono a 1.33. Se si ottenesse un altro esito croce in un sesto lancio della moneta, l’ipotesi \\(H2\\) diventerebbe più probabile dell’ipotesi \\(H_1\\). In conclusione, questo esercizio ci fa capire come sia possibile, sulla base delle evidenze disponibili, passare da credenze a priori a credenze a posteriori. Se prima di lanciare la moneta ritenevamo che l’ipotesi \\(H_1\\) fosse tre volte più plausibile dell’ipotesi \\(H_2\\), dopo avere osservato uno specifico campione di dati siamo giunti alla conclusione opposta. Il processo di aggiornamento Bayesiano ci fornisce dunque un metodo per modificare il livello di fiducia in una data ipotesi, alla luce di nuova informazione. Conclusioni Il teorema di Bayes costituisce il fondamento dell’approccio più moderno della statistica, quello appunto detto Bayesiano. Chi usa il teorema di Bayes non è, solo per questo motivo, “bayesiano.” Ci vuole ben altro. Ci vuole un modo diverso per intendere il significato della probabilità e un modo diverso per intendere gli obiettivi dell’inferenza statistica. L’approccio bayesiano è stato, negli scorsi decenni, un approccio piuttosto dogmatico a questi temi e, a causa di ciò, è stato considerato da alcuni come un metodo un po’ troppo lontano dall’atteggiamento critico e non dogmatico che costituisce il fondamento della comunità scientifica. In anni recenti, questi aspetti più “ruvidi” dell’approccio bayesiano sono stati abbandonati e una gran parte della comunità scientifica riconosce all’approccio bayesiano il merito di consentire lo sviluppo di modelli anche molto complessi senza, d’altra parte, richiedere conoscenze matematiche troppo avanzate all’utente. Per questa ragione l’approccio bayesiano sta prendendo sempre più piede, anche in psicologia. Un introduzione a questi temi sarà presentata nell’ultima parte di queste dispense. "],["chapter-distr-congiunta.html", "Capitolo 13 Probabilità congiunta 13.1 Funzione di probabilità congiunta Conclusioni", " Capitolo 13 Probabilità congiunta Finora abbiamo considerato unicamente le leggi di singole variabile aleatorie. Tuttavia, in psicologia e nella vita quotidiana, siamo spesso interessati a studiare problemi di probabilità legati al valore congiunto di due o più variabili aleatorie. Ad esempio, potremmo misurare il QI dei bambini e il loro peso alla nascita, o l’altezza e il peso delle giraffe, o il livello di inquinamento atmosferico e il tasso di malattie respiratorie nelle città, o il numero di amici di Facebook e l’età. Che relazione tra le variabili ci possiamo aspettare in ciascuno di questi esempi? Perché? Per capire la relazione che sussiste tra due variabili aleatorie è necessario calcolare gli indici di covarianza e correlazione. Per fare ciò è necessario utilizzare la funzione di probabilità congiunta. L’obiettivo di questo capitolo è quello di chiarire cosa si intende per funzione di probabilità congiunta di due variabili casuali \\(X\\) e \\(Y\\). Esamineremo qui in dettaglio il caso discreto. 13.1 Funzione di probabilità congiunta Dopo aver trattato delle distribuzioni di probabilità di una variabile aleatoria, che associa ad ogni evento elementare dello spazio campionario uno ed un solo numero reale, è naturale estendere questo concetto al caso di due o più dimensioni. Iniziamo a descrivere il caso discreto con un esempio. Consideriamo qui l’esperimento casuale corrispondente al lancio di tre monete equilibrate. Lo spazio campionario di tale esperimento casuale è \\[\\Omega = \\{TTT, TTC, TCT, CTT, CCT, CTC, TCC, CCC\\}.\\] Dato che i tre lanci sono tra loro indipendenti, non c’è ragione di aspettarsi che uno degli otto risultati possibili dell’esperimento sia più probabile degli altri, dunque possiamo associare a ciascuno degli otto eventi elementari dello spazio campionario la stessa probabilità, ovvero 1/8. Su tale spazio campionario consideriamo le variabili aleatorie \\(X \\in \\{0, 1, 2, 3\\}\\), che conta il numero delle teste nei tre lanci, e \\(Y \\in \\{0, 1\\}\\), che conta il numero delle teste al primo lancio. Indicando con T = ‘testa’ e C = ‘croce,’ si ottiene dunque la situazione riportata nella tabella successiva. Spazio campionario dell’esperimento consistente nel lancio di tre monete equilibrate su cui sono state definite le variabili aleatorie \\(X\\) e \\(Y\\). \\(\\omega\\) \\(X\\) \\(Y\\) \\(P(\\omega)\\) \\(\\omega_1\\) = TTT 3 1 1/8 \\(\\omega_2\\) = TTC 2 1 1/8 \\(\\omega_3\\) = TCT 2 1 1/8 \\(\\omega_4\\) = CTT 2 0 1/8 \\(\\omega_5\\) = CCT 1 0 1/8 \\(\\omega_6\\) = CTC 1 0 1/8 \\(\\omega_7\\) = TCC 1 1 1/8 \\(\\omega_8\\) = CCC 0 0 1/8 Ci poniamo il problema di associare un livello di probabilità ad ogni coppia \\((x, y)\\) definita su \\(\\Omega\\). La coppia \\((X = 0, Y = 0)\\) si realizza in corrispondenza di un solo evento elementare, ovvero CCC; avrà dunque una probabilità pari a \\(Pr(X=0, Y=0) = Pr(CCC) = 1/8\\). Nel caso della coppia \\((X = 1, Y = 0)\\) ci sono due eventi elementari che danno luogo al risultato considerato, ovvero, CCT e CTC; la probabilità \\(Pr(X=1, Y=0)\\) sarà dunque data dall’unione delle probabilità dei due eventi elementari corrispondenti, cioé \\(Pr(X=1, Y=0) = Pr(CCT \\:\\cup\\: CTC) = 1/8 + 1/8 = 1/4\\). Riportiamo qui sotto i calcoli svolti per tutti i possibili valori di \\(X\\) e \\(Y\\). \\[ \\begin{aligned} P(X = 0, Y = 0) &amp;= P(\\omega_8 = CCC) = 1/8; \\notag\\\\ P(X = 1, Y = 0) &amp;= P(\\omega_5 = CCT) + P(\\omega_6 = CTC) = 2/8; \\notag\\\\ P(X = 1, Y = 1) &amp;= P(\\omega_7 = TCC) = 1/8; \\notag\\\\ P(X = 2, Y = 0) &amp;= P(\\omega_4 = CTT) = 1/8; \\notag\\\\ P(X = 2, Y = 1) &amp;= P(\\omega_3 = TCT) + P(\\omega_2 = TTC) = 2/8; \\notag\\\\ P(X = 3, Y = 1) &amp;= P(\\omega_1 = TTT) = 1/8; \\notag \\end{aligned} \\] Le probabilità così trovate possono essere riportate nella tabella seguente. Distribuzione di probabilità congiunta per i risultati dell’esperimento consistente nel lancio di tre monete equilibrate. \\(x\\y\\) 0 1 0 1/8 0 1 2/8 1/8 2 1/8 2/8 3 0 1/8 La tabella qui sopra ci fornisce il risultato che cercavamo, ovvero la distribuzione di probabilità congiunta delle variabili aleatorie \\(X\\) = “numero di realizzazioni con il risultato testa nei tre lanci” e \\(Y\\) = “numero di realizzazioni con il risultato testa nel primo lancio” per l’esperimento casuale considerato. Una generica funzione di probabilità congiunta bivariata può essere rappresentata come qui indicato. In generale, possiamo dire che, dato uno spazio campionario discreto \\(\\Omega\\), è possibile associare ad ogni evento elementare \\(\\omega_i\\) dello spazio campionario una coppia di numeri reali \\((x, y)\\), essendo \\(x = X(\\omega)\\) e \\(y = Y(\\omega)\\), il che ci conduce alla seguente definizione. La funzione che associa ad ogni coppia \\((x, y)\\) un livello di probabilità prende il nome di funzione di probabilità congiunta: \\[P(x, y) = P(X = x, Y = y).\\] Il termine “congiunta” deriva dal fatto che questa probabilità è legata al verificarsi di una coppia di valori, il primo associato alla variabile aleatoria \\(X\\) ed il secondo alla variabile aleatoria \\(Y\\). Nel caso di due sole variabili, si parla di distribuzione bivariata, mentre nel caso di più variabili si parla di distribuzione multivariata. 13.1.1 Proprietà Una distribuzione di massa di probabilità congiunta bivariata deve soddisfare due proprietà: \\(0 \\leq p(x_i, y_j) \\leq 1\\); la probabilità totale deve essere uguale a \\(1.0\\). Tale proprietà può essere espressa nel modo seguente \\[\\sum_{i} \\sum_{j} p(x_i, y_j) = 1.0.\\] 13.1.2 Eventi Si noti che dalla probabilità congiunta possiamo calcolare la probabilità di qualsiasi evento definito in base alle variabili aleatorie \\(X\\) e \\(Y\\). Per capire come questo possa essere fatto, consideriamo nuovamente l’esperimento discusso sopra. Exercizio 13.1 Per la distribuzione di massa di probabilità congiunta riportata nella tabella precedente si trovi la probabilità dell’evento \\(X+Y \\leq 1\\). Soluzione. Per trovare la probabilità richiesta dobbiamo semplicemente sommare le probabilità associate a tutte le coppie \\((x,y)\\) che soddisfano la conzione \\(X+Y \\leq 1\\). Ovvero, \\[ \\begin{aligned} P_{XY}(X+Y \\leq 1) = &amp;P_{XY}(0, 0) + P_{XY}(1, 0)= 3/8.\\notag \\end{aligned} \\] 13.1.3 Funzioni di probabilità marginali Data la funzione di probabilità congiunta \\(p(x, y)\\) è possibile pervenire alla costruzione della funzione di probabilità della singola variabile aleatoria, \\(X\\) o \\(Y\\): \\[ p_X(x) = P(X = x) = \\sum_y p(x,y) \\] \\[ p_Y(y) = P(Y = y) = \\sum_x p(x,y) \\] che prendono, rispettivamente, il nome di funzione di probabilità marginale di \\(X\\) funzione di probabilità marginale di \\(Y\\). Si noti che \\(P_X\\) e \\(P_Y\\) sono normalizzate: \\[ \\sum_x P_X(x) = 1.0, \\quad \\sum_y P_Y(y) = 1.0. \\] Per l’esperimento casuale consistente nel lancio di tre monete equilibrate, si calcolino le probabilità marginali di \\(X\\) e \\(Y\\). Nell’ultima colonna a destra e nell’ultima riga in basso della tabella seguente sono riportate le distribuzioni di probabilità marginali di \\(X\\) e \\(Y\\). \\(P_X\\) si ottiene sommando su ciascuna riga fissata la colonna \\(j\\), \\(P_X(X = j) = \\sum_y p_{xy}(x = j, y)\\). \\(P_Y\\) si trova sommando su ciascuna colonna fissata la riga \\(i,\\) \\(P_Y (Y = i) = \\sum_x p_{xy}(x, y = i)\\). Si noti che: \\[ \\sum_x P_X(x) = 1, \\quad \\sum_y P_Y(y) = 1. \\] Distribuzione di probabilità congiunta \\(p(x,y)\\) per i risultati dell’esperimento consistente nel lancio di tre monete equilibrate e probabilità marginali \\(p(x)\\) e \\(p(y)\\). \\(x\\y\\) 0 1 \\(p(x)\\) 0 1/8 0 1/8 1 2/8 1/8 3/8 2 1/8 2/8 3/8 3 0 1/8 1/8 \\(p(y)\\) 4/8 4/8 1.0 13.1.4 Indipendenza stocastica Ora abbiamo tutti gli strumenti per potere dare una definizione statistica precisa al concetto di indipendenza. La definizione proposta sarà necessariamente coerente con la definizione di indipendenza che abbiamo usato fino ad ora. Ma, espressa in questi nuovi termini, potrà essere utilizzata in indagini probabilistiche e statistiche più complesse. Ricordiamo che gli eventi \\(A\\) e \\(B\\) si dicono indipendenti se \\(P (A \\cap B)\\, = P(A) P(B)\\). Diciamo quindi che \\(X\\) e \\(Y\\) sono indipendenti se qualsiasi evento definito da \\(X\\) è indipendente da qualsiasi evento definito da \\(Y\\). La definizione formale che garantisce che ciò accada è la seguente. Le variabili aleatorie distribuite congiuntamente \\(X\\) e \\(Y\\) sono indipendenti se la loro distribuzione congiunta è il prodotto delle distribuzioni marginali: \\[P(X, Y)\\, = P_X(x)P_Y(y).\\] Nel caso discreto, dunque, l’indipendenza implica che la probabilità riportata in ciascuna cella della tabella di probabilità congiunta deve essere uguale al prodotto delle probabilità marginali di riga e di colonna: \\[p(x_i, y_i)\\, = p_X(x_i) p_Y(y_i).\\notag\\] Exercizio 13.2 Per la situazione rappresentata nella tabella qui sopra le variabili aleatorie \\(X\\) e \\(Y\\) sono indipendenti? Soluzione. Nella tabellale variabili aleatorie \\(X\\) e \\(Y\\) non sono indipendenti: le probabilità congiunte non sono ricavabili dal prodotto delle marginali. Per esempio, nessuna delle probabilità marginali è uguale a \\(0\\) per cui nessuno dei valori dentro la tabella (probabilità congiunte) che risulta essere uguale a \\(0\\) può essere il prodotto delle probabilità marginali. Conclusioni La funzione di probabilità congiunta tiene simultaneamente conto del comportamento di due variabili aleatorie \\(X\\) e \\(Y\\) e di come esse si influenzano reciprocamente. In particolare, si osserva che se le due variabili non si influenzano, cioè se sono statisticamente indipendenti, allora la distribuzione di massa di probabilità congiunta si ottiene come prodotto delle funzioni di probabilità marginali di \\(X\\) e \\(Y\\): \\(P_{X, Y}(x, y) = P_X(x) P_Y(y)\\). "],["chapter-distrcampmean.html", "Capitolo 14 Distribuzione campionaria della media dei campioni 14.1 Parametri e statistiche 14.2 La legge dei grandi numeri 14.3 Distribuzione campionaria 14.4 Distribuzione campionaria della media 14.5 Teorema del limite centrale 14.6 Intervalli di confidenza Conclusioni", " Capitolo 14 Distribuzione campionaria della media dei campioni L’inferenza statistica può essere descritta come un insieme di operazioni sui dati che producono delle stime e delle affermazioni sul grado di incertezza che il ricercatore attribuisce alle sue previsioni e ai parametri di processi e/o popolazioni. L’obiettivo di questo capitolo è quello di fornire un’introduzione alle basi teoriche della stima e dell’interpretazione che può essere fornita alle inferenze statistiche. 14.1 Parametri e statistiche In statistica, per popolazione si intende un insieme di elementi che presenta caratteristiche aleatorie, mentre per campione si intende un sottoinsieme della popolazione. Ma a cosa corrisponde in pratica la popolazione? Per uno psicologo la popolazione è un gruppo di individui. Per un biologo marino la popolazione è un gruppo di delfini, ad esempio. Nella maggior parte dei casi, le popolazioni oggetto di interesse per i ricercatori sono insiemi di entità concrete che esistono nel mondo reale. Dal punto di vista della statistica, invece, le popolazioni sono delle entità astratte. Infatti, gli statistici operazionalizzano il concetto di “popolazione” nei termini di un oggetto matematico che consente di essere manipolato con facilità. In precedenza noi abbiamo già incontrato questi oggetti matematici: sono le distribuzioni di probabilità. L’idea è semplice. Supponiamo di occuparci del quoziente di intelligenza, QI. Abbiamo detto che, per uno psicologo, la popolazione di interesse solitamente è un gruppo di individui, ciascuno dei quali è dotato di uno specifico punteggio del QI. Uno statistico “semplifica” tale situazione definendo in maniera operativa la popolazione come la distribuzione di densità rappresentata nella figura 14.1. In precedenza abbiamo visto infatti come una distribuzione di densità non sia altro che la descrizione matematica della “forma” di un istogramma che rappresenta un numero molto alto di osservazioni. library(&quot;ggfortify&quot;) ggdistribution(dnorm, seq(60, 140, 0.1), mean = 100, sd = 15) + labs( x = &quot;Quoziente d&#39;intelligenza&quot;, y = &quot;Densità di probabilità&quot; ) Figura 14.1: Grafico della distribuzione dei punteggi del QI nella popolazione. I test di intelligenza sono progettati in modo che il QI medio sia pari a 100, la deviazione standard dei punteggi QI sia uguale a 15 e la distribuzione dei punteggi del QI sia normale. I valori riportati sopra sono detti parametri in quanto descrivono le proprietà dell’intera popolazione. Cioè, diciamo che la media della popolazione è \\(\\mu = 100\\) e la deviazione standard della popolazione è \\(\\sigma = 15\\). Dal punto di vista statistico, dunque, possiamo rappresentare questa ipotetica popolazione di valori del QI mediante l’oggetto matematico che corrisponde a una particolare distribuzione Normale: \\[ QI \\sim \\mathcal{N}(\\mu = 100, \\sigma = 15). \\] Supponiamo ora di eseguire un esperimento nel quale il test di intelligenza viene somministrato a 100 persone selezionate a caso. Tale campione casuale semplice consiste nel seguente insieme di 100 numeri: set.seed(123) iq1 &lt;- rnorm(100, 100, 15) # i valori QI sono numeri interi! iq1 &lt;- round(iq1) iq1 #&gt; [1] 92 97 123 101 102 126 107 81 90 93 118 105 106 102 92 127 107 71 111 93 84 #&gt; [22] 97 85 89 91 75 113 102 83 119 106 96 113 113 112 110 108 99 95 94 90 97 #&gt; [43] 81 133 118 83 94 93 112 99 104 100 99 121 97 123 77 109 102 103 106 92 95 #&gt; [64] 85 84 105 107 101 114 131 93 65 115 89 90 115 96 82 103 98 100 106 94 110 #&gt; [85] 97 105 116 107 95 117 115 108 104 91 120 91 133 123 96 85 Tali valori sono stati trovati utilizzando la funzione rnorm() che genera numeri casuali estratti da una distribuzione normale. Nello specifico, abbiamo estratto 100 valori casuali dalla distribuzione normale con media 100 e deviazione standard 15. Se costruiamo un istogramma con i dati di un tale campione otteniamo il grafico mostrato nella figura 14.2. data.frame(iq1) %&gt;% ggplot(aes(x = iq1)) + geom_histogram(aes(y = ..density..)) + labs( x = &quot;Quoziente d&#39;intelligenza&quot;, y = &quot;Densità&quot; ) #&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Figura 14.2: Istogramma della distribuzione dei punteggi del QI in un campione di 100 osservazioni. Come possiamo vedere, l’istogramma ha approssimativamente la forma corretta, ma è un’approssimazione molto cruda della distribuzione della popolazione mostrata nella figura 14.1. Se calcoliamo la media del campione, otteniamo un numero abbastanza vicino alla media della popolazione di 100, ma non identico: nel campione considerato la media e la deviazione standard sono uguali a: mean(iq1) #&gt; [1] 101.42 sd(iq1) #&gt; [1] 13.66643 Queste statistiche campionarie descrivono le proprietà di uno specifico campione che è stato osservato e, sebbene siano abbastanza simili ai parametri della popolazione, non sono uguali ad essi. In generale, le statistiche campionarie sono ciò che è possibile calcolare a partire dai dati osservati sul campione mentre i parametri della popolazione sono ciò che vorremmo conoscere. 14.2 La legge dei grandi numeri Nella sezione Parametri e statistiche abbiamo considerato i risultati di un esperimento casuale nel quale sono stati osservati i valori fittizi del QI di un campione di ampiezza \\(n = 100\\). I risultati sono incoraggianti: la media campionaria di 101.42 ci fornisce un’approssimazione ragionevole della media della popolazione \\(\\mu = 100\\). In molti studi un tale livello di precisione è accettabile, ma in altre situazioni è necessario essere più precisi. Cosa dobbiamo fare se vogliamo che le statistiche campionarie siano più vicine ai parametri della popolazione? La risposta è ovvia: dobbiamo raccogliere più dati. Supponiamo dunque di condurre un nuovo esperimento nel quale misuriamo il QI di 10000 persone. Possiamo simulare i risultati di questo esperimento usando R: set.seed(123) iq2 &lt;- rnorm(n = 10000, mean = 100, sd = 15) iq2 &lt;- round(iq2) head(iq2) #&gt; [1] 92 97 123 101 102 126 Nella figura 14.3 è riportato l’istogramma dei valori del QI di questo campione più numeroso. È chiaro che, in questo secondo caso, otteniamo un’approssimazione migliore rispetto al precedente campione più piccolo. Ciò si riflette anche nelle statistiche del campione: mean(iq2) #&gt; [1] 99.9671 sd(iq2) #&gt; [1] 14.9855 Questi valori sono molto vicini ai parametri della popolazione. data.frame(iq2) %&gt;% ggplot(aes(x = iq2)) + geom_histogram(aes(y = ..density..)) + labs( x = &quot;Quoziente d&#39;intelligenza&quot;, y = &quot;Densità&quot; ) #&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Figura 14.3: Istogramma della distribuzione dei punteggi del QI in un campione di 10000 osservazioni. Il messaggio, un po’ banale, che ricaviamo a questa simulazione è che, generalmente, i campioni di dimensioni maggiori forniscono informazioni migliori. Ho chiamato “banali” i risultati di questa simulazione perché dovrebbe essere evidente a tutti che le cose stanno così. Infatti, questo punto è talmente ovvio che, quando Jacob Bernoulli – uno dei fondatori della teoria della probabilità – formalizzò questa idea nel 1713, commentò il risultato nel modo seguente: Perché anche il più stupido degli uomini, basandosi soltanto sul suo istinto, da solo e senza alcuna istruzione (il che è notevole), è convinto che maggiore è il numero di osservazioni, minore è il pericolo di sbagliare. In statistica questa intuizione va sotto il nome di Legge dei grandi numeri. La Legge dei grandi numeri ci dice che la media aritmetica di un campione di \\(n\\) osservazioni (in termini tecnici: di \\(n\\) variabili aleatorie \\(X_i\\) indipendenti e identicamente distribuite), ovvero \\(\\frac{1}{n}\\sum_{i=1}^nX_i\\), per \\(n\\) crescente tende o converge al valore atteso teorico \\(\\mu\\). La Legge dei grandi numeri è uno degli strumenti più importanti della statistica. Si noti che la Legge dei grandi numeri non può dirci se lo strumento o l’esperimento considerati stiano producendo dei dati utili o dei dati che è sensato riassumere tramite la media. Ad esempio, se il dispositivo di misurazione è difettoso, la media di molte misurazioni sarà una stima molto accurata della cosa sbagliata! Questo è un esempio di errore sistematico, o errore di campionamento, che sono qualcosa di molto diverso dal fenomeno di fluttuazione casuale che viene descritto dalla Legge dei grandi numeri. 14.3 Distribuzione campionaria La Legge dei grandi numeri è uno strumento molto potente, ma non è sufficiente per rispondere a tutte le nostre domande. Tutto ciò che ci offre è una “garanzia a lungo termine.” Essa ci garantisce che, a lungo termine, le statistiche campionarie saranno corrette – le statistiche campionarie forniranno la risposta esatta se verrà raccolta una quantità infinita di dati. Ma come ha affermato John Maynard Keynes (1923) in economia, una garanzia a lungo termine è di scarsa utilità nella vita reale: Il lungo periodo è una guida fuorviante per ciò che accade ora. Alla lunga saremo tutti morti. Gli economisti si sono dati un compito troppo facile, troppo inutile, se nelle stagioni tempestose possono solo dirci che, quando la tempesta sarà passata da un pezzo, l’oceano sarà di nuovo piatto. Come in economia, così anche in psicologia e nella statistica. Non è sufficiente sapere che, a lungo termine, arriveremo alla risposta giusta. È di scarso conforto sapere che un campione di dati infinitamente grande ci fornisce il valore esatto della media della popolazione, quando il campione che possiamo ottenere in qualsiasi situazione pratica non può che avere una numerosità modesta. Nell’attività pratica della ricerca psicologica, quindi, è necessario sapere qualcosa di più del comportamento delle statistiche campionarie (per esempio, la media) quando esse vengono calcolate a partire da un campione di dati molto più piccolo di quello ipotizzato dalla Legge dei grandi numeri. Queste considerazioni ci portano alla necessità di formulare un nuovo concetto: quello di distribuzione campionaria (sampling distribution). Definizione 14.1 (Distribuzione campionaria) La distribuzione campionaria di una statistica basata su \\(n\\) osservazioni è la distribuzione di frequenza dei valori che la statistica assume. Tale distribuzione è generata teoricamente prendendo infiniti campioni di dimensione \\(n\\) e calcolando i valori della statistica per ogni campione. 14.3.1 Simulazione Tenendo a mente quanto detto nella sezione precedente, abbandoniamo l’idea che i nostri campioni siano in grado di raggiungere numerosità dell’ordine di grandezza delle decine o delle centinaia di migliaia di osservazioni. Prendiamo invece in esame una situazione più vicina a quella in cui gli psicologi si trovano ad operare. Consideriamo, quale esempio, un’ampiezza campionaria di \\(n = 5\\). Come in precedenza, possiamo simulare questo esperimento casuale in R, usando la funzione rnorm(): iq3 &lt;- round(rnorm(n = 5, mean = 100, sd = 15)) iq3 #&gt; [1] 136 97 114 91 103 Il QI medio in questo campione risulta pari a 108.2. Non sorprende che questo risultato sia molto meno accurato rispetto all’esperimento casuale precedente. Immaginiamo ora di replicare l’esperimento; immaginiamo cioè di ripetere nuovamente la procedura descritta sopra: estraiamo un nuovo campione casuale e misuriamo il QI di 5 persone. Ancora una volta utilizziamo R per effettuare la simulazione: iq4 &lt;- round(rnorm(n = 5, mean = 100, sd = 15)) iq4 #&gt; [1] 117 121 97 76 96 mean(iq4) #&gt; [1] 101.4 In quest altro campione casuale il QI medio è 101.4. Procediamo in questo modo e simuliamo l’esperimento casuale dieci volte in maniera tale da ottenere i risultati seguenti. Iniziamo creando una lista di 10 campioni di ampiezza \\(n = 5\\). set.seed(123) sample_list &lt;- list() for (i in 1:10) { sample_list[[i]] &lt;- round(rnorm(5, 100, 15)) } sample_list[[1]] #&gt; [1] 92 97 123 101 102 sample_list[[2]] #&gt; [1] 126 107 81 90 93 Trasformiamo la lista in un data.frame. df &lt;- data.frame(matrix(unlist(sample_list), nrow=length(sample_list), byrow=TRUE)) df #&gt; X1 X2 X3 X4 X5 #&gt; 1 92 97 123 101 102 #&gt; 2 126 107 81 90 93 #&gt; 3 118 105 106 102 92 #&gt; 4 127 107 71 111 93 #&gt; 5 84 97 85 89 91 #&gt; 6 75 113 102 83 119 #&gt; 7 106 96 113 113 112 #&gt; 8 110 108 99 95 94 #&gt; 9 90 97 81 133 118 #&gt; 10 83 94 93 112 99 Le medie di ciascuno dei 10 campioni di ampiezza \\(n = 5\\) sono: rowMeans(df) #&gt; [1] 103.0 99.4 104.6 101.8 89.2 98.4 108.0 101.2 103.8 96.2 Poniamoci ora il problema di replicare tante volte la procedura che ci porta a calcolare la media dei valori del QI di cinque persone prese a caso. Per ciascuna replica dell’esperimento casuale salviamo il valore della media campionaria. Così facendo, generiamo tanti valori, ciascuno dei quali corrisponde alla media di un campione casuale di 5 osservazioni. Usando i poteri magici di R, possiamo eseguire una tale simulazione mediante le seguenti istruzioni: n_samples &lt;- 10000 sample_size &lt;- 5 sample_means &lt;- rep(NA, n_samples) for (i in 1:n_samples) { y &lt;- round(rnorm(5, 100, 15)) sample_means[i] &lt;- mean(y) } Nella figura 14.4 sono riportati i risultati della simulazione. Come illustrato dalla figura, la media dei 5 punteggi del QI è solitamente compresa tra 80 e 120. Ma il risultato più importante di questa simulazione è quello che ci fa capire che, se ripetiamo l’esperimento casuale più e più volte, otteniamo una distribuzione di medie campionarie. Un tale distribuzione ha un nome speciale in statistica: si chiama distribuzione campionaria della media. data.frame(sample_means) %&gt;% ggplot(aes(x = sample_means)) + geom_histogram(aes(y = ..density..)) + labs( x = &quot;Media del quoziente d&#39;intelligenza in campioni di ampiezza n = 5&quot;, y = &quot;Densità&quot; ) #&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Figura 14.4: Istogramma della distribuzione delle medie dei punteggi del QI calcolate su 10000 campioni casuali di ampiezza \\(n=5\\). La “distribuzione campionaria” è un importante concetto della statistica ed è fondamentale per comprendere il comportamento dei piccoli campioni. Quando abbiamo eseguito per la prima volta l’esperimento casuale relativo all’estrazione di cinque punteggi IQ dalla popolazione, abbiamo trovato una media campionaria pari a 101.42. Quello che impariamo dalla distribuzione campionaria delle medie di campioni di ampiezza \\(n = 5\\) della figura 14.4 è che un tale esperimento casuale è poco accurato. Infatti, la distribuzione campionaria della media dei campioni di ampiezza \\(n=5\\) ci fa capire che, se ripetendo un tale esperimento casuale tante volte, otteniamo delle medie campionarie con valori che possono essere compresi nell’intervallo tra 80 e 120. In altre parole, la distribuzione campionaria della media di campioni di ampiezza 5 ci dice che il risultato dell’esperimento casuale (ovvero, la media osservata in un singolo campione) varia di molto tra i diversi campioni che possono essere estratti dalla popolazione. Di conseguenza, se il nostro obiettivo è quello di stimare la media della popolazione, allora non dobbiamo fidarci troppo del risultato ottenuto per caso da un singolo campione di numerosità \\(n\\) = 5. Nella discussione seguente mostreremo come sia possibile utilizzare la stima della distribuzione campionaria per descrivere le proprietà statistiche delle stime (ovvero, il grado di incertezza che è associato alle stime che otteniamo). La distribuzione campionaria può essere solo stimata In generale, la distribuzione campionaria non è nota, poiché dipende dalle caratteristiche della popolazione e non solo dai dati osservati nel campione. In pratica, quindi, non possiamo mai conoscere le caratteristiche esatte della distribuzione campionaria di una statistica; tali caratteristiche possono solo essere stimate. 14.4 Distribuzione campionaria della media Consideriamo ora l’inferenza statistica nel caso della statistica campionaria corrispondente alla media del campione. Denotiamo con \\(\\bar{X}_n\\) la media calcolata su un campione di \\(n\\) osservazioni. Abbiamo detto che, ogni volta che osserviamo un nuovo campione di ampiezza \\(n\\), la statistica \\(\\bar{X}_n\\) assumerà un valore diverso. In termini tecnici diciamo che \\(\\bar{X}_n\\) è una variabile aleatoria, ovvero è una variabile che assume un nuovo valore ogni qualvolta l’esperimento casuale viene ripetuto (nel caso presente l’esperimento casuale corrisponde all’estrazione di un campione casuale dalla popolazione e al calcolo della media delle osservazioni campionarie). L’insieme dei valori che \\(\\bar{X}_n\\) può assumere in tutti i campioni casuali di ampiezza \\(n\\) che possono essere estratti dalla popolazione è detto distribuzione campionaria della media. 14.4.1 Valore atteso della media campionaria Qual è la media (valore atteso) della distribuzione campionaria della media? È facile mostrare che \\(\\mu_{\\bar{X}_n}\\) coincide con il valore medio \\(\\mu\\) della popolazione da cui i campioni di ampiezza \\(n\\) sono stati estratti. Dimostrazione. Ponendo \\(\\bar{X}_n = S_n/n\\), dove \\(S_n = X_1 + X_2 + \\dots + X_n\\) è la somma di \\(n\\) variabili aleatorie iid, ne segue che: \\[ \\mathbb{E}(\\bar{X}_n) = \\frac{1}{n} \\mathbb{E}(S_n) = \\frac{1}{n} \\mathbb{E}(X_1 + X_2 + \\dots + X_n ) = \\frac{1}{n} n \\mu = \\mu. \\] 14.4.2 Varianza della media campionaria Qual è la varianza della distribuzione campionaria della media? Anche in questo caso si può facilmente mostrare come la varianza della distribuzione delle medie campionarie è legata alla varianza \\(\\sigma^2\\) della popolazione dalla seguente relazione: \\[ var(\\bar{X}_n) = \\frac{\\sigma^2}{n}, \\tag{14.1} \\] dove \\(n\\) è la numerosità dei campioni casuali. Prima di presentare la dimostrazione dell’eq. (14.1) è necessario ricordare la seguente proprietà della varianza: se una variabile aleatoria \\(X\\) viene moltiplicata per una costante \\(a\\), la varianza della variabile aleatoria \\(aX\\) diventa \\[ var(a X) = a^2 var(X). \\] Possiamo ora comprendere la dimostrazione seguente. Dimostrazione. \\[ var(\\bar{X}_n) = \\frac{1}{n^2} var(S_n) = \\frac{1}{n^2} n \\sigma^2 = \\frac{\\sigma^2}{n}. \\] I due risultati che abbiamo ottenuto sopra sono molto importanti. Il primo ci dice che la media campionaria è uno stimatore corretto (ovvero, non distorto) della media della popolazione. Il secondo quantifica l’errore medio che compiamo usando usiamo la media del campione quale stima della media della popolazione. 14.4.3 Errore standard La radice quadrata della varianza della distribuzione campionaria della media si chiama errore standard della media campionaria. Questa è una quantità molto importante perché ci informa sul livello di incertezza della nostra stima fornendoci un valore che ha la stessa unità di misura delle osservazioni. Se vogliamo stimare la media della popolazione utilizzando la media del campione quale stimatore ci possiamo aspettare di compiere un errore medio pari a \\(\\frac{\\hat{\\sigma}_n}{\\sqrt{n}},\\) laddove \\(\\hat{\\sigma}_n\\) è la deviazione standard del campione utilizzata quale stima della deviazione standard della popolazione. 14.4.3.1 Simulazione Per chiarire le due conclusioni precedenti, utilizziamo nuovamente la simulazione che abbiamo eseguito in precedenza, quando abbiamo generato 10000 medie campionarie per campioni di ampiezza \\(n = 5\\) estratti dalla popolazione \\(\\mathcal{N}(\\mu = 100, \\sigma = 15\\)). La distribuzione di tali medie è rappresentata nella figura 14.4. In realtà, quella fornita dalla figura 14.4 non è esattamente la distribuzione campionaria delle medie di campioni casuali di ampiezza \\(n=5\\) estratti dalla popolazione \\(\\mathcal{N}(\\mu = 100, \\sigma = 15\\)): la vera distribuzione campionaria della media si otterrebbe estraendo infiniti campioni di ampiezza \\(n = 5\\) dalla popolazione. Tuttavia, avendo a disposizione le medie di 10000 campioni, ci possiamo aspettare un risultato empirico non troppo diverso da quello teorico. Verifichiamo dunque le due conclusioni a cui siamo giunti sopra. Sappiamo che la media delle 10000 medie di campioni di ampiezza \\(n=5\\) dovrà essere molto simile (anche se non identica, dato che il numero dei campioni è grande, ma non infinito) alla media della popolazione. Infatti, in questa simulazione, abbiamo che \\(\\hat{\\mu}_{\\bar{X}_n} =\\) 99.97 contro un valore teorico \\(\\mu=100\\). All’aumentare del numero di campioni estratti \\(\\mu_{\\bar{X}_n}\\) diventa sempre più simile a \\(\\mu\\). Calcoliamo ora la deviazione standard (detta errore standard) delle 10000 medie campionarie che abbiamo trovato. Nella simulazione, tale valore è pari a 6.663 mentre il valore teorico è \\(\\sigma_{\\bar{X}} = \\frac{\\sigma}{\\sqrt{n}} = \\frac{15}{\\sqrt{5}} = 6.708\\). Possiamo dunque dire che, con 10000 medie campionarie le proprietà della distribuzione campionaria della media vengono approssimate molto bene. Si noti che possiamo attribuire a \\(\\sigma_{\\bar{X}}\\) la stessa interpretazione che è possibile fornire, in generale, alla deviazione standard. Nel caso di un campione, la deviazione standard \\(\\sigma\\) ci dice di quanto, in media, i valori osservati sono lontani dalla media. Nel caso della distribuzione campionaria delle medie dei campioni, \\(\\sigma_{\\bar{X}}\\) ci dice quale errore medio compiamo stimando \\(\\mu\\) con \\(\\bar{X}\\). In altre parole, ci dice che, se considerassimo tutte le medie \\(\\bar{X}\\) che si possono calcolare sulla base degli infiniti campioni di dimensioni \\(n\\) che possiamo estrarre dalla popolazione, la distanza media tra ciascuna di queste medie e la media della distribuzione (che corrisponde alla media della popolazione) è pari a \\(\\sigma_{\\bar{X}}\\). La quantità \\(\\sigma_{\\bar{X}}\\) può dunque essere considerata come una misura di errore nella stima di \\(\\mu\\) mediante \\(\\bar{X}\\). 14.4.4 Distribuzioni delle statistiche campionarie Qualunque statistica campionaria ha una sua distribuzione teorica. Consideriamo, ad esempio, il massimo del campione quale statistica campionaria di interesse. Ripetiamo la simulazione che abbiamo descritto sopra calcolando, questa volta, il valore massimo del campione. set.seed(123) n_samples &lt;- 10000 sample_size &lt;- 5 sample_max &lt;- rep(NA, n_samples) for (i in 1:n_samples) { y &lt;- round(rnorm(5, 100, 15)) sample_max[i] &lt;- max(y) } I risultati di questa simulazione sono riportati nella figura 14.5. data.frame(sample_max) %&gt;% ggplot(aes(x = sample_max)) + geom_histogram(aes(y = ..density..)) + labs( x = &quot;Valore massimo del QI in campioni di ampiezza n = 5&quot;, y = &quot;Densità&quot; ) #&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Figura 14.5: Istogramma della distribuzione del QI massimo osservato in ciascun campione casuali di ampiezza \\(n=5\\). Per creare la figura sono stati considerati 10000 campioni casuali. Non dovrebbe sorprenderci che, prendendo 5 persone a caso per poi selezionare la persona con il punteggio QI più alto, otteniamo una distribuzione che, rispetto alla distribuzione della figura 14.5, è traslata verso destra. Nella presente simulazione, la distribuzione del QI massimo di un campione casuale di ampiezza \\(n = 5\\) si situa approssimativamente nell’intervallo compreso tra 90 e 150. 14.5 Teorema del limite centrale Chiediamoci ora quale sia la relazione che intercorre tra la distribuzione campionaria della media e l’ampiezza \\(n\\) dei campioni. In ciascun pannello della figura 14.6 sono riportati i risultati di una simulazione nella quale sono stati generati 10000 campioni di ampiezza \\(n\\) per poi calcolare il QI medio in ciascun campione. par(mfrow=c(2, 3)) mu &lt;- 100 sigma &lt;- 15 nrep &lt;- 1e5 qi &lt;- rep(NA, nrep) get_mean &lt;- function(nobs, mu, sigma) { x &lt;- round(rnorm(n = nobs, mean = mu, sd = sigma)) mean(x) } ymax &lt;- 0.14 nobs &lt;- 1 qi &lt;- replicate(nrep, get_mean(nobs, mu, sigma)) hist(qi, freq=FALSE, yaxt=&#39;n&#39;, ylim=c(0, ymax), xlim = c(40, 160), ylab = &quot;&quot;, xlab = &quot;QI&quot;, main = &quot;n = 1&quot;) curve(dnorm(x, mean=mu, sd=sigma), add=TRUE, yaxt=&quot;n&quot;) nobs &lt;- 2 qi &lt;- replicate(nrep, get_mean(nobs, mu, sigma)) hist(qi, freq=FALSE, yaxt=&#39;n&#39;, ylim=c(0, ymax), xlim = c(40, 160), ylab = &quot;&quot;, xlab = &quot;QI&quot;, main = &quot;n = 2&quot;) curve(dnorm(x, mean=mu, sd=sigma), add=TRUE, yaxt=&quot;n&quot;) nobs &lt;- 3 qi &lt;- replicate(nrep, get_mean(nobs, mu, sigma)) hist(qi, freq=FALSE, yaxt=&#39;n&#39;, ylim=c(0, ymax), xlim = c(40, 160), ylab = &quot;&quot;, xlab = &quot;QI&quot;, main = &quot;n = 3&quot;) curve(dnorm(x, mean=mu, sd=sigma), add=TRUE, yaxt=&quot;n&quot;) nobs &lt;- 5 qi &lt;- replicate(nrep, get_mean(nobs, mu, sigma)) hist(qi, freq=FALSE, yaxt=&#39;n&#39;, ylim=c(0, ymax), xlim = c(40, 160), ylab = &quot;&quot;, xlab = &quot;QI&quot;, main = &quot;n = 5&quot;) curve(dnorm(x, mean=mu, sd=sigma), add=TRUE, yaxt=&quot;n&quot;) nobs &lt;- 15 qi &lt;- replicate(nrep, get_mean(nobs, mu, sigma)) hist(qi, freq=FALSE, yaxt=&#39;n&#39;, ylim=c(0, ymax), xlim = c(40, 160), ylab = &quot;&quot;, xlab = &quot;QI&quot;, main = &quot;n = 15&quot;) curve(dnorm(x, mean=mu, sd=sigma), add=TRUE, yaxt=&quot;n&quot;) nobs &lt;- 30 qi &lt;- replicate(nrep, get_mean(nobs, mu, sigma)) hist(qi, freq=FALSE, yaxt=&#39;n&#39;, ylim=c(0, ymax), xlim = c(40, 160), ylab = &quot;&quot;, xlab = &quot;QI&quot;, main = &quot;n = 30&quot;) curve(dnorm(x, mean=mu, sd=sigma), add=TRUE, yaxt=&quot;n&quot;) par(mfrow=c(1, 1)) Figura 14.6: Nel primo pannello in alto a sinistra ciascun campione contiene una sola osservazione, per cui la media del campione è identica al valore del QI di una persona. Di conseguenza, la distribuzione campionaria della media è identica alla distribuzione dei valori del QI nella popolazione. Quando \\(n=2\\) la media di ciascun campione tende ad essere più simile alla media della popolazione di quanto lo sia ciascuna singola osservazione della popolazione. Quindi anche l’ampiezza dell’istogramma (ovvero, la distribuzione campionaria della media) diminuisce, se confrontata con la dispersione della popolazione. Quando giungiamo ad una numerosità campionaria pari a \\(n=30\\) vediamo che la maggior parte delle medie campionarie tende ad addensarsi intorno alla media della popolazione. Gli istogrammi mostrano la distribuzione delle medie così ottenute, cioè ci forniscono una rappresentazione grafica della distribuzione campionaria della media al variare dell’ampiezza campionaria \\(n\\). I punteggi del QI sono stati ricavati da una distribuzione normale con media 100 e deviazione standard 15 e tale distribuzione viene visualizzata con una linea nera continua in ciascun pannello della figura 14.6. Quello che ci chiediamo è come varia la distribuzione campionaria della media in funzione dell’ampiezza del campione. Intuitivamente, conosciamo già parte della risposta. Se abbiamo a disposizione solo poche osservazioni, è probabile che la media campionaria sia abbastanza imprecisa: se ripetiamo l’esperimento casuale del campionamento e ricalcoliamo la media del campione, otteniamo una risposta molto diversa ad ogni ripetizione dell’esperimento casuale. Di conseguenza, la distribuzione campionaria della media comprenderà una gamma di valori molto grande. Invece, si ottengono risultati molto simili tra loro se ripetiamo l’esperimento del campionamento utilizzando campioni di grandi dimensioni. In questo secondo caso, la distribuzione campionaria includerà una gamma di valori delle medie molto minore che in precedenza. Questo andamento si può notare nei pannelli della figura 14.6: l’errore standard della media campionaria diminuisce all’aumentare dell’ampiezza del campione. Ciò che abbiamo descritto finora, tuttavia, riguarda solo un aspetto di quello che accade alla distribuzione campionaria di \\(\\bar{X}\\) all’aumentare di \\(n\\). Gli esempi discussi finora erano relativi al caso di campioni casuali del QI. Poiché i punteggi del QI seguono approssimativamente una distribuzione normale, abbiamo assunto che anche la popolazione abbia una distribuzione normale. Tuttavia, si presentano spesso casi in cui la distribuzione della popolazione non è normale. In queste circostanze, cosa succede alla distribuzione campionaria della media? La cosa straordinaria è questa: non importa quale sia la forma della distribuzione della popolazione, all’aumentare della dimensione campionaria \\(n\\), la distribuzione di frequenza delle medie campionarie si approssima sempre più alla tipica forma a campana di una distribuzione normale. Per farci un’idea di quello che succede, eseguiamo alcune simulazioni usando R. # needed for printing width &lt;- 6 height &lt;- 6 # parameters of the beta a &lt;- 2 b &lt;- 1 # mean and standard deviation of the beta s &lt;- sqrt(a * b / (a + b)^2 / (a + b + 1)) m &lt;- a / (a + b) # define function to draw a plot plot_one &lt;- function(n, N = 50000) { # generate N random sample means of size n X &lt;- matrix(rbeta(n * N, a, b), n, N) X &lt;- colMeans(X) # plot the data hist( X, breaks = seq(0, 1, .025), border = &quot;white&quot;, freq = FALSE, #col = ifelse(colour, emphColLight, emphGrey), col = &quot;gray&quot;, xlab = &quot;Media campionaria&quot;, ylab = &quot;&quot;, xlim = c(0, 1.2), main = paste(&quot;n =&quot;, n), axes = FALSE, font.main = 1, ylim = c(0, 5) ) #box() axis(1) # axis(2) # plot the theoretical distribution lines(x &lt;- seq(0, 1.2, .01), dnorm(x, m, s / sqrt(n)), lwd = 2, col = &quot;black&quot;, type = &quot;l&quot; ) } Consideriamo la distribuzione della popolazione rappresentata dall’istogramma riportato nella figura 14.7. Confrontando l’istogramma triangolare con la curva a campana tracciata dalla linea nera risulta chiaro che la distribuzione della popolazione non assomiglia affatto a una distribuzione normale. plot_one(1) Figura 14.7: Dimostrazione del Teorema del limite centrale. Consideriamo una popolazione che non segue la distribuzione normale. La distribuzione di tale popolazione è rappresentata dall’istogramma grigio. In una prima simulazione, ho estratto 50000 campioni di ampiezza \\(n=2\\) da questa distribuzione e, per ciascuno di essi ho calcolato la media campionaria. Come si può vedere nella figura 14.8, la distribuzione campionaria non è triangolare. Certamente non è Normale, ma assomiglia di più ad una distribuzione campanulare di quanto assomigli alla distribuzione della popolazione raffigurata nella figura 14.7. plot_one(2) Figura 14.8: Distribuzione campionaria di \\(\bar{X}\\) per campioni casuali di ampiezza \\(n=2\\) estratti dalla popolazione rappresentata nella figura 1.7. Quando aumento la numerosità del campione a \\(n=4\\) la distribuzione campionaria della media si approssima abbastanza bene alla normale, figura 14.9. plot_one(4) Figura 14.9: Distribuzione campionaria di \\(\bar{X}\\) per campioni casuali di ampiezza \\(n=4\\) estratti dalla popolazione rappresentata nella figura 1.7. Già con \\(n=8\\) l’approssimazione diventa molto buona, come indicato nella figura 14.10. plot_one(8) Figura 14.10: Distribuzione campionaria di \\(\bar{X}\\) per campioni casuali di ampiezza \\(n=8\\) estratti dalla popolazione rappresentata nella figura 1.7. In altre parole, se la dimensione del campione non è piccola, allora la distribuzione campionaria della media sarà approssimativamente normale indipendentemente dalla distribuzione della popolazione! Questo comportamento della distribuzione campionaria di \\(\\bar{X}\\) al variare di \\(n\\) viene descritto in maniera formale dal Teorema del limite centrale. Teorema 14.1 (Teorema del limite centrale.) Siano \\(X_1, X_2, \\dots\\) variabili aleatorie i.i.d., tutte con lo stesso valore atteso \\(\\mu\\) e la stessa varianza \\(\\sigma^2\\). Allora, \\[\\lim_{n \\rightarrow +\\infty} P\\left(a \\leq \\bar{X}_n \\leq b \\right) = P(a \\leq Y \\leq b), \\label{theo:tlc}\\] dove \\(Y \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right)\\). Il Teorema del limite centrale ci dice che, se vengono selezionati campioni sufficientemente grandi (tipicamente è sufficiente che \\(n &gt; 30\\) purché il carattere osservato non sia troppo asimmetrico), allora la media campionaria \\(\\bar{X}\\) di \\(n\\) variabili aleatorie indipendenti \\(X_1, X_2, \\dots\\) converge in distribuzione ad una variabile aleatoria normale di media \\(\\mu\\) e varianza \\(\\sigma^2/n\\). È altresì molto importante notare che, se le variabili di partenza \\(X_1\\), \\(X_2\\), …\\(X_n\\) sono esse stesse Normali, tutte con lo stesso valore atteso \\(\\mu\\) e la stessa varianza \\(\\sigma^2\\), allora il Teoremadel limite centrale è esatto. Ovvero per ogni \\(n\\), \\[ \\bar{X}_n \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right). \\] Questa proprietà discende dal seguente teorema. Teorema 14.2 Se \\(X_1, X_2, \\dots, X_n\\) sono \\(n\\) variabili aleatorie Normali tra di loro indipendenti, ciascuna con valore atteso \\(\\mu\\) e varianza \\(\\sigma^2\\), allora la variabile aleatoria \\(X_1 + X_2 + \\dots + X_n\\) è a sua volta una variabile aleatoria Normale con valore atteso \\(n \\mu\\) e varianza \\(n \\sigma^2\\). In conclusione, il Teorema del limite centrale ci consente di specificare completamente le proprietà della distribuzione campionaria di \\(\\bar{X}_n\\). Se la popolazione è normale, allora \\(\\bar{X}_n \\sim \\mathcal{N}\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right)\\) indipendentemente da \\(n\\). Se invece la popolazione non è normale, allora la distribuzione di \\(\\bar{X}_n\\) tende a \\(\\mathcal{N}\\left(\\mu, \\frac{\\sigma}{\\sqrt{n}}\\right)\\) al crescere di \\(n\\). Esaminiamo ora un esercizio in cui viene applicato il TLC. Supponiamo di misurare un oggetto con una bilancia non molto precisa. Supponiamo inoltre che l’errore di misura \\(E\\) della bilancia si distribuisca in maniera Normale con media \\(0\\) e deviazione standard \\(\\sigma = 2\\) grammi. Se l’oggetto considerato ha un peso uguale a \\(w\\), il peso osservato \\(X\\) sarà dato dalla somma del suo peso vero e l’errore di misurazione: \\(X = w + E\\). Dato che \\(w\\) è una costante, \\(X\\) seguirà la distribuzione normale con media \\(\\mathbb{E}(X) = \\mathbb{E}(w + E) = w + \\mathbb{E}(E) = w\\) e varianza \\(var(X) = var(w + E) = var(E) = 4\\). Qual è la probabilità di ottenere una misurazione che non differisce di più di un grammo dal peso vero? Dobbiamo trovare la probabilità \\[ \\begin{aligned} P(-1 \\leq X - w \\leq 1) &amp;= P\\bigg(-\\frac{1}{2} \\leq \\frac{X - w}{\\sigma} \\leq \\frac{1}{2}\\bigg)\\notag\\\\ &amp;= P\\bigg(-\\frac{1}{2} \\leq Z \\leq \\frac{1}{2}\\bigg)\\notag \\end{aligned} \\] ovvero pnorm(0.5, 0, 1) - pnorm(-0.5, 0, 1) #&gt; [1] 0.3829249 Considerando l’evento complementare, possiamo dunque dire che c’è una probabilità maggiore di \\(0.6\\) che la bilancia produca un valore che differisce di almeno un grammo dal peso vero. Chiediamoci ora cosa succede se, invece di accontentarci di una singola misurazione, calcoliamo la media di \\(n = 10\\) misurazioni. In questo secondo caso, \\[ \\begin{aligned} P\\left(-1 \\leq \\frac{S_{10}}{10} - w \\leq 1\\right) &amp;= P\\bigg(-\\frac{1}{\\sqrt{4/10}} \\leq \\frac{\\frac{S_{10}}{10} - w}{\\sigma/\\sqrt{10}} \\leq \\frac{1}{\\sqrt{4/10}}\\bigg)\\notag\\\\ &amp;= P\\bigg(-\\frac{\\sqrt{10}}{2} \\leq Z \\leq \\frac{\\sqrt{10}}{2}\\bigg)\\notag \\end{aligned} \\] ovvero pnorm(sqrt(10)/2, 0, 1) - pnorm(-sqrt(10)/2, 0, 1) #&gt; [1] 0.8861537 Considerando l’evento complementare, possiamo concludere che c’è una probabilità pari a solo 0.114 che la media di 10 misurazioni assuma un valore che differisce di più di un grammo dal peso vero. È dunque ovvio che le medie di misurazioni ripetute sono migliori delle singole misure. 14.6 Intervalli di confidenza 14.6.1 Parametri di un modello statistico Nel gergo statistico, i parametri sono i valori sconosciuti che determinano un modello statistico. Si consideri il modello statistico \\(Y \\sim \\mathcal{N}(\\mu, \\sigma)\\). Il modello statistico precedente ci dice che \\(Y\\) è una v.a. distribuita come una normale di parametri \\(\\mu\\) e \\(\\sigma\\). Supponiamo che la \\(Y\\) sia il QI. In questo caso è facile capire cosa sono i parametri \\(\\mu\\) e \\(\\sigma\\). Quello del QI, infatti, è un caso particolare perché il test di intelligenza Wechsler Adult Intelligence Scale (WAIS) è stato costruito in modo tale da produrre dei dati che si distribuiscono in un modo noto: il QI segue la distribuzione normale di parametri \\(\\mu = 100\\) e \\(\\sigma = 15\\). In generale, però, i parametri di un modello statistico sono sconosciuti. 14.6.2 L’incertezza della stima Dato che i parametri sono, in genere, sconosciuti, è necessario stimarli. Non è sufficiente, però, ottenere una stima puntuale di un parametro. È anche necessario quantificare l’incertezza della stima. L’incertezza della stima viene descritta dall’approccio frequentista nei termini di un intervallo di confidenza. L’intervallo di confidenza si costruisce mediante l’errore standard. L’errore standard è la deviazione standard stimata della stima di un parametro e quantifica il grado della nostra incertezza sulla quantità di interesse. Chiariamo questa idea facendo riferimento alla la figura 14.4. Tale figura riporta la distribuzione di un grande numero di medie campionarie, laddove la media di ciascun campione può essere considerata come una stima della media \\(\\mu\\) della popolazione. La deviazione standard di queste stime, chiamata errore standard, ci fornisce una misura dell’incertezza della nostra stima. In altre parole, quantifica la variabilità dei valori delle stime del parametro \\(\\mu\\) che sono calcolate sulla base di campioni diversi. Come abbiamo visto nella simulazione del TLC, l’errore standard ha la proprietà di diminuire all’aumentare della dimensione del campione. L’errore standard viene utilizzato per calcolare l’intervallo di confidenza. L’intervallo di confidenza rappresenta un intervallo di valori di un parametro o quantità di interesse che sono approssimativamente coerenti con i dati, data la distribuzione campionaria presunta. All’intervallo di confidenza possiamo dunque assegnare la seguente interpretazione. Supponiamo che il modello statistico sia corretto e supponiamo di ripetere tante volte il processo di campionamento. Se per ogni campione estratto dalla popolazione calcoliamo una stima del parametro, allora gli intervalli di confidenza del 50% e del 95% includeranno il vero valore del parametro il 50% e il 95% delle volte. Sotto l’ipotesi che la distribuzione campionaria segua la distribuzione normale, per campioni di grandi dimensioni l’intervallo di confidenza al 95% si costruisce nel modo seguente: \\[ \\text{stima del parametro} \\pm 2 \\text{ errori standard.} \\] Dalla distribuzione normale sappiamo che una stima del parametro \\(\\pm\\) 1 errore standard corrisponde ad un intervallo del 68% e una stima del parametro \\(\\pm\\) \\(\\frac{2}{3}\\) di un errore standard corrisponde ad un intervallo del 50%. Un intervallo del 50% è particolarmente facile da interpretare dato che il vero valore del parametro ha la stessa probabilità di essere incluso o escluso dall’intervallo. Un intervallo del 95% basato sulla distribuzione normale è circa tre volte più ampio di un intervallo del 50%. Conclusioni I risultati precedenti consentono le seguenti conclusioni. Se \\(X_1, \\dots, X_n\\) è un insieme di variabili aleatorie i.i.d., tutte con media \\(\\mu\\) e varianza \\(\\sigma^2\\), allora \\[ \\mathbb{E}(\\bar{X}) = \\mu, \\quad var(\\bar{X}) = \\frac{\\sigma^2}{n}. \\] Se le \\(X_i\\) seguono la distribuzione normale, ne segue che \\(\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma/\\sqrt{n})\\), in quanto qualunque combinazione lineare di variabili aleatorie Normali è ancora una variabile aleatoria Normale. Invece, se le \\(X_i\\) non seguono la distribuzione normale, il Teorema del limite centrale ci consente comunque di dire che \\(\\bar{X}\\) tende a \\(\\mathcal{N}(\\mu, \\sigma/\\sqrt{n})\\) al crescere di \\(n\\). I risultati precedenti sono estremamente importanti perché specificano completamente la distribuzione della media campionaria e vengono utilizzati dall’approccio frequentista per l’inferenza sulla media di una popolazione. "],["chapter-stima-funzione-aposteriori.html", "Capitolo 15 Stima della funzione a posteriori 15.1 Metodi numerici convenzionali 15.2 Approssimazione quadratica 15.3 Integrazione con metodo Monte Carlo 15.4 Metodi MC basati su Catena di Markov Conclusioni", " Capitolo 15 Stima della funzione a posteriori Quando usiamo il teorema di Bayes per calcolare la distribuzione a posteriori del parametro di un modello statistico, al denominatore troviamo un integrale. Tale integrale, nella maggior parte dei casi, non si può risolvere per via analitica. L’inferenza bayesiana si sviluppa dunque mediante una stima numerica della funzione a posteriori. Dato che questi metodi sono “computazionalmente intensivi,” possono solo essere svolti mediante software. In anni recenti i metodi Bayesiani di analisi dei dati sono diventati sempre più popolari proprio perché la potenza di calcolo necessaria per svolgere tali calcoli è ora alla portata di tutti. Questo non era vero solo pochi decenni fa. Per capire come la distribuzione a posteriori possa essere approssimata per via numerica esamineremo qui tre diverse tecniche che possono essere utilizzate a questo scopo: i metodi numerici convenzionali, il metodo dell’approssimazione quadratica, i metodi Monte Carlo basati su Catena di Markov (MCMC). 15.1 Metodi numerici convenzionali È possibile stimare l’intera distribuzione a posteriori mediante metodi numerici convenzionali. Questo è l’approccio più semplice. Tuttavia, anche se tali metodi possono fornire risultati accuratissimi, a causa della “maledizione della dimensionalità,” tali procedure numeriche sono utilizzabili solo nel caso di modelli statistici semplici, con non più di due parametri. Nella pratica concreta tali metodi vengono sostituiti da altre tecniche più efficienti in quanto, anche in comuni modelli utilizzati in psicologia, vengono stimati centinaia se non migliaia di parametri. Nell’esempio che faremo in questa sezione risulterà chiara la ragione per cui, in tali circostanze, non è possibile usare una tale procedura. I metodi numerici convenzionali sono invece utili come strumento didattico in quanto ci forniscono una procedura molto diretta e intuitiva che rende molto trasparente il processo dell’aggiornamento Bayesiano. Per questa ragione esamineremo qui un esempio relativo a tale procedura esaminando un modello statistico che dipende da un solo parametro sconosciuto. 15.1.1 La procedura dell’approssimazione numerica È molto semplice trovare una approssimazione numerica della distribuzione a posteriori e ciò può essere fatto come indicato di seguito. Anche se la maggior parte dei parametri è continua (ovvero, in linea di principio ciascun parametro può assumere un numero infinito di valori), possiamo ottenere un’eccellente approssimazione della distribuzione a posteriori considerando solo una griglia finita di valori dei parametri. Per calcolare la probabilità a posteriori in corrispondenza di ciascun particolare valore del parametro, chiamiamolo \\(\\theta&#39;\\), è sufficiente moltiplicare la probabilità a priori di \\(\\theta&#39;\\) per il valore della funzione di verosimiglianza in corrispondenza di \\(\\theta&#39;\\). Una stima della distribuzione a posteriori si genera ripetendo questo procedimento per ciascun valore nella griglia. 15.1.2 Un esempio pratico Facciamo un esempio concreto consideriando nuovamente la ricerca di Zetsche et al. (2019). Questi autori si sono chiesti se gli individui depressi manifestino delle aspettative accurate circa il loro umore futuro, oppure se tali aspettative siano distorte negativamente. Consideriamo qui i 30 partecipanti dello studio di Zetsche et al. (2019) che hanno riportato la presenza di un episodio di depressione maggiore in atto. All’inizio della settimana di test a questi pazienti è stato chiesto di valutare l’umore che si aspettavano di sentire nei giorni seguenti della settimana. Mediante una app, i partecipanti dovevano poi valutare il proprio umore in cinque momenti diversi di ciascuno dei cinque giorni successivi. Lo studio considera diverse emozioni, ma qui ci concentriamo solo sulla tristezza. Sulla base dei dati forniti dagli autori, abbiamo calcolato la media dei giudizi relativi al livello di tristezza raccolti da ciascun partecipante tramite la app. Tale media è stata poi sottratta dall’aspettativa del livello di tristezza fornita all’inizio della settimana. Per semplificare l’analisi abbiamo considerato la discrepanza tra aspettative e realtà come un evento dicotomico: valori positivi di tale differenza indicano che le aspettative circa il livello di tristezza sono maggiori del livello di tristezza che in seguito viene effettivamente esperito; ciò significa che le aspettative sono negativamente distorte (evento codificato con “1”). Si può dire il contrario (le aspettative sono positivamente distorte) se tale differenza assume valori negativi (evento codificato con “0”). Nel campione dei 30 partecipanti clinici qui esaminati, 23 partecipanti manifestano delle aspettative negativamente distorte e 7 partecipanti manifestano delle aspettative positivamente distorte. Chiamiamo \\(\\theta\\) la probabilità dell’evento “le aspettative del partecipante sono distorte negativamente.” Ci poniamo il problema di ottenere la stima a posteriori di \\(\\theta\\), dati i 23 \"successi\" in 30 prove che sono stati osservati. Per questo esempio considereremo 50 valori egualmente spaziati per il parametro \\(\\theta\\): 0.000, 0.0204, …, 0.978, 1.000. In R abbiamo: n_points &lt;- 50 p_grid &lt;- seq(from = 0, to = 1, length.out = n_points) p_grid #&gt; [1] 0.00000000 0.02040816 0.04081633 0.06122449 0.08163265 0.10204082 0.12244898 0.14285714 #&gt; [9] 0.16326531 0.18367347 0.20408163 0.22448980 0.24489796 0.26530612 0.28571429 0.30612245 #&gt; [17] 0.32653061 0.34693878 0.36734694 0.38775510 0.40816327 0.42857143 0.44897959 0.46938776 #&gt; [25] 0.48979592 0.51020408 0.53061224 0.55102041 0.57142857 0.59183673 0.61224490 0.63265306 #&gt; [33] 0.65306122 0.67346939 0.69387755 0.71428571 0.73469388 0.75510204 0.77551020 0.79591837 #&gt; [41] 0.81632653 0.83673469 0.85714286 0.87755102 0.89795918 0.91836735 0.93877551 0.95918367 #&gt; [49] 0.97959184 1.00000000 15.1.2.1 Distribuzione a priori Supponiamo che le nostre credenze a priori sulla tendenza di un individuo clinicamente depresso a manifestare delle aspettative distorte negativamente circa il suo umore futuro siano molto scarse. Assumiamo quindi per \\(\\theta\\) una distribuzione iniziale uniforme nell’intervallo [0, 1]. Dato che consideriamo soltanto \\(n = 50\\) valori del parametro \\(\\theta\\), creiamo un vettore di 50 elementi che conterrà i valori della distribuzione a priori scalando ciascun valore di questo vettore per \\(n\\) in modo tale che la somma di tutti i valori della distribuzione a priori (0.02, 0.02, …, 0.02, 0.02) sia uguale a 1.0 (in questo modo viene definita una funzione di massa di probabilità): prior1 &lt;- dbeta(p_grid, 1, 1) / sum(dbeta(p_grid, 1, 1)) sum(prior1) #&gt; [1] 1 Stampo i valori: prior1 #&gt; [1] 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 #&gt; [18] 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 #&gt; [35] 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 La distribuzione a priori così costruita è riportata nella figura 15.1. p1 &lt;- data.frame(p_grid, prior1) %&gt;% ggplot(aes(x=p_grid, xend=p_grid, y=0, yend=prior1)) + geom_line()+ geom_segment(color = &quot;#8184FC&quot;) + ylim(0, 0.17) + labs( x = &quot;Parametro \\U03B8&quot;, y = &quot;Probabilità a priori&quot;, title = &quot;50 punti&quot; ) p1 Figura 15.1: Rappresentazione della distribuzione a priori per il parametro \\(\\theta\\), ovvero la probabilità di aspettative future distorte negativamente (Zetsche et al., 2019). 15.1.2.2 Funzione di verosimiglianza Calcoliamo ora la funzione di verosimiglianza utilizzando i 50 valori \\(\\theta\\) che abbiamo considerato. Per ciascun valore \\(\\theta\\) applichiamo la formula della probabilità binomiale tendendo sempre costanti i valori dei dati (ovvero 23 “successi” in 30 prove). Per esempio, per il valore \\(\\theta = 0.816\\) l’ordinata della funzione di verosimiglianza sarà \\[\\begin{aligned} \\binom{30}{23}&amp; \\cdot 0.816^{23} \\cdot (1 - 0.816)^{7} = 0.135\\notag \\end{aligned} \\] e per \\(\\theta = 0.837\\) l’ordinata della funzione di verosimiglianza sarà \\[\\begin{aligned} \\binom{30}{23}&amp; \\cdot 0.837^{23} \\cdot (1 - 0.837)^{7} = 0.104.\\notag \\end{aligned} \\] Svolgendo tutti i calcoli con R otteniamo i valori seguenti: likelihood &lt;- dbinom(23, size = 30, prob = p_grid) likelihood #&gt; [1] 0.000000e+00 2.352564e-33 1.703051e-26 1.644169e-22 1.053708e-19 1.525217e-17 #&gt; [7] 8.602222e-16 2.528440e-14 4.606907e-13 5.819027e-12 5.499269e-11 4.105534e-10 #&gt; [13] 2.520191e-09 1.311195e-08 5.919348e-08 2.362132e-07 8.456875e-07 2.749336e-06 #&gt; [19] 8.196948e-06 2.259614e-05 5.798673e-05 1.393165e-04 3.148623e-04 6.720574e-04 #&gt; [25] 1.359225e-03 2.611870e-03 4.778973e-03 8.340230e-03 1.390025e-02 2.214199e-02 #&gt; [31] 3.372227e-02 4.909974e-02 6.830377e-02 9.068035e-02 1.146850e-01 1.378206e-01 #&gt; [37] 1.568244e-01 1.681749e-01 1.688979e-01 1.575211e-01 1.348746e-01 1.043545e-01 #&gt; [43] 7.133007e-02 4.165680e-02 1.972669e-02 6.936821e-03 1.535082e-03 1.473375e-04 #&gt; [49] 1.868105e-06 0.000000e+00 La funzione di verosimiglianza così ottenuta è riportata nella figura 15.2. p2 &lt;- data.frame(p_grid, likelihood) %&gt;% ggplot(aes(x=p_grid, xend=p_grid, y=0, yend=likelihood)) + geom_segment(color = &quot;#8184FC&quot;) + ylim(0, 0.17) + labs( x = &quot;Parametro \\U03B8&quot;, y = &quot;Verosimiglianza&quot; ) p2 Figura 15.2: Rappresentazione della funzione di verosimiglianza per il parametro \\(\\theta\\), ovvero la probabilità di aspettative future distorte negativamente (Zetsche et al., 2019). 15.1.2.3 La stima della distribuzione a posteriori La distribuzione a posteriori del parametro \\(\\theta\\) è data dal prodotto della verosimiglianza e della distribuzione a priori, scalata per una costante di normalizzazione. Quindi, facendo il prodotto dei valori della distribuzione a priori e i valori della funzione di verosimiglianza otteniamo la funzione a posteriori non standardizzata. Dato che la distribuzione a priori è uniforme, per ottenere questo risultato è sufficiente moltiplicare ciascun valore della funzione di verosimiglianza per 0.02. Per esempio, per il primo valore della funzione di verosimiglianza che abbiamo calcolato sopra, avremo \\(0.135 \\cdot 0.02\\); per il secondo valore della funzione di verosimiglianza che abbiamo calcolato sopra avremo \\(0.104 \\cdot 0.02\\). Usando R, la funzione a posteriori non standardizzata diventa: unstd_posterior &lt;- likelihood * prior1 unstd_posterior #&gt; [1] 0.000000e+00 4.705127e-35 3.406102e-28 3.288337e-24 2.107415e-21 3.050433e-19 #&gt; [7] 1.720444e-17 5.056880e-16 9.213813e-15 1.163805e-13 1.099854e-12 8.211068e-12 #&gt; [13] 5.040382e-11 2.622390e-10 1.183870e-09 4.724263e-09 1.691375e-08 5.498671e-08 #&gt; [19] 1.639390e-07 4.519229e-07 1.159735e-06 2.786331e-06 6.297247e-06 1.344115e-05 #&gt; [25] 2.718450e-05 5.223741e-05 9.557946e-05 1.668046e-04 2.780049e-04 4.428398e-04 #&gt; [31] 6.744454e-04 9.819948e-04 1.366075e-03 1.813607e-03 2.293700e-03 2.756411e-03 #&gt; [37] 3.136488e-03 3.363497e-03 3.377958e-03 3.150422e-03 2.697491e-03 2.087091e-03 #&gt; [43] 1.426601e-03 8.331361e-04 3.945339e-04 1.387364e-04 3.070164e-05 2.946751e-06 #&gt; [49] 3.736209e-08 0.000000e+00 Avendo svolto questo prodotto per tutti i 50 valori della funzione di verosimiglianza, dobbiamo poi dividere ciascuno dei 50 numeri così trovati per la costante di normalizzazione. Nel caso discreto, trovare il denominatore del teorema di Bayes è molto facile: esso è dato dalla somma di tutti i valori della distribuzione a posteriori non normalizzata. Per i dati presenti, tale costante di normalizzazione è uguale a 0.032. sum(unstd_posterior) #&gt; [1] 0.0316129 Possiamo dunque standardizzare i due valori trovati sopra nel modo seguente: \\(0.135 \\cdot 0.02 / 0.032\\) e \\(0.104 \\cdot 0.02 / 0.032\\). Così facendo, otterremo il risultato per cui la somma di tutti e 50 i valori della distribuzione a posteriori normalizzata sarà uguale a 1.0. Svolgiamo tutti i calcoli in R: posterior &lt;- unstd_posterior / sum(unstd_posterior) posterior #&gt; [1] 0.000000e+00 1.488357e-33 1.077440e-26 1.040188e-22 6.666313e-20 9.649330e-18 #&gt; [7] 5.442222e-16 1.599625e-14 2.914574e-13 3.681425e-12 3.479129e-11 2.597379e-10 #&gt; [13] 1.594406e-09 8.295316e-09 3.744893e-08 1.494410e-07 5.350268e-07 1.739376e-06 #&gt; [19] 5.185824e-06 1.429552e-05 3.668548e-05 8.813904e-05 1.991986e-04 4.251792e-04 #&gt; [25] 8.599178e-04 1.652408e-03 3.023432e-03 5.276472e-03 8.794033e-03 1.400820e-02 #&gt; [31] 2.133450e-02 3.106310e-02 4.321259e-02 5.736920e-02 7.255582e-02 8.719259e-02 #&gt; [37] 9.921545e-02 1.063963e-01 1.068538e-01 9.965619e-02 8.532881e-02 6.602021e-02 #&gt; [43] 4.512719e-02 2.635430e-02 1.248015e-02 4.388601e-03 9.711744e-04 9.321354e-05 #&gt; [49] 1.181862e-06 0.000000e+00 Verifichiamo: sum(posterior) #&gt; [1] 1 In questo particolare esempio, la distribuzione a posteriori trovata come descritto sopra non è altro che la versione normalizzata della funzione di verosimiglianza: questo avviene perché la distribuzione a priori uniforme non ha aggiunto altre informazioni oltre a quelle che erano già fornite dalla funzione di verosimiglianza. La funzione a posteriori che abbiamo calcolato con il metodo dell’approssimazione numerica è riportata nella figura 15.3. p3 &lt;- data.frame(p_grid, posterior) %&gt;% ggplot(aes(x=p_grid, xend=p_grid, y=0, yend=posterior)) + geom_segment(color = &quot;#8184FC&quot;) + ylim(0, 0.17) + labs( x = &quot;Parametro \\U03B8&quot;, y = &quot;Probabilità a posteriori&quot; ) p3 Figura 15.3: Rappresentazione della distribuzione a posteriori per il parametro \\(\\theta\\), ovvero la probabilità di aspettative future distorte negativamente (Zetsche et al., 2019). Le funzioni rappresentate nelle figure 15.1, 15.2 e 15.3 sono state calcolate utilizzando 50 modalità equi-spaziate per il parametro \\(\\theta\\). I segmenti verticali rappresentano l’intensità della funzione in corrispondenza di ciascuna modalità parametro \\(\\theta\\). Nella figura 15.1 e nella figura 15.3 la somma delle lunghezze dei segmenti verticali è pari ad 1.0; ciò non si verifica, invece, nel caso della figura 15.3. 15.1.3 Un esempio pratico (versione 2) Continuiamo la discussione dell’esempio precedente supponendo che la letteratura precedente ci fornisca delle informazioni a proposito di \\(\\theta\\), ovvero sulla probabilità che le aspettative future di un individuo clinicamente depresso siano distorte negativamente. In tali circostanze, invece di utilizzare la distribuzione uniforme per \\(p(\\theta)\\), definiamo la distribuzione a priori per \\(\\theta\\) come una distribuzione che ha la forma di una Beta di parametri \\(\\alpha = 2\\) e \\(\\beta = 10\\). In questo modo, la distribuzione a priori di \\(\\theta\\) ritiene molto plausibili valori bassi di \\(\\theta\\), mentre i valori \\(\\theta\\) superiori a 0.5 vengono considerati impossibili. Questo è equivalente a dire che ci aspettiamo che le aspettative relative all’umore futuro siano distorte negativamente solo per pochissimi individui clinicamente depressi – in altre parole, ci aspettiamo che la maggioranza degli individui clinicamente depressi sia inguaribilmente ottimista. Questa è, ovviamente, un’opinione a priori molto difficile da giustificare. La esamino qui, non perché abbia senso nel contesto dei dati di Zetsche et al. (2019), ma soltanto per fare un esempio che mostra come la distribuzione a posteriori fornisca una sorta di “compromesso” tra la distribuzione a priori e la verosimiglianza. Con calcoli del tutto simili a quelli descritti sopra si giunge alla distribuzione a posteriori rappresentata nella figura 15.4. Iniziamo a definire una griglia unidimensionale equispaziata di possibili valori del parametro \\(\\theta\\). Anche in questo caso usiamo 50 valori possibili del parametro \\(\\theta\\): n_points &lt;- 50 p_grid &lt;- seq(from = 0, to = 1, length.out = n_points) Per la distribuzione a priori scelgo una Beta(2, 10). alpha &lt;- 2 beta &lt;- 10 prior2 &lt;- dbeta(p_grid, alpha, beta) / sum(dbeta(p_grid, alpha, beta)) sum(prior2) #&gt; [1] 1 Tale distribuzione a priori è rappresentata nella figura 15.4. plot_df &lt;- data.frame(p_grid, prior2) p4 &lt;- plot_df %&gt;% ggplot(aes(x=p_grid, xend=p_grid, y=0, yend=prior2)) + geom_segment(color = &quot;#8184FC&quot;) + ylim(0, 0.17) + labs( x = &quot;&quot;, y = &quot;Probabilità a priori&quot;, title = &quot;50 punti&quot; ) p4 Figura 15.4: Rappresentazione di una funzione a priori informativa per il parametro \\(\\theta\\). Calcoliamo il valore della funzione di verosimiglianza in corrispondenza di ciascun punto della griglia. La funzione di verosimiglianza è identica a quella considerata nell’esempio precedente. likelihood &lt;- dbinom(23, size = 30, prob = p_grid) Calcolo il prodotto tra la verosimiglianza e la distribuzione a priori, per ciascun punto della griglia: unstd_posterior2 &lt;- likelihood * prior2 Normalizzo la distribuzione a posteriori in modo tale che la somma sia 1. posterior2 &lt;- unstd_posterior2 / sum(unstd_posterior2) sum(posterior2) #&gt; [1] 1 La nuova funzione a posteriori è rappresentata nella figura 15.5. plot_df &lt;- data.frame(p_grid, posterior2) p5 &lt;- plot_df %&gt;% ggplot(aes(x = p_grid, xend = p_grid, y = 0, yend = posterior2)) + geom_segment(color = &quot;#8184FC&quot;) + ylim(0, 0.17) + labs( x = &quot;Parametro \\U03B8&quot;, y = &quot;Probabilità a posteriori&quot; ) p5 Figura 15.5: Rappresentazione della funzione a posteriori per il parametro \\(\\theta\\) calcolata utilizzando una distribuzione a priori informativa. Facendo un confronto tra le figure 15.4 e 15.5 si nota come la distribuzione a priori per il parametro \\(\\theta\\) e la distribuzione a posteriori per il parametro \\(\\theta\\) sono molto diverse. In particolare, si noti che la distribuzione a posteriori rappresentata nella 15.5 risulta spostata verso destra su posizioni più vicine a quelle della verosimiglianza, rappresentata nella figura 15.2. Si noti anche, a causa dell’effetto della distribuzione a priori, le distribuzioni a posteriori riportate nelle figure 15.3 e 15.5 sono molto diverse tra loro. Discuteremo in seguito l’influenza della distribuzione a priori sull’inferenza finale. 15.1.4 Sommario della funzione a posteriori Una volta calcolata la distribuzione a posteriori dobbiamo riassumerla in qualche modo. Nel caso in cui venga usato il metodo di approssimazione numerica, il problema del calcolo delle aree sottese alla funzione a posteriori in qualunque intervallo può essere risolto in vari modi. Tuttavia, questo problema trova una soluzione molto più semplice se viene utilizzato un metodo diverso per la stima della distribuzione a posteriori, come vedremo di seguito. Non discuteremo dunque la possibile soluzione di questo problema nel caso presente, in quanto il metodo dell’approssimazione numerica per il calcolo della distribuzione a posteriori è solo un esempio didattico. 15.2 Approssimazione quadratica I metodi numerici convenzionali possono essere usati solo quando il numero di parametri da stimare è piccolo. La ragione di ciò sta nella cosiddetta “maledizione della dimensionalità.” Vediamo cosa significa. Nel caso di un solo parametro, supponiamo di utilizzare una griglia di 100 valori. Per due parametri avremo bisogno di \\(100^2\\) valori. Ma già per 10 parametri avremo bisogno di \\(10^{10}\\) valori – è facile capire che una tale quantità di valori è troppo grande anche per un computer potente come quello che utilizziamo normalmente. Dobbiamo dunque affrontare il problema in un altro modo. Una possibile soluzione al nostro problema ci viene fornita dal metodo dell’approssimazione quadratica. La motivazione di tale metodo è la seguente. Sappiamo che, in generale, la regione della distribuzione a posteriori che si trova in prossimità del suo massimo può essere ben approssimata dalla forma di una distribuzione Normale. Descrivere la distribuzione a posteriori mediante la distribuzione Normale significa utilizzare un’approssimazione che viene, appunto, chiamata “quadratica”5. L’approssimazione quadratica si pone due obiettivi. Trovare la moda della distribuzione a posteriori. Ci sono varie procedure di ottimizzazione, implementate in R, in grado di trovare il massimo di una distribuzione. Stimare la curvatura della distribuzione in prossimità della moda. Una stima della curvatura è sufficiente per trovare un’approssimazione quadratica dell’intera distribuzione. In alcuni casi, questi calcoli possono essere fatti seguendo una procedura analitica, ma solitamente vengono usate delle tecniche numeriche. Una descrizione della distribuzione a posteriori ottenuta mediante l’approssimazione quadratica si ottiene mediante la funzione quap() contenuta nel pacchetto rethinking. Tale pacchetto, creato da Richard McElreath per accompagnare il suo testo Statistical Rethinking\\(^2\\), può essere scaricato utilizzando le istruzioni seguenti6: install.packages(c(&quot;coda&quot;, &quot;mvtnorm&quot;, &quot;devtools&quot;, &quot;loo&quot;, &quot;dagitty&quot;)) library(&quot;devtools&quot;) devtools::install_github(&quot;rmcelreath/rethinking&quot;) Vedremo nel capitolo XX come tale funzione possa essere usata7. Dal nostro punto di vista non è importante capire come si svolgono in pratica i calcoli necessari per la stima della distribuzione a posteriori con il metodo dell’approssimazione quadratica. Quello che è importante capire è il significato della distribuzione a posteriori e questo significato è stato chiarito nella sezione La procedura dell’approssimazione numerica. L’approssimazione quadratica fornisce risultati simili (o identici) a quelli ottenuti con il metodo descritto nella sezione La procedura dell’approssimazione numerica. Il vantaggio dell’approssimazione quadratica è che disponiamo di una serie di funzioni R che svolgono tutti i calcoli per noi. In realtà, l’approssimazione quadratica è poco usata in pratica, perché per problemi complessi è più conveniente usare i metodi Monte Carlo basati su Catena di Markov (MCMC) che verranno descritti nella successiva sezione Integrazione con metodo Monte Carlo. Per potere utilizzare i metodi MCMC è necessario installare sul proprio computer del software aggiuntivo e tale operazione, talvolta, può risultare complessa. Non è l’obiettivo di questo insegnamento affrontare questo problema Per questa ragione, per svolgere gli esercizi che discuteremo sarà sufficiente fare ricorso al metodo dell’approssimazione quadratica; ovvero sarà sufficiente usare la funzione rethinking::quap(). 15.3 Integrazione con metodo Monte Carlo Prima di introdurre i metodi MCMC per la stima della funzione a posteriori, spendiamo due parole sul metodo Monte Carlo quale tecnica che consente il calcolo degli integrali mediante simulazione numerica. Il termine Monte-Carlo si riferisce al fatto che per la computazione si ricorre ad un ripetuto campionamento casuale attraverso la generazioni di sequenze di numeri casuali. 15.3.1 Legge forte dei grandi numeri L’integrazione con metodo Monte Carlo trova la sua giustificazione nella Legge forte dei grandi numeri la quale può essere espressa nei termini seguenti. Data una successione di variabili casuali \\(Y_{1}, Y_{2},\\dots, Y_{n},\\dots\\) indipendenti e identicamente distribuite con media \\(\\mu\\), ne segue che \\[ P\\left( \\lim_{n \\rightarrow \\infty} \\frac{1}{n} \\sum_{i=1}^n Y_i = \\mu \\right) = 1. \\] Ciò significa che, al crescere di \\(n\\), la media delle realizzazioni di \\(Y_{1}, Y_{2},\\dots, Y_{n},\\dots\\) converge con probabilità 1 al vero valore \\(\\mu\\). Un esempio della legge forte dei grandi numeri riguarda una serie di lanci di una moneta dove \\(Y=1\\) significa “testa” e \\(Y=0\\) significa “croce.” Per la legge forte dei grandi numeri, nel caso di una moneta equilibrata la proporzione di eventi “testa” converge alla vera probabilità dell’evento “testa” \\[ \\frac{1}{n} \\sum_{i=1}^n Y_i \\rightarrow \\frac{1}{2} \\] con probabilità di uno. Quello che è stato detto sopra non è che un modo sofisticato per dire che, se vogliamo calcolare un’approssimazione del valore atteso di una variabile aleatoria, non dobbiamo fare altro che la media aritmetica di un grande numero di realizzazione di tale variabile aleatoria. Come è facile intuire, l’approssimazione migliora al crescere del numero di dati che abbiamo a disposizione. 15.4 Metodi MC basati su Catena di Markov I metodi Monte Carlo basati su Catena di Markov consentono di costruire sequenze di punti (le “catene”) nello spazio dei parametri, la cui densità è proporzionale alla distribuzione di probabilità a posteriori a cui siamo interessati. Questo, evidentemente, è il risultato vorremmo ottenere. Ma cosa sono le catene di Markov? In termini formali possiamo dire che una catena di Markov è una sequenza di variabili aleatorie \\(Y_{1}, Y_{2},\\dots, Y_{n}\\) tale che la dipendenza della distribuzione di \\(Y_{i+1}\\) dai valori di \\(Y_{1}, \\dots, Y_{i}\\) è interamente dovuta al valore di \\(Y_i\\), cioè il passaggio ad uno stato del sistema dipende unicamente dallo stato immediatamente precedente e non dal come si è giunti a tale stato (dalla storia). Per questo motivo si dice che un processo markoviano è senza memoria. In generale è possibile generare catene di Markov che convergono ad una soluzione unica e stazionaria tale per cui gli elementi della catena sono campioni dalla distribuzione di interesse. Nel caso dell’inferenza Bayesiana la distribuzione di interesse è la distribuzione a posteriori, \\(p(\\theta \\mid x)\\). Le catene di Markov possono quindi essere utilizzate per stimare i valori di aspettazione di variabili rispetto alla distribuzione a posteriori. In altre parole, possiamo utilizzare le catene di Markov per stimare i valori a posteriori dei parametri sconosciuti di un modello statistico – un esempio è il parametro \\(p\\) nel problema del mappamondo che abbiamo discusso in precedenza. La generazioni di elementi di una catena ha una natura probabilistica e esistono diversi algoritmi per costruire catene di Markov. Due aspetti da tenere in considerazione sotto questo punto di vista sono il periodo di burn-in e le correlazioni tra punti. Al crescere degli step della catena si ottiene una migliore approssimazione della distribuzione target. All’inizio del campionamento però la distribuzione può essere significativamente lontana dalla distribuzione stazionaria. Ci vuole un certo tempo prima di raggiungere la distribuzione stazionaria di equilibrio e tale periodo è detto di burn-in. Perciò i campioni provenienti da tale parte iniziale della catena vanno tipicamente scartati poiché non rappresentano accuratamente la distribuzione desiderata. Normalmente, un algoritmo MCMC genera catene di Markov di campioni, ognuno dei quali è autocorrelato a quelli generati immediatamente prima e dopo di lui. Conseguentemente campioni successivi non sono indipendenti ma formano una catena di Markov con un certo grado di correlazione. Questa correlazione introduce una distorsione nella soluzione che si ottiene con questo metodo. L’arte dei diversi algoritmi MCMC risiede nel rendere il meccanismo efficiente e capace di produrre un risultato non distorto, il che implica la riduzione al minimo del tempo di burn-in e della correlazione tra i diversi campioni. Presentiamo ora, in una forma intuitiva, l’algoritmo di Metropolis, ovvero il primo algoritmo MCMC che è stato proposto. Tale algoritmo è stato sviluppato in seguito per renderlo via via più efficiente. Il nostro obiettivo, però, è solo quello di capire la logica sottostante – lasciamo che siano gli ingegneri a risolvere il problema di rendere l’algoritmo più efficiente. 15.4.1 Il problema del turista viaggiatore L’algoritmo di Metropolis è stato presentato usando varie metafore: quella di un politico che viaggia tra isole diverse (Kruschke, 2014), o quella di un re che, anche lui, si sposta tra le isole di un arcipelago (McElreath, 2020). Qui mutiamo leggermente la metafora e immaginiamo un turista in vacanza su un’isola che dispone di 10 spiagge di grandezza diversa. Muovendosi in senso orario, la grandezza delle spiagge aumenta: partendo dalla spiaggia più piccola si arriva ad una spiaggia un po’ più grande, via via fino ad arrivare all’ultima spiaggia, la decima, che è la più grande di tutte. Quindi indicheremo con i numeri da 1 a 10 le spiagge dell’isola. Tali numeri rappresentano anche la grandezza (relativa) di ciascuna spiaggia. Dato che l’isola è circolare, la decima spiaggia confina con la prima spiaggia. Nella nostra metafora, immaginiamo un turista in vacanza sull’isola che abbiamo appena descritto. Per non annoiarsi, il nostro turista vuole passare un po’ di tempo su ogni spiaggia, ma con il vincolo che il tempo passato su ciascuna spiaggia deve essere proporzionale alla grandezza della spiaggia. Infatti, il turista preferisce le spiagge più grandi; nel contempo, però, vuole anche visitare spiagge diverse, quindi il vincolo descritto sopra sembra un buon compromesso tra il desiderio di cambiare spiaggia di tanto in tanto e il desiderio di passare più tempo sulle spiagge più grandi. Essendo in vacanza, il turista non vuole preparare un calendario che stabilisca in anticipo la spiaggia da visitare ogni giorno, ma vuole decidere in maniera rilassata e un po’ casuale, ogni mattina, restando però fedele al vincolo che si è dato. Al bar incontra un altro turista, l’ingegnere Metropolis, che gli suggerisce come fare per ottenere l’obiettivo che si è prefissato. Seguendo le istruzioni di Metropolis, il nostro turista decide di comportarsi nel modo seguente. Ogni mattina decide tra due alternative: ritornare sulla spiaggia dove era stato il giorno prima (chiamiamola spiaggia corrente) oppure andare in una delle due spiagge contigue. Lancia una moneta. Se esce testa, considera la possibilità di andare nella spiaggia a che confina con la spiaggia corrente muovendosi in senso orario; se esce croce, considera la possibilità di andare nella spiaggia a che confina con la spiaggia corrente muovendosi in senso antiorario. La spiaggia individuata in questo modo viene chiamata spiaggia proposta. Dopo avere trovato la spiaggia proposta, il turista deve decidere se effettivamente andare lì oppure no e, per decidere, procede in questo modo. Prende un numero di conchiglie proporzionale alla grandezza della spiaggia proposta – per esempio, se la spiaggia proposta è la numero 7, allora prenderà 7 conchiglie. Prende un numero di sassolini proporzionale alla grandezza della spiaggia corrente – per esempio, se la spiaggia corrente è la numero 6, allora prenderà 6 sassolini. Se il numero di conchiglie è maggiore del numero di sassolini, il turista si sposta sempre nella spiaggia proposta. Ma se ci sono meno conchiglie che sassolini, scarta un numero di sassolini uguale al numero di conchiglie e mette gli oggetti rimanenti in un sacchetto – per esempio, se la spiaggia proposta è la 5 e la spiaggia corrente è la 6, allora metterà nel sacchetto 5 conchiglie e 1 sassolino. Mescola bene ed estrae dal sacchetto un oggetto: se è una conchiglia si sposta nella spiaggia proposta, se è un sassolino resta nella spiaggia corrente. Di conseguenza, la probabilità che il turista cambi spiaggia (ovvero \\(\\frac{5}{6}\\)) è uguale al numero di conchiglie diviso per il numero originale di sassolini. Decidere di procedere in questo modo potrebbe sembrare un modo per rovinarsi le vacanze. Invece, questo algoritmo funziona! Seguendo la proposta di Metropolis, il turista passerà su ciascuna spiaggia un numero di giorni proporzionale alla grandezza della spiaggia. McElreath (2020) ha implementato in R l’algoritmo di Metropolis che abbiamo descritto sopra nel modo seguente: num_weeks &lt;- 1e5 positions &lt;- rep(0, num_weeks) current &lt;- 10 for (i in 1:num_weeks) { # record current position positions[i] &lt;- current # flip coin to generate proposal proposal &lt;- current + sample(c(-1, 1), size = 1) # now make sure he loops around the archipelago if (proposal &lt; 1) proposal &lt;- 10 if (proposal &gt; 10) proposal &lt;- 1 # move? prob_move &lt;- proposal / current current &lt;- ifelse(runif(1) &lt; prob_move, proposal, current) } Le istruzioni seguenti sono state usate per generare la figura 15.6. Se guardiamo la figura e consideriamo un giorno qualsiasi è difficile capire qual è la spiaggia scelta dal turista. ggplot( data.frame(x = 1:100, y = positions[1:100]), aes(x, y) ) + geom_point(color = &quot;#8184FC&quot;) + labs( x = &quot;Giorno&quot;, y = &quot;Isola&quot; ) + scale_y_continuous(breaks=1:10) Figura 15.6: Risultati dell’algoritmo di Metropolis utilizzato dal turista viaggiatore. La figura mostra la spiaggia scelta dal turista (asse verticale) in funzione di ciascun giorno della sua vacanza (asse orizzontale). Tuttavia, se esaminiamo la figura 15.7 che descrive il comportamento a lungo termine dell’algoritmo, ci rendiamo conto che l’algoritmo ha prodotto il risultato che si voleva ottenere: il tempo trascorso dal turista su ciascuna spiaggia è proporzionale alla grandezza della spiaggia. ggplot( data.frame(x = 1:10, y = as.numeric(table(positions))), aes(x = x, xend = x, y = 0, yend = y) ) + geom_segment(color = &quot;#8184FC&quot;, size = 1.5) + labs( x = &quot;Isola&quot;, y = &quot;Numero di giorni&quot; ) + scale_x_continuous(breaks=1:10) Figura 15.7: Risultati dell’algoritmo di Metropolis utilizzato dal turista viaggiatore. La figura mostra che il numero di volte in cui ciascuna spiaggia è stata visitata è proporzionale alla grandezza della spiaggia. L’algoritmo di Metropolis funziona anche se il turista decide di spostarsi dalla spiaggia corrente a qualunque altra spiaggia, non solo su quelle confinanti. Inoltre, l’algoritmo funziona per qualunque numero di spiagge e anche se il turista non sa quante spiagge ci sono sull’isola. Affinché l’algoritmo funzioni è solo necessario conoscere la grandezza della spiaggia “corrente” e quella della spiaggia “proposta.” 15.4.2 L’algoritmo di Metropolis L’algoritmo descritto nella sezione Il problema del turista viaggiatore è un caso speciale dell’algoritmo di Metropolis e l’algoritmo di Metropolis è un caso speciale dei metodi MCMC. L’algoritmo di Metropolis, al di là dell’uso che ne fa il fortunato turista dell’esempio discusso in precedenza, viene in realtà impiegato per per ottenere una sequenza di campioni casuali da una distribuzione a posteriori la cui forma è, solitamente, sconosciuta. Fuor di metafora: i numeri che identificano ciascuna spiaggia corrispondono ai valori del parametro che vogliamo stimare – non è necessario che il parametro assuma solo valori discreti, può anche assumere un insieme continuo di valori; la grandezza della spiaggia corrisponde alla densità a posteriori associata a ciascuno dei possibili valori del parametro; i giorni di permanenza su una spiaggia corrispondono al numero di campioni estratti dalla distribuzione a posteriori. L’aspetto cruciale di questa discussione è il fatto che, all’aumentare delle ripetizioni dell’algoritmo di Metropolis, la distribuzione dei valori così ottenuti diventa via via più simile alla distribuzione a posteriori del parametro \\(\\theta\\), anche se questa è sconosciuta. Per un grande numero di passi della catena l’approssimazione è sufficiente. Con questo metodo è dunque possibile generare un grande numero di campioni casuali dalla distribuzione a posteriori per poi poterne calcolare misure di sintesi e potere fare inferenza. 15.4.3 Una applicazione concreta L’algoritmo di Metropolis consente di effettuare quello che viene chiamato un dependent sampling, ovvero ci consente di generare campioni casuali dalla distribuzione a posteriori utilizzando soltanto il numeratore del teorema di Bayes: \\[ P(\\theta \\mid x) = \\frac{P(x \\mid \\theta)P(\\theta)}{P(x)} \\] ovvero \\[ P(\\theta \\mid x) \\propto P(x \\mid \\theta)P(\\theta) \\] L’algoritmo di Metropolis è la versione più semplice e più conosciuta degli algoritmi MCMC. Vediamo come funziona. Per prima cosa troviamo un valore casuale del parametro estraendolo da una distribuzione “proposta”: \\(\\theta_0 \\sim \\Pi(\\theta)\\). La distribuzione proposta può essere qualunque distribuzione, anche se, idealmente, è meglio che sia simile alla distribuzione a posteriori. Ma in pratica la distribuzione a posteriori è sconosciuta e quindi utilizziamo un qualche metodo arbitrario di iniziare la catena di Markov (ovvero utilizziamo un valore iniziale arbitrario). In ciascuna iterazione \\(t\\) viene proposto un nuovo valore del parametro, \\(\\theta&#39;_t\\). Il valore \\(\\theta&#39;_t\\) viene estratto in maniera casuale da una qualsiasi distribuzione simmetrica centrata sul valore del parametro dell’interazione precedente, \\(t-1\\). Ad esempio, possiamo usare la distribuzione Normale con una appropriata deviazione standard: \\(\\theta_t \\sim \\mathcal{N}(\\theta_{t-1}, \\sigma)\\). In pratica, questo significa che il valore proposto del parametro sarà un valore nella prossimità di quello attualmente considerato. Calcoliamo poi il rapporto \\(r\\) tra la distribuzione a posteriori non normalizzata determinata dal valore proposto \\(\\theta&#39;_t\\) e la distribuzione a posteriori non normalizzata determinata dal valore del parametro \\(\\theta&#39;_{t-1}\\) dell’iterazione precedente della catena: \\(r = \\frac{P(x \\mid \\theta&#39;_t) P(\\theta&#39;_t)}{P(x \\mid \\theta&#39;_{t-1}) P(\\theta&#39;_{t-1})}\\). Soffermiamoci su tale formula per capire bene cosa significa. La distribuzione a posteriori non normalizzata corrisponde al numeratore del teorema di Bayes, ovvero \\(P(x \\mid \\theta) P(\\theta)\\), laddove \\(P(x \\mid \\theta)\\) è la verosimiglianza di \\(x\\) dato \\(\\theta\\) e \\(P(\\theta)\\) è la distribuzione a priori di \\(\\theta\\). Abbiamo visto nella sezione Un esempio pratico (versione 2) che ciascuna di tali densità può essere rappresentata mediante una curva e che il prodotto di due densità si ottiene facendo il prodotto dei valori delle ordinate corrispondenti di discuna delle due curve. Il numeratore del teorema di Bayes ci fornisce la distribuzione a posteriori non normalizzata in quanto l’area sottesa alla curva così ottenuta non è unitaria (quindi tale curva non rappresenta una funzione di densità). Dato che qui facciamo un rapporto, però, questo è irrilevante. Al numeratore del rapporto \\(r\\) dobbiamo fare il prodotto tra due scalari: la densità (l’ordinata) della funzione di verosimiglianza in corrispondenza del valore proposto \\(x = \\theta&#39;_t\\) e la densità della distribuzione a priori in corrispondenza del valore proposto \\(x = \\theta&#39;_t\\). In maniera corrispondente, al denominatore del rapporto \\(r\\) dobbiamo fare il prodotto tra due scalari: la densità (l’ordinata) della funzione di verosimiglianza in corrispondenza del valore \\(\\theta_{t-1}\\) e la densità della distribuzione a priori in corrispondenza del valore \\(\\theta_{t-1}\\). Utilizziamo poi il valore del rapporto \\(r\\) per decidere se dobbiamo effettivamente muoverci nella nuova posizione \\(\\theta&#39;_t\\), oppure se dobbiamo campionare un diverso valore \\(\\theta&#39;_t\\). Per decidere, confrontiamo il valore \\(r\\) con un valore casuale estratto da una distribuzione uniforme che assume valori tra zero e uno: \\(U(0, 1)\\). Se \\(r &gt; u \\sim U(0, 1)\\) allora accettiamo \\(\\theta&#39;_t\\) e la catena si muove in quella nuova posizione, ovvero \\(\\theta_t = \\theta&#39;_t\\). Altrimenti \\(\\theta_t = \\theta_{t-1}\\) e ripetiamo la procedura descritta sopra campionando un nuovo valore \\(\\theta&#39;_t\\). Per fare un esempio concreto, consideriamo nuovamente i 30 pazienti esaminati da Zetsche et al. (2019) e discussi nella sezione Un esempio pratico. Di essi, 23 hanno manifestato delle aspettative distorte negativamente sul loro stato d’animo futuro. Utilizzando l’algoritmo di Metropolis, ci poniamo il problema di ottenere la stima a posteriori di \\(\\theta\\) (probabilità di manifestare un’aspettativa distorta negativamente) dati i 23 “successi” in 30 prove e usando la stessa distribuzione a priori per \\(\\theta\\) che è stata usata nella sezione Un esempio pratico (versione 2). 15.4.3.1 Verosimiglianza Per trovare la funzione di verosimiglianza usando i 30 valori di Zetsche et al. (2019) definisco la funzione likelihood() come indicato sotto. Tale funzione ritorna l’ordinata della funzione di verosimiglianza binomiale per ciascun valore del vettore param che viene dato in input alla funzione. x &lt;- 23 N &lt;- 30 param &lt;- seq(0, 1, length.out = 100) likelihood &lt;- function(param, x = 23, N = 30) { dbinom(x, N, param) } data.frame(x=param, y=likelihood(param)) %&gt;% ggplot(aes(x, y)) + geom_line() + labs( x = expression(theta), y = &quot;Verosimiglianza&quot; ) 15.4.3.2 Distribuzione a priori Se abbiamo ragioni forti per avere delle aspettative rispetto al valore possibile della nostra stima, una distribuzione a priori informativa verrà combinata con le informazioni fornite dal campione per produrre una stima ``razionale’’ a posteriori. Nel caso presente utilizziamo la distribuzione informativa presentata nella sezione Un esempio pratico (versione 2) unicamente a scopo esemplicativo, ovvero per fare in modo da “allontanare” la distribuzione a posteriori dalla distribuzione di verosimiglianza. prior &lt;- function(param, alpha = 2, beta = 10) { param_vals &lt;- seq(0, 1, length.out = 100) dbeta(param, alpha, beta) # / sum(dbeta(param_vals, alpha, beta)) } data.frame(x=param, y=prior(param)) %&gt;% ggplot(aes(x, y)) + geom_line() + labs( x = expression(theta), y = &quot;Densità&quot; ) 15.4.3.3 Distribuzione a posteriori Abbiamo visto in precedenza come la funzione a posteriori è data dal prodotto della densità a priori e della verosimiglianza. posterior &lt;- function(param) { likelihood(param) * prior(param) } data.frame(x=param, y=posterior(param)) %&gt;% ggplot(aes(x, y)) + geom_line() + labs( x = expression(theta), y = &quot;Densità&quot; ) Questo è il risultato che vogliamo ottenere utilizzando l’algoritmo di Metropolis. Dalla figura precedente vediamo che la moda della distribuzione a posteriori è pari a circa 0.6. Questo è il valore più verosimile a posteriori per il parametro \\(\\theta\\). 15.4.3.4 Algoritmo di Metropolis Implementiamo ora l’algoritmo di Metropolis. Utilizziamo una distribuzione proposta gaussiana. Il valore proposto da tale distribuzione ausiliaria corrisponde ad un valore selezionato a caso da una distribuzione gaussiana con media uguale al valore del parametro attualmente considerato nella catena e con una deviazione standard ``adeguata’’. In questo esempio, la deviazione standard è stata scelta empiricamente in modo tale da ottenere un tasso di accettazione sensato. È stato mostrato che un tasso di accettazione ottimale dovrebbe essere tra il 20% e il 30%. Se il tasso di accettazione è troppo grande, infatti, l’algoritmo esplora uno spazio troppo ristretto della distribuzione a posteriori. Il tasso di accettazione è influenzato dalla distribuzione proposta: in generale, tanto più la distribuzione proposta è simile alla distribuzione target, tanto più alto diventa il tasso di accettazione. proposal_distribution &lt;- function(param) { while(1) { res = rnorm(1, mean = param, sd = 0.9) if (res &gt; 0 &amp; res &lt; 1) break } res } In questa implementazione molto semplice della distribuzione proposta ho inserito dei controlli che fanno in modo che il valore proposto da tale distribuzione ausiliaria sia incluso nell’intervallo [0, 1]. Si possono trovare implementazioni migliori di questa idea di quella fornita qui. Ma lo scopo è solo quello di spiegare la struttura logica dell’algoritmo di Metropolis, non quella di proporre un’implementazione efficente dell’algoritmo. Per i nostri scopi, tale implementazione “ingenua” funziona, e tanto basta. L’algoritmo di Metropolis è implementato nella funzione seguente: run_metropolis_MCMC &lt;- function(startvalue, iterations) { chain &lt;- vector(length = iterations + 1) chain[1] &lt;- startvalue for (i in 1:iterations) { proposal &lt;- proposal_distribution(chain[i]) r &lt;- posterior(proposal) / posterior(chain[i]) if (runif(1) &lt; r) { chain[i + 1] &lt;- proposal } else { chain[i + 1] &lt;- chain[i] } } chain } Generiamo dunqe una catena di valori \\(\\theta\\) con le seguenti istruzioni: set.seed(123) startvalue &lt;- runif(1, 0, 1) niter &lt;- 1e4 chain &lt;- run_metropolis_MCMC(startvalue, niter) Otteniamo così 4,000 valori della distribuzione a posteriori per il parametro \\(\\theta\\). Di questi valori, 2,000 vengono considerati burn-in e vengono esclusi. Ci restano dunque con 2,000 stime a posteriori di \\(\\theta\\). Il tasso di accettazione è pari a burnIn &lt;- niter / 2 acceptance &lt;- 1 - mean(duplicated(chain[-(1:burnIn)])) acceptance #&gt; [1] 0.2511498 il che conferma che la deviazione standard che abbiamo scelto per la distribuzione proposta (\\(\\sigma\\) = 0.9) è adeguata. Una figura che rappresenta la distribuzione a posteriori per \\(\\theta\\), insieme alla rappresentazione dei valori della catena di Markov realizzata dall’algoritmo di Metropolis, può essere prodotta mediante le seguenti istruzioni: p1 &lt;- data.frame(x=chain[-(1:burnIn)]) %&gt;% ggplot(aes(x)) + geom_histogram() + labs( x = expression(theta), y = &quot;Frequenza&quot;, title = &quot;Distribuzione a posteriori&quot; ) + geom_vline(xintercept = mean(chain[-(1:burnIn)])) p2 &lt;- data.frame(x=1:length(chain[-(1:burnIn)]), y=chain[-(1:burnIn)]) %&gt;% ggplot(aes(x, y)) + geom_line() + labs( x = &quot;Numero di passi&quot;, y = expression(theta), title = &quot;Valori della catena&quot; ) + geom_hline(yintercept = mean(chain[-(1:burnIn)])) p1 + p2 #&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. A questo punto è molto facile trovare il massimo a posteriori per il parametro \\(\\theta\\): mean(chain[-(1:burnIn)]) #&gt; [1] 0.5921799 Conclusioni Lo scopo di questa discussione è stato quello di mostrare come sia possibile combinare le nostre conoscenze a priori (espresse nei termini di una densità di probabilità) con le evidenze fornite dai dati (espresse nei termini della funzione di verosimiglianza), così da determinare, mediante il teorema di Bayes, una distribuzione a posteriori, la quale condensa l’incertezza che si ha sul parametro \\(\\theta\\). Per illustrare tale problema, nel caso più semplice abbiamo considerato una situazione nella quale \\(\\theta\\) corrisponde alla probabilità di successo in una sequenza di prove Bernoulliane. Abbiamo visto come, in queste circostanze, è ragionevole esprimere le nostre credenze a priori mediante la densità Beta, con opportuni parametri. L’inferenza rispetto ad una proporzione rappresenta un caso particolare, ovvero un caso nel quale la distribuzione a priori è Beta e la verosimiglianza è Binomiale. In tali circostanze, anche la distribuzione a posteriori sarà una distribuzione Beta. Per questa ragione, in questo caso specifico, i parametri della distribuzione a posteriori possono essere determinati analiticamente (la soluzione richiede una serie di passaggi algebrici che qui non vengono discussi). In generale, però, tale approccio non è perseguibile. La determinazione della distribuzione a posteriori richiede il calcolo della funzione di verosimiglianza e dell’integrale che si trova al denominatore del rapporto di Bayes. Nel caso di parametri continui, però, spesso tale integrale può essere impossibile da risolvere analiticamente. In passato, tale difficoltà è stata affrontata limitando l’analisi statistica al caso di funzioni di verosimiglianza semplici, le quali possono essere combinate con distribuzioni a priori coniugate per la verosimiglianza, così da produrre un integrale trattabile. Invece di approcci matematici analitici, un’altra classe di metodi fa ricorso all’approssimazione numerica dell’integrale. Tale approssimazione numerica dipende dall’uso di metodi MCMC, ovvero dipende dall’uso di una classe di algoritmi per il campionamento da distribuzioni di probabilità che sono estremamente onerosi dal punto di vista computazionale e che possono essere utilizzati nelle applicazioni pratiche solo grazie alla grande potenza di calcolo dei moderni computer. Lo sviluppo di software che rendono sempre più semplice l’uso dei metodi MCMC, insieme all’incremento della potenza di calcolo dei computer, ha contribuito a rendere sempre più popolare il metodo dell’inferenza Bayesiana che, in questo modo, può essere estesa a problemi di qualunque grado di complessità. In seguito, quest’idea è stata completamente screditata.↩︎ I metodi di stima MCMC costituiscono la modalità usuale per generare la distribuzione a posteriori nell’analisi Bayesiana. In queste dispense, però, ci limitiamo ai metodi di stima basati sull’approssimazione quadratica. Abbiamo deciso di svolgere gli esercizi mediante l’approssimazione quadratica piuttosto che con il metodo MCMC perché l’installazione sul proprio computer del software necessario per le analisi MCMC costituisce un problema di tipo informatico che esula dagli scopi di questo insegnamento.↩︎ Le analisi Bayesiane che discuteremo in queste dispense, per la maggior parte, faranno uso della funzione quap(). È dunque fondamentale che gli studenti installino il pacchetto rethinking sul loro computer.↩︎ "],["chapter-reglin.html", "Capitolo 16 Regressione lineare semplice Obiettivi di apprendimento Motivazione 16.1 La funzione lineare 16.2 L’errore di misurazione 16.3 Scopi della regressione lineare 16.4 Quantificare l’associazione fra due caratteri quantitativi 16.5 Stime dei minimi quadrati 16.6 Bontà dell’adattamento 16.7 Inferenza sull’associazione tra \\(x\\) e \\(y\\) nella popolazione Considerazioni conclusive", " Capitolo 16 Regressione lineare semplice Obiettivi di apprendimento Lo studio di questo capitolo dovrebbe insegnare allo studente come: Spiegare il concetto di stima dei minimi quadrati. Collegare i concetti di coefficiente angolare del modello lineare di regressione semplice e correlazione di Pearson. Descrivere come possa essere valutata la bontà di adattamento del modello ai dati. Spiegare come si può fare inferenza sull’associazione tra \\(X\\) e \\(Y\\) nella popolazione. Applicare il metodo del test dell’ipotesi nulla alle ipotesi relative ai coefficienti del modello di regressione. Spiegare l’influenza dei punti influenti e dei valori anomali sulla soluzione dei minimi quadrati. Motivazione Lo scopo della ricerca è trovare le associazioni tra le variabili e fare confronti fra le condizioni sperimentali. Nel caso della psicologia, il ricercatore vuole scoprire le leggi generali che descrivono le relazioni tra i costrutti psicologici e le relazioni che intercorrono tra i fenomeni psicologici e quelli non psicologici (sociali, economici, storici, …). Abbiamo già visto come la correlazione di Pearson sia uno strumento adatto a questo scopo. Infatti, essa ci informa sulla direzione e sull’intensità della relazione lineare tra due variabili. Tuttavia, la correlazione non è sufficiente, in quanto il ricercatore ha a disposizione solo i dati di un campione, mentre vorrebbe descrivere la relazione tra le variabili nella popolazione. A causa della variabilità campionaria, le proprietà dei campioni sono necessariamente diverse da quelle della popolazione: ciò che si può osservare nella popolazione potrebbe non emergere nel campione e, al contrario, il campione manifesta caratteristiche che non sono necessariamente presenti nella popolazione. È dunque necessario chiarire, dal punto di vista statistico, il legame che intercorre tra le proprietà del campione e le proprietà della popolazione da cui esso è stato estratto. Come nel caso della media, anche in questo caso dovrà essere costruita la distribuzione di una statistica; ma però, nel caso presente, la statistica di interesse sarà costruita utilizzando, non i dati di una sola variabile, ma bensì i dati che descrivono l’andamento congiunto di due variabili. Il modello di regressione utilizza la funzione matematica più semplice per descrivere la relazione fra due variabili, ovvero la funzione lineare. Inizieremo a descrivere le proprietà geometriche della funzione lineare per poi utilizzare questa semplice funzione per costruire il modello statistico della regressione lineare. 16.1 La funzione lineare Si chiama funzione lineare una funzione del tipo \\[ f(x) = a + b x, \\] dove \\(a\\) e \\(b\\) sono delle costanti. Il grafico di tale funzione è una retta di cui il parametro \\(b\\) è detto coefficiente angolare e il parametro \\(a\\) è detto intercetta con l’asse delle \\(y\\) (infatti, la retta interseca l’asse \\(y\\) nel punto \\((0,a)\\), se \\(b \\neq 0\\)). Per assegnare un’interpretazione geometrica alle costanti \\(a\\) e \\(b\\) si consideri la funzione \\[ y = b x. \\] Tale funzione rappresenta un caso particolare, ovvero quello della proporzionalità diretta tra \\(x\\) e \\(y\\). Il caso generale della linearità \\[ y = a + b x \\] non fa altro che sommare una costante \\(a\\) a ciascuno dei valori \\(y = b x\\). Nella funzione lineare \\(y = a + b x\\), se \\(b\\) è positivo allora \\(y\\) aumenta al crescere di \\(x\\); se \\(b\\) è negativo allora \\(y\\) diminuisce al crescere di \\(x\\); se \\(b=0\\) la retta è orizzontale, ovvero \\(y\\) non muta al variare di \\(x\\). Consideriamo ora il coefficiente \\(b\\). Si consideri un punto \\(x_0\\) e un incremento arbitrario \\(\\varepsilon\\) come indicato nella figura 16.1. Le differenze \\(\\Delta x = (x_0 + \\varepsilon) - x_0\\) e \\(\\Delta y = f(x_0 + \\varepsilon) - f(x_0)\\) sono detti incrementi di \\(x\\) e \\(y\\). Il coefficiente angolare \\(b\\) è uguale al rapporto \\[ b = \\frac{\\Delta y}{\\Delta x} = \\frac{f(x_0 + \\varepsilon) - f(x_0)}{(x_0 + \\varepsilon) - x_0}, \\] indipendentemente dalla grandezza degli incrementi \\(\\Delta x\\) e \\(\\Delta y\\). Il modo più semplice per assegnare un’interpretazione geometrica al coefficiente angolare (o pendenza) della retta è dunque quello di porre \\(\\Delta x = 1\\). In tali circostanze infatti \\(b = \\Delta y\\). Figura 16.1: La funzione lineare \\(y = a + bx\\). 16.2 L’errore di misurazione Per descrivere l’associazione tra due variabili, tuttavia, la funzione lineare non è sufficiente. Nel mondo empirico, infatti, la relazione tra variabili non è mai perfettamente lineare. È dunque necessario includere nel modello di regressione anche una componente d’errore, ovvero una componente della \\(y\\) che non può essere spiegata dal modello lineare. Nel caso di due sole variabili, questo ci conduce alla seguente formulazione del modello di regressione: \\[\\begin{equation} y = \\alpha + \\beta x + \\varepsilon, \\tag{16.1} \\end{equation}\\] laddove i parametri \\(\\alpha\\) e \\(\\beta\\) descrivono l’associazione tra le variabili aleatorie \\(y\\) e \\(x\\) (nella popolazione), e il termine d’errore \\(\\varepsilon\\) specifica quant’è grande la porzione della variabile \\(y\\) che non può essere predetta nei termini di una relazione lineare con la \\(x\\). Si noti che l’eq. (16.1) ci consente di formulare una predizione, nei termini di un modello lineare, del valore atteso della \\(y\\) conoscendo \\(x\\), ovvero \\[\\begin{equation} \\hat{y} = \\mathbb{E}(y \\mid x) = \\alpha + \\beta x. \\tag{16.2} \\end{equation}\\] In altri termini, se i parametri del modello (\\(\\alpha\\) e \\(\\beta\\)) sono noti, allora è possibile predire \\(y\\) sulla base della nostra conoscenza della \\(x\\). Per esempio, se conosciamo la relazione lineare tra quoziente di intelligenza ed aspettativa di vita, allora possiamo prevedere quanto a lungo vivrà una persona sulla base del suo QI. Sì, c’è una relazione lineare tra intelligenza e aspettativa di vita! – per una discussione, si veda, ad esempio, l’articolo di David Z. Hambrick pubblicato su Scientific American il 22 dicembre 2015. Ma quando sarà accurata la nostra previsione? Ciò dipende dal termine d’errore dell’eq. (16.1). L’analisi di regressione ci fornisce un metodo per rispondere a domande di questo tipo. 16.3 Scopi della regressione lineare Il modello di regressione lineare si pone tre obiettivi: descrivere l’associazione tra le variabili \\(x\\) e \\(y\\) nel campione esaminato; misurare la bontà dell’adattamento dell’associazione tra \\(x\\) e \\(y\\); fare inferenze sull’associazione tra \\(x\\) e \\(y\\) nella popolazione da cui il campione è stato estratto. Il primo obiettivo intende rispondere alla stessa domanda a cui risponde il coefficiente di correlazione: quali sono l’intensità e il segno della relazione lineare che descrive l’associazione tra due variabili? Vedremo che c’è una precisa relazione tra il coefficiente \\(b\\) del modello di regressione (che rappresenta la pendenza della retta di regressione) e il coefficiente di correlazione \\(r\\) di Pearson: il coefficiente di correlazione non è altro che la pendenza della retta di regressione quando i dati sono standardizzati. Vi è però un’importante differenza tra la correlazione ed il modello di regressione. La correlazione è un indicatore simmetrico di associazione tra due caratteri. Il modello di regressione, invece, si chiede come varia una variabile, detta dipendente e solitamente denotata con \\(y\\), al variare di un’altra variabile, detta indipendente (o predittore), solitamente denotata con \\(x\\). L’analisi della regressione lineare si pone dunque il problema di studiare la relazione asimmetrica tra due variabili. Il secondo obiettivo del modello di regressione lineare si chiede se il modello di regressione sia sensato per descrivere l’associazione osservata tra le due variabili. Vogliamo trovare un indice che descriva quanto distanti sono i dati dalla retta di regressione. Se i punti di un diagramma a dispersione sono molto vicini alla retta di regressione, allora il modello di regressione è adeguato per descrivere l’associazione tra le due variabili. In questo caso la bontà di adattamento del modello ai dati è grande. Oppure può succedere che i punti di un diagramma a dispersione siano molto lontani alla retta di regressione e/o che la retta di regressione sia piatta. In questi due ultimi casi non vi è evidenza di una associazione lineare tra le due variabili e l’indice che misura la bontà dell’adattamento dell’associazione tra \\(x\\) e \\(y\\) assume un valore basso e prossimo allo zero. Tale indice va sotto il nome di coefficiente di determinazione. Il terzo obiettivo è quello più ambizioso: ci chiediamo quale potrebbe essere l’associazione tra le variabili \\(x\\) e \\(y\\) nella popolazione, alla luce delle informazioni che sono state osservate nel campione. Quello che vorremmo conoscere è \\(p(\\theta \\mid \\text{dati})\\), laddove \\(\\theta\\) è il parametro sconosciuto che rappresenta la pendenza della retta di regressione nella popolazione. Vedremo come l’approccio Bayesiano può essere usato per rispondere a questa domanda. Il modello di regressione è, probabilmente, il più importante dei modelli statistici. Noi qui ne esamineremo solo le sue caratteristiche di base. Ma tale modello può essere esteso in modo tale da includere più di un predittore (nel qual caso si parla di modello di regressione multipla), oppure una variabile dipendente qualitativa (il che produce il modello di regressione logistica), oppure molteplici variabili dipendenti continue (il che produce il modello di regressione multivariato). Sviluppi più moderni di questo modello considerano inoltre il caso della violazione dell’assunzione di indipendenza tra le osservazioni, il che conduce alla costruzione dei modelli ad effetti misti (mixed-effects models). Infine, uno sviluppo importante del modello di regressione lineare è l’analisi fattoriale, nel qual caso viene ipotizzata l’esistenza di variabili indipendenti inosservabili (latenti), le quali corrispondono ai costrutti psicologici. Il modello fattoriale, così formulato, costituisce il fondamento della Psicometria, ovvero di quelle tecniche statistiche che stanno alla base della costruzione e della validazione dei reattivi psicologici. 16.4 Quantificare l’associazione fra due caratteri quantitativi Consideriamo tre variabili aleatorie \\(X\\), \\(Y\\) ed \\(\\varepsilon\\) legate dalla relazione lineare \\[ y = \\alpha + \\beta x + \\varepsilon, \\] dove \\(\\alpha\\) e \\(\\beta\\) sono numeri reali e \\(\\mathbb{E}(\\varepsilon) = 0\\). Chiameremo modello lineare (semplice) la relazione dell’eq. (16.1) e chiameremo retta di regressione la retta \\[\\begin{equation} y = \\alpha + \\beta x. \\tag{16.3} \\end{equation}\\] Il parametro \\(\\alpha\\) è l’ordinata all’origine (o intercetta) mentre il parametro \\(\\beta\\) è il coefficiente angolare della retta. Possiamo interpretare l’eq. (16.1) pensando che le variabili aleatorie \\(x\\) ed \\(y\\) siano legate tra loro da una relazione lineare perturbata da un errore casuale \\(\\varepsilon\\). Dato un insieme di realizzazioni campionarie delle variabili aleatorie \\(x\\) e \\(y\\), ci poniamo lo scopo di determinare la retta di regressione campionaria \\[\\begin{equation} \\hat{y}_i = a + b x_i \\tag{16.4} \\end{equation}\\] che approssima il meglio possibile la distribuzione dei punti \\(x_i\\), \\(y_i\\), \\(i = 1, \\dots, n\\). Lo studio di questo problema è detto regressione lineare. 16.5 Stime dei minimi quadrati Il primo obiettivo dell’analisi di regressione è quello di trovare la retta che meglio descrive l’andamento dei dati osservati in un campione. Iniziamo con il definire i residui \\(e_i\\) tramite la relazione \\[\\begin{equation} e_i = y_i - (a + b x_i). \\tag{16.5} \\end{equation}\\] In altri termini, il residuo \\(i\\)-esimo è la differenza fra l’ordinata del punto (\\(x_i\\), \\(y_i\\)) e quella del punto di ascissa \\(x_i\\) sulla retta di regressione campionaria. Per determinare i coefficienti \\(a\\) e \\(b\\) della retta (16.4) non è sufficiente minimizzare la somma dei residui \\(\\sum_{i=1}^{n}e_i\\), in quanto i residui possono essere sia positivi che negativi e la loro somma può essere molto prossima allo zero anche per differenze molto grandi tra i valori osservati e la retta di regressione. Infatti, ciascuna retta passante per il punto (\\(\\bar{x}, \\bar{y}\\)) ha \\(\\sum_{i=1}^{n}e_i=0\\). Dimostrazione. Una retta passante per il punto (\\(\\bar{x}, \\bar{y}\\)) soddisfa l’equazione \\(\\bar{y} = a + b \\bar{x}\\). Sottraendo tale equazione dall’equazione \\(y_i = a + b x_i + e_i\\) otteniamo \\[ y_i - \\bar{y} = b (x_i - \\bar{x}) + e_i. \\] Sommando su tutte le osservazioni, si ha che \\[ \\sum_{i=1}^n e_i = \\sum_{i=1}^n (y_i - \\bar{y} ) - b \\sum_{i=1}^n (x_i - \\bar{x}) = 0 - b(0) = 0. \\] Questo problema viene risolto scegliendo i coefficienti \\(a\\) e \\(b\\) che minimizzano, non tanto la somma dei residui, ma bensì l’errore quadratico, cioè la somma dei quadrati degli errori: \\[ S(a, b) = \\sum_{i=1}^{n} e_i^2 = \\sum (y_i - a - b x_i)^2. \\] Il metodo più diretto per determinare quelli che vengono chiamati i coefficienti dei minimi quadrati è quello di trovare le derivate parziali della funzione \\(S(a, b)\\) rispetto ai coefficienti \\(a\\) e \\(b\\): \\[\\begin{equation} \\begin{aligned} \\frac{\\partial S(a,b)}{\\partial a} &amp;= \\sum (-1)(2)(y_i - a - b x_i), \\notag \\\\ \\frac{\\partial S(a,b)}{\\partial b} &amp;= \\sum (-x_i)(2)(y_i - a - b x_i). \\end{aligned} \\tag{16.6} \\end{equation}\\] Ponendo le derivate uguali a zero e dividendo entrambi i membri per \\(-2\\) si ottengono le equazioni normali \\[\\begin{equation} \\begin{aligned} an + b \\sum x_i &amp;= \\sum y_i, \\notag \\\\ a \\sum x_i + b \\sum x_i^2 &amp;= \\sum x_i y_i. \\end{aligned} \\tag{16.7} \\end{equation}\\] I coefficienti dei minimi quadrati \\(a\\) e \\(b\\) si trovano risolvendo le equazioni (16.7) e sono uguali a: \\[\\begin{equation} \\begin{aligned} a &amp;= \\bar{y} - b \\bar{x},\\\\ b &amp;= \\frac{\\sum (x_i - \\bar{x}) (y_i - \\bar{y})}{\\sum (x_i - \\bar{x})^2}. \\end{aligned} \\tag{16.8} \\end{equation}\\] 16.5.1 Un esempio concreto Consideriamo i dati relativi a 34 coppie di gemelli monozigoti separati alla nascita (Anderson &amp; Finn (2012)). Dei gemelli conosciamo l’ordine della nascita e il quoziente di intelligenza misurato con il Dominoes Intelligence test. Il test è costituito da 48 domande a ciascuna delle quali viene assegnato un punto nel caso di risposta corretta. La media del test nella popolazione è di 28 punti, che corrisponde al punteggiodi 100 sulla scala WAIS. I dati sono: iq1 &lt;- c(22, 32, 29, 13, 32, 24, 33, 19, 13, 36, 26, 26, 32, 27, 6, 16, 41, 29, 13, 20, 28, 30, 22, 23, 27, 40, 30, 30, 21, 27, 15, 38, 4, 12) iq2 &lt;- c(12, 28, 35, 4, 18, 33, 26, 9, 22, 34, 17, 20, 33, 28, 10, 28, 40, 30, 10, 24, 22, 34, 23, 21, 25, 38, 25, 26, 27, 24, 9, 27, 2, 9) df &lt;- data.frame(iq1, iq2) Un diagramma di dispersione per questi dati, insieme alla retta di regressione dei minimi quadrati, è riportato nella figura 16.2. p &lt;- df %&gt;% ggplot(aes(x = iq1, y = iq2)) + geom_smooth(method = &quot;lm&quot;, se=FALSE, color=&quot;lightgrey&quot;, formula = y ~ x) + geom_point() + labs( x = &quot;Qi primo nato&quot;, y = &quot;QI secondo nato&quot;, title = &quot;Gemelli monozigoti separati alla nascita&quot;, caption = &quot;(Fonte: Anderson e Finn, 2012)&quot; ) p Figura 16.2: Retta di regressione che descrive la relazione lineare tra il quoziente di intelligenza del secondo nato e il quoziente di intelligenza del primo nato. I coefficienti di regressione si trovano con le formule dei minimi quadrati. Usando R, per \\(b\\) otteniamo b &lt;- cov(df$iq1, df$iq2) / var(df$iq1) b #&gt; [1] 0.8498545 e per \\(a\\) otteniamo a &lt;- mean(df$iq2) - b * mean(df$iq1) a #&gt; [1] 1.838871 Tali risultati corrispondono ai valori trovati dalla funzione lm() con la seguente sintassi: fm &lt;- lm(iq2 ~ iq1, data = df) L’oggetto creato da {lm() può essere visionato utilizzando coef(fm) o con summary(fm). summary(fm) #&gt; #&gt; Call: #&gt; lm(formula = iq2 ~ iq1, data = df) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -11.0342 -3.8218 -0.5852 3.4658 12.5635 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 1.8389 3.0269 0.608 0.548 #&gt; iq1 0.8499 0.1155 7.357 2.29e-08 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 6.102 on 32 degrees of freedom #&gt; Multiple R-squared: 0.6285, Adjusted R-squared: 0.6169 #&gt; F-statistic: 54.13 on 1 and 32 DF, p-value: 2.288e-08 I valori predetti dal modello di regressione sono dati da yhat &lt;- a + b * df$iq1 o, in maniera equivalente, possono essere trovati con predict(fm) predict(fm) #&gt; 1 2 3 4 5 6 7 8 9 #&gt; 20.535671 29.034216 26.484652 12.886980 29.034216 22.235380 29.884070 17.986107 12.886980 #&gt; 10 11 12 13 14 15 16 17 18 #&gt; 32.433634 23.935089 23.935089 29.034216 24.784943 6.937998 15.436543 36.682907 26.484652 #&gt; 19 20 21 22 23 24 25 26 27 #&gt; 12.886980 18.835962 25.634798 27.334507 20.535671 21.385525 24.784943 35.833052 27.334507 #&gt; 28 29 30 31 32 33 34 #&gt; 27.334507 19.685816 24.784943 14.586689 34.133343 5.238289 12.037125 I residui di regressione, ovvero la differenza tra il valore osservato e il valore predetto dal modello, si trovano mediante l’istruzione e &lt;- df$iq2 - yhat o, in maniera equivalente, con residuals(fm) residuals(fm) #&gt; 1 2 3 4 5 6 7 #&gt; -8.5356706 -1.0342160 8.5153476 -8.8869798 -11.0342160 10.7646203 -3.8840705 #&gt; 8 9 10 11 12 13 14 #&gt; -8.9861070 9.1130202 1.5663659 -6.9350888 -3.9350888 3.9657840 3.2150567 #&gt; 15 16 17 18 19 20 21 #&gt; 3.0620019 12.5634566 3.3170932 3.5153476 -2.8869798 5.1640385 -3.6347978 #&gt; 22 23 24 25 26 27 28 #&gt; 6.6654931 2.4643294 -0.3855252 0.2150567 2.1669478 -2.3345069 -1.3345069 #&gt; 29 30 31 32 33 34 #&gt; 7.3141839 -0.7849433 -5.5866889 -7.1333432 -3.2382890 -3.0371253 I residui possono essere rappresentanti graficamente come riportato nella figura 16.3. df$predicted &lt;- predict(fm) df$residuals &lt;- residuals(fm) p1 &lt;- df %&gt;% ggplot(aes(x = iq1, y = iq2)) + geom_smooth(method = &quot;lm&quot;, se = FALSE, color = &quot;lightgrey&quot;) + geom_segment(aes(xend = iq1, yend = predicted), alpha = .2) + geom_point() + geom_point(aes(y = predicted), shape = 1) + labs( x = &quot;Qi primo nato&quot;, y = &quot;QI secondo nato&quot;, title = &quot;Gemelli monozigoti separati alla nascita&quot;, caption = &quot;(Fonte: Anderson e Finn, 2012)&quot; ) p1 #&gt; `geom_smooth()` using formula &#39;y ~ x&#39; Figura 16.3: Residui del modello di regressione che esprime il quoziente di intelligenza del secondo nato in funzione del quoziente di intelligenza del primo nato. 16.5.2 Coefficiente angolare e correlazione di Pearson Ricordando che \\(r_{xy}=s_{xy} / (s_x s_y)\\) è il coefficiente di correlazione lineare e che \\(b=s_{xy} /s_x^2\\) è la stima dei minimi quadrati del coefficiente angolare della retta di regressione, sostituendo \\(r_{xy}s_xs_y\\) al numeratore dell’equazione di \\(b\\) e semplificando, si ottiene \\[\\begin{equation} b = r_{yx}\\frac{s_y}{s_x}. \\end{equation}\\] Se i dati vengono standardizzati, dunque, l’equazione della retta di regressione campionaria diventa \\[\\begin{equation} z_{y_i} = r_{xy} z_{x_i} + e_i, \\end{equation}\\] in quanto \\(a = \\bar{z}_y - b\\bar{z}_x =0\\) e \\(s_x = s_y = 1\\). Si può dunque assegnare al coefficiente di correlazione di Pearson la seguente interpretazione: \\(r_{xy}\\) è uguale alla pendenza \\(b\\) della retta di regressione quando le variabili \\(x\\) e \\(y\\) vengono standardizzate (Rodgers &amp; Nicewander, 1988). Facciamo un esempio calcolando i coefficienti di regressione sui punteggi standardizzati del quoziente di intelligenza dei gemelli monozigoti. ziq1 &lt;- scale(df$iq1) ziq2 &lt;- scale(df$iq2) fm1 &lt;- lm(ziq2 ~ ziq1) coef(fm1) #&gt; (Intercept) ziq1 #&gt; 1.818206e-16 7.927594e-01 Utilizzando i valori standardizzati del QI l’intercetta diventa pari a zero e la pendenza della retta di regressione diventa uguale alla correlazione tra le due variabili: cor(df$iq1, df$iq2) #&gt; [1] 0.7927594 16.5.3 Regressione verso la media Il termine regressione fu introdotto da Francis Galton (1822-1911), un antropologo che fu, tra le altre cose, promotore dell’eugenetica. Nel 1886, nell’ambito dei suoi studi sull’ereditarietà dei caratteri, Galton raccolse le stature di \\(928\\) figli adulti e dei loro \\(205\\) genitori (padri e madri) – i dati sono disponibili nel data.frame Galton contenuto nel pacchetto R HistData. Galton esaminò la relazione tra l’altezza media dei figli e l’altezza media dei genitori, che chiamò “mid-parent height.” In questi dati, genitori e figli hanno la stessa altezza media di \\(68.2\\) pollici. Galton osservò però come l’altezza media dei figli nati da genitori di una data altezza era più simile al valore dell’altezza media della popolazione intera di quanto lo fosse la mid-height dei genitori. Ad esempio, per genitori con una mid-height compresa tra \\(70\\) e \\(71\\) pollici, l’altezza media dei figli risultò essere di \\(69.5\\) pollici. Nelle parole di Galton, questo corrispondeva ad una regression toward mediocrity, un concetto che noi oggi chiamiamo “regressione verso la media.” Nonostante l’interpretazione (errata) di Galton, è importante capire come questo sia un fenomeno statistico, non genetico. Esaminiamo la ragione per cui ciò si verifica. In precedenza abbiamo visto come, nel caso di dati standardizzati, la retta di regressione campionaria diventa: \\[\\hat{z}_{y_i} = r_{xy} z_{x_i}.\\] Dal momento che \\(r_{xy}\\) è il coefficiente di regressione, esso assume valori compresi tra \\(-1\\) e \\(1\\). Assumiamo che \\(r_{xy}\\) sia positivo e minore di \\(1\\) (ovvero, assumiamo che la correlazione tra \\(x\\) e \\(y\\) sia positiva ma non perfetta). La formula \\(\\hat{z}_{y_i} = r_{xy} z_{x_i}\\) implica che, se \\(z_{x_i}\\) è positivo, allora il valore predetto \\(\\hat{z}_{y_i}\\) dovrà essere minore di \\(z_{x_i}\\). In maniera equivalente, si può dire che la ‘distanza’ tra il valore predetto \\(\\hat{y}\\) della variabile di risposta e la media \\(\\bar{y}\\) tenderà ad essere minore della distanza tra \\(x\\) e \\(\\bar{x}\\): \\[ \\frac{\\hat{y} - \\bar{y}}{s_y} &lt; \\frac{x - \\bar{x}}{s_x}. \\] Il termine ‘distanza’ è stato messo tra virgolette in quanto è necessario tenere in considerazione l’unità di misura delle variabili. Per fare questo, la distanza tra le osservazioni e il centro della distribuzione viene misurata solo dopo avere standardizzato le variabili – ovvero, viene misurata in unità di deviazioni standard. 16.5.4 Punti influenti e valori anomali La soluzione dei minimi quadrati è fortemente influenzata dalla presenza di punti influenti che sono anche delle osservazioni anomale. Un’osservazione anomala è un’osservazione con un residuo elevato (ovvero, avente un valore anomalo di \\(y\\) rispetto alla previsione). Un punto di leva è un punto con un valore anomalo \\(x\\). Un punto influente è un’osservazione che influenza in maniera rilevante le stime dei minimi quadrati. Non sempre un punto anomalo è anche un punto influente. Per contro esistono punti non anomali che influiscono notevolmente sulle stime dei minimi quadrati – si veda la Figura 16.4. Figura 16.4: Osservazioni anomale e osservazioni influenti. 16.6 Bontà dell’adattamento Il secondo obiettivo dell’analisi della regressione è quello di misurare la bontà di adattamento del modello di regressione ai dati. 16.6.1 Errore standard della stima Un indice assoluto della bontà di adattamento è fornito dalla deviazione standard dei residui, \\(s_e\\), chiamata anche errore standard della stima. Uno stimatore non distorto della varianza dei residui nella popolazione è dato da \\[\\begin{equation} s^2_e = \\frac{\\sum e_i^2}{n-2} \\tag{16.9} \\end{equation}\\] e quindi l’errore standard della stima sarà \\[\\begin{equation} s_e = \\sqrt{\\frac{\\sum e_i^2}{n-2}}. \\tag{16.10} \\end{equation}\\] Dato che \\(s_e\\) è possiede la stessa unità di misura della variabile \\(y\\), l’errore standard della stima può essere considerato come una sorta di “residuo medio.” Consideriamo nuovamente l’esempio dei gemelli monozigoti separati alla nascita. L’errore standard della regressione sqrt(sum(e^2) / (length(e) - 2)) #&gt; [1] 6.101646 è simile, anche se non identico, al valore medio dei residui mean(abs(fm$residuals)) #&gt; [1] 4.91695 In conclusione, se usiamo la retta di regressione per predire il quoziente di intelligenza del gemello nato per secondo a partire dal quoziente di intelligenza del gemello nato per primo compiamo, in media, un errore di circa 6 punti. 16.6.2 Indice di determinazione Un importante risultato dei minimi quadrati riguarda la cosiddetta scomposizione della devianza di regressione mediante la quale si definisce l’indice di determinazione, il quale fornisce una misura relativa della bontà di adattamento del modello di regressione ai dati del campione. Come indicato nella figura 16.5, per una generica osservazione \\(x_i, y_i\\), la variazione di \\(y_i\\) rispetto alla media \\(\\bar{y}\\) può essere descritta come la somma di due componenti: il residuo \\(e_i=y_i- \\hat{y}_i\\) e lo scarto di \\(\\hat{y}_i\\) rispetto alla media \\(\\bar{y}\\): \\(y_i - \\bar{y} = (y_i- \\hat{y}_i) + (\\hat{y}_i - \\bar{y}) = e_i + (\\hat{y}_i - \\bar{y})\\). Figura 16.5: Scomposizione della devianza. Se consideriamo tutte le osservazioni, la devianza delle \\(y\\) può essere scomposta nel seguente modo: \\[ \\begin{aligned} \\sum (y_i - \\bar{y})^2 &amp;= \\sum \\left[ e_i + (\\hat{y}_i - \\bar{y}) \\right]^2 = \\sum e_i^2 + \\sum (\\hat{y}_i - \\bar{y})^2 + 2 \\sum e_i (\\hat{y}_i - \\bar{y}) \\notag\\end{aligned} \\] Per i vincoli imposti sui residui dalle equazioni normali, il doppio prodotto si annulla, infatti \\[ \\begin{aligned} \\sum e_i (\\hat{y}_i - \\bar{y}) &amp;= \\sum e_i \\hat{y}_i - \\bar{y}\\sum e_i = \\sum e_i (a + b x_i) \\notag \\\\ &amp;= a \\sum e_i + b \\sum e_i x_i = 0 \\notag\\end{aligned} \\] Di conseguenza, possiamo concludere che la devianza totale (\\(\\dev_T\\)) si scompone nella somma della devianza di dispersione (\\(dev_E\\)) e della devianza di regressione (\\(\\dev_T\\)): \\[ \\begin{aligned} \\underbrace{\\sum_{i=1}^n (y_i - \\bar{y})^2}_{\\tiny{\\text{Devianza totale}}} &amp;= \\underbrace{\\sum_{i=1}^n e_i^2}_{\\tiny{\\text{Devianza di dispersione}}} + \\underbrace{\\sum_{i=1}^n (\\hat{y}_i - \\bar{y})^2}_{\\tiny{\\text{Devianza di regressione}}} \\notag \\end{aligned} \\] La devianza di regressione, \\(dev_R \\triangleq dev_T - dev_E\\), indica dunque la riduzione degli errori al quadrato che è imputabile alla regressione lineare. Il rapporto \\(dev_T/dev_T\\), detto indice di determinazione, esprime tale riduzione degli errori in termini proporzionali e definisce il coefficiente di correlazione al quadrato: \\[\\begin{equation} r^2 \\triangleq \\frac{dev_R}{dev_T} = 1 - \\frac{dev_E}{dev_T}. \\tag{16.11} \\end{equation}\\] Quando l’insieme di tutte le deviazioni della \\(y\\) dalla media è spiegato dall’insieme di tutte le deviazioni della variabile teorica \\(\\hat{y}\\) dalla media, si ha che l’adattamento (o accostamento) del modello al campione di dati è perfetto, la devianza residua è nulla ed \\(r^2 = 1\\); nel caso opposto, la variabilità totale coincide con quella residua, per cui \\(r^2 = 0\\). Tra questi due estremi, \\(r\\) indica l’intensità della relazione lineare tra le due variabili e \\(r^2\\), con \\(0 \\leq r^2 \\leq 1\\), esprime la porzione della devianza totale della \\(y\\) che è spiegata dalla regressione lineare sulla \\(x\\). Per i dati dei gemelli monozitoti separati alla nascita, la devianza totale si scompone nelle componenti di “devianza spiegata” e “devianza non spiegata” nel modo seguente: dev_t &lt;- sum((df$iq2 - mean(df$iq2))^2) dev_r &lt;- sum((yhat - mean(df$iq2))^2) dev_e &lt;- sum((df$iq2 - yhat)^2) le quali assumono i valori, rispettivamente, pari a \\(3206.618\\), \\(2015.255\\) e \\(1191.363\\). Ne segue che il coefficiente di determinazione è dev_r / dev_t = 0.628, ovvero 1 - dev_e / dev_t = 0.628. Questo risultato coincide con quello trovato con lm(): summary(fm)$r.squared #&gt; [1] 0.6284675 Possiamo quindi concludere che, nel caso del campione esaminato, i fattori genetici spiegano circa il 63% della varianza del quoziente di intelligenza dei gemelli monozigoti (quando prevediamo il QI dei secondi nati dal QI dei primi nati). 16.7 Inferenza sull’associazione tra \\(x\\) e \\(y\\) nella popolazione Il terzo obiettivo dell’analisi di regressione è quello di fare inferenze sull’associazione tra le due variabili nella popolazione da cui il campione deriva. Ci chiediamo se l’associazione osservata nel campione rifletta le proprietà della popolazione oppure sia imputabile agli errori di campionamento. Se si segue la scuola frequentista, nella regressione bivariata il problema dell’inferenza statistica è basato sulla stessa logica seguita nel caso di una singola variabile aleatoria. Nell’inferenza su una media, per esempio, viene valutata l’ipotesi nulla \\(H_0: \\mu=0\\) e il parametro di interesse, la media \\(\\mu\\) della popolazione, viene stimato mediante un’opportuna statistica, ovvero la media campionaria \\(\\bar{y}\\). Le inferenze statistiche sono basate sulla conoscenza delle proprietà della distribuzione della statistica campionaria \\(\\bar{y}\\). È possibile però anche definire degli stimatori che dipendono da due (o più) caratteri. Per esempio, il coefficiente \\(b\\) della retta di regressione campionaria, che viene usato quale stimatore del coefficiente angolare \\(\\beta\\) della funzione di regressione nella popolazione \\(y = \\alpha + \\beta x + \\varepsilon\\), è definito rispetto a due caratteri, \\(x\\) e \\(y\\). Per ciascun campione casuale di \\(n\\) osservazioni \\(x, y\\), lo stimatore \\(b\\) di \\(\\beta\\) assume un diverso valore (\\(b\\) è una variabile aleatoria). L’insieme delle stime \\(b\\) di \\(\\beta\\) nell’universo dei campioni di ampiezza \\(n\\) costituisce la distribuzione campionaria di \\(b\\). Analogamente si può dire dello stimatore \\(a\\) di \\(\\alpha\\). Il problema che ci poniamo ora è appunto quello di descrivere le proprietà delle distribuzioni campionarie dei due stimatori dei minimi quadrati \\(a\\) e \\(b\\). Per fare questo, dobbiamo però prima introdurre il modello statistico della regressione lineare. 16.7.1 Modello statistico di regressione lineare In corrispondenza di a ciascun valore della variabile \\(x\\), che si ipotizza essere costante da campione a campione, corrisponde nella popolazione una distribuzione di valori \\(y\\). Ci chiediamo che relazione intercorra tra le medie condizionali \\(\\bar{y}_i \\mid x_i\\) e la variabile \\(x\\). Se disponiamo di un campione di ciascuna distribuzione condizionata \\(y_i \\mid x_i\\), allora possiamo calcolare la media condizionale nel campione per stimare la corrispondente media nella popolazione. Una tale situazione si può verificare in un contesto sperimentale, in cui, mantenendo fissi i valori del carattere \\(x\\), la ripetizione delle prove produce un campione del carattere \\(y\\) subordinatamente ad ogni \\(x\\). Nel caso di dati di tipo osservazionale, invece, vengono osservate coppie di valori (\\(x_i, y_i\\)), con \\(i=1, \\dots, n\\), e per ogni valore \\(x\\) si ha a disposizione un unico valore \\(y\\). Allo scopo di attenuare le conseguenze derivanti dalle limitazioni di cui soffrono i dati a disposizione, si definisce il modello statistico di regressione lineare introducendo nell’analisi delle ipotesi sulla popolazione. Il modello statistico di regressione è basato sulle quattro seguenti ipotesi a proposito della struttura della popolazione. La funzione di regressione è lineare (linearità): \\[ \\mathbb{E}(y_i \\mid x_1, \\dots, x_n) = \\alpha + \\beta x_i, \\quad i=1, \\dots, n, \\] ovvero, le medie delle distribuzioni condizionali \\(y \\mid x_i\\) sono linearmente associate alla variabile esplicativa x. Le varianze delle distribuzioni condizionali \\(y \\mid x_i\\) sono costanti al variare della \\(x\\) (omoschedasticità): \\[ var(y_i \\mid x_1, \\dots, x_n) = \\sigma^2, \\quad i=1, \\dots, n. \\] Le osservazioni \\(y_i\\) sono tra loro incorrelate subordinatamente alle \\(x_i\\) (indipendenza): \\[ cov(y_i, y_j \\mid x_1, \\dots, x_n) = 0, \\quad per \\hskip.1 in i \\neq j, \\] ovvero, l’osservazione \\(y_i\\) è selezionata dalla distribuzione condizionale \\(y_i \\mid x_i\\) tramite un campionamento casuale indipendente. La distribuzione di \\(y_i\\) subordinata a \\(X=x_i\\) segue la distribuzione gaussiana (normalità): \\[ (y_i \\mid x_i) \\sim \\mathcal{N}(\\alpha+\\beta x_i, \\sigma^2). \\] 16.7.2 Proprietà degli stimatori dei minimi quadrati Può essere dimostrato (vedi Appendici) che, se le assunzioni del modello lineare sono soddisfatte, allora i coefficienti dei minimi quadrati avranno le seguenti proprietà: \\[\\begin{equation} \\begin{aligned} b &amp;\\sim \\mathcal{N}\\bigg(\\beta, \\frac{\\sigma^2_{\\varepsilon}}{\\sum(x_i-\\bar{x})^2}\\bigg),\\\\ a &amp;\\sim \\mathcal{N}\\bigg(\\alpha, \\frac{\\sigma^2_{\\varepsilon}\\textstyle\\sum x_i^2}{n \\textstyle\\sum (x_i-\\bar{x})^2} \\bigg). \\end{aligned} \\tag{16.12} \\end{equation}\\] 16.7.3 Le inferenze sul modello di regressione L’inferenza statistica sul modello di regressione può essere svolta in modi diversi. Esamineremo qui l’approccio frequentista per affrontare in seguito l’approccio Bayesiano. L’inferenza statistica frequentista si articola nella formulazione degli intervalli di confidenza per i parametri di interesse e nei test di significatività statistica. Un’ipotesi che viene frequentemente sottoposta a verifica è quella di significatività, cioè l’ipotesi che alla variabile esplicativa sia associato un coefficiente nullo. In tal caso, l’ipotesi nulla è \\[ H_0:\\beta=0 \\] e l’ipotesi alternativa è \\[ H_1:\\beta \\neq 0. \\] Sotto l’ipotesi nulla \\(H_0: \\beta = 0\\) la statistica \\[ t_{\\hat{\\beta}} = \\frac{\\hat{\\beta}}{s_{\\hat{\\beta}}} \\] si distribuisce come una variabile aleatoria \\(t\\) di Student con \\(n-2\\) gradi di libertà. Di fronte al problema di decidere se il valore stimato \\(\\hat{\\beta}\\) sia sufficientemente ‘distante’ da zero, in modo da respingere l’ipotesi nulla che il vero valore \\(\\beta\\) sia nullo, non è sufficiente basarsi soltanto sul valore numerico assunto da \\(\\hat{\\beta}\\), ma occorre tener conto della variabilità campionaria. La statistica ottenuta dividendo \\(\\hat{\\beta}\\) per la stima del suo errore standard, \\(s_{\\hat{\\beta}}\\), ci permette di utilizzare la distribuzione \\(t\\) di Student come metrica per stabilire se la stima trovata si debba considerare ‘diversa’ da quanto ipotizzato sotto \\(H_0\\). L’ipotesi nulla viene rifiutata quando il valore assoluto del rapporto è esterno alla regione di accettazione, i cui limiti sono definiti dai valori critici della distribuzione \\(t\\) di Student con \\(n - 2\\) gradi di libertà per il livello di significatività \\(\\alpha\\) prescelto. Se l’ipotesi nulla viene rifiutata si dice che il coefficiente \\(\\hat{\\beta}\\) è “statisticamente significativo” ammettendo così la possibilità di descrivere con un modello lineare la relazione esistente tra le variabili \\(x\\) e \\(y\\). Quando non si può rifiutare l’ipotesi nulla nel modello di regressione, si conclude che il coefficiente angolare della retta non risulta significativamente diverso da zero, individuando così nella popolazione una retta parallela all’asse delle ascisse. Il valore-\\(p\\) esprime la probabilità di ottenere un valore del test uguale o superiore a quello ottenuto nel campione esaminato, utilizzando la distribuzione campionaria del test sotto l’ipotesi nulla. Se \\(t_{\\hat{\\beta}}\\) è il valore osservato del rapporto \\(t\\) per il coefficiente angolare della retta di regressione, allora il \\(p\\)-valore è dato da \\[p = 2 \\times Pr(t \\geq |t_{\\hat{\\beta}}|),\\] dove \\(t\\) è il valore di una variabile aleatoria \\(t\\) di Student con \\((n-2)\\) gradi di libertà. Ogni volta che il \\(p\\)-valore del test è inferiore al livello di significatività che si è scelto per \\(H_0\\), il test porta al rifiuto dell’ipotesi nulla. Solitamente si sceglie un livello \\(\\alpha\\) pari a 0.05 o 0.01. Consideriamo nuovamente la regressione del QI del secondo nato sul QI del primo nato nei gemelli monozigoti esaminati da Anderson &amp; Finn (2012). Dall’output prodotto dalla funzione lm() possiamo ricavare le informazioni per il calcolo della statistica \\(t\\): summary(fm) #&gt; #&gt; Call: #&gt; lm(formula = iq2 ~ iq1, data = df) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -11.0342 -3.8218 -0.5852 3.4658 12.5635 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 1.8389 3.0269 0.608 0.548 #&gt; iq1 0.8499 0.1155 7.357 2.29e-08 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 6.102 on 32 degrees of freedom #&gt; Multiple R-squared: 0.6285, Adjusted R-squared: 0.6169 #&gt; F-statistic: 54.13 on 1 and 32 DF, p-value: 2.288e-08 che risulta essere \\[ t = \\frac{B}{s_{\\hat{\\beta}}}=\\frac{0.8499}{0.1155} = 7.357. \\] Supponendo un’ipotesi alternativa bidirezionale, \\(H_1: \\beta \\neq 0\\), la regione critica sarà suddivisa nelle due code della distribuzione \\(t\\) di Student con \\(25\\) gradi di libertà. Essendo il valore critico \\(t_{n-2, 1-\\alpha/2}\\) pari a qt(.975, 32) #&gt; [1] 2.036933 si può rifiutare \\(H_0\\). In maniera corrispondente, possiamo considerare il \\(p\\)-valore. Il \\(p\\)-valore è l’area sottesa alla funzione di densità \\(t\\) di Student con \\(n-2=32\\) gradi di libertà nei due intervalli \\([-\\infty, -t_{\\hat{\\beta}}]\\) e \\([t_{\\hat{\\beta}}, \\infty]\\) è 1 - pt(7.357, 32) #&gt; [1] 1.145083e-08 Dato che il \\(p\\)-valore è minore di \\(\\alpha = 0.05\\), l’approccio frequentista conclude rigettando \\(H_0\\). Il risultato si può riportare nel modo seguente: L’analisi della regressione bivariata ha rivelato una relazione lineare positiva tra il QI dei gemelli monozigoti primi nati e il QI dei gemelli secondi nati, \\(\\hat{\\beta} = 0.85\\), \\(t_{32} = 7.36\\), \\(p = .0001\\). I test di significatività possono essere eseguiti con R utilizzando la funzione summary() applicata all’oggetto creato dal lm(): Il test statistico sul parametro \\(\\beta\\) del modello di regressione verifica l’ipotesi nulla di indipendenza, ovvero l’ipotesi che, nella popolazione, la pendenza della retta di regressione sia uguale a zero. Più informativo del test statistico \\(H_0: \\beta=0\\) è l’intervallo di confidenza per il parametro \\(\\beta\\): \\[ \\hat{\\beta} \\pm t_{\\alpha/2} s_{\\hat{\\beta}}. \\] Nel caso presente, abbiamo fm$coef[2] + c(-1, 1) * qt(.025, 32) * 0.1155 #&gt; [1] 1.0851203 0.6145887 Dato che il limite inferiore dell’intervallo di confidenza è superiore allo zero, possiamo concludere che vi è un’associazione (lineare) positiva tra il QI del primo nato e il QI del secondo nato, nelle coppie di gemelli monozigoti che sono state esaminate da Anderson &amp; Finn (2012). Considerazioni conclusive Il modello di regressione lineare semplice viene usato per descrivere la relazione tra due variabili e per determinare il segno e l’intensità di tale relazione. Inoltre, il modello di regressione ci consente di prevedere il valore della variabile dipendente in base ad alcuni nuovi valori della variabile indipendente. Il modello di regressione lineare semplice è in realtà molto limitato, in quanto descrive soltanto la relazione tra la variabile dipendente \\(y\\) e una sola variabile esplicativa \\(x\\). Esso diventa molto più utile quando incorpora più variabili indipendenti. In questo secondo caso, però, i calcoli per la stima dei coefficienti del modello diventano più complicati. Abbiamo deciso qui di presentare solo il modello di regressione lineare semplice perché, in quel caso, sia la logica dell’inferenza sia le procedure di calcolo sono facilmente maneggiabili. Nel caso più generale, quello del modello di regressione multipla, la logica dell’inferenza rimarrà identica a quella discussa qui, ma le procedure di calcolo richiedono l’uso dell’algebra matriciale che esula dagli scopi del presente insegnamento. Il modello di regressione multipla può includere sia regressori quantitativi, sia regressori qualitativi, utilizzando un opportuna schema di codifica. È interessante notare come un modello di regressione multipla che include una sola variabile esplicativa quantitativa corrisponde all’analisi della varianza ad una via; un modello di regressione multipla che include più di una variabile esplicativa quantitativa corrisponde all’analisi della varianza più vie. Questi argomenti verranno sviluppati negli insegnamenti di carattere quantitativo più avanzati. Possiamo qui concludere dicendo che il modello di regressione, nelle sue varie forme e varianti, costituisce la tecnica di analisi dei dati maggiormente usata in psicologia. "],["chapter-stat-models.html", "Capitolo 17 Il modello lineare 17.1 Modello Binomiale 17.2 Il presidente Trump e l’idrossiclorochina 17.3 Modello Normale 17.4 Il modello di regressione lineare 17.5 Una variabile indipendente continua Conclusioni", " Capitolo 17 Il modello lineare Prima di descrivere come il modello di regressione lineare possa essere applicato ai dati mediante l’approccio Bayesiano, esamineremo i modelli statistici Bayesiani che vengono utilizzati in alcuni casi più semplici, ovvero (1) il modello statistico per una proporzione e (2) il modello statistico utilizzato per il confronto tra due proporzioni. Estenderemo poi la discussione al caso in cui viene considerato (3) un campione di osservazioni misurate su scala continua, assumendo che ciascuna osservazione provenga da una distribuzione Normale. In tali circostanze, l’oggetto dell’inferenza sarà il parametro \\(\\mu\\) che rappresenta la media della popolazione da cui le osservazioni sono state tratte. A questo punto saremo nelle condizioni di discutere (4) l’inferenza Bayesiana sulla differenza tra le medie di due popolazioni. Tale problema verrà affrontato specificando un modello di regressione lineare che include una variabile dipendente continua e una variabile indipendente dicotomica. Una volta chiarite le proprietà del modello di regressione in questo caso semplice, sarà immediato estendere la discussione (5) al caso di una variabile indipendente continua. 17.1 Modello Binomiale Se facciamo nuovamente riferimento all’esempio del mappamondo di McElreath (2020), nel quale abbiamo osservato \\(A = 6\\) volte “acqua” in \\(N = 9\\) prove Bernoulliane indipendenti, allora il modello statistico che descrive l’esperimento casuale può essere formulato nei termini seguenti: \\[\\begin{equation} \\begin{aligned} A &amp;\\sim \\text{Binomiale}(N, p) \\\\ p &amp;\\sim \\text{Uniforme}(0, 1) \\end{aligned} \\tag{17.1} \\end{equation}\\] dove la prima riga definisce la funzione di verosimiglianza e la seconda riga definisce la distribuzione a priori. Il segno \\(\\sim\\) (tilde) si può leggere “si distribuisce come.” La prima riga, dunque, ci dice che la variabile aleatoria \\(Y\\) segue la distribuzione Binomiale di parametri \\(N\\) e \\(p\\). La seconda riga specifica che, quale distribuzione a priori, assumiamo una distribuzione uniforme in (0 e 1) per il parametro \\(p\\). 17.2 Il presidente Trump e l’idrossiclorochina Cito dal Washington Post del 7 aprile 2020: One of the most bizarre and disturbing aspects of President Trump’s nightly press briefings on the coronavirus pandemic is when he turns into a drug salesman. Like a cable TV pitchman hawking ‘male enhancement’ pills, Trump regularly extols the virtues of taking hydroxychloroquine, a drug used to treat malaria and lupus, as a potential ‘game changer’ that just might cure Covid-19. Tralasciamo qui il fatto che il presidente Trump non è un esperto in questo campo. Esaminiamo invece le evidenze iniziali a supporto dell’ipotesi che l’idrossiclorochina possa essere utile per la cura del Covid-19, evidenze disponibili nel momento in cui il presidente Trump ha fatto le affermazioni riportate sopra.8 Tali evidenze sono state fornite da Gautret et al. (2020). Il disegno sperimentale di Gautret et al. (2020) comprende, tra le altre cose, il confronto tra una condizione sperimentale e una condizione di controllo. Un articolo pubblicato da Hulme et al. (2020) si è posto il problema di rianalizzare i dati di Gautret et al. (2020) – si veda https://osf.io/5dgmx/. Tra gli autori di questo secondo articolo figura anche Eric-Jan Wagenmakers, uno psicologo molto conosciuto per i suoi contributi metodologici. Hulme et al. (2020) sottolineano il fatto che Gautret et al. (2020) si sono concentrati, nella loro analisi dei dati, soltanto su una parte del loro campione. Se però vengono considerati anche i pazienti che sono stati esclusi dall’analisi dei dati, le conclusioni a cui sono giunti Gautret et al. (2020) risultano fortemente indebolite. L’analisi dei dati proposta da Hulme et al. (2020) richiede l’uso di alcuni strumenti statistici che, in queste dispense, non verranno discussi. Ma possiamo giungere alle stesse conclusioni di Hulme et al. (2020) anche usando le procedure statistiche che abbiamo descritto finora. Nella ricerca di Gautret et al. (2020) il confronto importante è tra la proporzione di paziente positivi al virus SARS-CoV-2 nel gruppo a cui è stata somministrata l’idrossiclorochina (6 su 14) e nel gruppo di controllo (a cui non è stata somministrata l’idrossiclorochina: 14 positivi su 16). Ciò che faremo sarà di calcolare la distribuzione a posteriori per queste due proporzioni. Rappresenteremo graficamente le due distribuzioni a posteriori per il parametro \\(p\\) che rappresenta la probabilità di risultare positivo al SARS-CoV-2. Calcoleremo anche, separatamente per i due gruppi, l’intervallo di credibilità al 95%. Quindi concluderemo facendo il confronto tra gli intervalli di credibilità dei due gruppi. Leggiamo i dati in R creando i due vettori seguenti. Il vettore ym contiene i dati del gruppo a cui è stata somministrata l’idrossiclorochina e il vettore yc i dati del gruppo di controllo. Il valore \\(y = 1\\) indica che il paziente è positivo al virus SARS-CoV-2 (l’ordine di 0 e 1 è irrilevante). ym &lt;- c(rep(1, 6), rep(0, 8)) ym #&gt; [1] 1 1 1 1 1 1 0 0 0 0 0 0 0 0 yc &lt;- c(rep(1, 14), rep(0, 2)) yc #&gt; [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 Utilizzando la sintassi di rethinking, definiamo ora il modello statistico per una proporzione specificando una distribuzione a priori non informativa: suppressPackageStartupMessages(library(&quot;rethinking&quot;)) options(mc.cores = parallel::detectCores()) flist &lt;- alist( y ~ dbinom(1, p), p ~ dbeta(1, 1) ) Calcoliamo la distribuzione a posteriori per il parametro \\(p\\) nel caso del gruppo sperimentale m &lt;- quap( flist, data = list(y = ym) ) Così facendo troviamo il seguente intervallo di credibilità al 95%: precis(m, prob = 0.95) #&gt; mean sd 2.5% 97.5% #&gt; p 0.4285716 0.1322594 0.1693479 0.6877954 Creiamo ora un grafico che rappresenta la distribuzione a posteriori del parametro \\(p\\): post &lt;- extract.samples(m) plot( density(post$p), xlim = c(0, 1), ylim = c(0, 5), main = &quot;&quot;, xlab = &quot;Parametro p&quot;, ylab = &quot;Densità&quot; ) Ripetiamo quindi la stessa procedura seguita sopra, usando però i dati del gruppo di controllo, e rappresentiamo la nuova distribuzione a posteriori del parametro \\(p\\) come abbiamo fatto in precedenza: m &lt;- quap( flist, data = list(y = yc) ) precis(m, prob = 0.95) #&gt; mean sd 2.5% 97.5% #&gt; p 0.8750014 0.08267432 0.7129627 1.03704 post &lt;- extract.samples(m) plot( density(post$p), xlim = c(0, 1), ylim = c(0, 5), main = &quot;&quot;, xlab = &quot;Parametro p&quot;, ylab = &quot;Densità&quot; ) lines(density(post$p), xlim = c(0, 1)) Le due figure che abbiamo realizzato presentano le distribuzioni a posteriori del parametro \\(p\\) (cioè la probabilità di risultare positivo al virus SARS-CoV-2) per i due gruppi di pazienti considerati nella ricerca di Gautret et al. (2020). Le figure mostrano che le due distribuzioni a posteriori sono chiaramente separate, il che suggerisce che il parametro \\(p\\) assume valori diversi nei due gruppi. Coerentemente con la conclusioni di Gautret et al. (2020), le stime a posteriori per il parametro \\(p\\) che abbiamo trovato suggeriscono dunque che i pazienti del gruppo sperimentale (a cui è stata somministrata l’idrossiclorochina) hanno una minore probabilità di risultare positivi al SARS-CoV-2 rispetto ai pazienti del gruppo di controllo (a cui non è stata somministrata l’idrossiclorochina). Possiamo giungere a questa conclusione senza guardare le due figure ma confrontando gli intervalli di credibilità al 95% dei due gruppi. Gli intervalli di credibilità non si sovrappongono e questo suggerisce che il parametro \\(p\\) è diverso nei due gruppi. Possiamo dunque concludere, con un grado di certezza soggettiva del 95%, che nel gruppo sperimentale vi è una probabilità più bassa di risultare positivi al SARS-CoV-2 rispetto al gruppo di controllo. Fino a questo punto non abbiamo fatto altro che replicare le conclusioni a cui sono giunti Gautret et al. (2020), sia pur utilizzando una procedura statistica diversa. Tuttavia, in questa anlisi dei dati c’è un aspetto che non abbiamo considerato. Hulme et al. (2020) hanno osservato che Gautret et al. (2020), nella loro analisi statistica, hanno escluso alcuni pazienti i quali, nel gruppo sperimentale, sono in realtà peggiorati, anziché essere migliorati. Se consideriamo dunque i dati di tutti i pazienti del campione che è stato raccolto (non solo quelli selezionati da Gautret et al. (2020), la situazione è la seguente. Gruppo sperimentale: 10 positivi su 18; gruppo di controllo: 14 positivi su 16. Ripetiamo dunque l’analisi descritta sopra utilizzando, per il gruppo sperimentale, tutti i dati che abbiamo a disposizione. Così facendo otteniamo il seguente intervallo di credibilità al 95%: ym &lt;- c(rep(1, 10), rep(0, 8)) ym #&gt; [1] 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 m &lt;- quap( flist, data = list(y = ym) ) precis(m, prob = 0.95) #&gt; mean sd 2.5% 97.5% #&gt; p 0.5555876 0.1171192 0.3260382 0.785137 Quando utilizziamo tutti i dati (e non soltanto i pazienti selezionati da Gautret et al. (2020)) notiamo che l’intervallo di credibilità al 95% per il gruppo sperimentale, ovvero [0.33, 0.79], si sovrappone all’intervallo di credibilità al 95% per il gruppo di controllo, ovvero [0.71 1.04]. In base agli standard correnti, un risultato di questo tipo non viene considerato come evidenza sufficiente per potere concludere che il parametro \\(p\\) assume un valore diverso nei due gruppi. Concludiamo dicendo che questo, ovviamente, è solo un esercizio didattico: la ricerca di Gautret et al. (2020) include tante altre informazioni che qui non sono state considerate. Tuttavia, notiamo che la semplice analisi statistica che abbiamo descritto è stata in grado di replicare le conclusioni a cui sono giunti (per altra via) Hulme et al. (2020). 17.3 Modello Normale Facciamo ora un altro esempio considerando, in questo caso, la distribuzione Normale \\[ \\begin{aligned} Y_i &amp;\\sim \\mathcal{N}(\\mu, \\sigma) \\\\ \\mu &amp;\\sim \\mathcal{N}(\\mu = \\bar{X}, \\sigma = 100) \\\\ \\sigma &amp;= s_Y \\end{aligned} \\] Questo secondo modello statistico ci dice che la variabile aleatoria \\(Y\\) segue la distribuzione Normale di parametri \\(\\mu\\) e \\(\\sigma\\). Il parametro \\(\\mu\\) è sconosciuto e abbiamo deciso di descrivere la nostra incertezza a priori relativa ad esso mediante una distribuzione a priori che segue la legge Normale con media uguale alla media campionaria e con deviazione standard 100. Il parametro \\(\\sigma\\) è fissato ad un valore pari alla deviazione standard del campione, \\(s_y\\). In generale, però, anche il parametro \\(\\sigma\\) viene considerato ignoto e ad esso potrebbe essere assegnata una distribuzione a priori come, ad esempio, \\(\\sigma \\sim \\text{Unif}(0, 100)\\). 17.3.1 Il modello normale con quap() Per fare un esempio, consideriamo i 30 valori del BDI-II dei soggetti clinici di Zetsche et al. (2019): df &lt;- data.frame( x &lt;- c(26, 35, 30, 25, 44, 30, 33, 43, 22, 43, 24, 19, 39, 31, 25, 28, 35, 30, 26, 31, 41, 36, 26, 35, 33, 28, 27, 34, 27, 22) ) Calcoliamo le statistiche descrittive: true_sd &lt;- sd(df$x) true_sd #&gt; [1] 6.606858 sample_mean &lt;- mean(df$x) sample_mean #&gt; [1] 30.93333 Definiamo ora il modello statistico mediante la funzione alist() flist &lt;- alist( x ~ dnorm(mu, sigma), mu ~ a, a ~ dnorm(sample_mean, 100), sigma ~ true_sd ) e stimiamo la distribuzione a posteriori di \\(\\mu\\): set.seed(123) m1 &lt;- quap( flist, data = df ) Esaminando il risultato ottenuto mediante precis(): precis(m1) #&gt; mean sd 5.5% 94.5% #&gt; a 30.93333 1.206154 29.00567 32.861 Possiamo così stabilire che l’intervallo di credibilità al 95% per il valore medio del BDI-II è compreso tra [29.0, 32.8]. Questo esempio ci mostra come possiamo calcolare l’intervallo di credibilità nel caso della media di un campione. Nella sezione successiva ci porremo il problema di come sia possibile fare il confronto tra le medie di due campioni indipendenti. 17.4 Il modello di regressione lineare I due modelli statistici che abbiamo presentato sopra descrivono il comportamento di una singola variabile aleatoria: una proporzione di “successi” o la media del livello BDI-II in un campione. Se la distribuzione a priori non è informativa, la distribuzione a posteriori risulta centrata sul valore della statistica campionaria utilizzata per la stima del parametro (\\(\\bar{y}\\) o \\(p\\)). Quello che “guadagnamo” calcolando la distribuzione a posteriori del parametro è la possibilità di quantificare la nostra incertezza rispetto alla stima del parametro (\\(\\mu\\) o \\(\\pi\\)): se l’intervallo di credibilità è grande, questo significa che i dati del campione sono poco informativi rispetto al valore del parametro; se invece l’intervallo di credibilità è piccolo, allora concludiamo che siamo piuttosto certi del valore della nostra stima. Tuttavia, i modelli di interesse per la psicologia (e per le altre scienze) descrivono le relazioni tra due o più variabili, e non soltanto il valore di una singola variabile. Per esempio, nel suo studio Regression towards mediocrity in hereditary stature, Galton (1886) si è chiesto come sia possibile descrivere la relazione tra l’altezza dei figli e l’altezza dei padri. Il modo più semplice per rispondere ad una domanda di questo tipo è quello di formulare la risposta nei termini di un modello di regressione lineare – infatti, la tecnica statistica della regressione lineare fu inventata da Galton proprio per questo scopo. Il modello di regressione lineare è dunque il più semplice dei modelli statistici che descrivono la relazione tra due (o più) variabili. Usando la notazione che abbiamo introdotto in questo capitolo, il modello di regressione può essere descritto nel modo seguente: \\[ \\begin{aligned} Y_i &amp;\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\ \\mu_i &amp;= \\alpha + \\beta(X_i - \\bar{X}) \\\\ \\alpha &amp;\\sim \\mathcal{N}(0, \\sigma_{\\alpha}) \\\\ \\beta &amp;\\sim \\mathcal{N}(0, \\sigma_{\\beta}) \\\\ \\sigma &amp;\\sim \\text{Unif}(0, 50) \\end{aligned} \\] La verosimiglianza indica che ciascun valore \\(Y_i\\) (la nostra variabile dipendente) segue una distribuzione Normale. Tuttavia, ciascuna \\(Y_i\\) segue una distribuzione Normale avente una media diversa (come indicato dal pedice \\(i\\) usato per \\(\\mu_i\\)). In questa formulazione del modello, tutte le distribuzioni Normali relative alla \\(Y\\) hanno la stessa deviazione standard (\\(\\sigma\\), il che corrisponde all’assunzione di omoschedasticità). La cosa importante è che la media \\(\\mu\\) non è più il parametro che deve essere stimato – come avveniva invece nel caso del modello Normale che abbiamo discusso nel caso dei valori BDI-II. Nel modello statistico della regressione lineare, invece, \\(\\mu_i\\) è espresso nei termini di due altri due parametri, \\(\\alpha\\) e \\(\\beta\\), e nei termini di una quantità osservabile chiamata \\(X\\) (la nostra variabile indipendente), come indicato nella seconda riga della descrizione del modello statistico. La seconda riga della specificazione del modello statistico non esprime una relazione stocastica (non viene usato il segno \\(\\sim\\)), ma bensì una relazione deterministica (come indicato dall’uso del segno di uguale). Ciò significa che, una volta fissati i parametri \\(\\alpha\\) e \\(\\beta\\), il valore \\(\\mu_i\\) è determinato in maniera univoca (questa è la componente deterministica del modello di regressione lineare). Se il modello di regressione lineare è espresso come \\(\\mu_i = \\alpha + \\beta(X_i - \\bar{X})\\), allora possiamo assegnare ai parametri \\(\\alpha\\) e \\(\\beta\\) l’interpretazione che abbiamo già incontrato in precedenza. Il parametro \\(\\alpha\\) è uguale alla media della \\(Y\\). In precedenza abbiamo detto che, dal punto di vista geometrico, \\(\\alpha\\) corrisponde all’ordinata del punto in cui la retta di regressione interseca l’asse verticale di un sistema di coordinate cartesiane. Nel caso presente abbiamo espresso i dati come scarti dalla media: \\(X_i - \\bar{X}\\), da cui segue che la media di \\(X\\) avrà valore zero. Da ciò deriva l’interpretazione di \\(\\alpha\\) che abbiamo fornito sopra. Il parametro \\(\\beta\\) ci dice di quanto varia, in media, il valore \\(Y\\) per ogni variazione unitaria della \\(X\\). Abbiamo visto in precedenza che il parametro \\(\\beta\\) viene chiamato “pendenza” perché, in termini geometrici, il modello di regressione lineare assume la forma di una retta che, all’interno di un diagramma a dispersione, approssima quanto meglio è possibile la nube di punti \\((X, Y)\\). Nel modello statistico presentato sopra, la nostra incertezza su \\(\\beta\\) è stata quantificata mediante una distribuzione a priori centrata sullo zero e con una deviazione standard pari a \\(\\sigma_{\\beta}\\). La nostra incertezza su \\(\\alpha\\) è stata quantificata mediante una distribuzione a priori centrata sullo zero e con una deviazione standard pari a \\(\\sigma_{\\alpha}\\). Infine, la nostra incertezza su \\(\\sigma\\) è stata quantificata mediante una distribuzione uniforme compresa tra 0 e 50. Per ora ci siamo limitati a descrivere la formulazione Bayesiana del modello di regressione mediante la sintassi di rethinking, così come fa McElreath (2020). Nelle sezioni seguenti vedremo come sia possibile svolgere l’analisi di regressione in termini Bayesiani. Inizieremo considerando il caso più semplice, ovvero quello nel quale la variabile \\(X\\) è una variabile dicotomica; considereremo poi il caso in cui \\(X\\) è una variabile continua. 17.4.1 Variabile indipendente dicotomica Solitamente, in un modello di regressione lineare come quello descritto nella sezione Il modello di regressione lineare, la variabile \\(X\\) è una variabile continua. Tuttavia, è anche possibile che \\(X\\) sia una variabile discreta. Consideriamo qui il caso più semplice, ovvero quello in cui \\(X\\) assume solo due valori: 0 e 1. In tali circostanze, il modello lineare può essere usato per il confronto tra le medie di due gruppi. Vediamo perché. Se \\(X\\) è una variabile dicotomica (con valori 0 e 1), allora per il modello lineare \\(\\mu_i = \\alpha + \\beta x_i\\) abbiamo quanto segue. Quando \\(X=0\\), il modello diventa \\[\\mu_i = \\alpha\\] mentre, quando \\(X=1\\), il modello diventa \\[\\mu_i = \\alpha + \\beta.\\] Ciò significa che il parametro \\(\\alpha\\) è uguale alla media del gruppo codificato con \\(X=0\\) e il parametro \\(\\beta\\) è uguale alla differenza tra le medie dei due gruppi (essendo la media del secondo gruppo uguale a \\(\\alpha + \\beta\\)). In tali circostanze, il parametro \\(\\beta\\) risulta particolarmente utile in quanto, nel caso di due gruppi, codifica direttamente l’effetto di una manipolazione sperimentale o di un trattamento (ovvero, esprime la differenza tra le medie di due gruppi). Per “effetto di un trattamento” si intende appunto la differenza tra le medie di due gruppi (per esempio, il gruppo “sperimentale” e il gruppo “di controllo”). L’inferenza su \\(\\beta\\) può dunque aiutarci a capire quanto può essere considerato “robusto” l’effetto di un trattamento o di una manipolazione sperimentale. 17.4.2 Un esempio pratico Esaminiamo un sottoinsieme di dati tratto dal National Longitudinal Survey of Youth i quali fanno parte di un esempio discusso da Gelman et al. (2020). I soggetti sono bambini di 3 e 4 anni. La variabile dipendente, kid_score, è il punteggio totale del Peabody Individual Achievement Test (PIAT) costituito dalla somma dei punteggi di tre sottoscale (Mathematics, Reading comprehension, Reading recognition). La variabile indipendente, mom_hs, è il livello di istruzione della madre, codificato con due livelli: scuola media superiore completata oppure no. La domanda della ricerca è se il QI del figlio (misurato con la scala PIAT) risulta o meno associato al livello di istruzione della madre. Codifichiamo il livello di istruzione della madre (\\(X\\)) con una variabile indicatrice (ovvero, una variabile che assume solo i valori 0 e 1) tale per cui: \\(X=0\\): la madre non ha completato la scuola secondaria di secondo grado (scuola media superiore); \\(X=1\\): la madre ha completato la scuola media superiore. Supponiamo che i dati siano contenuti nel data.frame df. library(&quot;foreign&quot;) df &lt;- read.dta(here(&quot;data&quot;, &quot;kidiq.dta&quot;)) head(df) #&gt; kid_score mom_hs mom_iq mom_work mom_age #&gt; 1 65 1 121.11753 4 27 #&gt; 2 98 1 89.36188 4 25 #&gt; 3 85 1 115.44316 4 27 #&gt; 4 83 1 99.44964 3 25 #&gt; 5 115 1 92.74571 4 27 #&gt; 6 98 0 107.90184 1 18 Calcoliamo le statistiche descrittive per i due gruppi: df %&gt;% group_by(mom_hs) %&gt;% summarise( mean_kid_score = mean(kid_score), std = sqrt(var(kid_score)) ) #&gt; `summarise()` ungrouping output (override with `.groups` argument) #&gt; # A tibble: 2 x 3 #&gt; mom_hs mean_kid_score std #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 0 77.5 22.6 #&gt; 2 1 89.3 19.0 Il punteggio PIAT medio è 77.5 per i bambini la cui madre non ha il diploma di scuola media superiore, e pari a 89.3 per i bambini la cui madre ha completato la scuola media superiore. Questa differenza suggerisce un’associazione tra le variabili, ma tale differenza potrebbe essere soltanto la conseguenza della variabilità campionaria, senza riflettere una caratteristica generale della popolazione. Come possiamo usare il modello statistico lineare per fare inferenza sulla differenza osservata tra i due gruppi? Per rispondere a questa domanda specifichiamo il modello statistico che descrive la differenza tra i punteggi PIAT dei due gruppi mediante un modello di regressione lineare: flist &lt;- alist( kid_score ~ dnorm(mu, sigma), mu ~ a + b * mom_hs, a ~ dnorm(86.8, 100), b ~ dnorm(0, 100), sigma ~ dunif(0, 100) ) Si noti che abbiamo specificato tale modello statistico seguendo la stessa logica descritta all’inizio della sezione Il modello di regressione lineare. Ovvero, abbiamo esplicitato: la verosimiglianza dei dati; il modello statistico della regressione lineare che esprime il valore atteso della variabile dipendente come una funzione lineare della variabile indipendente; la distribuzione a priori di ciascuno dei parametri del modello, ovvero \\(a\\), \\(b\\) e \\(\\sigma\\). Nel caso presente, abbiamo specificato due distribuzioni a priori “debolmente informative” per i parametri \\(a\\) e \\(b\\). La distribuzione a priori del parametro \\(a\\) è una distribuzione Normale centrata sulla media di tutti i dati (calcolata ignorando la suddivisione in gruppi), con una deviazione standard relativamente grande. Ciò significa che, a priori, per il parametro \\(a\\) riteniamo plausibili valori che sono inclusi nell’intervallo \\(86.8 \\pm 2 \\times 100\\) punti PIAT, anche se riteniamo più probabili i valori prossimi a 86.8. Così facendo, prima di avere osservato i dati campionari, esprimiamo una generale incertezza su quello che potrebbe essere il valore della media del gruppo codificato con \\(X = 0\\). In maniera simile, caratterizziamo il possibile valore della differenza tra le medie tra i due gruppi (ciò a cui siamo interessati) in maniera molto vaga: affermiamo che potrebbe essere un valore qualsiasi, probabilmente contenuto nell’intervallo \\(0 \\pm 2 \\times 100\\), assegnando a priori una plausibilità maggiore ai valori prossimi allo zero (positivi e negativi). Per il parametro \\(b\\), specifichiamo dunque una distribuzione a priori Normale centrata sullo zero. Così facendo, la distribuzione a priori non favorisce né l’ipotesi secondo cui il parametro \\(b\\) sia maggiore di zero (ovvero, che la media dei punteggi PIAT sia maggiore nel gruppo codificato con \\(X = 0\\) rispetto al gruppo codificato con \\(X = 1\\)), né l’ipotesi opposta. Specificando per \\(b\\) una distribuzione a priori simmetrica centrata sullo zero non introduciamo dunque alcuna distorsione nella distribuzione a posteriori: non favoriamo né l’ipotesi a cui potremmo essere interessati (ad esempio, \\(a &gt; 0\\)), né l’ipotesi opposta. Infine, specifichiamo distribuzione a priori uniforme nell’intervallo (0, 100) per il parametro \\(\\sigma\\) che descrive la distribuzione dei dati attorno al loro valore atteso (ovvero, attorno alla retta di regressione). Adattiamo il modello ai dati utilizzando la funzione quap(): m1 &lt;- quap( flist, data = df ) Estraiamo alcuni campioni dalla distribuzione a posteriori: post &lt;- extract.samples(m1) post[1:5, ] #&gt; a b sigma #&gt; 1 80.07328 9.006764 19.73586 #&gt; 2 77.26278 11.935567 19.77395 #&gt; 3 76.66754 11.448966 19.31510 #&gt; 4 77.23189 10.742990 19.97299 #&gt; 5 80.54546 9.255061 19.83349 Esaminiamo la distribuzione a posteriori dei parametri mediante le istruzioni seguenti. par(mfrow = c(1, 3)) dens( post$a, lwd = 2.5, xlab = &quot;&quot;, ylab = &quot;Densità&quot;, main = &quot;p(a | x, y)&quot;, cex.lab = 1.5, cex.axis = 1.35, cex.main = 1.5, cex.sub = 1.5 ) dens( post$b, lwd = 2.5, xlab = &quot;&quot;, ylab = &quot;&quot;, main = &quot;p(b | x, y)&quot;, cex.lab = 1.5, cex.axis = 1.35, cex.main = 1.5, cex.sub = 1.5 ) dens( post$sigma, lwd = 2.5, xlab = &quot;&quot;, ylab = &quot;&quot;, main = &quot;p(sigma | x, y)&quot;, cex.lab = 1.5, cex.axis = 1.35, cex.main = 1.5, cex.sub = 1.5 ) par(mfrow = c(1, 1)) Figura 17.1: Distribuzioni a posteriori dei parametri a, b e \\(\\sigma\\) del modello statistico lineare che descrive i punteggi del Peabody Individual Achievement Test come funzione del gruppo di appartenenza: i bambini la cui madre non ha completato la scuola media superiore e i bambini la cui madre ha completato la scuola media superiore. I dati sono tratti da Gelman et al. (2020). I risultati possono anche essere esaminati mediante la funzione precis() che fornisce la stima a posteriori del parametro e l’intervallo di credibilità al livello desiderato: precis(m1, prob = 0.95) #&gt; mean sd 2.5% 97.5% #&gt; a 77.55837 2.0528231 73.534910 81.58183 #&gt; b 11.75868 2.3158682 7.219661 16.29770 #&gt; sigma 19.80505 0.6721414 18.487679 21.12243 I risultati confermano ciò che ci aspettavamo: il coefficiente \\(a\\) corrisponde alla media del gruppo codificato con \\(X = 0\\), ovvero la media dei punteggi PIAT per i bambini la cui madre non ha completato la scuola media superiore; il coefficiente \\(b\\) corrisponde alla differenza tra le medie dei due gruppi, ovvero 89.32 - 77.55 = 11.77. Il coefficiente \\(b\\) ci dice dunque che i bambini la cui madre ha completato la scuola superiore ottengono in media 12 punti in più rispetto ai bambini la cui madre non ha completato la scuola superiore. Per ora non consideriamo l’interpretazione del parametro \\(\\sigma\\) (si veda più sotto). Una rappresentazione grafica dell’interpretazione che abbiamo fornito ai parametri del modello lineare è fornita nella figura 17.2. Figura 17.2: Distribuzione dei punteggi del Peabody Individual Achievement Test in due gruppi di bambini facenti parte del campione discusso da Gelman et al. (2020): bambini la cui madre non hanno completato la scuola media superiore (\\(X\\) = 0) e bambini la cui madre ha completato la scuola media superiore (\\(X\\) = 1). Abbiamo visto sopra che il parametro \\(b\\) = 11.77 riflette semplicemente la differenza tra le medie dei due gruppi. Ma il modello statistico lineare ci dice qualcosa in più: esso quantifica la nostra incertezza relativamente a tale differenza, al di là delle caratteristiche specifiche del particolare campione che abbiamo esaminato. È ovvio chiedersi: se esaminassimo un altro campione, quanto sarebbe grande questa differenza? E in un altro campione ancora? Il modello statistico lineare ci dice che, indipendentemente da quale campione di dati verrà esaminiamo, ci possiamo aspettare, con un grado di certezza del 95%, che la differenza tra le medie dei due gruppi sia compresa nell’intervallo tra 7.2 e 16.3 punti PIAT. Questo è il significato dell’intervallo di credibilità al 95% che è stato calcolato e che ci viene fornito dalla funzione precis(). L’intervallo di credibilità al 95% rappresenta una stima dell’intervallo di valori che contengono il 95% dell’area della distribuzione a posteriori del parametro \\(b\\). Nella figura 17.1 si vedono le distribuzioni a posteriori dei parametri \\(a\\) e \\(b\\). Tali distribuzioni sono state generate estraendo un numero molto grande di campioni dalle distribuzioni a posteriori di \\(a\\) e \\(b\\). Solitamente tali stime sono ottenute mediante una variante dell’algoritmo di Metropolis; l’approssimazione quadratica qui usata fornisce un’approssimazione a questo processo. Dalla figura 17.1 vediamo che le distribuzioni a posteriori tendono ad essere Normali. Vediamo inoltre che i valori più plausibili per il parametro \\(b\\) sono compresi tra 7.2 e 16.3, come ci dice l’intervallo di credibilità al 95%. Il problema di come sia possibile specificare un intervallo di credibilità sulla base delle informazioni fornite dalla distribuzione a posteriori è discusso nel capitolo XX.9 In conclusione, il modello statistico lineare riassume la differenza nei punteggi medi del test PIAT nei due gruppi di bambini: i bambini la cui madre ha completato la scuola media superiore e bambini la cui madre non ha completato la scuola media superiore. Il modello statistico lineare ci consente inoltre di fare inferenza sulla differenza nei punteggi medi del test PIAT nei due gruppi di bambini. Viene infatti definito un livello di credibilità che descrive, ad un determinato grado di certezza, quelli che sono i valori plausibili di tale differenza, al di là delle idiosincrasie del particolare campione che abbiamo esaminato, ovvero tenendo in considerazione il fenomeno della variabilità campionaria. Questo è il processo di inferenza Bayesiana che viene svolta mediante l’uso di un modello statistico lineare. 17.4.2.1 Quale distribuzione a priori è corretta? Un grave problema che è emerso negli anni recenti relativamente all’analisi dei dati psicologici (e non solo) è il cosiddetto “\\(p\\)-hacking,” ovvero la pratica di adattare il modello e i dati allo scopo di ottenere il risultato desiderato. Il risultato desiderato è generalmente un valore-\\(p\\) inferiore al 5%. Il problema è che quando il modello statistico viene modificato alla luce dei dati osservati, i valori-\\(p\\) non mantengono più il loro significato originario: in altre parole, il “\\(p\\)-hacking” aumenta la probabilità di ottenere dei risultati falsi. L’approccio Bayesiano non prevede i valori-\\(p\\), ma il rischio rimane se scegliamo le distribuzioni a priori in base alle proprietà del campione allo scopo di ottenere il risultato desiderato. La procedura che invece deve essere seguita è quella di scegliere le distribuzioni a priori sulla base di considerazioni generali, indipendentemente dalle specifiche caratteristiche del campione. 17.5 Una variabile indipendente continua Continuiamo ora con l’esempio relativo al National Longitudinal Survey of Youth discusso da Gelman et al. (2020) e poniamoci ora il problema di descrivere l’associazione tra l’intelligenza del bambino, kid_score (ovvero il punteggio totale del Peabody Individual Achievement Test,PIAT), e mom_iq (ovvero il quoziente di intelligenza della madre), che rappresenta una variabile continua. df %&gt;% ggplot(aes(x = mom_iq, y = kid_score)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) + labs( x = &quot;QI della madre&quot;, y = &quot;Peabody Individual Achievement Test&quot; ) #&gt; `geom_smooth()` using formula &#39;y ~ x&#39; Figura 17.3: Punteggio del test PIAT come funzione del QI materno con sovrapposta la retta di regressione. Ogni punto sulla retta di regressione può essere concepito come un punteggio il punteggio predetto per un bambino la cui madri ha il QI corrispondente o come il punteggio PIAT medio per una sottopopolazione di bambini le cui madri hanno tutte quel particolare valore di QI. I dati sono tratti da Gelman et al. (2020).) Il modello statistico lineare diventa: \\[ \\begin{aligned} Y_i &amp;\\sim \\mathcal{N}(\\mu_i, \\sigma) \\\\ \\mu_i &amp;= \\alpha + \\beta(X_i - \\bar{X}) \\\\ \\alpha &amp;\\sim \\mathcal{N}(0, \\sigma_{\\alpha}) \\\\ \\beta &amp;\\sim \\mathcal{N}(0, \\sigma_{\\beta}) \\\\ \\sigma &amp;\\sim \\text{Unif}(0, 50) \\end{aligned} \\] Abbiamo descritto \\(X\\) nei termini degli scostamenti dalla media (\\(X_i - \\bar{X}\\)) per fare in modo che il coefficiente \\(\\alpha\\) corrisponda al valore atteso della \\(Y\\) in corrispondenza della media di \\(X\\) (quoziente di intelligenza della madre) – questa è una conseguenza del fatto che la retta di regressione passa per il punto \\((\\bar{X}, \\bar{Y})\\). Infatti, avrebbe poco senso chiederci qual è il valore atteso del punteggio PIAT quando il quoziente d’intelligenza della madre è uguale a zero. Specifichiamo dunque il modello statistico lineare con la sintassi richiesta da rethinking: flist &lt;- alist( kid_score ~ dnorm(mu, sigma), mu ~ a + b * (mom_iq - mean(mom_iq)), a ~ dnorm(mean(kid_score), 100), b ~ dnorm(0, 100), sigma ~ dunif(0, 100) ) Adattiamo il modello di regressione ai dati m2 &lt;- quap( flist, data = df ) Esaminiamo il risultato ottenuto mediante la funzione precis(): precis(m2, prob = 0.95) #&gt; mean sd 2.5% 97.5% #&gt; a 86.7973283 0.87475112 85.0828476 88.5118090 #&gt; b 0.6099751 0.05838627 0.4955402 0.7244101 #&gt; sigma 18.2240956 0.61857167 17.0117174 19.4364738 Troviamo così che \\[ \\mathbb{E}(\\text{kid_score}) = 86 + 0.61 \\cdot x, \\] laddove \\(x\\) è la variabile kid_score espressa come scostamento rispetto al suo valore medio. Tale retta di regressione stimata è mostrata assieme ai dati nella figura 17.3. Il coefficiente \\(b\\) ci dice che, all’aumentare di un punto del quoziente d’intelligenza della madre, la media dei punteggi PIAT cresce di 0.61 unità. Il parametro \\(\\sigma\\) ci dice che la deviazione standard che quantifica la dispersione dei dati attorno alla retta di regressione è pari a 18.22. L’intervallo di credibilità di questo coefficiente ci dice che, con un livello di certezza del 95%, possiamo essere sicuri che, all’aumentare di un punto del quoziente d’intelligenza della madre, la media dei punteggi PIAT crescerà, come minimo, di 0.50 punti e, come massimo, di 0.72 punti. La differenza 0.72 - 0.50 esprime il nostro grado di incertezza rispetto alla stima del parametro, quando vogliamo che la nostra stima sia “credibile” al livello di 0.95. Ma non c’è niente di “magico” o necessario relativamente al livello di 0.95. Infatti, il default della funzione precis() è 0.89. Ciascuno di questi valori è arbitrario. Sono possibili tantissime soglie per quantificare la nostra incertezza: alcuni ricercatori usano il livello di 0.5. Il nostro obiettivo è quello di descrivere il livello della nostra incertezza relativamente alla stima del parametro. E la nostra incertezza è descritta dall’intera distribuzione a posteriori. Per cui il metodo più semplice, più diretto e più completo per descrivere la nostra incertezza rispetto alla stima dei parametri è quello di riportare graficamente tutta la distribuzione a posteriori, come indicato per esempio nella figura 17.4. post &lt;- extract.samples(m2) par(mfrow = c(1, 3)) dens( post$a, lwd = 2.5, xlab = &quot;&quot;, ylab = &quot;Densità&quot;, main = &quot;p(a | x, y)&quot;, cex.lab = 1.5, cex.axis = 1.35, cex.main = 1.5, cex.sub = 1.5 ) dens( post$b, lwd = 2.5, xlab = &quot;&quot;, ylab = &quot;&quot;, main = &quot;p(b | x, y)&quot;, cex.lab = 1.5, cex.axis = 1.35, cex.main = 1.5, cex.sub = 1.5 ) dens( post$sigma, lwd = 2.5, xlab = &quot;&quot;, ylab = &quot;&quot;, main = &quot;p(sigma | x, y)&quot;, cex.lab = 1.5, cex.axis = 1.35, cex.main = 1.5, cex.sub = 1.5 ) par(mfrow = c(1, 1)) Figura 17.4: Distribuzione a posteriori dei parametri \\(a\\), \\(b\\) e \\(sigma\\) del modello statistico lineare che descrive i punteggi del Peabody Individual Achievement Test come funzione del quoziente d’intelligenza della madre espresso come scostamento rispetto al suo valore medio. I dati sono tratti da Gelman et al. (2020). Conclusioni Questo capitolo ha introdotto il modello bivariato di regressione lineare, ovvero un metodo che ci consente di stimare l’associazione tra una variabile indipendente e una variabile dipendente. La distribuzione Normale può essere usata per specificare la funzione di verosimiglianza in modelli statistici di questo tipo perché può essere concepita come un modo di contare in quanti diversi modi diverse combinazioni di \\(\\mu\\) e \\(\\sigma\\) possono produrre un’osservazione. Per adattare questi modelli ai dati, il presente capitolo ha introdotto un’approssimazione quadratica della distribuzione a posteriori tramite la funzione quap(). Sono state inoltre introdotte nuove procedure per visualizzare le distribuzioni a posteriori e per descrivere le stime a posteriori. Si noti che, per definire la distribuzione a priori del parametro \\(p\\) di una distribuzione di Bernoulli, abbiamo usato una distribuzione uniforme (a priori non informativa), ovvero una Beta(1, 1). In tali circostanze, l’intervallo di credibilità è praticamente identico all’intervallo di confidenza di tipo frequentista. L’intervallo di credibilità, invece, differisce dall’intervallo di confidenza frequentista quando il modello statistico Bayesiano include una distribuzione a priori informativa o debolmente informativa. L’analisi dei dati Bayesiana fa quasi sempre uso di distribuzioni a priori debolmente informative, mentre le distribuzioni a priori informative sono più rare. Le distribuzioni a priori debolmente informative hanno quale scopo la regolarizzazione, cioè, l’obiettivo di mantenere le inferenze in una gamma ragionevole di valori; ciò contribuisce nel contempo a limitare l’influenza eccessiva delle osservazioni estreme (valori anomali). In seguito, quest’idea è stata completamente screditata.↩︎ I metodi di stima MCMC costituiscono la modalità usuale per generare la distribuzione a posteriori nell’analisi Bayesiana. In queste dispense, però, ci limitiamo ai metodi di stima basati sull’approssimazione quadratica. Abbiamo deciso di svolgere gli esercizi mediante l’approssimazione quadratica piuttosto che con il metodo MCMC perché l’installazione sul proprio computer del software necessario per le analisi MCMC costituisce un problema di tipo informatico che esula dagli scopi di questo insegnamento.↩︎ "],["appendici.html", "Appendici Simbologia di base Numeri binari, interi, razionali, irrazionali e reali Intervalli Insiemi Proprietà degli stimatori dei minimi quadrati", " Appendici Simbologia di base Per una scrittura più sintetica possono essere utilizzati alcuni simboli matematici. L’operatore logico booleano \\(\\land\\) significa “e” (congiunzione forte) mentre il connettivo di disgiunzione \\(\\lor\\) significa “o” (oppure) (congiunzione debole). Il quantificatore esistenziale \\(\\exists\\) vuol dire “esiste almeno un” e indica l’esistenza di almeno una istanza del concetto/oggetto indicato. Il quantificatore esistenziale di unicità \\(\\exists!\\) (“esiste soltanto un”) indica l’esistenza di esattamente una istanza del concetto/oggetto indicato. Il quantificatore esistenziale \\(\\nexists\\) nega l’esistenza del concetto/oggetto indicato. Il quantificatore universale \\(\\forall\\) vuol dire “per ogni.” L’implicazione logica “\\(\\Rightarrow\\)” significa “implica” (se …allora). \\(P \\Rightarrow Q\\) vuol dire che \\(P\\) è condizione sufficiente per la verità di \\(Q\\) e che \\(Q\\) è condizione necessaria per la verità di \\(P\\). L’equivalenza matematica “\\(\\iff\\)” significa “se e solo se” e indica una condizione necessaria e sufficiente, o corrispondenza biunivoca. Il simbolo \\(\\vert\\) si legge “tale che.” Il simbolo \\(\\triangleq\\) (o \\(:=\\)) si legge “uguale per definizione.” Il simbolo \\(\\Delta\\) indica la differenza fra due valori della variabile scritta a destra del simbolo. Il simbolo \\(\\propto\\) si legge “proporzionale a.” Il simbolo \\(\\approx\\) si legge “circa.” Il simbolo \\(\\in\\) della teoria degli insiemi vuol dire “appartiene” e indica l’appartenenza di un elemento ad un insieme. Il simbolo \\(\\notin\\) vuol dire “non appartiene.” Il simbolo \\(\\subseteq\\) si legge “è un sottoinsieme di” (può coincidere con l’insieme stesso). Il simbolo \\(\\subset\\) si legge “è un sottoinsieme proprio di.” Il simbolo \\(\\#\\) indica la cardinalità di un insieme. Il simbolo \\(\\cap\\) indica l’intersezione di due insiemi. Il simbolo \\(\\cup\\) indica l’unione di due insiemi. Il simbolo \\(\\emptyset\\) indica l’insieme vuoto o evento impossibile. Numeri binari, interi, razionali, irrazionali e reali Numeri binari I più semplici sono i numeri binari, cioè zero o uno. Useremo spesso numeri binari per rappresentare se qualcosa è vero o falso, o presente o assente. Supponiamo di chiedere a 10 studenti “Ti piacciono i mirtilli?” Poniamo che le risposte siano le seguenti: opinion &lt;- c(&#39;Yes&#39;,&#39;No&#39;,&#39;Yes&#39;,&#39;No&#39;,&#39;Yes&#39;,&#39;No&#39;,&#39;Yes&#39;,&#39;Yes&#39;,&#39;Yes&#39;,&#39;Yes&#39;) opinion #&gt; [1] &quot;Yes&quot; &quot;No&quot; &quot;Yes&quot; &quot;No&quot; &quot;Yes&quot; &quot;No&quot; &quot;Yes&quot; &quot;Yes&quot; &quot;Yes&quot; &quot;Yes&quot; Tali risposte possono essere ricodificate nei termini di valori di verità, ovvero, vero e falso, generalmente denotati rispettivamente come 1 e 0. In tale ricodifica può essere effettuata mediante l’operatore == che è un test per l’uguaglianza e restituisce il valore logico VERO se le due cose sono uguali e FALSO se non lo sono: opinion &lt;- opinion == &quot;Yes&quot; opinion #&gt; [1] TRUE FALSE TRUE FALSE TRUE FALSE TRUE TRUE TRUE TRUE R considera i valori di verità e i numeri binari in modo equivalente, con TRUE uguale a 1 e FALSE uguale a zero. Di conseguenza, possiamo effettuare operazioni algebriche sui valori logici VERO e FALSO. Nell’esempio, possiamo sommare i valori di verità, dividere per 10 sum(opinion) / length(opinion) #&gt; [1] 0.7 e concludere che 7 risposte su 10 sono positive. Numeri interi Un numero intero è un numero senza decimali. Si dicono naturali i numeri che servono a contare, come 1, 2, … L’insieme dei numeri naturali si indica con il simbolo \\(\\mathbb{N}\\). È anche necessario introdurre i numeri con il segno per poter trattare grandezze negative. Si ottengono così l’insieme numerico dei numeri interi relativi: \\(\\mathbb{Z} = \\{0, \\pm 1, \\pm 2, \\dots \\}\\) Numeri razionali I numeri razionali sono i numeri frazionari \\(m/n\\), dove \\(m, n \\in N\\), con \\(n \\neq 0\\). Si ottengono così i numeri razionali: \\(\\mathbb{Q} = \\{\\frac{m}{n} \\,\\vert\\, m, n \\in \\mathbb{Z}, n \\neq 0\\}\\). È evidente che \\(\\mathbb{N} \\subseteq \\mathbb{Z} \\subseteq \\mathbb{Q}\\). Anche in questo caso è necessario poter trattare grandezze negative. I numeri razionali non negativi sono indicati con \\(\\mathbb{Q^+} = \\{q \\in \\mathbb{Q} \\,\\vert\\, q \\geq 0\\}\\). Numeri irrazionali Tuttavia, non tutti i punti di una retta \\(r\\) possono essere rappresentati mediante i numeri interi e razionali. È dunque necessario introdurre un’altra classe di numeri. Si dicono irrazionali, e sono denotati con \\(\\mathbb{R}\\), i numeri che possono essere scritti come una frazione \\(a / b\\), con \\(a\\) e \\(b\\) interi e \\(b\\) diverso da 0. I numeri irrazionali sono i numeri illimitati e non periodici che quindi non possono essere espressi sotto forma di frazione. Per esempio, \\(\\sqrt{2}\\), \\(\\sqrt{3}\\) e \\({\\displaystyle \\pi =3,141592\\ldots}\\) sono numeri irrazionali. Numeri reali I punti della retta \\(r\\) sono quindi “di più” dei numeri razionali. Per poter rappresentare tutti i punti della retta abbiamo dunque bisogno dei numeri reali. I numeri reali possono essere positivi, negativi o nulli e comprendono, come casi particolari, i numeri interi, i numeri razionali e i numeri irrazionali. Spesso in statisticac il numero dei decimali indica il grado di precisione della misurazione. Intervalli Un intervallo si dice chiuso se gli estremi sono compresi nell’intervallo, aperto se gli estremi non sono compresi. Le caratteristiche degli intervalli sono riportate nella tabella seguente. Intervallo chiuso \\[a, b\\] \\(a \\leq x \\leq b\\) aperto (a, b) \\(a &lt; x &lt; b\\) chiuso a sinistra e aperto a destra [a, b) \\(a \\leq x &lt; b\\) aperto a sinistra e chiuso a destra (a, b] \\(a &lt; x \\leq b\\) Insiemi Un insieme (o collezione, classe, gruppo, …) è un concetto primitivo, ovvero è un concetto che già possediamo. Georg Cantor l’ha definito nel modo seguente: un insieme è una collezione di oggetti, determinati e distinti, della nostra percezione o del nostro pensiero, concepiti come un tutto unico; tali oggetti si dicono elementi dell’insieme. Mentre non è rilevante la natura degli oggetti che costituiscono l’insieme, ciò che importa è distinguere se un dato oggetto appartenga o meno ad un insieme. Deve essere vera una delle due possibilità: il dato oggetto è un elemento dell’insieme considerato oppure non è elemento dell’insieme considerato. Due insiemi \\(A\\) e \\(B\\) si dicono uguali se sono formati dagli stessi elementi, anche se disposti in ordine diverso: \\(A=B\\). Due insiemi \\(A\\) e \\(B\\) si dicono diversi se non contengono gli stessi elementi: \\(A \\neq B\\). Ad esempio, i seguenti insiemi sono uguali: \\[\\{1, 2, 3\\} = \\{3, 1, 2\\} = \\{1, 3, 2\\}= \\{1, 1, 1, 2, 3, 3, 3\\}.\\] Gli insiemi sono denotati da una lettera maiuscola, mentre le lettere minuscole, di solito, designano gli elementi di un insieme. Per esempio, un generico insieme \\(A\\) si indica con \\[A = \\{a_1, a_2, \\dots, a_n\\}, \\quad \\text{con~} n &gt; 0.\\] La scrittura \\(a \\in A\\) dice che \\(a\\) è un elemento di \\(A\\). Per dire che \\(b\\) non è un elemento di \\(A\\) si scrive \\(b \\notin A.\\) Per quegli insiemi i cui elementi soddisfano una certa proprietà che li caratterizza, tale proprietà può essere usata per descrivere più sinteticamente l’insieme: \\[ A = \\{x ~\\vert~ \\text{proprietà posseduta da~} x\\}, \\] che si legge come “\\(A\\) è l’insieme degli elementi \\(x\\) per cui è vera la proprietà indicata.” Per esempio, per indicare l’insieme \\(A\\) delle coppie di numeri reali \\((x,y)\\) che appartengono alla parabola \\(y = x^2 + 1\\) si può scrivere: \\[ A = \\{(x,y) ~\\vert~ y = x^2 + 1\\}. \\] Dati due insiemi \\(A\\) e \\(B\\), diremo che \\(A\\) è un sottoinsieme di \\(B\\) se e solo se tutti gli elementi di \\(A\\) sono anche elementi di \\(B\\): \\[A \\subseteq B \\iff (\\forall x \\in A \\Rightarrow x \\in B).\\] Se esiste almeno un elemento di \\(B\\) che non appartiene ad \\(A\\) allora diremo che \\(A\\) è un sottoinsieme proprio di \\(B\\): \\[ A \\subset B \\iff (A \\subseteq B, \\exists~ x \\in B ~\\vert~ x \\notin A). \\] Un altro insieme, detto insieme delle parti, o insieme potenza, che si associa all’insieme \\(A\\) è l’insieme di tutti i sottoinsiemi di \\(A\\), inclusi l’insieme vuoto e \\(A\\) stesso. Per esempio, per l’insieme \\(A = \\{a, b, c\\}\\), l’insieme delle parti è: \\[ \\mathcal{P}(A) = \\{ \\emptyset, \\{a\\}, \\{b\\}, \\{c\\}, \\{a, b\\}, \\{a, c\\}, \\{c, b\\}, \\{a, b, c\\} \\}. \\] Operazioni tra insiemi Si definisce intersezione di \\(A\\) e \\(B\\) l’insieme \\(A \\cap B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) e contemporaneamente a \\(B\\): \\[A \\cap B = \\{x ~\\vert~ x \\in A \\land x \\in B\\}.\\] Si definisce unione di \\(A\\) e \\(B\\) l’insieme \\(A \\cup B\\) di tutti gli elementi \\(x\\) che appartengono ad \\(A\\) o a \\(B\\), cioè \\[ A \\cup B = \\{x ~\\vert~ x \\in A \\lor x \\in B\\}. \\] Differenza. Si indica con \\(A \\setminus B\\) l’insieme degli elementi di \\(A\\) che non appartengono a \\(B\\): \\[A \\setminus B = \\{x ~\\vert~ x \\in A \\land x \\notin B\\}.\\] Insieme complementare. Nel caso che sia \\(B \\subseteq A\\), l’insieme differenza \\(A \\setminus B\\) è detto insieme complementare di \\(B\\) in \\(A\\) e si indica con \\(B^C\\). Dato un insieme \\(S\\), una partizione di \\(S\\) è una collezione di sottoinsiemi di \\(S\\), \\(S_1, \\dots, S_k\\), tali che \\[S = S_1 \\cup S_2 \\cup \\dots S_k\\] e \\[S_i \\cap S_j, \\quad \\text{con~} i \\neq j.\\] La relazione tra unione, intersezione e insieme complementare è data dalle leggi di DeMorgan: \\[(A \\cup B)^c = A^c \\cap B^c,\\] \\[(A \\cap B)^c = A^c \\cup B^c.\\] Diagrammi di Eulero-Venn In molte situazioni è utile servirsi dei cosiddetti diagrammi di Eulero-Venn per rappresentare gli insiemi e verificare le proprietà delle operazioni tra insiemi (si veda la figura 17.5. I diagrammi di Venn sono così nominati in onore del matematico inglese del diciannovesimo secolo John Venn anche se Leibnitz e Eulero avevano già in precedenza utilizzato rappresentazioni simili. In tale rappresentazione, gli insiemi sono individuati da regioni del piano delimitate da una curva chiusa. Nel caso di insiemi finiti, è possibile evidenziare esplicitamente alcuni elementi di un insieme mediante punti, quando si possono anche evidenziare tutti gli elementi degli insiemi considerati. Figura 17.5: In tutte le figure \\(S\\) è la regione delimitata dal rettangolo, \\(L\\) è la regione all’interno del cerchio di sinistra e \\(R\\) è la regione all’interno del cerchio di destra. La regione evidenziata mostra l’insieme indicato sotto ciascuna figura. I diagrammi di Eulero-Venn che forniscono una dimostrazione delle leggi di DeMorgan sono forniti nella figura 17.6. Figura 17.6: Dimostrazione delle leggi di DeMorgan. Coppie ordinate e prodotto cartesiano Una coppia ordinata \\((x,y)\\) è l’insieme i cui elementi sono \\(x \\in A\\) e \\(y \\in B\\) e nella quale \\(x\\) è la prima componente (o prima coordinata), \\(y\\) la seconda. L’insieme di tutte le coppie ordinate costruite a partire dagli insiemi \\(A\\) e \\(B\\) viene detto prodotto cartesiano: \\[A \\times B = \\{(x, y) ~\\vert~ x \\in A \\land y \\in B\\}.\\] Ad esempio, sia \\(A = \\{1, 2, 3\\}\\) e \\(B = \\{a, b\\}\\). Allora, \\[\\{1, 2\\} \\times \\{a, b, c\\} = \\{(1, a), (1, b), (1, c), (2, a), (2, b), (2, c)\\}.\\] Cardinalità Si definisce cardinalità (o potenza) di un insieme finito il numero degli elementi dell’insieme. Viene indicata con \\(\\vert A\\vert, \\#(A)\\) o \\(\\text{c}(A)\\). Proprietà degli stimatori dei minimi quadrati Il coefficiente dei minimi quadrati \\(b\\) è una combinazione lineare delle osservazioni \\(y_i\\). Tale proprietà è importante perché consente di derivare la distribuzione di \\(b\\) dalla distribuzione delle \\(y_i\\). Può essere dimostrato che la formula per il calcolo di \\(b\\) si può scrivere nel modo seguente: \\[\\begin{aligned} b &amp;= \\sum_i \\left[\\frac{x_i-\\bar{x}}{\\sum_j(x_j-\\bar{x})^2}\\right]y_i = \\textstyle\\sum m_i y_i,\\end{aligned}\\] dove \\(m_i \\triangleq (x_i-\\bar{x}) / \\sum (x_j-\\bar{x})^2\\) è il peso associato a ciascun valore \\(y_i\\). Dato che i valori \\(x_i\\) sono fissi e \\(m_i\\) dipende solo da \\(x_i\\), anche i pesi \\(m_i\\) sono fissi. Il valore atteso di \\(b\\) è uguale a \\[\\begin{aligned} E(b) &amp;= \\textstyle\\sum m_i E(y_i)\\notag\\\\ &amp;= \\textstyle\\sum m_i (\\alpha + \\beta x_i)\\notag\\\\ &amp;= \\textstyle\\alpha\\sum m_i + \\beta \\sum m_i x_i\\notag\\\\ &amp;= \\frac{\\alpha \\sum(x_i-\\bar{x})}{\\sum(x_i-\\bar{x})^2} + \\beta \\frac{\\sum(x_i-\\bar{x})x_i}{\\sum(x_i-\\bar{x})^2}\\notag\\\\ &amp;= 0 + \\beta \\frac{\\sum x_i^2 -\\bar{x}\\sum x_i}{\\sum(x_i-\\bar{x})^2}\\notag\\\\ &amp;= \\beta \\frac{\\sum x_i^2 - n\\bar{x}^2}{\\sum(x_i-\\bar{x})^2}\\notag\\\\ &amp;= \\beta.\\end{aligned}\\] Il coefficiente dei minimi quadrati \\(b\\) è dunque uno stimatore corretto di \\(\\beta\\). In maniera equivalente si può dimostrare che \\(E(a) = \\alpha\\). Sotto le ipotesi di omoschedasticità \\(\\big[ \\var(y_i) = \\var(\\varepsilon_i)=\\sigma^2_{\\varepsilon}\\big]\\) e indipendenza, la varianza di \\(b\\) è \\[\\begin{aligned} \\var(b) &amp;= \\textstyle\\var\\big(\\sum m_i y_i\\big)\\notag\\\\ &amp;= \\textstyle\\mathop{\\sum m_i^2} \\var(y_i)\\notag\\\\ &amp;= \\textstyle\\mathop{\\sum m_i^2} \\sigma^2_{\\varepsilon}\\notag\\\\ &amp;= \\frac{\\mathop{\\sigma^2_{\\varepsilon}} \\textstyle\\sum(x_i-\\bar{x})^2}{\\big[\\textstyle\\sum(x_i-\\bar{x})^2\\big]^2}\\notag\\\\ &amp;= \\frac{\\sigma^2_{\\varepsilon}}{\\sum(x_i-\\bar{x})^2}.\\end{aligned}\\] In maniera simile si dimostra che la varianza di \\(a\\) è \\[\\var(a)= \\frac{\\sigma^2_{\\varepsilon} \\textstyle\\sum x_i^2}{n \\textstyle\\sum (x_i-\\bar{x})^2}.\\] Dato che sia \\(a\\) che \\(b\\) sono funzioni lineari di \\(y_i\\), se i valori \\(y_i\\) seguono la distribuzione gaussiana, allora anche \\(a\\) e \\(b\\) saranno distribuiti secondo una distribuzione normale. In conclusione, \\[\\begin{aligned} b &amp;\\sim \\mathcal{N}\\bigg(\\beta, \\frac{\\sigma^2_{\\varepsilon}}{\\sum(x_i-\\bar{x})^2}\\bigg),\\\\ a &amp;\\sim \\mathcal{N}\\bigg(\\alpha, \\frac{\\sigma^2_{\\varepsilon}\\textstyle\\sum x_i^2}{n \\textstyle\\sum (x_i-\\bar{x})^2} \\bigg).\\end{aligned}\\] "],["bibliografia.html", "Bibliografia", " Bibliografia Anderson, T. W., &amp; Finn, J. D. (2012). The new statistical analysis of data. Springer Science &amp; Business Media. Cesario, J., Johnson, D. J., &amp; Terrill, W. (2019). Is there evidence of racial disparity in police use of deadly force? Analyses of officer-involved fatal shootings in 2015–2016. Social Psychological and Personality Science, 10(5), 586–595. Gautret, P., Lagier, J. C., Parola, P., Meddeb, L., Mailhe, M., Doudier, B., &amp; Honoré, S. (2020). Hydroxychloroquine and azithromycin as a treatment of COVID-19: Results of an open-label non-randomized clinical trial. International Journal of Antimicrobial Agents. Gelman, A., Hill, J., &amp; Vehtari, A. (2020). Regression and other stories. Cambridge University Press. Grolemund, G. (2014). Hands-on programming with R: Write your own functions and simulations. O’Reilly Media, Inc. Hulme, O. J., Wagenmakers, E. J., Damkier, P., Madelung, C. F., Siebner, H. R., Helweg-Larsen, J., &amp; Madsen, K. H. (2020). Reply to gautret et al. 2020: A bayesian reanalysis of the effects of hydroxychloroquine and azithromycin on viral carriage in patients with COVID-19. medRxiv. Kruschke, J. (2014). Doing bayesian data analysis: A tutorial with r, JAGS, and stan. Academic Press. McElreath, R. (2020). Statistical rethinking: A bayesian course with examples in r and stan (2nd Edition). CRC Press. Ross, C. T., Winterhalder, B., &amp; McElreath, R. (2020). Racial disparities in police use of deadly force against unarmed individuals persist after appropriately benchmarking shooting data on violent crime rates. Social Psychological and Personality Science, 1–10. Stevens, S. S. (1946). On the theory of scales of measurement. Science, 103(2684), 677–680. Tufte, E. R. (2001). The visual display of quantitative information. Graphics press Cheshire, CT. Zetsche, U., Bürkner, P.-C., &amp; Renneberg, B. (2019). Future expectations in clinical depression: Biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688. "]]
