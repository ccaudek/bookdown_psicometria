[["index.html", "PSICOMETRIA Prefazione Perché tanta statistica in psicologia? Come studiare?", " PSICOMETRIA Corrado Caudek 2020-12-16 Prefazione Questo LIBRO-IN-PROGRESS è stato aggiornato il giorno: 16 Dic 2020. Queste dispense contengono il materiale delle lezioni dell’insegnamento Psicometria B000286 (A.A. 2019/2020) rivolto agli studenti del primo anno del Corso di Laurea in Scienze e Tecniche Psicologiche dell’Università di Firenze. L’insegnamento di Psicometria si propone di fornire agli studenti un’introduzione all’analisi dei dati in psicologia. Alcuni degli argomenti trattati richiedono delle conoscenze pregresse, soprattutto di tipo matematico. Tali conoscenze sono state aggiunte delle appendici di queste dispense. La lettura di tale materiale è consigliata a tutti, sia a chi sta studiando gli argomenti proposti per la prima volta, sia a chi deve ripassare per colmare eventuali lacune pregresse. Perché tanta statistica in psicologia? Sembra sensato spendere due parole su un tema che è importante per gli studenti: quello indicato dal titolo di questa sezione. È ovvio che agli studenti di psicologia la statistica non piace. Se piacesse, forse studierebbero statistica e non psicologia; ma non lo fanno. Di conseguenza, gli studenti di psicologia si chiedono: ``perché dobbiamo perdere tanto tempo a studiare queste cose quando in realtà quello che ci interessa è tutt’altro?’’ Questa è una bella domanda. Per cercare di rispondere a questa domanda introduco il paradosso di Simpson. Consideriamo un fenomeno sociale che ha suscitato un enorme interesse in tempi recenti: la brutalità della polizia e le diseguaglianze razziali messe in evidenza dalle uccisioni da parte della polizia statunitense. Per affrontare questo tema, esaminiamo l’analisi statistica descritta in un articolo di Ross et al. (2020). La logica di tale analisi statistica può essere descritta nel modo seguente. Immaginiamo due gruppi di individui: Montechi e Capuleti. Il 10% dei Montechi e il 20% dei Capuleti commette crimini violenti (ovvero, sono dei criminali). In un anno, il 14% dei Montechi viene ucciso dalla polizia contro il 26% dei Capuleti. Come si fa a capire se c’è un pregiudizio verso uno dei due gruppi? Cesario et al. (2019) sostengono che è necessario dividere la frequenza relativa di uccisioni da parte della polizia per la percentuale di criminali in ciascun gruppo. Quindi, secondo questa logica, il tasso di uccisioni da parte della polizia è di 14/10 = 1.4% per i Capuleti e di 26/20 = 1.3% per i Montechi. Questo indica una discriminazione contro i Capuleti e ci fornisce la risposta alla nostra domanda. Ma le cose stanno effettivamente così? Forse no. Se decomponiamo il numero di uccisioni da parte della polizia in ciascuna delle modalità della variabile criminalità (ovvero, criminali vs. non criminali), scopriamo che, per i Capuleti, i 14 morti possono essere suddivisi in 5 morti di criminali e 9 morti di non criminali. Per Montechi, i 26 morti si suddividono in 10 morti di criminali e 16 morti di non criminali. Quindi, i criminali Capuleti vengono uccisi dalla polizia ad un tasso del 5/10 = 50% e i criminali Montechi vengono uccisi ad un tasso del 10/20 = 50% – lo stesso tasso nei due gruppi. Ma i non criminali Capuleti vengono uccisi dalla polizia ad un tasso del 9/90 = 10%, mentre i non criminali Montechi vengono uccisi ad un tasso del 16/80 = 20%. Ciò significa che i criminali di entrambi i gruppi hanno la stessa probabilità di essere uccisi dalla polizia, ma i non criminali Montechi hanno due volte la probabilità di essere uccisi dalla polizia dei non criminali Capuleti. Questo indica un’enorme discriminazione contro i Montechi! Eppure, l’analisi precedente aveva prodotto il risultato opposto. Lasciando perdere Shakespeare, Ross et al. (2020) hanno dimostrato che questo è esattamente ciò che sta succedendo con i dati reali sulle sparatorie della polizia negli Stati Uniti: i neri disarmati negli Stati Uniti vengono uccisi a tassi molto più alti rispetto ai bianchi disarmati, sebbene i tassi siano simili nei due gruppi quando si considerano solo le sparatorie con individui armati; se tuttavia si riassumono i dati considerando solo la frequenza totale dei morti scalata per il tasso di criminalità questo fatto viene oscurato. L’articolo di ci fa vedere come sia necessario stare molto attenti con l’uso della statistica, specialmente quando gli errori statistici possono avere un impatto enorme sulla percezione pubblica – e, nella psicologia, sulla pratica dello psicologo. Le analisi statistiche precedenti sono un esempio di ciò che viene chiamato il paradosso di Simpson, ovvero il fatto che, alle volte, quando si riassumono i dati in un modo apparentemente ragionevole, si finisce per giungere ad una conclusione del tutto sbagliata. Il paradosso di Simpson illustra il fatto che non è semplice neppure i dati, figurarsi poi fare delle inferenze! Queste considerazioni ci fanno capire che, senza un certo livello di consapevolezza metodologica, lo psicologo (e non solo) si espone al rischio di fare errori gravissimi. Ma c’è un’altra ragione ancora più semplice che dovrebbe farci capire perché la statistica è così importante per la psicologia. Infatti, a ben pensarci, la psicologia è una disciplina intrinsecamente statistica, se per statistica intendiamo quella disciplina che studia la variazione delle caratteristiche degli individui nella popolazione. La psicologia studia gli individui ed è proprio la variabilità inter- e intra-individuale ciò che vogliamo descrivere e, in certi casi, predire. In questo senso, la psicologia è molto diversa dall’ingegneria, per esempio. Le proprietà di un determinato ponte, sotto certe condizioni, sono molto simili a quelle di un altro ponte, sotto le medesime condizioni. Quindi, per un ingegnere la statistica è poco importante: le proprietà dei materiali sono unicamente dipendenti dalla loro composizione e restano costanti. Ma lo stesso non si può dire degli individui: ogni individuo è unico e cambia nel tempo. E le variazioni tra gli individui, e di un individuo nel tempo, sono l’oggetto di studio proprio della psicologia: è dunque chiaro che i problemi che la psicologia si pone sono molto diversi da quelli affrontati, per esempio, dagli ingegneri. Questa è la ragione per cui abbiamo tanto bisogno della statistica in psicologia: perché la statistica ci consente di descrivere la variazione e il cambiamento. E queste sono appunto le caratteristiche di base dei fenomeni psicologici. Sono sicuro che, leggendo queste righe, a molti studenti sarà venuta in mente la seguente domanda: perché non chiediamo a qualche esperto di fare il “lavoro sporco” (ovvero le analisi statistiche) per noi, mentre noi (psicologi) ci occupiamo solo di ciò che ci interessa, ovvero dei problemi psicologici slegati dai dettagli `tecnici’ della statistica? La risposta a questa domanda è che non è possibile progettare uno studio psicologico sensato senza avere almeno una comprensione rudimentale della teoria statistica. Ma non possiamo liberarci della statistica anche se non vogliamo diventare dei ricercatori e ci accontentiamo di svolgere la professione di psicologo. Infatti, anche in questo secondo caso, non possiamo fare a meno di leggere la letteratura psicologica più recente: il continuo aggiornamento delle nostre conoscenze è infatti richiesto dalla deontologia della professione. Ma è necessario conoscere un bel po’ di statistica per potere fare questo. Per rendersi conto di quanto ciò sia vero basta aprire a caso una rivista specialistica di psicologia: gli articoli che riportano i risultati delle ricerche psicologiche sono zeppi di analisi statistiche e di modelli formali. E la comprensione della letteratura psicologica è proprio uno dei requisiti minimi del bagaglio professionale dello psicologo. Le considerazioni precedenti cercano di chiarire il seguente punto: la statistica non è qualcosa che, in un singolo insegnamento universitario, dobbiamo studiare a malincuore, per poi potercela tranquillamente dimenticare. Nel bene e nel male, gli psicologi usano strumenti statistici in tantissime fasi della loro attività professionale: in particolare quando costruiscono, somministrano e interpretano i test psicometrici. È dunque chiaro che possedere delle solide basi di statistica è un tassello imprescindibile del bagaglio professionale dello psicologo. Come studiare? Il giusto metodo di studio per prepararsi all’esame di Psicometria è quello di seguire attivamente le lezioni, assimilare i concetti via via che essi vengono presentati e verificare in autonomia le procedure presentate a lezione. È importante fare domande a lezione per sviluppare la capacità di mettere in relazione tra loro i diversi argomenti trattati, prendere parte alle esercitazioni organizzate dai Peer Tutor, utilizzare i forum attivi su Moodle e, soprattutto, svolgere gli esercizi proposti su Moodle. I problemi forniti su Moodle rappresentano la difficoltà richiesta per superare l’esame e consentono allo studente di capire se le competenze sviluppate risultino essere sufficienti rispetto alle richieste dell’insegnamento. Incoraggio inoltre gli studenti a venire a ricevimento e parlare con me per per chiarire ciò che non si è capito appieno. "],["chapter-pacchetti.html", "Capitolo 1 Pacchetti", " Capitolo 1 Pacchetti Riporto qui tutti i pacchetti che verranno usati in queste dispense. suppressPackageStartupMessages(library(&quot;here&quot;)) suppressPackageStartupMessages(library(&quot;tidyverse&quot;)) suppressPackageStartupMessages(library(&quot;ggpubr&quot;)) suppressPackageStartupMessages(library(&quot;ggExtra&quot;)) suppressPackageStartupMessages(library(&quot;car&quot;)) suppressPackageStartupMessages(library(&quot;cowplot&quot;)) suppressPackageStartupMessages(library(&quot;tidybayes&quot;)) suppressPackageStartupMessages(library(&quot;datasauRus&quot;)) suppressPackageStartupMessages(library(&quot;RColorBrewer&quot;)) suppressPackageStartupMessages(library(&quot;rio&quot;)) library(&quot;patchwork&quot;) theme_set(theme_tidybayes() + panel_border()) set.seed(12345) sessionInfo() #&gt; R version 3.6.3 (2020-02-29) #&gt; Platform: x86_64-apple-darwin15.6.0 (64-bit) #&gt; Running under: macOS Mojave 10.14.6 #&gt; #&gt; Matrix products: default #&gt; BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib #&gt; LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib #&gt; #&gt; locale: #&gt; [1] it_IT.UTF-8/it_IT.UTF-8/it_IT.UTF-8/C/it_IT.UTF-8/it_IT.UTF-8 #&gt; #&gt; attached base packages: #&gt; [1] stats graphics grDevices utils datasets methods base #&gt; #&gt; other attached packages: #&gt; [1] pander_0.6.3 knitr_1.30.2 rio_0.5.16 ggExtra_0.9 #&gt; [5] bayesplot_1.7.2 datasauRus_0.1.4 ggpubr_0.4.0 patchwork_1.1.0 #&gt; [9] car_3.0-10 carData_3.0-4 cowplot_1.1.0 RColorBrewer_1.1-2 #&gt; [13] tidybayes_2.3.1 here_1.0.1 forcats_0.5.0 stringr_1.4.0 #&gt; [17] dplyr_1.0.2 purrr_0.3.4 readr_1.4.0 tidyr_1.1.2 #&gt; [21] tibble_3.0.4 ggplot2_3.3.2 tidyverse_1.3.0 #&gt; #&gt; loaded via a namespace (and not attached): #&gt; [1] fs_1.5.0 lubridate_1.7.9.2 httr_1.4.2 #&gt; [4] rprojroot_2.0.2 tools_3.6.3 backports_1.2.1 #&gt; [7] R6_2.5.0 DBI_1.1.0 colorspace_2.0-0 #&gt; [10] ggdist_2.3.0 withr_2.3.0 tidyselect_1.1.0 #&gt; [13] curl_4.3 compiler_3.6.3 cli_2.2.0 #&gt; [16] rvest_0.3.6 arrayhelpers_1.1-0 xml2_1.3.2 #&gt; [19] bookdown_0.21 scales_1.1.1 ggridges_0.5.2 #&gt; [22] askpass_1.1 digest_0.6.27 foreign_0.8-75 #&gt; [25] rmarkdown_2.5 pkgconfig_2.0.3 htmltools_0.5.0 #&gt; [28] fastmap_1.0.1 dbplyr_2.0.0 highr_0.8 #&gt; [31] rlang_0.4.9 readxl_1.3.1 rstudioapi_0.13 #&gt; [34] shiny_1.5.0 farver_2.0.3 generics_0.1.0 #&gt; [37] svUnit_1.0.3 jsonlite_1.7.2 zip_2.1.1 #&gt; [40] distributional_0.2.1 magrittr_2.0.1 Rcpp_1.0.5 #&gt; [43] munsell_0.5.0 fansi_0.4.1 abind_1.4-5 #&gt; [46] lifecycle_0.2.0 stringi_1.5.3 yaml_2.2.1 #&gt; [49] plyr_1.8.6 grid_3.6.3 promises_1.1.1 #&gt; [52] crayon_1.3.4 miniUI_0.1.1.1 lattice_0.20-41 #&gt; [55] haven_2.3.1 hms_0.5.3 magick_2.5.2 #&gt; [58] pillar_1.4.7 ggsignif_0.6.0 codetools_0.2-18 #&gt; [61] reprex_0.3.0 glue_1.4.2 evaluate_0.14 #&gt; [64] pdftools_2.3.1 qpdf_1.1 data.table_1.13.4 #&gt; [67] modelr_0.1.8 httpuv_1.5.4 vctrs_0.3.5 #&gt; [70] cellranger_1.1.0 gtable_0.3.0 assertthat_0.2.1 #&gt; [73] xfun_0.19 openxlsx_4.2.3 mime_0.9 #&gt; [76] xtable_1.8-4 broom_0.7.2 later_1.1.0.1 #&gt; [79] rstatix_0.6.0 coda_0.19-4 tinytex_0.28 #&gt; [82] ellipsis_0.3.1 "],["chapter-terminologia.html", "Capitolo 2 Terminologia 2.1 Metodi e procedure della psicologia 2.2 Variabili e costanti 2.3 Variabili indipendenti e variabili dipendenti 2.4 La matrice dei dati", " Capitolo 2 Terminologia 2.1 Metodi e procedure della psicologia Una teoria psicologica di un qualche aspetto del comportamento umano o della mente ha le seguenti proprietà: descrive le caratteristiche del comportamento in questione, formula predizioni sulle caratteristiche future del comportamento, è sostenuta da evidenze empiriche, deve essere falsificabile (ovvero, in linea di principio, deve potere fare delle predizioni su aspetti del fenomeno considerato che non sono ancora noti e che, se venissero indagati, potrebbero portare a rigettare la teoria, se si dimostrassero incompatibili con essa). L’analisi dei dati si riferisce al punto 3 indicato sopra e, nelle sue fasi distinte, ovvero la misurazione, l’analisi descrittiva, l’inferenza causale, ha un ruolo centrale nello sviluppo delle teorie psicologiche. Prima di affrontare il primo degli ambiti in cui abbiamo articolato l’analisi dei dati, ovvero quello della misurazione, prenderemo qui in esame la terminologia che viene utilizzata. 2.2 Variabili e costanti L’analisi dei dati inizia con l’individuazione delle unità portatrici di informazioni circa il fenomeno di interesse. Si dice popolazione (o universo) l’insieme \\(\\Omega\\) delle entità capaci di fornire informazioni sul fenomeno oggetto dell’indagine statistica. Possiamo dunque scrivere \\(\\Omega = \\{\\omega_i\\}_{i=1, \\dots, n}= \\{\\omega_1, \\omega_2, \\dots, \\omega_n\\}\\) oppure \\(\\Omega = \\{\\omega_1, \\omega_2, \\dots \\}\\) nel caso di popolazioni finite o infinite, rispettivamente. Gli elementi \\(\\omega_i\\) dell’insieme \\(\\Omega\\) sono detti unità statistiche. Un sottoinsieme della popolazione viene chiamato campione. Ciascuna unità statistica \\(\\omega_i\\) (abbreviata con u.s.) è portatrice dell’informazione che verrà rilevata mediante un’operazione di misurazione. Definiamo variabile statistica la proprietà (o grandezza) che è oggetto di studio nell’analisi dei dati. Una variabile è una proprietà di un fenomeno che può essere espressa in più valori sia numerici sia categoriali. Il termine “variabile” si contrappone al termine “costante” che descrive una proprietà invariante di tutte le unità statistiche. Si dice modalità ciascuna delle varianti con cui una variabile statistica può presentarsi. Definiamo insieme delle modalità di una variabile statistica l’insieme \\(M\\) di tutte le possibili espressioni con cui la variabile può manifestarsi. Le modalità osservate e facenti parte del campione si chiamano dati (si veda la Tabella 1.1). Proprietà oggetto di studio, variabile e modalità. Fenomeno studiato Popolazione Variabile Modalità Tipo Intelligenza Tutti gli italiani WAIS-IV \\(112\\), \\(92\\), \\(121\\), … Quantitativo discreto Velocità di esecuzione nel compito Stroop Bambini dai 6 agli 8 anni Reciproco dei tempi di reazione \\(1/2.36\\) s, \\(1/4.72\\) s, \\(1/3.81\\) s, … Quantitativo continuo Disturbo di personalità Detenuti nelle carceri italiane Assessment del disturbo di personalità tramite interviste cliniche strutturate Cluster A, Cluster B, Cluster C proposti dal DSM-V Qualitativo 2.3 Variabili indipendenti e variabili dipendenti È importante distinguere il concetto di variabile indipendente, che descrive ciò che viene manipolato dallo sperimentatore o che è già presente nel campione, dalla variabile dipendente, che descrive ciò che varia al variare della variabile indipendente e che viene misurato nel campione. Exercizio 2.1 Uno psicologo convoca 120 studenti universitari per un test di memoria. Prima di iniziare l’esperimento, a metà dei soggetti viene detto che si tratta di un compito particolarmente difficile; agli altri soggetti non viene data alcuna indicazione. Lo psicologo misura il punteggio nella prova di memoria di ciascun soggetto. Si individuino la variabile indipendente e la variabile dipendente di questo esperimento. Soluzione. La variabile indipendente è l’informazione sulla difficoltà della prova. La variabile indipendente viene manipolata dallo sperimentatore assegnando i soggetti (di solito in maniera causale) o alla condizione (modalità) “informazione assegnata” o “informazione non data.” La variabile dipendente è ciò che viene misurato nell’esperimento, ovvero il punteggio nella prova di memoria di ciascun soggetto. 2.4 La matrice dei dati Le realizzazioni delle variabili esaminate in una rilevazione statistica vengono organizzate in una matrice dei dati. Le colonne della matrice dei dati contengono gli insiemi dei dati individuali di ciascuna variabile statistica considerata. Ogni riga della matrice contiene tutte le informazioni relative alla stessa unità statistica. Una generica matrice dei dati ha l’aspetto seguente: \\[D_{m,n} = \\begin{pmatrix} \\omega_1 &amp; a_{1} &amp; b_{1} &amp; \\cdots &amp; x_{1} &amp; y_{1}\\\\ \\omega_2 &amp; a_{2} &amp; b_{2} &amp; \\cdots &amp; x_{2} &amp; y_{2}\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots \\\\ \\omega_n &amp; a_{n} &amp; b_{n} &amp; \\cdots &amp; x_{n} &amp; y_{n} \\end{pmatrix}\\] dove, nel caso presente, la prima colonna contiene il nome delle unità statistiche, la seconda e la terza colonna si riferiscono a due mutabili statistiche (variabili categoriali; \\(A\\) e \\(B\\)) e ne presentano le modalità osservate nel campione mentre le ultime due colonne si riferiscono a due variabili statistiche (\\(X\\) e \\(Y\\)) e ne presentano le modalità osservate nel campione. Generalmente, tra le unità statistiche \\(\\omega_i\\) non esiste un ordine progressivo; l’indice attribuito alle unità statistiche nella matrice dei dati si riferisce semplicemente alla riga che esse occupano. "],["chapter-misurazione.html", "Capitolo 3 La misurazione in psicologia 3.1 Le scale di misura 3.2 Variabili discrete vs. variabili continue 3.3 Perché alcune misurazioni sono migliori di altre? Conclusioni", " Capitolo 3 La misurazione in psicologia Le osservazioni empiriche – osservazioni sul campo, sondaggi o risultati di esperimenti – forniscono il materiale che viene utilizzato in un’indagine statistica e sono chiamate dati. Quando parliamo di dati dobbiamo chiederci: in che misura i dati che sono stati raccolti sono in grado di rappresentare in maniera veritiera le caratteristiche del fenomeno esaminato? C’è un’intera disciplina che cerca di rispondere alla domanda precedente: la “teoria della misurazione.” Senza entrare nei dettagli, il presente capitolo intende fornire un’introduzione generale alle tematiche della misurazione in psicologia. 3.1 Le scale di misura I risultati delle misurazioni, ovvero le variabili, devono avere almeno due valori possibili (altrimenti sarebbero delle costanti). È importante notare che le modalità delle variabili sono in grado di descrivere l’intensità del fenomeno misurato con livelli diversi di precisione. La capacità delle variabili di “catturare” in forma numerica le proprietà del fenomeno che esse rappresentano viene descritta dalla teoria delle scale di misura di Stevens (1946). Secondo tale teoria, possiamo distinguere quattro scale di misura aventi proprietà diverse: le scale nominali (nominal scales), ordinali (ordinal scales), a intervalli (interval scales), di rapporti (ratio scales). 3.1.1 Scala nominale La scala nominale raggruppa i dati in categorie qualitative mutuamente esclusive (cioè nessun dato si può collocare in più di una categoria). Esiste la sola relazione di equivalenza tra le misure delle u.s., cioè nella scala nominale gli elementi del campione appartenenti a classi diverse sono differenti, mentre tutti quelli della stessa classe sono tra loro equivalenti: \\(x_i = x_j\\) oppure \\(x_i \\neq x_j\\). È ammessa l’operazione del conteggio delle u.s. presenti in ogni categoria e il conteggio delle classi di equivalenze, dunque la descrizione dei dati avviene tramite le frequenze assolute e le frequenze relative. A partire da una scala nominale è possibile costruire altre scale equivalenti trasformando i valori della scala di partenza in modo tale da cambiare i nomi delle modalità ma lasciando però inalterata la suddivisione u.s. nelle medesime classi di equivalenza. Questo significa che prendendo una variabile misurata su scala nominale e cambiando i nomi delle sue categorie otteniamo una nuova variabile esattamente corrispondente alla prima. 3.1.2 Scala ordinale La scala ordinale conserva la proprietà della scala nominale di classificare ciascun dato all’interno di una sola categoria, ma alla relazione di equivalenza tra elementi di una stessa classe aggiunge la relazione di ordinamento tra le varie classi di equivalenza. Essendo basata su una relazione d’ordine, una scala ordinale descrive soltanto l’ordine di rango tra le modalità, ma non dà alcuna informazione su quanto una modalità sia più grande di un’altra. Non ci dice, per esempio, se la distanza tra le modalità \\(a\\) e \\(b\\) sia uguale, maggiore o minore della distanza tra le modalità \\(b\\) e \\(c\\). Esempio 3.1 (Scala Mohs) Un esempio classico di scala ordinale è quello della scala Mohs per la determinazione della durezza dei minerali. Per stabilire la durezza dei minerali si usa il criterio empirico della scalfittura. Vengono stabiliti livelli di durezza crescente da 1 a 10 con riferimento a dieci minerali: talco, gesso, calcite, fluorite, apatite, ortoclasio, quarzo, topazio, corindone e diamante. Un minerale appartenente ad uno di questi livelli se scalfisce quello di livello inferiore ed è scalfito da quello di livello superiore. 3.1.3 Scala ad intervalli La scala ad intervalli include le proprietà di quella nominale e di quella ordinale, e in più consente di misurare le distanze tra le coppie di u.s. nei termini di un intervallo costante, chiamato unità di misura, a cui viene attribuito il valore “1.” La posizione dell’origine della scala, cioè il punto zero, è scelta arbitrariamente, nel senso che non indica l’assenza della quantità che si sta misurando. Avendo uno zero arbitrario, questa scala di misura consente valori negativi. Lo zero, infatti, non viene attribuito all’u.s. in cui la proprietà misurata risulta assente. La scala a intervalli equivalenti ci consente di effettuare operazioni algebriche basate sulla differenza tra i numeri associati ai diversi punti della scala, operazioni algebriche non era possibile eseguire nel caso di misure a livello di scala ordinale o nominale. Il limite della scala ad intervalli è quello di non consentire il calcolo del rapporto tra coppie di misure. Possiamo dire, per esempio, che la distanza tra \\(a\\) e \\(b\\) è la metà della distanza tra \\(c\\) e \\(d\\). Oppure che la distanza tra \\(a\\) e \\(b\\) è uguale alla distanza tra \\(c\\) e \\(d\\). Non possiamo dire, però, che \\(a\\) possiede la proprietà misurata in quantità doppia rispetto \\(b\\). Non possiamo cioè stabilire dei rapporti diretti tra le misure ottenute. Solo per le differenze tra le modalità sono dunque permesse tutte le operazioni aritmetiche: le differenze possono essere tra loro sommate, elevate a potenza oppure divise, determinando così le quantità che stanno alla base della statistica inferenziale. Nelle scale ad intervalli equivalenti, l’unità di misura è arbitraria, ovvero può essere cambiata attraverso una dilatazione, operazione che consiste nel moltiplicare tutti i valori della scala per una costante positiva. Poiché l’aggiunta di una costante non altera le differenze tra i valori della scala, è anche ammessa la traslazione, operazione che consiste nel sommare una costante a tutti i valori della scala. Essendo la scala invariate rispetto alla traslazione e alla dilatazione, le trasformazioni ammissibili sono le trasformazioni lineari: \\[y&#39; = a + by, \\quad b &gt; 0.\\] L’aspetto che rimane invariante a seguito di una trasformazione lineare è l’uguaglianza dei rapporti fra intervalli. Esempio 3.2 (Temperatura) Esempio di scala ad intervalli è la temperatura misurata in gradi Celsius o Fahrenheit, ma non Kelvin. Come per la scala nominale, è possibile stabilire se due modalità sono uguali o diverse: 30\\(^\\circ\\)C \\(\\neq\\) 20\\(^\\circ\\)C. Come per la scala ordinale è possibile mettere due modalità in una relazione d’ordine: 30\\(^\\circ\\)C \\(&gt;\\) 20\\(^\\circ\\)C. In aggiunta ai casi precedenti, però, è possibile definire una unità di misura per cui è possibile dire che tra 30\\(^\\circ\\)C e 20\\(^\\circ\\)C c’è una differenza di 30\\(^\\circ\\) - 20\\(^\\circ\\) = 10\\(^\\circ\\)C. I valori di temperatura, oltre a poter essere ordinati secondo l’intensità del fenomeno, godono della proprietà che le differenze tra loro sono direttamente confrontabili e quantificabili. Il limite della scala ad intervalli è quello di non consentire il calcolo del rapporto tra coppie di misure. Ad esempio, una temperatura di 80\\(^\\circ\\)C non è il doppio di una di 40\\(^\\circ\\)C. Se infatti esprimiamo le stesse temperature nei termini della scala Fahrenheit, allora i due valori non saranno in rapporto di 1 a 2 tra loro. Infatti, 20\\(^\\circ\\)C = 68\\(^\\circ\\)F e 40\\(^\\circ\\)C = 104\\(^\\circ\\)F. Questo significa che la relazione “il doppio di” che avevamo individuato in precedenza si applicava ai numeri della scala centigrada, ma non alla proprietà misurata (cioè la temperatura). La decisione di che scala usare (Centigrada vs. Fahrenheit) è arbitraria. Ma questa arbitrarietà non deve influenzare le inferenze che traiamo dai dati. Queste inferenze, infatti, devono dirci qualcosa a proposito della realtà empirica e non possono in nessun modo essere condizionate dalle nostre scelte arbitrarie che ci portano a scegliere la scala Centigrada piuttosto che quella Fahrenheit. Consideriamo ora l’aspetto invariante di una trasformazione lineare, ovvero l’uguaglianza dei rapporti fra intervalli. Prendiamo in esame, ad esempio, tre temperature: \\(20^\\circ C = 68^\\circ F\\), \\(15^\\circ C = 59^\\circ F\\), \\(10^\\circ C = 50 ^\\circ F\\). È facile rendersi conto del fatto che i rapporti fra intervalli restano costanti indipendentemente dall’unità di misura che è stata scelta: \\[ \\frac{20^\\circ C - 10^\\circ C}{20^\\circ C - 15^\\circ C} = \\frac{68^\\circ F - 50^\\circ F}{68^\\circ F-59^\\circ F} = 2. \\] 3.1.4 Scala di rapporti Nella scala a rapporti equivalenti la posizione dello zero non è arbitraria, ma corrisponde all’elemento dotato di intensità nulla rispetto alla proprietà misurata. Una scala a rapporti equivalenti si costruisce associando il numero 0 all’elemento con intensità nulla; viene poi scelta un’unità di misura \\(u\\) e, ad ogni elemento, si assegna un numero \\(a\\) definito come: \\[a = \\frac{d}{u}\\] dove \\(d\\) rappresenta la distanza dall’origine. Alle u.s. vengono dunque assegnati dei numeri tali per cui le differenze e i rapporti tra i numeri riflettono le differenze e i rapporti tra le intensità della proprietà misurata. Operazioni aritmetiche sono possibili non solo sulle differenze tra i valori della scala (come per la scala a intervalli equivalenti), ma anche sui valori stessi della scala. L’unica arbitrarietà riguarda l’unità di misura che si utilizza. L’unità di misura può cambiare, ma qualsiasi unità di misura si scelga, lo zero deve sempre indicare l’intensità nulla della proprietà considerata. Le trasformazioni ammissibili a questo livello di scala sono dette trasformazioni di similarità: \\[y&#39; = by, \\quad b &gt; 0.\\] A questo livello di scala, a seguito delle trasformazioni ammissibili, rimangono invariati anche i rapporti: \\[\\frac{y_i}{y_j} = \\frac{y&#39;_i}{y&#39;_j}.\\] 3.1.5 Gerarchia dei livelli di scala di misura Stevens (1946) parla di livelli di scala poiché i quattro tipi di scala di misura stanno in una precisa gerarchia: la scala nominale rappresenta il livello più basso della misurazione, la scala a rapporti equivalenti è invece il livello più alto. Scale di modalità Operazioni aritmetiche nominali enumerare le classi di equivalenza e/o le frequenze per ciascuna classe di equivalenza ordinali enumerare le classi di equivalenza e/o le frequenze per ciascuna classe di equivalenza intervallari differenze (rapporti tra differenze) di rapporti rapporti diretti tra le misure Passando da un livello di misurazione ad uno più alto aumenta il numero di operazioni aritmetiche che possono essere compiute sui valori della scala, come indicato nella figura seguente. Figura 3.1: I quattro livelli di scala secondo Stevens (1946). Per ciò che riguarda le trasformazioni ammissibili, più il livello di scala è basso, più le funzioni sono generali (sono minori cioè i vincoli per passare da una rappresentazione numerica ad un’altra equivalente). Salendo la gerarchia, la natura delle funzioni di trasformazione si fa più restrittiva. 3.2 Variabili discrete vs. variabili continue Le variabili a livello di intervalli e di rapporti possono essere discrete o continue. Le variabili discrete possono assumere alcuni valori ma non altri. Una volta che l’elenco di valori accettabili è stato specificato, non ci sono casi che cadono tra questi valori. Le variabili discrete di solito assumono valori interi. Quando una variabile può assumere qualsiasi valore entro un intervallo specificato, allora si dice che la variabile è continua. In teoria, ciò significa che frazioni e decimali possono essere utilizzati per raggiungere un livello di precisione qualsiasi. In pratica, a un certo punto dobbiamo arrotondare i numeri, rendendo tecnicamente la variabile discreta. In variabili veramente discrete, tuttavia, non è possibile aumentare a piacimento il livello di precisione della misurazione. Figura 3.2: Le variabili continue possono assumere un insieme continuo di valori, al contrario delle variabili discrete, per le quali l’insieme dei possibili valori ha cardinalità al più numerabile. Esempio 3.3 Il numero di biciclette possedute da una persona è una variabile discreta poiché tale variabile può assumere come modalità solo i numeri interi non negativi. Le frazioni di biciclette non sono sensate. 3.3 Perché alcune misurazioni sono migliori di altre? In psicologia, ciò che vogliamo misurare non è una caratteristica fisica, ma invece è un concetto teorico inosservabile, ovvero un costrutto. Ad esempio, supponiamo che un docente voglia valutare quanto bene uno studente comprenda la distinzione tra le quattro diverse scale di misura che sono state descritte sopra. Il docente potrebbe predisporre un test costituito da un insieme di domande e potrebbe contare a quante domande lo studente risponde correttamente. Questo test, però, può o può non essere una buona misura del costrutto relativo alla conoscenza effettiva delle quattro scale di misura. Per esempio, se il docente scrive le domande del test in modo ambiguo o se usa una linguaggio troppo tecnico che lo studente non conosce, allora i risultati del test potrebbero suggerire che lo studente non conosce la materia in questione anche se in realtà questo non è vero. D’altra parte, se il docente prepara un test a scelta multipla con risposte errate molto ovvie, allora lo studente può ottenere dei buoni risultati al test anche senza essere in grado di comprendere adeguatamente le proprietà delle quattro scale di misura. In generale non è possibile misurare un costrutto senza una certa quantità di errore. Poniamoci dunque il problema di determinare in che modo una misurazione possa dirsi adeguata. 3.3.1 Tipologie di errori L’errore è, per definizione, la differenza tra il valore vero e il valore misurato della grandezza in esame. Gli errori sono classificati come sistematici (o determinati) e casuali (o indeterminati). Gli errori casuali sono fluttuazioni, in eccesso o in difetto rispetto al valore reale, delle singole determinazioni e sono dovuti alle molte variabili incontrollabili che influenzano ogni misura psicologica. Gli errori sistematici, invece, influiscono sulla misurazione sempre nello stesso senso e, solitamente, per una stessa quantità (possono essere additivi o proporzionali). Le differenze tra le due tipologie di errori, sistematici e casuali, introducono i concetti di accuratezza e di precisione della misura. Una misura viene definita: accurata, quando vi è un accordo tra la misura effettuata ed il valore reale; precisa quando, ripetendo più volte la misura, i risultati ottenuti sono concordanti, cioè differiscono in maniera irrilevante tra loro. La metafora del tiro a bersaglio illustra la relazione tra precisione e accuratezza. Figura 3.3: Illustrazione dei concetti di precisione e accuratezza: (a) bassa precisione e bassa accuratezza, (b) bassa precisione e alta accuratezza, (c) alta precisione e bassa accuratezza, (d) alta precisione e alta accuratezza. Per tenere sotto controllo l’incidenza degli errori, sono stati introdotti in psicologia i concetti di attendibilità e validità: l’attendibilità esprime il grado di accordo o coerenza tra misurazioni indipendenti dello stesso costrutto psicologico1; la validità descrive il grado in cui uno strumento misura ciò che dice di misurare. 3.3.2 Attendibilità Uno strumento si dice attendibile quando valuta in modo coerente e stabile la stessa variabile: i risultati ottenuti si mantengono costanti dopo ripetute somministrazione ed in assenza di variazioni psicologiche e fisiche dei soggetti sottoposti al test o cambiamenti dell’ambiente in cui ha luogo la somministrazione. 3.3.3 Validità L’attendibilità di uno strumento non è sufficiente: in primo luogo uno strumento di misura deve essere valido, laddove la validità rappresenta il grado in cui uno strumento misura effettivamente ciò che dovrebbe misurare. In genere, si fa riferimento ad almeno quattro tipi di validità. La validità di costrutto riguarda il grado in cui un test misura ciò per cui è stato costruito. Essa si suddivide in: validità convergente e validità divergente. La validità convergente fa riferimento alla concordanza tra uno strumento e un altro che misura lo stesso costrutto. La validità divergente, al contrario, valuta il grado di discriminazione tra strumenti che misurano costrutti differenti. Senza validità di costrutto le altre forme di validità non hanno senso. In base alla validità di contenuto, un test fornisce una misura valida di un attributo psicologico se il dominio dell’attributo è rappresentato in maniera adeguata dagli item del test. Un requisito di base della validità di contenuto è la rilevanza e la rappresentatività del contenuto degli item in riferimento all’attributo che il test intende misurare. La validità di criterio valuta il grado di concordanza tra i risultati dello strumento considerato e i risultati ottenuti da altri strumenti che misurano lo stesso costrutto, o tra i risultati dello strumento considerato e un criterio esterno. Nella validità concorrente, costrutto e criterio vengono misurati contestualmente, consentendo un confronto immediato. Nella validità predittiva, il costrutto viene misurato prima e il criterio in un momento successivo, consentendo la valutazione della capacità dello strumento di predire un evento futuro. Infine, la validità di facciata fa riferimento al grado in cui il test appare valido ai soggetti a cui esso è diretto. La validità di facciata è importante in ambiti particolari, quali ad esempio la selezione del personale per una determinata occupazione. In questo caso è ovviamente importante che chi si sottopone al test ritenga che il test vada a misurare quegli aspetti che sono importanti per le mansioni lavorative che dovranno essere svolte, piuttosto che altre cose. In generale, la validità di facciata non è utile, tranne in casi particolari. Conclusioni Una domanda che uno psicologo spesso si pone è: “sulla base delle evidenze osservate, possiamo concludere dicendo che l’intervento psicologico è efficace nel trattamento e nella cura del disturbo?” Le considerazioni svolte in questo capitolo dovrebbero farci capire che, prima di cercare di rispondere a questa domanda con l’analisi statistica dei dati, devono essere affrontati i problemi della validità e dell’attendibilità delle misure (oltre a stabilire l’appropriato livello di scala di misura delle osservazioni). L’attendibilità è un prerequisito della validità. Se gli errori di misurazione sono troppo grandi, i dati sono inutili. Inoltre, uno strumento di misurazione può essere preciso ma non valido. La validità e l’attendibilità delle misurazioni sono dunque entrambe necessarie. In generale, l’attendibilità e la validità delle misure devono essere valutate per capire se i dati raccolti da un ricercatore siano adeguati (1) per fornire una risposta alla domanda della ricerca, e (2) per giungere alla conclusione proposta dal ricercatore alla luce dei risultati dell’analisi statistica che è stata eseguita. È chiaro che le informazioni fornite in questo capitolo si limitano a scalfire la superficie di questi problemi. I concetti qui introdotti, però, devono sempre essere tenuti a mente e costituiscono il fondamento di quanto verrà esposto nei capitoli successivi. Un costrutto rappresenta il risultato di una fondata riflessione scientifica, non è per definizione accessibile all’osservazione diretta, ma viene inferito dall’osservazione di opportuni indicatori (Sartori, 2005).↩︎ "],["chapter-descriptive-stats.html", "Capitolo 4 Statistica descrittiva 4.1 Perché riassumere i dati? 4.2 Distribuzioni di frequenze 4.3 Istogramma 4.4 Funzione di densità empirica 4.5 Forma di una distribuzione 4.6 Indici di posizione 4.7 Indici di tendenza centrale 4.8 Indici di dispersione 4.9 Le relazioni tra variabili 4.10 Correlazione e causazione Conclusioni", " Capitolo 4 Statistica descrittiva Nel 1907 Francis Galton, cugino di Charles Darwin, matematico e statistico autodidatta, geografo, esploratore, teorico della dattiloscopia (ovvero, dell’uso delle impronte digitali a fini identificativi) e dell’eugenetica, scrisse una lettera alla rivista scientifica Nature sulla sua visita alla Fat Stock and Poultry Exhibition di Plymouth. Lì vide alcuni membri del pubblico partecipare ad un gioco il cui scopo era quello di indovinare il peso della carcassa di un grande bue che era appena stato scuoiato. Galton si procurò i 787 dei biglietti che erano stati compilati dal pubblico e considerò il valore medio di 547 kg come la “scelta democratica” dei partecipanti, in quanto “ogni altra stima era stata giudicata troppo alta o troppo bassa dalla maggioranza dei votanti.” Il punto interessante è che il peso corretto di 543 kg si dimostrò essere molto simile alla “scelta democratica” basata sulle stime dei 787 partecipanti. Galton intitolò la sua lettera a Nature Vox Populi (voce del popolo), ma questo processo decisionale è ora meglio conosciuto come la “saggezza delle folle” (wisdom of crowds). Possiamo dire che, nel suo articolo del 1907, Galton effettuò quello che ora chiamiamo un riepilogo dei dati, ovvero calcolò un indice sintetico a partire da un insieme di dati. In questo capitolo esamineremo le tecniche che sono state sviluppate nel secolo successivo per riassumere le grandi masse di dati con cui sempre più spesso ci dobbiamo confrontare. Vedremo come calcolare e interpretare gli indici di posizione e di dispersione, discuteremo le distribuzioni di frequenze e le relazioni tra variabili. Vedremo inoltre quali sono le tecniche di visualizzazione che ci consentono di rappresentare questi sommari dei dati mediante dei grafici. Ma prima di entrare nei dettagli, prendiamoci un momento per capire perché abbiamo bisogno della statistica descrittiva. 4.1 Perché riassumere i dati? Quando riassumiamo i dati, necessariamente buttiamo via delle informazioni. Ma è una buona idea procedere in questo modo? Non sarebbe meglio conservare le informazioni specifiche di ciascun soggetto che partecipa ad un esperimento psicologico, al di là di ciò che viene trasmesso dagli indici riassuntivi della statistica descrittiva? Che dire delle informazioni che descrivono come sono stati raccolti i dati, come l’ora del giorno o l’umore del partecipante? Tutte queste informazioni vengono perdute quando riassumiamo i dati. La risposta alla domanda che ci siamo posti è che, in generale, non è una buona idea conservare tutti i dettagli di ciò che sappiamo. È molto più utile riassumere le informazioni perché la semplificazione risultante consente i processi di generalizzazione. In un contesto letterario, l’importanza della generalizzazione è stata sottolineata da Jorge Luis Borges nel suo racconto “Funes o della memoria,” che descrive un individuo che perde la capacità di dimenticare. Borges si concentra sulla relazione tra generalizzazione e pensiero: Pensare è dimenticare una differenza, generalizzare, astrarre. Nel mondo troppo pieno di Funes, c’erano solo dettagli. Come possiamo ben capire, la vita di Funes non è facile. Se facciamo riferimento alla psicologia possiamo dire che gli psicologi hanno studiato a lungo l’utilità della generalizzazione per il pensiero. Un esempio è fornito dal fenomeno della formazione dei concetti e lo psicologo che viene in mente a questo proposito è sicuramente Eleanor Rosch, la quale ha studiato i principi di base della categorizzazione. I concetti ci forniscono uno strumento potente per organizzare le conoscenze. Noi siamo in grado di riconoscere facilmente i diversi esemplare di un concetto – per esempio, “gli uccelli” – anche se i singoli esemplari che fanno parte di una categoria sono molto diversi tra loro (l’aquila, la gallina, il pettirosso). L’uso dei concetti, cioè la generalizzazione, è utile perché ci consente di fare previsioni sulle proprietà dei singoli esemplari che appartengono ad una categoria, anche se non abbiamo mai avuto esperienza diretta con essi – per esempio, possiamo fare la predizione che tutti gli uccelli possono volare e mangiare vermi, ma non possono guidare un’automobile o parlare in inglese. Queste previsioni non sono sempre corrette, ma sono utili. Le statistiche descrittive, in un certo senso, ci fornisco l’analogo dei “prototipi” che, secondo Eleanor Rosch, stanno alla base del processo psicologico di creazione dei concetti. Un prototipo è l’esemplare più rappresentativo di una categoria. In maniera simile, una statistica descrittiva come la media, ad esempio, potrebbe essere intesa come l’osservazione “tipica.” La statistica descrittiva ci fornisce gli strumenti per riassumere i dati che abbiamo a disposizione in una forma visiva o numerica. Le rappresentazioni grafiche più usate della statistica descrittiva sono gli istogrammi, i diagrammi a dispersione o i box-plot, e gli indici sintetici più comuni sono la media, la mediana, la varianza e la deviazione standard. 4.2 Distribuzioni di frequenze Per introdurre i principali strumenti della statistica descrittiva considereremo qui i dati raccolti da Zetsche et al. (2019). Questi autori hanno studiato le aspettative negative le quali sono state evidenziate come un meccanismo chiave nel mantenimento e nella reiterazione della depressione. Zetsche et al. (2019) hanno valutato le aspettative di individui depressi circa il loro umore futuro ed si sono chiesti se queste aspettative fossero accurate oppure distorte negativamente. In uno degli studi descritti viene esaminato un campione costituito da 30 soggetti con almeno un episodio depressivo maggiore e da 37 controlli sani. Gli autori hanno misurato il livello depressivo con il Beck Depression Inventory (BDI-II). Ma qual è la la gravità della depressione riportata dai soggetti nel campione esaminato da Zetsche et al. (2019)? Dei 67 soggetti considerati, uno non ha completato il BDI-II e quindi abbiamo a disposizione 66 valori del BDI-II. I dati sono riportati nella tabella [tab:bdi2_values]. Per semplicità i dati sono stati ordinati in ordine crescente. È chiaro che i dati grezzi sono di difficile lettura. Poniamoci dunque il problema di creare una rappresentazione sintetica e comprensibile di questo insieme di valori. Uno dei modi che ci consentono di effettuare una sintesi dei dati è quello di generare una distribuzione di frequenze. Una distribuzione di frequenze è un riepilogo del conteggio della frequenza con cui le modalità osservate in un insieme di dati si verificano in un intervallo di valori. Per creare una distribuzione di frequenze possiamo procedere effettuando una partizione delle modalità della variabile di interesse in \\(m\\) classi (denotate con \\(\\Delta_i\\)) tra loro disgiunte. In tale partizione, la classe \\(i\\)-esima coincide con un intervallo di valori aperto a destra \\([a_i, b_i)\\) o aperto a sinistra \\((a_i, b_i]\\). Ad ogni classe \\(\\Delta_i\\) avente \\(a_i\\) e \\(b_i\\) come limite inferiore e superiore associamo l’ampiezza \\(b_i - a_i\\) (non necessariamente uguale per ogni classe) e il valore centrale \\(\\bar{x}_i\\). La scelta delle classi è arbitraria, ma è buona norma non definire classi con un numero troppo piccolo (&lt; 5) di osservazioni. Poiché ogni elemento dell’insieme \\(\\{x_i\\}_{i=1}^n\\) appartiene ad una ed una sola classe \\(\\Delta_i\\), possiamo calcolare le quantità elencate di seguito. La frequenza assoluta \\(n_i\\) di ciascuna classe, ovvero il numero di osservazioni che ricadono nella classe \\(\\Delta_i\\). Proprietà: \\(n_1 + n_2 + \\dots + n_m = n\\). La frequenza relativa \\(f_i = n_i/n\\) di ciascuna classe. Proprietà: \\(f_1+f_2+\\dots+f_m =1\\). La frequenza cumulata \\(N_i\\), ovvero il numero totale delle osservazioni che ricadono nelle classi fino alla \\(i\\)-esima compresa: \\(N_i = \\sum_{i=1}^m n_i.\\) La frequenza cumulata relativa \\(F_i\\), ovvero \\(F_i = f_1+f_2+\\dots+f_m = \\frac{N_i}{n} = \\frac{1}{n} \\sum_{i=1}^m f_i.\\) Calcoliamo ora la distribuzione di frequenza assoluta e la distribuzione di frequenza relativa per i valori del BDI-II del campione clinico di Zetsche et al. (2019). Per costruire una distribuzione di frequenza è innanzitutto necessario scegliere gli intervalli delle classi. Facendo riferimento ai cut-off usati per l’interpretazione del BDI-II, definiamo i seguenti intervalli aperti a destra: depressione minima: [0, 13.5), depressione lieve: [13.5, 19.5), depressione moderata: [19.5, 28.5), depressione severa: [28.5, 63). La distribuzione di frequenza della variabile bdi2 è riportata nella tabella seguente. Questa distribuzione di frequenza ci aiuta a capire meglio cosa sta succedendo. Se consideriamo la frequenza relativa, ad esempio, possiamo notare che ci sono due valori maggiormente ricorrenti e tali valori corrispondono alle due classi più estreme. Questo ha senso nel caso presente, in quanto il campione esaminato da Zetsche et al. (2019) includeva due gruppi di soggetti: soggetti sani (con valori BDI-II bassi) e soggetti depressi (con valori BDI-II alti). In una distribuzione di frequenza tali valori tipici vanno sotto il nome di mode della distribuzione. Limiti delle classi Freq. ass. Freq. rel. Freq. ass. cum. Freq. rel. cum. \\([0, 13.5)\\) 36 36/66 36 36/66 \\([13.5, 19.5)\\) 1 1/66 37 37/66 \\([19.5, 28.5)\\) 12 12/66 49 49/66 \\([28.5, 63)\\) 17 17/66 66 66/66 4.2.1 Esercizio con R Poniamoci ora il problema di costruire la tabella precedente partendo dai dati grezzi messi a disposizione da Zetsche et al. (2019). Leggiamo i dati assumendo che il file data.mood.csv si trovi nella cartella data contenuta nella working directory. df &lt;- read.csv( here(&quot;data&quot;, &quot;data.mood.csv&quot;), header=TRUE ) C’è un solo valore di depressione per ciascun soggetto ma tale valore viene ripetuto tante volte quante volte sono le righe del data.frame associate ad ogni soggetto (ciascuna riga corrispondente ad una prova diversa). È dunque necessario trasformare il data.frame in modo tale da avere un’unica riga per ciascun soggetto, ovvero un unico valore BDI-II per soggetto. bysubj &lt;- df %&gt;% group_by(esm_id) %&gt;% summarise( bdi = mean(bdi) ) %&gt;% na.omit() #&gt; `summarise()` ungrouping output (override with `.groups` argument) Ci sono dunque 66 soggetti i quali hanno ottenuto i valori sulla scala del BDI-II stampati di seguito (li presento ordinati dal più piccolo al più grande). sort(bysubj$bdi) #&gt; [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 2 #&gt; [27] 2 2 2 3 3 3 5 7 9 12 19 22 22 24 25 25 26 26 26 27 27 28 28 30 30 30 #&gt; [53] 31 31 33 33 34 35 35 35 36 39 41 43 43 44 Calcolo ora le frequenze assolute per i seguenti intervalli aperti a destra: [0, 13.5), [13.5, 19.5), [19.5, 28.5), [28.5, 63). Esaminando i dati, possiamo notare che 36 soggetti cadono nella prima classe. È però necessario eseguire quest’operazione di conteggio utilizzando R. Uno dei modi possibili per calcolare le frequenze assolute è quello di usare la funzione cut(). Mediante tal funzione è possibile dividere il campo di variazione (ovvero, la differenza tra il valore massimo di una distribuzione ed il valore minimo) di una variabile continua x in intervalli e codificare ciascun valore x nei termini dell’intervallo a cui appartiene. Tale risultato si ottiene nel modo seguente. bysubj$bdi_level &lt;- cut( bysubj$bdi, breaks = c(0, 13.5, 19.5, 28.5, 63), include.lowest = TRUE, labels = c( &quot;minimal&quot;, &quot;mild&quot;, &quot;moderate&quot;, &quot;severe&quot; ) ) bysubj$bdi_level #&gt; [1] moderate severe severe moderate severe severe severe severe #&gt; [9] moderate severe moderate mild severe minimal minimal minimal #&gt; [17] severe moderate minimal minimal minimal minimal minimal moderate #&gt; [25] minimal minimal minimal minimal minimal minimal minimal severe #&gt; [33] minimal minimal severe minimal moderate minimal minimal minimal #&gt; [41] severe minimal minimal severe severe moderate severe severe #&gt; [49] minimal moderate minimal moderate severe moderate moderate minimal #&gt; [57] minimal minimal minimal minimal minimal minimal minimal minimal #&gt; [65] minimal minimal #&gt; Levels: minimal mild moderate severe Possiamo ora usare la funzione table() la quale ritorna un elenco che associa la frequenza assoluta a ciascuna modalità della variabile in input – ovvero, la distribuzione di frequenza assoluta. table(bysubj$bdi_level) #&gt; #&gt; minimal mild moderate severe #&gt; 36 1 12 17 Per ottenere la distribuzione di frequenza relativa è sufficiente dividere ciascuna frequenza assoluta per il numero totale di osservazioni: table(bysubj$bdi_level) / sum(table(bysubj$bdi_level)) #&gt; #&gt; minimal mild moderate severe #&gt; 0.54545455 0.01515152 0.18181818 0.25757576 In questo modo abbiamo ottenuto le distribuzioni di frequenza assoluta e relativa per i valori del BDI-II dei soggetti di Zetsche et al. (2019): Limiti delle classi Frequenza assoluta Frequenza relativa [0, 13.5) 36 36/66 [13.5, 19.5) 1 1/66 [19.5, 28.5) 12 12/66 [28.5, 63] 17 17/66 4.3 Istogramma I dati che sono stati sintetizzati in una distribuzione di frequenze possono essere rappresentati graficamente in un istogramma. Un istogramma si costruisce riportando sulle ascisse i limiti delle classi \\(\\Delta_i\\) e sulle ordinate i valori della funzione costante a tratti \\[\\varphi_n(x)= \\frac{f_i}{b_i-a_i}, \\quad x\\in \\Delta_i,\\, i=1, \\dots, m\\] che misura la densità della frequenza relativa della variabile \\(X\\) nella classe \\(\\Delta_i\\), ovvero il rapporto fra la frequenza relativa \\(f_i\\) e l’ampiezza (\\(b_i - a_i\\)) della classe. In questo modo il rettangolo dell’istogramma associato alla classe \\(\\Delta_i\\) avrà un’area proporzionale alla frequenza relativa \\(f_i\\). Si noti che l’area totale dell’istogramma delle frequenze relative è data della somma delle aree dei singoli rettangoli e quindi vale 1.0. 4.3.1 Esercizio con R Poniamoci il problema di costruire un istogramma per i dati del BDI-II. Nell’istogramma viene rappresentata la frequenza relativa delle classi: l’area di ogni barra dell’istogramma è proporzionale alla frequenza relativa della classe che la barra rappresenta. Come si trova l’altezza delle barre dell’istogramma? Per la classe [0, 13.5), ad esempio, la frequenza relativa è 36/66. Tale valore corrisponde all’area del rettangolo. Dato che la base del rettangolo è 13.5, l’altezza sarà 36/66 / 13.5, ovvero {r 36/66 / 13.5}. E così via per le altre barre dell’istogramma. Una rappresentazione grafica dell’istogramma delle frequenze relative si può ottenere con R utilizzando le funzioni di ggplot2. Il pacchetto ggplot2 è un potente strumento per rappresentare graficamente i dati. Le iniziali del nome, gg, si riferiscono alla ‘’Grammar of Graphics’’, che è un modo di pensare le figure come una serie di layer stratificati. Originariamente descritta da Leland Wilkinson, la grammatica dei grafici è stata aggiornata e applicata in R da Hadley Wickham, il creatore del pacchetto. Per chiarezza, precisiamo che la funzione ggplot() utilizza intervalli aperti a destra. p1 &lt;- bysubj %&gt;% ggplot(aes(x = bdi)) + geom_histogram( aes(y = ..density..), breaks = c(0, 13.5, 19.5, 28.5, 44.1) # il valore BDI-II massimo è 44 ) + scale_x_continuous(breaks=c(0, 13.5, 19.5, 28.5, 44.1)) + labs( x = &quot;BDI-II&quot;, y = &quot;Densità di frequenza&quot; ) p1 Figura 4.1: Istogramma per i valori BDI-II riportati da Zetsche et al. (2019). Con i quattro intervalli individuati dai cut-off del BDI-II otteniamo la rappresentazione riportata nella figura 4.1. Nel caso della prima barra dell’istogramma a sinistra, l’ampiezza dell’intervallo è pari a 13.5 e l’area della barra (ovvero, la frequenza relativa) è uguale a 36/66. Dunque l’altezza della barra è uguale a (36 / 66) / 13.5 = 0.040. Lo stesso procedimento si applica per il calcolo dell’altezza degli altri rettangoli. Anche se nel caso presente è sensato usare ampiezze diverse per gli intervalli delle classi, in generale gli istogrammi si costruiscono utilizzando intervalli riportati sulle ascisse con un’ampiezza uguale. Questo è il caso dell’istogramma seguente il quale è stato generato a partire dagli stessi dati. p2 &lt;- bysubj %&gt;% ggplot(aes(x = bdi)) + geom_histogram( aes(y = ..density..), breaks = seq(0, 44.1, length.out = 7) ) + scale_x_continuous(breaks=c(0.00, 7.35, 14.70, 22.05, 29.40, 36.75, 44.10)) + labs( x = &quot;BDI-II&quot;, y = &quot;Densità di frequanza&quot; ) p2 Figura 4.2: Una rappresentazione più comune per l’istogramma dei valori BDI-II di Zetsche et al. (2019) nella quale gli intervalli delle classi hanno ampiezze uguali. 4.4 Funzione di densità empirica Il confronto tra le figure 4.1 e 4.2 rende chiaro un limite degli istogrammi. È infatti ovvio che il profilo dell’istogramma è arbitrario: a seconda del numero e dei limiti delle classi che vengono scelte, cambiano sia il numero che la forma delle barre dell’istogramma. Questo rende difficile fornire un’interpretazione alle informazioni fornite da un istogramma. Il problema precedente può essere alleviato utilizzando una rappresentazione alternativa della distribuzione di frequenza, ovvero la stima della densità della frequenza dei dati (detta anche stima kernel di densità). Un modo semplice per pensare a tale rappresentazione, che in inglese va sotto il nome di density plot, è quello di immaginare un grande campione di dati, in modo che diventi possibile definire un enorme numero di classi di equivalenza di ampiezza molto piccola, le quali non risultino vuote. In tali circostanze, la funzione di densità empirica non è altro che il profilo lisciato dell’istogramma. La stessa idea si applica anche quando il campione è più piccolo. 4.4.1 Esercizio con R Nel caso dei dati del BDI-II otteniamo la reppresentazione fornita dalla figura seguente. p3 &lt;- bysubj %&gt;% ggplot(aes(x = bdi)) + geom_histogram( aes(y = ..density..), breaks = seq(0, 44.1, length.out = 7) ) + geom_density( aes(x = bdi), adjust = 0.5, size = 0.8, fill = &quot;steelblue3&quot;, alpha = 0.5 ) + labs( x = &quot;BDI-II&quot;, y = &quot;Densità di frequenza&quot; ) p3 Figura 4.3: Funzione di densità empirica per i valori BDI-II di Zetsche et al. (2019). Che interpretazione possiamo attribuire alla funzione di densità empirica rappresentata nella figura 4.3? La interpretiamo come abbiamo fatto con gli istogrammi: l’area sottesa al grafico della funzione di densità empirica in un certo intervallo rappresenta la proporzione dei casi della distribuzione che hanno valori compresi nell’intervallo considerato. 4.5 Forma di una distribuzione In generale, la forma di una distribuzione descrive come i dati si distribuiscono intorno ai valori centrali. Distinguiamo tra distribuzioni simmetriche e asimmetriche, e tra distribuzioni unimodali o multimodali. Un’illustrazione grafica è fornita nella figura seguente. Figura 4.4: 1: Asimmetria negativa. 2: Asimmetria positiva. 3: Distribuzione unimodale. 4: Distribuzione bimodale. Nel pannello 1 la distribuzione è unimodadle con asimmetria negativa; nel pannello 2 la distribuzione è unimodadle con asimmetria positiva; nel pannello 3 la distribuzione è simmetrica e unimodale; nel pannello 4 la distribuzione è bimodale. Se consideriamo nuovamente la figura 4.3 possiamo dire che la distribuzione dei valori del BDI-II nel campione considerato da Zetsche et al. (2019) è bimodale. 4.6 Indici di posizione 4.6.1 Quantili La descrizione della distribuzione dei valori BDI-II di Zetsche et al. (2019) può essere facilitata dalla determinazione di alcuni valori caratteristici che sintetizzano le informazioni contenute nella distribuzione di frequenze. Si dicono quantili (o frattili) quei valori caratteristici che hanno le seguenti proprietà. I quartili sono quei valori che ripartiscono i dati \\(x_i\\) in quattro parti ugualmente numerose (pari ciascuna al 25% del totale). Il primo quartile, \\(q_1\\), lascia alla sua sinistra il 25% del campione pensato come una fila ordinata (a destra quindi il 75%). Il secondo quartile \\(q_2\\) lascia a sinistra il 50% del campione (a destra quindi il 50%). Esso viene anche chiamato mediana. Il terzo quartile lascia a sinistra il 75% del campione (a destra quindi il 25%). Secondo lo stesso criterio, si dicono decili i quantili di ordine \\(p\\) multiplo di 0.10 e percentili i quantili di ordine \\(p\\) multiplo di 0.01. Come si calcolano i quantili? Consideriamo la definizione di quantile non interpolato di ordine \\(p\\) \\((0 &lt; p &lt; 1)\\). Si procede innanzitutto ordinando i dati in ordine crescente, \\(\\{x_1, x_2, \\dots, x_n\\}\\). Ci sono poi due possibilità. Se il valore \\(np\\) non è intero, sia \\(k\\) l’intero tale che \\(k &lt; np &lt; k + 1\\) – ovvero, la parte intera di \\(np\\). Allora \\(q_p = x_{k+1}.\\) Se \\(np = k\\) con \\(k\\) intero, allora \\(q_p = \\frac{1}{2}(x_{k} + x_{k+1}).\\) Se vogliamo calcolare il primo quartile \\(q_1\\), ad esempio, utilizziamo \\(p = 0.25\\). Dovendo calcolare gli altri quantili basta sostituire a \\(p\\) il valore appropriato[^2]. Gli indici di posizione, tra le altre cose, hanno un ruolo importante, ovvero vengono utilizzati per creare una rappresentazione grafica di una distribuzione di valori che è molto popolare e può essere usata in alternativa ad un istogramma (in realtà vedremo poi come possa essere combinata con un istogramma). Tale rappresentazione va sotto il nome di box-plot. Per fare un esempio, consideriamo i nove soggetti del campione clinico di Zetsche et al. (2019) che hanno riportato un unico episodio di depressione maggiore. Per tali soggetti i valori ordinati del BDI-II (per semplicità li chiameremo \\(x\\)) sono i seguenti: 19, 26, 27, 28, 28, 33, 33, 41, 43. Per il calcolo del secondo quartile (non interpolato), ovvero per il calcolo della mediana, dobbiamo considerare la quantità \\(np = 9 \\cdot 0.5 = 4.5\\), non intero. Quindi, \\(q_1 = x_{4 + 1} = 27\\). Per il calcolo del quantile (non interpolato) di ordine \\(p = 2/3\\) dobbiamo considerare la quantità \\(np = 9 \\cdot 2/3 = 6\\), intero. Quindi, \\(q_{\\frac{2}{3}} = \\frac{1}{2} (x_{6} + x_{7}) = \\frac{1}{2} (33 + 33) = 33\\). 4.6.2 Box-plot Il box-plot (o diagramma a scatola) è uno strumento grafico utile al fine di ottenere informazioni circa la dispersione e l’eventuale simmetria o asimmetria di una distribuzione. Per costruire un box-plot si rappresenta sul piano cartesiano un rettangolo (cioè la “scatola”) di altezza arbitraria la cui base corrisponde alla dist intanza interquartile (IQR = \\(q_{0.75} - q_{0.25}\\)). La linea interna alla scatola rappresenta la mediana \\(q_{0.5}\\). Si tracciano poi ai lati della scatola due segmenti di retta i cui estremi sono detti “valore adiacente” inferiore e superiore. Il valore adiacente inferiore è il valore più piccolo tra le osservazioni che risulta maggiore o uguale al primo quartile meno la distanza corrispondente a 1.5 volte la distanza interquartile. Il valore adiacente superiore è il valore più grande tra le osservazioni che risulta minore o uguale a \\(Q_3+1.5\\) IQR. I valori esterni ai valori adiacenti (chiamati valori anomali) vengono rappresentati individualmente nel box-plot per meglio evidenziarne la presenza e la posizione. Figura 4.5: Box-plot, laddove \\(M\\) è la mediana, \\(\bar{x}\\) è la media aritmetica e IQR è la distanza interquartile (\\(Q_3 - Q_1\\)). Consideriamo ora un caso concreto nel quale viene utilizzato un box-plot. Nel caso dei dati di Zetsche et al. (2019) ci chiediamo in che modo si differenziano le distribuzioni del BDI-II tra i due gruppi considerati, ovvero tra il gruppo dei pazienti e il gruppo di controllo. bysubj &lt;- df %&gt;% group_by(esm_id, group) %&gt;% summarise( bdi = mean(bdi), nr_of_episodes = mean(nr_of_episodes, na.rm = TRUE) ) %&gt;% na.omit() #&gt; `summarise()` regrouping output by &#39;esm_id&#39; (override with `.groups` argument) bysubj %&gt;% ggplot(aes(x=group, y=bdi)) + geom_boxplot() + labs( x = &quot;Gruppo&quot;, y = &quot;BDI-II&quot; ) La figura 4.6 fornisce due rappresentazioni grafiche che possono essere utilizzate per rispondere a questa domanda. bysubj &lt;- df %&gt;% group_by(esm_id, group) %&gt;% summarise( bdi = mean(bdi), nr_of_episodes = mean(nr_of_episodes, na.rm = TRUE) ) %&gt;% na.omit() #&gt; `summarise()` regrouping output by &#39;esm_id&#39; (override with `.groups` argument) p1 &lt;- bysubj %&gt;% ggplot(aes(x=group, y=bdi)) + geom_violin(trim=FALSE) + geom_dotplot(binaxis=&#39;y&#39;, stackdir=&#39;center&#39;, dotsize=0.7) + labs( x = &quot;Gruppo&quot;, y = &quot;BDI-II&quot; #, caption = &quot;Fonte: Zetsche, Buerkner, &amp; Renneberg (2020)&quot; ) p2 &lt;- bysubj %&gt;% ggplot(aes(x=group, y=bdi)) + geom_violin(trim=FALSE) + geom_boxplot(width=0.05) + labs( x = &quot;Gruppo&quot;, y = &quot;BDI-II&quot; #, caption = &quot;Fonte: Zetsche, Buerkner, &amp; Renneberg (2020)&quot; ) p1 + p2 #&gt; `stat_bindot()` using `bins = 30`. Pick better value with `binwidth`. Figura 4.6: Due versioni di un violin plot per i valori BDI-II di ciascuno dei due gruppi di soggetti esaminati da Zetsche et al. (2019). Nella figura 4.6 sinistra sono rappresentati i dati grezzi: questa è la pratica migliore quando il numero di osservazioni è piccolo. La linea curva che circonda (simmetricamente) le osservazioni è l’istogramma lisciato che abbiamo descritto in precedenza. Nella figura 4.6 destra sono rappresentanti gli stessi dati: la funzione di densità empirica è la stessa di prima, ma al suo interno viene collocato un box-plot. Questa seconda rappresentazione è da preferirsi quando ci sono molte osservazioni e non è utile rappresentare singolarmente ciascun dato. Entrambe le rappresentazioni suggeriscono che la distribuzione dei dati è all’incirca simmetrica nel gruppo clinico (codificato come mdd). Il gruppo di controllo (ctl) mostra invece un’asimmetria positiva, con tre osservazioni evidenziate nel boxplot come dei “valori anomali,” dato che si discostano dalla mediana di una quantità maggiore di 1.5 IQR. 4.6.3 L’eccellenza grafica Non c’è un modo “corretto” per rappresentare in forma grafica un insieme di dati. Ciascuno dei grafici che abbiamo discusso ha i suoi pregi e i suoi difetti. Un ricercatore che ha influenzato molto il modo in cui viene realizzata la visualizzazione dei dati scientifici è Edward Tufte, soprannominato dal New York Times il “Leonardo da Vinci dei dati.” Secondo Tufte, “l’eccellenza nella grafica consiste nel comunicare idee complesse in modo chiaro, preciso ed efficiente.” Nella visualizzazione delle informazioni, l’“eccellenza grafica” ha l’obiettivo di comunicare al lettore il maggior numero di idee nel minor tempo possibile, con meno inchiostro possibile, usando il minor spazio possibile. Secondo Tufte (2001), le rappresentazioni grafiche dovrebbero: mostrare i dati; indurre l’osservatore a riflettere sulla sostanza piuttosto che sulla progettazione grafica, o qualcos’altro; evitare di distorcere quanto i dati stanno comunicando (“integrità grafica”); presentare molte informazioni in forma succinta; rivelare la coerenza tra le molte dimensioni dei dati; incoraggiare l’osservatore a comparare differenti porzioni di dati; rivelare i dati a diversi livelli di dettaglio, da una visione ampia alla struttura di base; servire ad uno scopo preciso (descrizione, esplorazione, o la risposta a qualche domanda); essere fortemente integrate con le descrizioni statistiche e verbali dei dati fornite nel testo. In base a questi principi, la funzione di densità empirica fornisce una rappresentazione migliore dei dati di Zetsche et al. (2019) di quanto lo faccia un istogramma. Inoltre, se oltre al grupppo di appartenenza non ci sono altre dimensioni importanti da mettere in evidenza, allora la nostra scelta dovrebbe ricadere sul pannello di sinistra della figura 4.6. 4.7 Indici di tendenza centrale L’analisi grafica, esaminata in precedenza, costituisce la base di partenza di qualsivoglia analisi quantitativa dei dati. Tramite l’analisi grafica possiamo capire alcune caratteristiche importanti di una distribuzione: per esempio, se è simmetrica o asimmetrica; oppure se è unimodale o multimodale. Successivamente, possiamo calcolare degli indici numerici che descrivono in modo sintetico le caratteristiche di base dei dati esaminati. Tra le misure di tendenza centrale, ovvero tra gli indici che forniscono un’idea dei valori attorno ai quali sono prevalentemente concentrati i dati di un campione, quella più comunemente usata è la media. 4.7.1 Media Tutti conosciamo la media aritmetica di \\(\\{x_1, x_2, \\dots, x_n\\}\\), ovvero il numero reale \\(\\bar{x}\\) definito da \\[\\begin{equation} \\bar{x}=\\frac{1}{n}\\sum_{i=1}^n x_i. \\tag{4.1} \\end{equation}\\] Nell’eq. (4.1) abbiamo usato la notazione delle sommatorie per descrivere una somma di valori. Questa notazione è molto usata in statistica e viene descritta in Appendice. La media gode della seguente importante proprietà: la somma degli scarti tra ciascuna modalità \\(x_i\\) e la media aritmetica \\(\\bar{x}\\) è nulla, cioè \\[ \\sum_{i=1}^n (x_i - \\bar{x}) = 0.\\notag \\label{eq:diffmeansumzero}\\] Infatti, \\[\\begin{aligned} \\sum_{i=1}^n (x_i - \\bar{x}) &amp;= \\sum_i x_i - \\sum_i \\bar{x}\\notag\\\\ &amp;= \\sum_i x_i - n \\bar{x}\\notag\\\\ &amp;= \\sum_i x_i - \\sum_i x_i = 0.\\notag\\end{aligned} \\] Ciò ci consente di pensare alla media come al baricentro della distribuzione. Un’altra proprietà della media è la seguente. La somma dei quadrati degli scarti tra ciascuna modalità \\(x_i\\) e una costante arbitraria \\(a \\in \\Re\\), cioè \\[\\varphi(a) = \\sum_{i=1}^n (x_i - a)^2,\\notag\\] è minima per \\(a = \\bar{x}\\). Il concetto statistico di media ha suscitato molte battute. Per esempio, il fatto che, in media, ciascuno di noi ha un numero di gambe circa pari a 1.9999999. Oppure, il fatto che, in media, ciascuno di noi ha un testicolo. Ma la media ha altri problemi, oltre al fatto di ispirare battute simili alle precedenti. In particolare, dobbiamo notare che la media non è sempre l’indice che meglio rappresenta la tendenza centrale di una distribuzione. In particolare, ciò non accade quando la distribuzione è asimmetrica, o in presenza di valori anomali (outlier) – si veda il pannello di destra della figura 4.6. In tali circostanze, la tendenza centrale della distribuzione è meglio rappresentata dalla mediana o dalla media spuntata. 4.7.1.1 Esercizio con R Calcoliamo la media dei valori BDI-II per i due gruppi di soggetti di Zetsche et al. (2019). bysubj %&gt;% group_by(group) %&gt;% summarise( avg_bdi = mean(bdi) ) #&gt; `summarise()` ungrouping output (override with `.groups` argument) #&gt; # A tibble: 2 x 2 #&gt; group avg_bdi #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 ctl 1.69 #&gt; 2 mdd 30.9 4.7.2 Media spuntata La media spuntata \\(\\bar{x}_t\\) (trimmed mean) non è altro che la media dei dati calcolata considerando solo il 90% (o altra percentuale) dei dati centrali. Per calcolare \\(\\bar{x}_t\\) si ordinando i dati secondo una sequenza crescente, \\(x_1 \\leq x_2 \\leq x_3 \\leq \\dots \\leq x_n\\), per poi eliminare il primo 5% e l’ultimo 5% dei dati della serie così ordinata. La media spuntata è data dalla media aritmetica dei dati rimanenti. 4.7.2.1 Esercizio con R Calcoliamo la media spuntata dei valori BDI-II per i due gruppi di soggetti di Zetsche et al. (2019) escludendo il 10% dei valori più estremi in ciascun gruppo. bysubj %&gt;% group_by(group) %&gt;% summarise( avg_trim_bdi = mean(bdi, trim = 0.1) ) #&gt; `summarise()` ungrouping output (override with `.groups` argument) #&gt; # A tibble: 2 x 2 #&gt; group avg_trim_bdi #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 ctl 1 #&gt; 2 mdd 30.6 4.7.3 Moda e mediana In precedenza abbiamo già incontrato altri due popolari indici di tendenza centrale: la moda (Mo), ovvero il valore centrale della classe con la frequenza massima (può succedere che una distribuzione abbia più mode; in tal caso si dice multimodale e questo operatore perde il suo significato di indice di tendenza centrale) e la mediana \\(\\tilde{x}\\). 4.7.3.1 Esercizio con R Calcoliamo i quantili di ordine 0.25, 0.5 e 0.75 dei valori BDI-II per i due gruppi di soggetti di Zetsche et al. (2019). bysubj %&gt;% group_by(group) %&gt;% summarise( q25 = quantile(bdi, probs = 0.25), q50 = quantile(bdi, probs = 0.50), q75 = quantile(bdi, probs = 0.75) ) #&gt; `summarise()` ungrouping output (override with `.groups` argument) #&gt; # A tibble: 2 x 4 #&gt; group q25 q50 q75 #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 ctl 0 1 2 #&gt; 2 mdd 26 30 35 Osservazione. Si noti che solitamente i software restituiscono un valore interpolato del \\(p\\)-esimo quantile \\(q_p\\) \\((0 &lt; p &lt; 1)\\), il quale viene calcolato mediante specifiche procedure. Il risultato fornito dai software, dunque, non sarà identico a quello trovato utilizzando la definizione non interpolata di quantile che abbiamo presentato qui. Se, per qualche ragione, vogliamo conoscere l’algoritmo usato per la determinazione dei quantili interpolati, dobbiamo leggere la documentazione del software. 4.8 Indici di dispersione Le medie e gli indici di posizione descritti in precedenza forniscono delle sintesi dei dati che mettono in evidenza la tendenza centrale delle osservazioni. Tali indici, tuttavia, non considerano un aspetto importante della distribuzione dei dati, ovvero la variabilità dei valori numerici della variabile statistica. È dunque necessario sintetizzare la distribuzione di una variabile statistica oltre che con le misure di posizione anche tramite l’utilizzo di indicatori che valutino la dispersione delle unità statistice. 4.8.1 Indici basati sull’ordinamento dei dati È possibile calcolare degli indici di variabilità basati sull’ordinamento dei dati. L’indice più ovvio è l’intervallo di variazione, ovvero la distanza tra il valore massimo e il valore minimo di una distribuzione di modalità, mentre in precedenza abbiamo già incontrato la differenza interquartile. Questi due indici, però, hanno il limite di essere calcolati sulla base di due soli valori della distribuzione (\\(x_{\\text{max}}\\) e \\(x_{\\text{mini}}\\), oppure \\(x_{0.25}\\) e \\(x_{0.75}\\)). Pertanto non utilizzano tutte le informazioni che sono disponibili. Inoltre, l’intervallo di variazione ha il limite di essere pesantemente influenzato dalla presenza di valori anomali. 4.8.2 Scostamento medio semplice dalla media Dati i limiti delle statistiche precedenti è più comune misurare la variabilità di una variabile statistica come la dispersione dei dati attorno ad un indice di tendenza centrale. Scelto l’indice di tendenza centrale rispetto al quale si vuole misurare la dispersione, è possibile poi calcolare la media degli scostamenti dei singoli dati dal valore di riferimento. Ad esempio, se scegliamo la mediana quale misura di posizione centrale, è possibile calcolare la media aritmetica della distribuzione degli scarti in valore assoluto tra ciascuna modalità e la mediana stessa. Nel caso di una variabile statistica \\(X\\) lo scostamento medio semplice dalla media è la quantità \\[\\begin{equation} S_{Me} = \\frac{1}{n} \\sum_{i=1}^n |x_i - x_{0.5}|. \\tag{4.2} \\end{equation}\\] 4.8.2.1 Esercizio con R Calcoliamo lo scostamento medio semplice dalla media per il BDI-II dei due gruppi di soggetti di Zetsche et al. (2019). mean(abs(bysubj$bdi - median(bysubj$bdi))) #&gt; [1] 14.48387 Oppure, per i due gruppi: mean_abs_dev &lt;- function(x){ mean(abs(x - median(x))) } bysubj %&gt;% group_by(group) %&gt;% summarise( Mean_abs_dev = mean_abs_dev(bdi) ) #&gt; `summarise()` ungrouping output (override with `.groups` argument) #&gt; # A tibble: 2 x 2 #&gt; group Mean_abs_dev #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 ctl 1.62 #&gt; 2 mdd 5.27 La deviazione mediana assoluta è una misura robusta della dispersione statistica di un campione. Per un insieme \\(x_1, x_2, \\dots, x_n\\), il valore di MAD è definito come la mediana del valore assoluto delle deviazioni dei dati dalla mediana, ovvero: \\[\\begin{equation} MAD = \\text{med} (|x_i - \\text{med}(x_i)|). \\tag{4.3} \\end{equation}\\] Per i dati di Zetsche et al. (2019) abbiamo: bysubj %&gt;% group_by(group) %&gt;% summarise( MAD = mad(bdi) ) #&gt; `summarise()` ungrouping output (override with `.groups` argument) #&gt; # A tibble: 2 x 2 #&gt; group MAD #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 ctl 1.48 #&gt; 2 mdd 6.67 4.8.3 Varianza Anche se la statistica definita dall’eq. (4.2) è molto intuitiva, la misura di variabilità di gran lunga più usata per valutare la variabilità di una variabile statistica è senza dubbio la varianza. La varianza \\[\\begin{equation} s^2 = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2 \\tag{4.4} \\end{equation}\\] è la media dei quadrati degli scarti \\(x_i - \\bar{x}\\) tra ogni valore e la media della distribuzione. La varianza è una misura di dispersione più complessa di quelle esaminate in precedenza. È appropriata solo nel caso di distribuzioni simmetriche e, anch’essa, è fortemente influenzata dai valori anomali. Inoltre, è espressa in un’unità di misura che è il quadrato dell’unità di misura dei dati originari e quindi ad essa non può essere assegnata un’interpretazione intuitiva. 4.8.3.1 Esercizio con R Calcoliamo la varianza dei punteggi BDI-II nei due gruppi di soggetti di Zetsche et al. (2019). bysubj %&gt;% group_by(group) %&gt;% summarise( variance = var(bdi) ) #&gt; `summarise()` ungrouping output (override with `.groups` argument) #&gt; # A tibble: 2 x 2 #&gt; group variance #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 ctl 8.03 #&gt; 2 mdd 43.7 4.8.4 Deviazione standard Per le ragioni espresse sopra, la misura più usata della dispersione di una distribuzione di dati è la deviazione standard, ovvero la radice quadrata della varianza. A differenza della varianza, dunque, la deviazione standard è espressa nella stessa unità di misura dei dati. Come nel caso della varianza, anche la deviazione standard \\(s\\) dovrebbe essere usata soltanto quando la media è adeguata per misurare il centro della distribuzione, ovvero, nel caso di distribuzioni simmetriche. Come nel caso della media \\(\\bar{x}\\), anche la deviazione standard è fortemente influenzata dai dati anomali (outlier), ovvero dalla presenza di uno o di pochi dati che sono molto più distanti dalla media rispetto agli altri valori della distribuzione. Quando tutte le osservazioni sono uguali, \\(s=0\\), altrimenti \\(s &gt; 0\\). Alla deviazione standard può essere assegnata una semplice interpretazione: la deviazione standard è simile (ma non identica) allo scostamento medio semplice dalla media. La deviazione standard ci dice, dunque, quanto sono distanti, in media, le singole osservazioni dal centro della distribuzione. 4.8.4.1 Esercizio con R Calcoliamo la deviazione standard per il BDI-II dei due gruppi di soggetti di Zetsche et al. (2019). bysubj %&gt;% group_by(group) %&gt;% summarise( stdev = sd(bdi) ) #&gt; `summarise()` ungrouping output (override with `.groups` argument) #&gt; # A tibble: 2 x 2 #&gt; group stdev #&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 ctl 2.83 #&gt; 2 mdd 6.61 4.8.5 Indici di variabilità relativi A volte può essere interessante effettuare un confronto fra due misure di variabilità di grandezze incommensurabili, ovvero di caratteri rilevati mediante differenti unità di misura. In questi casi, le misure di variabilità precedentemente descritte si rivelano inadeguate in quanto dipendono dall’unità di misura adottata. Diventa dunque necessario ricorrere a particolari numeri adimensionali detti indici relativi di variabilità. Il più importante di tali indici è il coefficiente di variazione, ovvero il numero puro \\[C_v = \\frac{\\sigma}{\\bar{x}}\\] ottenuto dal rapporto tra la deviazione standard e la media dei dati. Un altro indice relativo di variabilità è la differenza interquartile rapportata al primo quartile oppure al terzo quartile oppure alla mediana, cioè: \\[\\frac{x_{0.75} - x_{0.25}}{x_{0.25}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.75}}, \\qquad \\frac{x_{0.75} - x_{0.25}}{x_{0.50}}.\\notag\\] 4.9 Le relazioni tra variabili Zetsche et al. (2019) hanno misurato il livello di depressione dei soggetti del loro esperimento utilizzando due scale psicometriche: il Beck Depression Inventory II (BDI-II) e la Center for Epidemiologic Studies Depression Scale (CES-D). Il BDI-II è uno strumento self-report che valutare la presenza e l’intensità di sintomi depressivi in pazienti adulti e adolescenti di almeno 13 anni di età con diagnosi psichiatrica mentre la CES-D è una scala self-report progettata per misurare i sintomi depressivi che sono stati vissuti nella settimana precedente nella popolazione generale, specialmente quella degli adolescenti/giovani adulti. Una domanda ovvia che ci può venire in mente è: quanto sono simili le misure ottenute mediante queste due scale? È chiaro che i numeri prodotti dalle scale BDI-II e CES-D non possono essere identici, e questo per due motivi: (1) la presenza degli errori di misurazione e (2) l’unità di misura delle due variabili. L’errore di misurazione corrompe sempre, almeno in parte, qualunque operazione di misurazione. E questo è vero specialmente in psicologia dove l’attendibilità degli strumenti di misurazione è minore che in altre discipline (quali la fisica, ad esempio). Il secondo motivo per cui i valori delle scale BDI-II e CES-D non possono essere uguali è che l’unità di misura delle due scale è arbitraria. Infatti, qual è l’unità di misura della depressione? Chi può dirlo! Ma, al di là delle differenze derivanti dall’errore di misurazione e dalla differente unità di misura, ci aspettiamo che, se le due scale misurano entrambe lo stesso costrutto, allora i valori prodotti dalle due scale dovranno essere tra loro linearmente associati. Per capire cosa si intende con “associazione lineare” iniziamo a guardare i dati. Per fare questo utilizziamo una rappresentazione grafica che va sotto il nome di diagramma a dispersione. 4.9.1 Diagramma a dispersione Il diagramma di dispersione è la rappresentazione grafica delle coppie di punti individuati dalle variabili BDI-II e CES-D, e si ottiene ponendo, ad esempio, i valori BDI-II sull’asse delle ascisse e quelli del CES-D sull’asse delle ordinate. In tale grafico, fornito dalla figura , cascun punto corrisponde ad un individuo del quale, nel caso presente, conosciamo il livello di depressione misurato dalle due scale psicometriche. A tale grafico sono state aggiunte le funzioni marginali (ovvero, che si riferiscono a ciascuna variabile considerata singolarmente) di densità empirica che abbiamo già incontrato in precedenza. bysubj &lt;- df %&gt;% group_by(esm_id, group) %&gt;% summarise( bdi = mean(bdi), cesd = mean(cesd_sum) ) %&gt;% na.omit() %&gt;% ungroup() #&gt; `summarise()` regrouping output by &#39;esm_id&#39; (override with `.groups` argument) m_cesd &lt;- mean(bysubj$cesd) m_bdi &lt;- mean(bysubj$bdi) FONT_SIZE &lt;- 10 p &lt;- bysubj %&gt;% ggplot( aes(x=bdi, y=cesd, color=group)) + geom_point(size=1) + geom_hline(yintercept= m_cesd, linetype=&quot;dashed&quot;, color = &quot;gray&quot;) + geom_vline(xintercept = m_bdi, linetype=&quot;dashed&quot;, color = &quot;gray&quot;) + geom_text(x=-1, y=16, label=&quot;I&quot;, color = &quot;gray&quot;, size=FONT_SIZE) + geom_text(x=0, y=46, label=&quot;IV&quot;, color = &quot;gray&quot;, size=FONT_SIZE) + geom_text(x=18, y=46, label=&quot;III&quot;, color = &quot;gray&quot;, size=FONT_SIZE) + geom_text(x=18, y=16, label=&quot;II&quot;, color = &quot;gray&quot;, size=FONT_SIZE) + theme(legend.position=&quot;none&quot;) + labs( x = &quot;BDI-II&quot;, y = &quot;CESD&quot; ) p2 &lt;- ggMarginal(p, type=&quot;density&quot;) p2 Figura 4.7: Associazione tra le variabili BDI-II e CES-D nel campione esaminato da Zetsche et al. (2019). Ai margini del diagramma a dispersione sono rappresentate le funzioni di densità empirica delle due variabili. Dalla figura 4.7 possiamo vedere che i dati mostrano una certa tendenza a disporsi attorno ad una retta – nel gergo statistico, questo fatto viene espresso dicendo che i punteggi BDI-II tendono ad essere linearmente associati ai punteggi CES-D. È ovvio, tuttavia, che tale relazione lineare è lungi dall’essere perfetta – se fosse perfetta, tutti i punti del diagramma a dispersione si disporrebbero esattamente lungo una retta. Il problema che ci poniamo è quello di trovare un indice numerico che descriva di quanto la nube di punti si discosta da una perfetta relazione lineare tra le due variabili. Per risolvere tale problema dobbiamo specificare un indice statistico che descrive la direzione e la forza della relazione lineare tra le due variabili. Ci sono vari indici statistici che possiamo utilizzare a questo scopo. 4.9.2 Covarianza Iniziamo a considerare il più importante di tali indici, chiamato covarianza. In realtà la definizione di questo indice non ci sorprenderà più di tanto in quanto, in una forma solo apparentemente diversa, l’abbiamo già incontrato in precedenza. Ci ricordiamo infatti che la varianza di una generica variabile \\(X\\) è definita come la media degli scarti quadratici di ciascuna osservazione dalla media: \\[\\begin{equation} S_{XX} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (X_i - \\bar{X}). \\tag{4.5} \\end{equation}\\] Infatti, la varianza viene talvolta descritta come la “covarianza di una variabile con sé stessa.” Adesso facciamo un passo ulteriore. Invece di valutare la dispersione di una sola variabile, chiediamoci come due variabili \\(X\\) e \\(Y\\) “variano insieme” (co-variano). È facile capire come una risposta a tale domanda possa essere fornita da una semplice trasformazione della formula precedente che diventa: \\[\\begin{equation} S_{XY} = \\frac{1}{n} \\sum_{i=1}^n(X_i - \\bar{X}) (Y_i - \\bar{Y}). \\tag{4.6} \\end{equation}\\] L’eq. (4.6) ci fornisce dunque la definizione della covarianza. Per capire il significato dell’eq. (4.6), supponiamo di dividere il grafico della figura 4.7 in quattro quadranti definiti da una retta verticale passante per la media dei valori BDI-II e da una retta orizzontale passante per la media dei valori CES-D. Numeriamo i quadranti partendo da quello in basso a sinistra e muovendoci in senso antiorario. Se prevalgono punti nel I e III quadrante, allora la nuvola di punti avrà un andamento crescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\)) e la covarianza segno positivo. Mentre se prevalgono punti nel II e IV quadrante la nuvola di punti avrà un andamento decrescente (per cui a valori bassi di \\(X\\) tendono ad associarsi valori elevati di \\(Y\\) e a valori elevati di \\(X\\) tendono ad associarsi valori bassi di \\(Y\\)) e la covarianza segno negativo. Dunque, il segno della covarianza ci informa sulla direzione della relazione lineare tra due variabili: l’associazione lineare si dice positiva se la covarianza è positiva, negativa se la covarianza è negativa. Il segno della covarianza ci informa sulla direzione della relazione, ma invece il valore assoluto della covarianza ci dice ben poco. Esso, infatti, dipende dall’unità di misura delle variabili. Nel caso presente questo concetto è difficile da comprendere, dato che le due variabili in esame non hanno un’unità di misura (ovvero, hanno un’unità di misura arbitraria e priva di significato). Ma quest’idea diventa chiara se pensiamo alla relazione lineare tra l’altezza e il peso delle persone, ad esempio. La covarianza tra queste due quantità è certamente positiva, ma il valore assoluto della covarianza diventa più grande se l’altezza viene misurata in millimetri e il peso in grammi, e diventa più piccolo l’altezza viene misurata in metri e il peso in chilogrammi. Dunque, il valore della covarianza cambia al mutare dell’unità di misura delle variabili anche se l’associazione tra le variabili resta costante. 4.9.3 Correlazione Dato che il valore assoluto della covarianza è di difficile interpretazione – in pratica, non viene mai interpretato – è necessario trasformare la covarianza in modo tale da renderla immune alle trasformazioni dell’unità di misura delle variabili. Questa operazione si dice standardizzazione e corrisponde alla divisione della covarianza per le deviazioni standard (\\(s_X\\), \\(s_Y\\)) delle due variabili: \\[\\begin{equation} r_{XY} = \\frac{S_{XY}}{s_X s_Y}. \\tag{4.7} \\end{equation}\\] La quantià che si ottiene in questo modo viene chiamata correlazione di Bravais-Pearson (dal nome degli autori che, indipendentemente l’uno dall’altro, la hanno introdotta). Il coefficiente di correlazione ha le seguenti proprietà: ha lo stesso segno della covarianza, dato che si ottiene dividendo la covarianza per due numeri positivi; è un numero puro, cioè non dipende dall’unità di misura delle variabili; assume valori compresi tra -1 e +1. Ad esso possiamo assegnare la seguente interpretazione: \\(r_{XY} = -1\\) \\(\\rightarrow\\) perfetta relazione negativa: tutti i punti si trovano esattamente su una retta con pendenza negativa (dal quadrante in alto a sinistra al quadrante in basso a destra); \\(r_{XY} = +1\\) \\(\\rightarrow\\) perfetta relazione positiva: tutti i punti si trovano esattamente su una retta con pendenza positiva (dal quadrante in basso a sinistra al quadrante in alto a destra); \\(-1 &lt; r_{XY} &lt; +1\\) \\(\\rightarrow\\) presenza di una relazione lineare di intensità diversa; \\(r_{XY} = 0\\) \\(\\rightarrow\\) assenza di relazione lineare tra \\(X\\) e \\(Y\\). Per i dati della figura 4.7, la covarianza è 207.426. Il segno positivo della covarianza ci dice che tra le due variabili c’è un’associazione lineare positiva. Per capire qual è l’intensità della relazione lineare tra le due variabili calcoliamo la correlazione. Essendo le deviazioni standard del BDI-II e del CES-D rispettavamente uguali a 15.37 e 14.93, la correlazione diventa uguale a \\(\\frac{207.426}{15.38 \\cdot 14.93} = 0.904.\\) Tale valore è prossimo a 1.0, il che vuol dire che i punti del diagramma a dispersione non si discostano troppo da una retta con una pendenza positiva. 4.10 Correlazione e causazione Facendo riferimento nuovamente alla figura 4.7, possiamo dire che, in molte applicazioni (ma non nel caso presente!) l’asse \\(x\\) rappresenta una quantità nota come variabile indipendente e l’interesse si concentra sulla sua influenza sulla variabile dipendente tracciata sull’asse \\(y\\). Ciò presuppone però che sia nota la direzione in cui l’influenza causale potrebbe risiedere. È importante tenere bene a mente che la correlazione è soltanto un indice descrittivo della relazione lineare tra due variabili e in nessun caso può essere usata per inferire alcunché sulle relazioni causali che legano le variabili. È ben nota l’espressione: “correlazione non significa causazione.” Di opinione diversa era invece Karl Pearson (1911), il quale ha affermato: Quanto spesso, quando è stato osservato un nuovo fenomeno, sentiamo che viene posta la domanda: ‘qual è la sua causa?’ Questa è una domanda a cui potrebbe essere assolutamente impossibile rispondere. Invece, può essere più facile rispondere alla domanda: ‘in che misura altri fenomeni sono associati con esso?’ Dalla risposta a questa seconda domanda possono risultare molte preziose conoscenze. Che alla seconda domanda posta da Pearson sia facile rispondere è indubbio. Che la nostra comprensione di un fenomeno possa aumentare sulla base delle informazioni fornite dalle correlazioni, invece, è molto dubbio e quasi certamente falso. 4.10.1 Usi della correlazione Anche se non può essere usata per studiare le relazioni causali, la correlazione viene usata per molti altri scopi tra i quali, per esempio, quello di misurare la validità concorrente di un test psiologico. Se un test psicologico misura effettivamente ciò che ci si aspetta che misuri (nel caso dell’esempio presente, la depressione), allora dovremo aspettarci che fornisca una correlazione alta con risultati di altri test che misurano lo stesso costrutto – come nel caso dei dati di (Zetsche et al., 2019). Un’altra proprietà desiderabile di un test psicometrico è la validità divergente: i risultati di test psicometrici che misurano costrutti diversi dovrebbero essere poco associati tra loro. In altre parole, in questo secondo caso dovremmo aspettarci che la correlazione sia bassa. 4.10.2 Correlazione di Spearman Una misura alternativa della relazione lineare tra due variabili è fornita dal coefficiente di correlazione di Spearman e dipende soltanto dalla relazione d’ordine dei dati, non dagli specifici valori dei dati. Tale misura di associazione è appropriata quando, del fenomeno in esame, gli psicologi sono stati in grado di misurare soltanto le relazioni d’ordine tra le diverse modalità della risposta dei soggetti, non l’intensità della risposta. Le variabili psicologiche che hanno questa proprietà si dicono ordinali. Nel caso di variabili ordinali, non è possibile sintetizzare i dati mediante le statistiche descrittive che abbiamo introdotto in questo capitolo, quali ad esempio la media e la varianza, ma è invece solo possibile riassumere i dati mediante una distribuzione di frequenze per le varie modalità della risposta. 4.10.3 Correlazione nulla Un ultimo aspetto da mettere in evidenza a proposito della correlazione riguarda il fatto che la correlazione descrive la direzione e l’intensità della relazione lineare tra due variabili. Relazioni non lineari tra le variabili, anche sono molto forti, non vengono catturate dalla correlazione. È importante rendersi conto che una correlazione pari a zero non significa che non c’è relazione tra le due variabili, ma solo che tra esse non c’è una relazione lineare. Un esempio di questo fatto è fornito dalla figura 4.8. slant &lt;- ggplot(datasaurus_dozen_wide, aes(x=slant_down_x,y=slant_down_y), colour=dataset) # loads slant-pattern dataset of datasauRus package into data frame slant slant &lt;- slant + geom_point() # as a scatter type geom slant &lt;- slant + theme_void() # eliminates unwanted axis labels slant &lt;- slant + theme(legend.position = &quot;none&quot;, panel.border = element_rect(colour = &quot;black&quot;, fill=NA, size = 1), plot.margin = margin(0,2,0,2), aspect.ratio = 1) # removes legend, adds a border, adds margin space below, and specifies # required aspect ratio dino &lt;- ggplot(datasaurus_dozen_wide, aes(x=dino_x,y=dino_y), colour=dataset) + geom_point() # loads dino-figure dataset of datasauRus package into data #frame dino as a scatter type geom dino &lt;- dino +theme_void() # eliminates unwanted axis labels dino &lt;- dino + theme(legend.position = &quot;none&quot;, panel.border = element_rect(colour = &quot;black&quot;, fill=NA, size = 1), plot.margin = margin(0,2,0,2), aspect.ratio = 1) # removes legend, adds a border, adds margin space below, specifies # required aspect ratio slant + dino Figura 4.8: Due insiemi di dati (fittizi) per i quali i coefficienti di correlazione di Pearson sono entrambi 0. Ma questo non significa che non vi sia alcuna relazione tra le variabili. Conclusioni La prima fase dell’analisi dei dati è sicuramente quella che ci porta a riassumere i dati mediante gli strumenti della statistica descrittiva. Ci sono diverse domande che vengono affrontate in questa fase: qual è la distribuzione delle variabili di interesse? Quali relazioni a coppie si possono osservare nel campione? Ci sono delle osservazioni ‘anomale,’ ovvero estremamente discrepanti rispetto alle altre, sia quando si esaminano le statistiche descrittive univariate (ovvero, quelle che riguardano le caratteristiche di una variabile presa singolarmente), sia quando vengono esaminate le statistiche bivariate (ovvero, le statistiche che descrivono l’associazione tra le variabili)? È importante avere ben chiare le idee su questi punti prima di procedere con qualsiasi procedura statistica di tipo inferenziale. Per rispondere alle domande che abbiamo elencato sopra, ed ad altre simili, è molto utile procedere con delle rappresentazioni grafiche dei dati. Dovrebbe essere chiaro che, quando disponiamo di grandi moli di dati (come è sempre il caso in psicologia), per fare questo è necessario usare un software statistico. "],["chapter-prob-discreta.html", "Capitolo 5 Che cos’è la probabilità? 5.1 Probabilità nel linguaggio naturale 5.2 Probabilità nel linguaggio scientifico 5.3 Terminologia 5.4 Le diverse definizioni della probabilità 5.5 Assegnare le probabilità agli eventi 5.6 Proprietà elementari della probabilità 5.7 Variabili aleatorie 5.8 Notazione Conclusioni", " Capitolo 5 Che cos’è la probabilità? È normale fare delle congetture rispetto a ciò di cui non siamo sicuri. Ma perché facciamo questo? Molto spesso perché, anche se sappiamo che le nostre conoscenze sono incomplete, dobbiamo comunque prendere delle decisioni. Ad esempio: “non so se tra qualche ora pioverà; devo o non devo prendere l’ombrello?” In maniera simile, anche se uno psicologo non sa in maniera certa quali sono i meccanismi che regolano i fenomeni psicologi, deve comunque decidere tra diverse alternative. Per esempio, deve fornire un parere, relativamente a chi, tra due genitori, sia più adatto per ottenere l’affidamento del figlio in caso di divorzio, oppure quale sia, in un caso specifico, l’approccio più efficace per il trattamento dei disturbi dell’alimentazione. Ovviamente la qualità delle congetture varia, così come varia la qualità delle decisioni che prendiamo. La teoria delle probabilità ci fornisce gli strumenti per prendere decisioni “razionali” in condizioni di incertezza, ovvero per formulare le migliori congetture possibili. La teoria delle probabilità ci consente di descrivere in maniera quantitativa quei fenomeni che, pur essendo altamente variabili, rivelano comunque una qualche coerenza a lungo termine. Il lancio ripetuto di una moneta è uno di questi fenomeni. È anche l’esempio tipico che viene usato per introdurre una discussione sulle probabilità. Sapere se una moneta sia onesta o meno, o calcolare la probabilità di ottenere testa un certo numero di volte può essere interessante nel mondo delle scommesse, ma nella vita quotidiana non ci capita spesso di lanciare una moneta per prendere una decisione. Allora perché ci preoccupiamo di studiare le proprietà statistiche dei lanci di una moneta? A questa domanda si può rispondere dicendo che l’esperimento (chiamato “casuale”) che corrisponde al lancio di una moneta è il surrogato di una molteplicità di eventi che, della vita reale, sono molto importanti. Per esempio: qual è la probabilità di successo di un intervento psicologico? Qual è la probabilità che un test per l’HIV dia esito positivo in una persona che non ha l’HIV? Qual è la probabilità di essere occupato entro un anno dalla laurea? I lanci di una moneta costituiscono una rappresentazione generica di molteplici altri eventi che hanno un grande significato nella nostra vita. Questa è la ragione per cui studiamo le proprietà statistiche dei fenomeni aleatori usando il lancio di una moneta quale esempio generico. La discussione della teoria della probabilità è certamente l’argomento più impegnativo affrontato in queste dispense. Fare uno sforzo di comprensione per chiarire i concetti di base della teoria della probabilità è però necessario per mettersi nelle condizioni di capire le caratteristiche dell’inferenza statistica che verranno discusse in seguito. 5.1 Probabilità nel linguaggio naturale In un articolo pubblicato su Harward Business Review nel 2018, Mauboussin e Mauboussin ci ricordano come, nel marzo del 1951, l’Office of National Estimates della CIA pubblicò un documento che suggeriva che un attacco sovietico alla Jugoslavia nel corso dell’anno fosse una “seria possibilità.” Sherman Kent, un professore di storia a Yale che fu chiamato a Washington, D.C. per dirigere l’Office of National Estimates, espresse perplessità sull’esatto significato dell’espressione “seria possibilità.” Lo interpretò nel senso che la probabilità di un attacco era di circa il 65%. Ma quando chiese ai membri del Board of National Estimates cosa ne pensassero, gli furono riferite cifre che andavano dal 20% all’80%. Una gamma così ampia rappresentava chiaramente un problema, poiché le implicazioni politiche di quegli estremi erano nettamente diverse. Kent riconobbe che la soluzione di tale problema era quella di usare i numeri per esprimere il nostro grado di certezza, notando mestamente: Non abbiamo usato i numeri… e sembra chiaro che abbiamo abusando delle parole. Da allora non è cambiato molto. Ancora oggi le persone nel mondo della politica, degli affari e nella vita quotidiana continuano a usare parole vaghe per descrivere i possibili risultati degli eventi. Perché? Phil Tetlock, professore di psicologia all’Università della Pennsylvania, che ha studiato a fondo il fenomeno psicologico della previsione, suggerisce che “una vaga verbosità conferisce sicurezza.” Quando usiamo una parola per descrivere la probabilità di un evento incerto, cerchiamo di porci nelle condizioni di non essere smentiti dopo che il risultato dell’evento verrà rivelato. Se si verifica l’evento che abbiamo previsto, è facile dire: “Ti avevo detto che probabilmente sarebbe successo questo.” Se la nostra predizione fallisce, possiamo sempre dire: “Ho solo detto che probabilmente sarebbe successo.” Parole così ambigue non solo consentono all’oratore di evitare di essere smentito, ma consentono anche al destinatario di interpretare il messaggio in modo coerente con le sue nozioni preconcette. Ovviamente, da tale ambiguità linguistica deriva una cattiva comunicazione. È dunque necessario procedere in modo diverso nel linguaggio scientifico. Vedremo in questo capitolo come sia possibile assegnare al termine “probabilità” un significato preciso. 5.2 Probabilità nel linguaggio scientifico La teoria della probabilità nasce nel 1654. Fu infatti in questa data che Antoine Gombaud Cavalier De Méré, un nobile francese, nonché accanito giocatore d’azzardo scrisse una lettera al suo amico Pascal per cercare di comprendere il motivo delle sue continue perdite nel gioco dei dadi. De Méré descrisse due diverse scommesse: scommessa A si lancia un dado per 4 volte di seguito e si vince se esce almeno una volta il 6; scommessa B si lanciano due dadi per 24 volte di seguito e si vince se esce almeno una volta il doppio 6. Il cavaliere De Méré pose a Pascal il seguente quesito: le possibilità di vittoria sono maggiori nella scommessa A o nella scommessa B? Il problema di De Méré divenne un motivo di scambio epistolare tra Pascal e Fermat, i due più grandi matematici del tempo, e viene considerato come la motivazione iniziale dello sviluppo della teoria della probabilità. Ma come può essere risolto il problema di De Méré? Una strategia possibile è quella di seguire l’esempio di De Méré, ovvero, giocare questo gioco molte volte. Così facendo, De Méré si rese conto che le possibilità di vittoria erano leggermente migliori nel caso della scommessa A. Utilizzando una simulazione al computer possiamo facilmente giungere a questa stessa conclusione senza perdere tutto il tempo che De Méré ha dedicato a questa materia. Una simulazione al computer ci consente infatti di ripetere il gioco di De Méré moltissime volte e di annotare il risultato ottenuto ad ogni ripetizione del gioco. Vedremo in seguito perché, utilizzando un computer, è possibile ottenere un risultato diverso ogni volta che si ripete una certa operazione, in modo tale da rappresentare il grado di casualità che si osserva quando si lancia di un dado. Per ora ci limitiamo ad esaminare i risultati che vengono prodotti in questo modo e che sono illustrati nella figura 5.1. # Game A: Throw a fair die at most four times, and win if you get a six. experiment_a &lt;- function(){ rolls &lt;- sample(1:6, size = 4, replace = TRUE) condition &lt;- sum(rolls == 6) &gt; 0 return(condition) } # Game B: Throw two fair dice at most twenty-four times, and win if you get a double-six. experiment_b &lt;- function(){ first.die &lt;- sample(1:6, size = 24, replace = TRUE) second.die &lt;- sample(1:6, size = 24, replace = TRUE) condition &lt;- sum((first.die == second.die) &amp; (first.die == 6)) &gt; 0 return(condition) } # number of replications nrep &lt;- 1e4 # Play game A nrep times. We get a vector of nrep elements. Eeach element of # of the simsA vector is the outcome obtained by playing game A once: TRUE if # the output is a win, FALSE if the output of the game is a loss. Remember than # TRUE = 1 and FALSE = 0. sims_a &lt;- replicate(nrep, experiment_a()) # The proportion of wins in game A prop_wins_a &lt;- sum(sims_a)/length(sims_a) prop_wins_a #&gt; [1] 0.5193 # To plot the results, we compute the nwins_a &lt;- cumsum(sims_a) ntrials &lt;- 1:nrep sims_b &lt;- replicate(nrep, experiment_b()) prop_wins_b &lt;- sum(sims_b)/length(sims_b) prop_wins_b #&gt; [1] 0.493 nwins_b &lt;- cumsum(sims_b) d &lt;- data.frame( n = c(ntrials, ntrials), pwin = c(nwins_a/ntrials, nwins_b/ntrials), game = rep(c(&quot;Scommessa A&quot;, &quot;Scommessa B&quot;), each = nrep) ) d %&gt;% ggplot( aes(x = n, y = pwin, col = game) ) + geom_point(alpha = 0.4) + geom_line() + scale_x_log10(breaks = c(1, 3, 10, 50, 200, 1000, 3000, 10000)) + theme(legend.title = element_blank()) + labs( x=&quot;Numero di ripetizioni del gioco di De Méré&quot;, y=&quot;Proporzione di vincite&quot;) + scale_color_manual(values = c(&quot;gray80&quot;, &quot;skyblue&quot;)) + theme(legend.position = &quot;bottom&quot;) Figura 5.1: Risultati ottenuti da 10000 ripetizioni delle due scommesse di De Méré. La figura 5.1 riportata la proporzione di vittorie in funzione del numero di ripetizioni di ciascuna scommessa e rivela che, a lungo termine (ovvero, se consideriamo un grande numero di ripetizioni del gioco di De Méré), la scommessa A risulta più conveniente della scommessa B. Nel caso di 10000 ripetizioni del gioco di De Méré, la proporzione di vittorie è risultata essere pari a 0.5182 per la scommessa A e pari a 0.4909 per la scommessa B. Se ripetiamo la stessa simulazione altre 10000 volte, otteniamo una proporzione di vittorie uguale a 0.5180 per la scommessa A e a 0.4878 per la scommessa B. Vedremo in questo capitolo come ciascuna di queste proporzioni possa essere considerata come una stima empirica di ciò che chiamiamo probabilità. Le proporzioni descritte sopra vengono sono delle “stime” poiché approssimano il vero valore della probabilità; infatti, ripetendo la simulazione due volte abbiamo ottenuto dei risultati leggermente diversi. Ma allora qual è il “vero” valore della probabilità? Un modo semplice per rispondere a questa domanda è quello di dire che, utilizzando la procedura descritta sopra, il vero valore della probabilità si otterrebbe se il gioco di De Méré venisse ripetuto infinite volte. Ma ovviamente, per qualunque applicazione concreta, non abbiamo bisogno di ripetere la simulazione infinite volte, in quanto un grande numero di ripetizioni ci fornisce un’approssimazione sufficiente. In conclusione, le considerazioni precedenti ci fanno capire che il concetto di probabilità sia legato a quello di incertezza. La probabilità può infatti essere definita come la quantificazione del livello di “casualità” di un evento, laddove viene detto casuale ciò che non è noto o non può essere predetto con certezza. 5.3 Terminologia Come qualsiasi altra branca della matematica, la teoria delle probabilità fa uso di una specifica terminologia i cui concetti di base sono descritti di seguito. Il calcolo delle probabilità si occupa di un generico esperimento casuale. Si dice esperimento casuale qualsiasi attività che produce un risultato osservabile. L’esecuzione di un esperimento casuale è chiamata prova dell’esperimento. Esempi sono: lanciare una moneta, lanciare un dado a 6 facce, provare un nuovo percorso per andare al lavoro per vedere se è più veloce di quello che usiamo di solito, o giocare al gioco di De Méré. Il risultato (o esito) di una prova si indica con \\(\\omega\\) ed è detto evento elementare. Prima che l’esperimento casuale venga eseguito non sappiamo quale esito verrà prodotto; dopo che l’esperimento casuale è stato eseguito, l’esito dell’esperimento si “cristallizza” nel risultato osservato. Si dice spazio campionario \\(\\Omega\\) (probability space) l’insieme di tutti i possibili esiti di un esperimento casuale. Lo spazio campionario può essere finito, infinito o infinito numerabile. Eseguire un esperimento casuale significa scegliere in maniera casuale uno dei possibili eventi elementari dello spazio campionario. Si dice evento composto (o non-elementare) un sottoinsieme dello spazio campionario, ovvero un insieme che può essere a sua volta scomposto in più eventi elementari. Per esempio, il numero 4 è un evento elementare dello spazio campionario finito \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\) che corrisponde all’esperimento casuale del lancio di un dado. L’evento composto \\(A\\) “il risultato è pari” è \\(A = \\{2, 4, 6\\}\\). 5.4 Le diverse definizioni della probabilità Ma, nello specifico, che cos’è la probabilità? A questa domanda si può rispondere in modi diversi. 5.4.1 Una definizione “ingenua” della probabilità Storicamente, la prima definizione della probabilità di un evento è stata quella che richiede di contare il numero di modi nei quali un evento può manifestarsi e di dividere tale numero per il numero totale di eventi dello spazio campionario \\(\\Omega\\). Definizione 5.1 Dato uno spazio campionario finito, la definizione ingenua della probabilità dell’evento \\(A\\) è \\[ \\begin{aligned} P_{\\text{ing}} = \\frac{|A|}{|\\Omega|} = \\frac{\\text{numero eventi elementari favorevoli all&#39;evento }A}{\\text{numero totale eventi elementari dello spazio campionario }\\Omega}.\\notag\\end{aligned} \\] La definizione 5.1 rende chiaro che il calcolo delle probabilità richiede di contare il numero di modi in cui un evento può realizzarsi. Per esempio, nell’esperimento casuale corrispondente al lancio di due dadi equilibrati, l’evento \\(A\\) = “la somma dei due dati è 5” si può realizzare in 4 modi diversi: \\(A = \\{ (1, 4), (2, 3), (3, 2), (4, 1) \\}\\). Contare il numero di modi in cui un evento può realizzarsi può essere semplice, nel caso di alcuni eventi (come il presente), oppure estremamente complesso, nel caso di altri eventi. In questo secondo caso, per contare il numero di modi in cui un evento può realizzarsi, al fine di calcolare la probabilità definita come indicato sopra, è necessario fare uso del calcolo combinatorio. In queste dispense ci accontenteremo di presentare alcune nozioni di base del calcolo combinatorio, ma non entreremo nei dettagli di questo argomento. 5.4.2 Una definizione “non ingenua” della probabilità Il calcolo combinatorio ci consente di contare il numero di casi nello spazio campionario e di applicare la definizione “ingenua” di probabilità descritta nella definizione 5.1. È però facile rendersi conto che tale definizione di probabilità ha un grosso problema: non può essere applicata al caso di uno spazio campionario infinito. Dobbiamo dunque trovare una definizione che risolva un tale problema. Per fare ciò vengono specificate alcune proprietà che vorremmo potere attribuire alla probabilità – in matematica, tali proprietà sono dette assiomi – per poi definire una funzione di probabilità che soddisfi tali proprietà. Arriviamo in questo modo alla seguente definizione non ingenua della probabilità. Definizione 5.2 Uno spazio di probabilità è una terna (\\(\\Omega\\), \\(\\mathcal{A}\\), \\(P\\)), dove \\(\\Omega\\) è l’insieme dei risultati possibili di un esperimento casuale, \\(\\mathcal{A}\\) è detta \\(\\sigma\\)-algebra, ovvero un insieme di insiemi (gli eventi) per i quali si può calcolare una probabilità, e \\(P()\\) è una misura di probabilità su \\(\\Omega\\), ovvero \\(P: \\Omega \\rightarrow [0, 1]\\). Per la precisione, una \\(\\sigma\\)-algebra è una famiglia di insiemi tali che \\(\\emptyset \\in \\mathcal{A}\\); se \\(A \\in \\mathcal{A}\\) allora anche il suo complementare \\(A^C\\) è in \\(\\mathcal{A}\\); unioni numerabili di elementi di \\(\\mathcal{A}\\) appartengono ancora ad \\(\\mathcal{A}\\). La funzione di probabilità \\(P()\\) deve soddisfare i seguenti assiomi: la probabilità \\(P(\\omega)\\) soddisfa la disuguaglianza \\(0 \\leq P(\\omega) \\leq 1;\\) la probabilità dell’evento certo (ovvero la probabilità dello spazio campionario \\(\\Omega\\)) è 1: \\(P(\\Omega) = \\sum_{\\omega \\in \\Omega} P(\\omega) = 1;\\) se \\(A_1, A_2, \\dots, A_k\\) sono eventi disgiunti, allora la probabilità che uno di essi si verifichi è pari alla somma delle loro separate probabilità: \\[\\begin{equation} P(A_1 \\text{ o } A_1 \\dots \\text{ o } A_k) = P(A_1) + P(A_2) +\\dots + P(A_k). \\tag{5.1} \\end{equation}\\] La definizione 5.2 corrisponde al cosiddetto approccio assiomatico messo a punto da Kolmogorov intorno al 1930, il quale è alla base della moderna teoria della probabilità. Nonostante l’enorme complessità dell’approccio assiomatico alla probabilità, per gli scopi dell’analisi dei dati psicologici le cose che dobbiamo capire sono molto semplici. I vincoli della \\(\\sigma\\)-algebra sono necessari per evitare i paradossi che si possono creare quando si manipolano gli insiemi (ad esempio, l’utilizzo dell’“l’insieme di tutti gli insiemi” tipicamente conduce ad un paradosso). Questi problemi sono però molto lontani dalle applicazioni della teoria della probabilità all’analisi dei dati psicologici. Gli psicologi tipicamente effettuano partizioni molto semplici dello spazio campionario: il trattamento ha funzionato oppure no? Per cui le aporie della teoria degli insiemi a cui la \\(\\sigma\\)-algebra vuole porre un freno sono problemi che non ci riguardano. Gli altri aspetti della teoria assiomatica della probabilità, invece, sono molto intuitivi. I primi due assiomi possono essere interpretati nel modo seguente. Si assegna il valore 0 all’“evento impossibile,” ovvero all’esito dell’esperimento casuale che non può verificarsi (ad esempio, il lancio di un dado a sei facce produce 7), e si assegna il valore 1 all’evento certo (ad esempio, il lancio di un dado a sei facce produce un numero compreso tra 1 e 6). Di conseguenza, la probabilità è un numero nell’intervallo \\([0, 1]\\). Il terzo assioma può essere compreso interpretando la probabilità come la frequenza relativa a lungo termine del verificarsi di un evento. Se due eventi sono incompatibili, allora la frequenza relativa dell’unione di tali eventi è la somma delle due singole frequenze relative. Lo stesso si vale per la probabilità. 5.5 Assegnare le probabilità agli eventi È importante capire che l’approccio assiomatico non ci dice come sia possibile assegnare un valore di probabilità a un evento definito in \\(\\Omega\\). A questo proposito esistono due diverse scuole di pensiero. 5.5.1 Approccio frequentista Una prima possibilità è di definire la nozione di probabilità in termini empirici. La probabilità di un evento \\(A\\) può essere concepita come il limite cui tende la frequenza relativa dell’evento, al tendere all’infinito del numero delle prove effettuate, ossia \\[\\begin{equation} P_A = \\lim_{n \\to \\infty} \\frac{n_A}{n}. \\end{equation}\\] Questo è l’approccio che abbiamo utilizzato in precedenza, quando abbiamo discusso il gioco di De Méré. Tale definizione assume che l’esperimento possa essere ripetuto più volte, idealmente infinite volte, sotto le medesime condizioni, e corrisponde alla definizione frequentista di probabilità. Per l’approccio frequentista, dire che la probabilità di ottenere testa è 0.5 significa affermare che l’evento “testa” verrebbe ottenuto nel 50% dei casi, se ripetessimo tantissime volte l’esperimento casuale del lancio di una moneta. Se non abbiamo a disposizione informazioni empiriche a proposito del verificarsi di un evento possiamo attribuire le probabilità agli eventi usando la nostra conoscenza della situazione. Tale approccio è seguito dalla definizione classica di probabilità in base alla quale la probabilità di un evento è il rapporto tra il numero di casi favorevoli e quelli possibili, supposto che tutti gli eventi siano equiprobabili, ossia \\[P_A = \\frac{n_A}{n},\\] dove \\(n\\) è il numero di casi possibili e \\(n_A\\) è il numero di casi favorevoli per l’evento \\(A\\). L’assunzione di equiprobabilità degli eventi elementari ha senso soprattutto nel caso dei giochi d’azzardo. In base all’approccio frequentista, la probabilità è il limite a cui tende una frequenza relativa empirica al crescere del numero di ripetizioni dell’esperimento casuale. È molto facile utilizzare per calcolare una tale probabilità. Per esempio, se vogliamo calcolare la probabilità di ottenere 3 nel lancio di un dado equilibrato, possiamo eseguire la seguente simulazione. n &lt;- 1e5 x &lt;- sample(1:6, n, replace = TRUE) x_01 &lt;- ifelse(x == 3, 1, 0) mean(x_01) #&gt; [1] 0.1676 Il risultato è ovviamente molto simile a \\(1/6\\). 5.5.2 Approccio Bayesiano Esistono però degli eventi per i quali non è possibile calcolare una frequenza relativa, ovvero quelli che si verificano una volta soltanto. Che cos’è allora la probabilità in questi casi? In base all’approccio Bayesiano la probabilità è una misura del grado di plausibilità di una proposizione. Questa definizione è applicabile a qualsiasi evento. Ciò consente di assegnare una probabilità anche a proposizioni quali “il candidato \\(A\\) vincerà le elezioni” oppure “l’accusato è innocente,” anche se non è possibile ripetere più volte un’elezione o un evento criminoso. Per assegnare le probabilità agli eventi, nell’approccio Bayesiano si utilizzano considerazioni “soggettive” che derivano dalle informazioni di cui il soggetto è in possesso. Il teorema di Bayes consente di aggiustare, alla luce dei dati osservati, tali credenze “a priori” per arrivare alla probabilità a posteriori. Quindi, tramite l’approccio Bayesiano, si usa una stima del grado di plausibilità di una proposizione prima dell’osservazione dei dati, al fine di associare un valore numerico al grado di plausibilità di quella stessa proposizione successivamente all’osservazione dei dati. Questo processo di “aggiornamento Bayesiano” corrisponde all’inferenza statistica e verrà discusso in dettaglio nel seguito delle dispense. 5.6 Proprietà elementari della probabilità Indipendentemente da come decidiamo di interpretare la probabilità (in termini frequentisti o Bayesiani), alla probabilità possono essere assegnate le seguenti proprietà. La probabilità dell’evento impossibile è zero: \\[P(\\emptyset) = 1 - P(\\Omega) = 0.\\] Se consideriamo due eventi \\(A\\) e \\(B\\) tali che \\(A \\subseteq B\\), cioè che \\(A\\) è contenuto o coincidente con \\(B\\), da ciò segue che \\[P(A) \\leq P(B).\\] Se \\(A^c\\) è il complementare dell’evento \\(A\\), allora \\[P(A^c) = 1 - P(A).\\] Dati \\(n\\) eventi \\(A_i\\) per \\(i= 1, \\cdots, n\\), gli eventi si dicono indipendenti se risulta \\[P(A_i \\cap A_j \\cap \\cdots \\cap A_k) = P(A_i) P(A_j) \\cdots P(A_k).\\] Se due eventi \\(A\\) e \\(B\\) non sono disgiunti, allora quando sommiamo le loro probabilità dobbiamo evitare che la loro parte comune \\(A \\cap B\\) venga contata due volte. Dati due eventi non necessariamente disgiunti, dunque, la probabilità dell’unione è pari alla somma delle singole probabilità dei due eventi meno la probabilità dell’intersezione: \\[\\begin{equation} P(A \\text{ o } B) = P(A \\cup B) = P(A) + P(B) - P(A \\cap B). \\tag{5.2} \\end{equation}\\] Exercizio 5.1 Nel 2012, a 97 deputati al Parlamento di Londra è stato chiesto: “Se lanci una moneta due volte, qual è la probabilità di ottenere due volte testa?” La maggioranza, 60 su 97, non ha saputo dare la risposta corretta. Come possiamo dare a questo problema una risposta migliore di quella fornita da questi politici? Soluzione. In base alla regola 4 elencata sopra, la risposta corretta è \\(0.5 \\times 0.5 = 0.25\\). Exercizio 5.2 Un’urna contiene \\(30\\) palline: \\(10\\) bianche numerate da \\(1\\) a \\(10\\), \\(10\\) rosse e \\(10\\) gialle numerate allo stesso modo. Qual è la probabilità che, estraendo una pallina a caso, venga estratta una pallina gialla o una pallina pari? Soluzione. Il numero totale di palline è \\(30\\). La probabilità che venga estratta una gialla è \\(P(G) = \\frac{10}{30} = \\frac{1}{3}\\). Le palline con numero pari sono \\(5\\) per ogni colore, quindi \\(15\\). La probabilità che venga estratto un numero pari è \\(P(P) = \\frac{15}{30} = \\frac{1}{2}\\). Gli eventi sono compatibili: i casi favorevoli a entrambi gli eventi (pallina gialla e pari) sono \\(5\\). La probabilità dell’evento cercato è dunque \\(P(\\text{gialla} \\cup \\text{pari}) = \\frac{1}{3} + \\frac{1}{2} - \\frac{5}{30} = \\frac{2}{3}\\). 5.7 Variabili aleatorie Il concetto di “variabile aleatoria” è estremamente utile per estendere la nostra capacità di quantificare l’incertezza e di riassumere i risultati di un esperimento casuale. Le variabili aleatorie sono un concetto fondamentale di tutta la teoria statistica; è quindi cruciale capire quale sia il loro significano. Iniziamo con una definizione. Definizione 5.3 Una variabile aleatoria è una funzione sullo spazio campionario \\(\\Omega\\) che associa ad ogni evento elementare \\(\\omega_i\\) un unico numero \\(X(\\omega_i) = x_i\\), ovvero \\(X: \\Omega \\rightarrow \\Re\\). Il dominio della variabile aleatoria \\(X\\) (che è una funzione) è dato dai punti dello spazio campionario \\(\\Omega\\). Ad ogni evento elementare \\(\\omega_i\\) attribuiamo il numero \\(X(\\omega_i)\\), ovvero il valore che la variabile aleatoria assume sul risultato \\(\\omega_i\\) dell’esperimento casuale. L’attributo “aleatoria” si riferisce al fatto che la variabile considerata trae origine da un esperimento di cui non siamo in grado di prevedere l’esito con certezza. Mediante una variabile aleatoria trasformiamo lo spazio campionario \\(\\Omega\\), che in genere è complesso, in uno spazio campionario più semplice formato da un insieme di numeri. Il maggior vantaggio di questa sostituzione è che molte variabili aleatorie, definite su spazi campionari anche molto diversi tra loro, danno luogo ad una stessa “distribuzione” di probabilità sull’asse reale. Le variabili aleatorie si indicano con le lettere maiuscole ed i valori da esse assunti con le lettere minuscole. Ci sono due classi di variabili aleatorie: variabili aleatorie discrete e variabili aleatorie continue. Consideriamo innanzitutto il caso delle variabili aleatorie discrete. Definizione 5.4 Una variabile aleatoria \\(X\\) viene detta discreta se può assumere un insieme discreto (finito o numerabile) di numeri reali. Se \\(X\\) è una variabile aleatoria discreta allora l’insieme dei possibili valori \\(x\\), tali per cui \\(P(X = x) &gt; 0\\), viene detto “supporto” di \\(X\\). Alcuni esempi di variabili aleatorie discrete sono i seguenti: il numero di intrusioni di pensieri, immagini, impulsi indesiderabili in un paziente OCD, il voto all’esame di Psicometria, la durata di vita di un individuo, il numero dei punti che si osservano nel lancio di due dadi e il guadagno (la perdita) che un giocatore realizzerà in \\(n\\) partite. Si noti che, in tutti questi casi, la variabile aleatoria considerata viene rappresentata mediante un numero. 5.7.1 A cosa servono le variabili aleatorie? Facendo riferimento agli esempi elencati sopra, possiamo chiederci perché questi numeri vengono considerati come “aleatori.” È ovvio che noi non conosciamo, ad esempio, il voto di Psicometria di Mario Rossi prima del momento in cui Mario Rossi avrà fatto l’esame. Le variabili aleatorie si pongono il seguente problema: come possiamo descrivere le nostre opinioni rispetto al voto (possibile) di Mario Rossi, prima che lui abbia fatto l’esame. Prima dell’esame, il voto di Psicometria di Mario Rossi si può solo descrivere facendo riferimento ad un insieme di valori possibili. Inoltre, molto spesso, possiamo anche dire che tali valori possibili non sono tutti egualmente verosimili: ci aspettiamo di osservare più spesso alcuni di questi valori rispetto agli altri. Le proprietà delle variabili aleatorie ci consentono di sistematizzare questo tipo di opinioni. Ovviamente, una volta che Mario Rossi avrà fatto l’esame, questa materia non avrà più alcuna componente aleatoria. 5.7.2 Funzione di massa di probabilità Per entrare nel merito di questa discussione, chiediamoci ora come sia possibile associare delle probabilità ai valori che vengono assunti dalle variabili aleatorie. Ad esempio, qual è la probabilità che Mario Rossi ottenga 29 all’esame? Ci occuperemo qui del caso delle variabili aleatorie discrete. Alle variabili aleatorie discrete vengono assegnale le probabilità mediante le cosiddette “distribuzioni di probabilità.” Una distribuzione di probabilità è un modello matematico che collega ciascun valore di una variabile aleatoria discreta alla probabilità di osservare un tale valore in un esperimento casuale. In pratica, ad ognuno dei valori che possono essere assunti da una variabile aleatoria discreta viene associata una determinata probabilità. La funzione che associa ad ogni valore della variabile aleatoria una probabilità corrispondente si chiama “distribuzione di probabilità” oppure “legge di probabilità.” Una descrizione intuitiva del concetto di distribuzione di probabilità può essere formulata nei termini seguenti. Possiamo pensare alla probabilità come ad una quantità positiva che viene “distribuita” sull’insieme dei valori della variabile aleatoria. Tale “distribuzione” (suddivisione, spartizione) viene scalata in maniera tale che ciascun elemento di essa corrisponda ad una proporzione del totale, nel senso che il valore totale della distribuzione è sempre pari a 1. Una distribuzione di probabilità non è dunque altro che un modo per suddividere la nostra certezza (cioè 1) tra i valori che la variabile aleatoria può assumere. In modo più formale, possiamo dire quanto segue. Definizione 5.5 Se \\(X\\) è una variabile aleatoria discreta, una distribuzione di probabilità può essere rappresentata mediante una funzione di massa di probabilità che associa a ciascuno dei valori \\(x\\) che la variabile aleatoria \\(X\\) può assumere la corrispondente probabilità \\(P_{\\pi}(X=x)\\). In maniera più semplice, una distribuzione di (massa) di probabilità è formata dall’elenco di tutti i valori possibili di una variabile aleatoria discreta e dalle probabilità loro associate. Si noti che \\(P_{\\pi}(X=x)\\) è un numero positivo se il valore \\(x\\) è compreso nel supporto di \\(X\\), altrimenti vale 0. Se \\(A\\) è un sottoinsieme della variabile aleatoria \\(X\\), allora denotiamo con \\(P_{\\pi}(A)\\) la probabilità assegnata ad \\(A\\) dalla distribuzione \\(P_{\\pi}\\). Mediante una distribuzione di probabilità \\(P_{\\pi}\\) è possibile determinare la probabilità di ciascun sottoinsieme \\(A \\subset X\\) come \\[P_{\\pi}(A) = \\sum_{x \\in A} P_{\\pi}(x).\\] Qui non facciamo altro che applicare il terzo assioma di Kolmogorov. Exercizio 5.3 Consideriamo nuovamente lo spazio campionario \\(\\Omega\\) dell’esercizio precedente e definiamo la variabile aleatoria \\(S(\\omega)\\) come la somma dei puntini che si ottengono dal lancio di due dadi. Per esempio, \\(S(\\{(6, 3)\\}) = 6 + 3 = 9\\). Iniziamo a chiederci qual è la probabilità dell’evento \\(S = 7\\). Soluzione. Per risolvere tale problema iniziamo a considerare il fatto che l’evento \\(S = 7\\) si verifica in corrispondenza di sei punti elementari dello spazio campionario \\(\\Omega\\): {(1, 6), (2, 5), (3, 4), (4, 3), (2, 5), (6, 1)}. Dunque, \\[\\begin{equation} P(S = 7) = P\\{(1, 6)\\} + P\\{(2, 5)\\} + P\\{(3, 4)\\} + P\\{(4, 3)\\} + P\\{(2, 5)\\} + P\\{(6, 1)\\}. \\end{equation}\\] Se possiamo assumere che i due dadi sono bilanciati, allora ciascun evento elementare dello spazio campionario ha probabilità \\(\\frac{1}{36}\\) e la probabilità cercata diventa \\(\\frac{1}{6}\\). È facile estendere il ragionamento fatto sopra a tutti i valori che \\(S\\) può assumere. In questo modo giungiamo alla funzione di massa di probabilità \\(P_0\\) riportata nella prima riga della tabella seguente. Distribuzione di massa di probabilità per la somma dei punti prodotti dal lancio di due dadi bilanciati (\\(P_0\\)) e di due dadi truccati (\\(P_1\\)). s 2 3 4 5 6 7 8 9 10 11 12 \\(P_0(S = s)\\) \\(\\frac{1}{36}\\) \\(\\frac{2}{36}\\) \\(\\frac{3}{36}\\) \\(\\frac{4}{36}\\) \\(\\frac{5}{36}\\) \\(\\frac{6}{36}\\) \\(\\frac{5}{36}\\) \\(\\frac{4}{36}\\) \\(\\frac{3}{36}\\) \\(\\frac{2}{36}\\) \\(\\frac{1}{36}\\) \\(P_1(S = s)\\) \\(\\frac{4}{64}\\) \\(\\frac{4}{64}\\) \\(\\frac{5}{64}\\) \\(\\frac{6}{64}\\) \\(\\frac{7}{64}\\) \\(\\frac{12}{64}\\) \\(\\frac{7}{64}\\) \\(\\frac{6}{64}\\) \\(\\frac{5}{64}\\) \\(\\frac{4}{64}\\) \\(\\frac{4}{64}\\) Per considerare un caso più generale, poniamoci ora il problema di trovare la funzione di massa di probabilità di \\(S\\) nel caso di due dadi truccati aventi la seguente distribuzione di probabilità: \\[ \\begin{aligned} P(\\{(1, 6)\\}) = \\frac{1}{4};\\notag\\\\ P(\\{(2, 3)\\}) = P(\\{4\\}) = P(\\{5\\}) = \\frac{1}{8}\\notag. \\label{eq:loaded_dice} \\end{aligned} \\] Nel caso dei due dadi truccati, la probabilità dell’evento elementare (1, 1) è 1/4 1/4. Dunque, P(S = 2) = 4/64. La probabilità dell’evento elementare (1, 2) è 1/4 1/8. Tale valore è uguale alla probabilità dell’evento elementare (2, 1). La probabilità che S sia uguale a 3 è 1/4 1/8 + 1/8 1/4 = 4/64, e così via. Svolgendo i calcoli per tutti i possibili valori di S otteniamo la funzione di massa di probabilità \\(P_1\\) riportata nella seconda riga della tabella precedente. Si noti che, a partire dalla funzione di massa di probabilità di S, è possibile calcolare la probabilità di altri eventi. Per esempio, possiamo dire che l’evento S &gt; 10 ha una probabilità minore nel caso dei dadi bilanciati, ovvero 3/36 = 1/12, rispetto al caso dei dadi truccati considerati in precedenza dove, per lo stesso evento, abbiamo una probabilità di 8/64 = 1/8. 5.8 Notazione Qui sotto è riportata la notazione che verrà usata per fare riferimento ad eventi e probabilità, nel caso discreto e continuo, in maniera tale che queste convenzioni siano elencate tutte in un posto solo. Gli eventi sono denotati da lettere maiuscole, es. \\(A\\), \\(B\\), \\(C\\). Una variabile aleatoria è denotata da una lettera maiuscola, ad esempio \\(X\\), e assume valori denotati dalla stessa lettera minuscola, ad esempio \\(x\\). La connessione tra eventi e valori viene espressa nei termini seguenti: “\\(X = x\\)” significa che l’evento \\(X\\) assume il valore \\(x\\). La probabilità di un evento è denotata con \\(P(A)\\). Una variabile aleatoria discreta ha una funzione di massa di probabilità denotata con \\(p(x)\\). La relazione tra \\(P\\) e \\(p\\) è che \\(P(X=x) = p(x)\\). Conclusioni In questo capitolo abbiamo visto come si costruisce lo spazio campionario di un esperimento casuale, quali sono le proprietà di base della probabilità e come si assegnano le probabilità agli eventi definiti sopra uno spazio campionario discreto. Abbiamo anche introdotto le nozioni di “variabile aleatoria” e di “funzione di massa di probabilità.” Le procedure di analisi dei dati psicologici che discuteremo in seguito faranno un grande uso di questi concetti e della notazione qui introdotta. "],["chapter-prob-cond.html", "Capitolo 6 Probabilità condizionata 6.1 Probabilità condizionata su altri eventi 6.2 Legge della probabilità composta 6.3 L’indipendendenza stocastica Conclusioni", " Capitolo 6 Probabilità condizionata L’attribuzione di una probabilità ad un evento è sempre condizionata dalle conoscenze che abbiamo a disposizione. Per un determinato stato di conoscenze, attribuiamo ad un dato evento una certa probabilità di verificarsi; ma se il nostro stato di conoscenze cambia, allora cambierà anche la probabilità che attribuiamo all’evento in questione. Per esempio, posiamo chiederci quale sia probabilità che Mario Rossi superi l’esame di Psicometria nel primo appello del presente anno accademico. In assenza di altre informazioni, la migliore stima di tale probabilità è data dalla proporzione di studenti che hanno superato l’esame di Psicometria nel corrispondente appello dei passati anni accademici. Ma se sappiamo che Mario Rossi è particolarmente portato per le materie quantitative, ha un’ottima preparazione di base e ha studiato molto, allora la probabilità sarà sicuramente più alta. 6.1 Probabilità condizionata su altri eventi La probabilità condizionata è una componente essenziale del ragionamento scientifico dato che chiarisce come sia possibile incorporare le evidenze disponibili, in maniera logica e coerente, nella nostra conoscenza del mondo. Infatti, si può pensare che tutte le probabilità siano probabilità condizionate, anche se l’evento condizionante non è sempre esplicitamente menzionato. Consideriamo il seguente problema. Exercizio 6.1 Lo screening per la diagnosi precoce del tumore mammario si avvale di test che sono accurati al 90%, nel senso che il 90% delle donne con cancro e il 90% delle donne senza cancro saranno classificate correttamente. Supponiamo che l’1% delle donne sottoposte allo screening abbia effettivamente il cancro al seno. Ci chiediamo: qual è la probabilità che una donna scelta casualmente abbia una mammografia positiva e, se ce l’ha, qual è la probabilità che abbia davvero il cancro? Soluzione. Per risolvere questo problema, supponiamo che il test in questione venga somministrato ad un grande campione di donne, diciamo a 1000 donne. Di queste 1000 donne, 10 (ovvero, l’1%) hanno il cancro al seno. Per queste 10 donne, il test darà un risultato positivo in 9 casi (ovvero, nel 90% dei casi). Per le rimanenti 990 donne che non hanno il cancro al seno, il test darà un risultato positivo in 99 casi (se la probabilità di un vero positivo è del 90%, la probabilità di un falso positivo è del 10%). Questa situazione è rappresentata nella figura 6.1. Mettendo insieme questi due risultati, vediamo che il test dà un risultato positivo per 9 donne che hanno effettivamente il cancro al seno e per 99 donne che non ce l’hanno, per un totale di 108 risultati positivi. Dunque, la probabilità di ottenere un risultato positivo al test è \\(\\frac{108}{1000}\\) = 11%. Ma delle 108 donne che hanno ottenuto un risultato positivo al test, solo 9 hanno il cancro al seno. Dunque, la probabilità di avere il cancro, dato un risultato positivo al test, è pari a \\(\\frac{9}{108}\\) = 8%. Figura 6.1: Rappresentazione ad albero che riporta le frequenze attese dei risultati di una mammografia in un campione di 1,000 donne Nell’esercizio 6.1 la probabilità dell’evento “ottenere un risultato positivo al test” è una probabilità non condizionata, mentre la probabilità dell’evento “avere il cancro al seno, dato che il test ha dato un risultato positivo” è una probabilità condizionata. In termini generali, la probabilità condizionata \\(P(A \\mid B)\\) rappresenta la probabilità che si verifichi l’evento \\(A\\) sapendo che si è verificato l’evento \\(B\\); oppure: la probabilità di \\(A\\) in una prova valida solo se si verifica anche \\(B\\). Ciò ci conduce alla seguente definizione. Definizione 6.1 (Probabilità condizionata) Dato un qualsiasi evento \\(A\\), si chiama probabilità condizionata di \\(A\\) dato \\(B\\) il numero \\[\\begin{equation} P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}, \\quad \\text{con}\\, P(B) &gt; 0, \\tag{6.1} \\end{equation}\\] dove \\(P(A\\cap B)\\) è la probabilità congiunta dei due eventi, ovvero la probabilità che si verifichino entrambi. In alcuni casi può essere conveniente leggere al contrario la formula 6.1 e utilizzarla per calcolare la probabilità dell’intersezione di due eventi. Per esempio se conosciamo la probabilità dell’evento \\(B\\) e la probabilità condizionata di \\(A\\) su \\(B\\), otteniamo \\[\\begin{equation} P(A \\cap B) = P(B)P(A \\mid B), \\tag{6.2} \\end{equation}\\] mentre se conosciamo la probabilità dell’evento \\(A\\) e la probabilità condizionata di \\(B\\) su \\(A\\), otteniamo \\(P(A \\cap B) = P(A)P(B \\mid A)\\). Exercizio 6.2 Da un mazzo di 52 carte (13 carte per ciascuno dei 4 semi) ne viene estratta 1 in modo casuale. Qual è la probabilità che esca una figura di cuori? Sapendo che la carta estratta ha il seme di cuori, qual è la probabilità che il valore numerico della carta sia 7, 8 o 9? Soluzione. Ci sono 13 carte di cuori, dunque la risposta alla prima domanda è 1/4. Per rispondere alla seconda domanda consideriamo solo le 13 carte di cuori; la probabilità cercata è dunque 3/13. 6.1.1 La fallacia del pubblico ministero Un errore comune che si commette è quello di credere che \\(P(A \\mid B)\\) sia uguale a \\(P(B \\mid A)\\). Tale fallacia ha particolare risalto in ambito forense tanto che è conosciuta con il nome di “fallacia del procuratore” (prosecutor’s fallacy). In essa, una piccola probabilità dell’evidenza, data l’innocenza, viene erroneamente interpretata come la probabilità dell’innocenza, data l’evidenza. Consideriamo il caso di un esame del DNA. Un esperto forense potrebbe affermare, ad esempio, che “se l’imputato è innocente, c’è solo una possibilità su un miliardo che vi sia una corrispondenza tra il suo DNA e il DNA trovato sulla scena del crimine.” Ma talvolta questa probabilità è erroneamente interpretata come avesse il seguente significato: “date le prove del DNA, c’è solo una possibilità su un miliardo che l’imputato sia innocente.” Le considerazioni precedenti risultano più chiare se facciamo nuovamente riferimento all’esercizio 6.1. In tale esercizio abbiamo visto come la probabilità di cancro dato un risultato positivo al test sia uguale a 0.08. Tale probabilità è molto diversa dalla probabilità di un risultato positivo al test data la presenza del cancro. Infatti, questa seconda probabilità è uguale a 0.90 ed è descritta nel problema come una delle caratteristiche del test in questione. 6.2 Legge della probabilità composta Il teorema della probabilità composta deriva dal concetto di probabilità condizionata per cui la probabilità che si verifichino due eventi \\(A_i\\) e \\(A_j\\) è pari alla probabilità di uno dei due eventi moltiplicato con la probabilità dell’altro evento condizionato al verificarsi del primo. L’equazione (6.2) si estende al caso di \\(n\\) eventi \\(A_1, \\dots, A_n\\) nella forma seguente: \\[\\begin{equation} \\begin{split} P(A_1 \\cap A_2 \\cap \\dots\\cap A_n) = {}&amp; P(A_1)P(A_2 \\mid A_1)P(A_3 \\mid A_1 \\cap A_2) \\dots\\\\ &amp; P(A_n \\mid A_1 \\cap A_2 \\cap \\dots \\cap A_{n-1}) \\end{split} \\tag{5.1} \\end{equation}\\] la quale esprime in forma generale la legge della probabilità composta. Exercizio 6.3 Da un’urna contenente 6 palline bianche e 4 nere si estrae una pallina per volta, senza reintrodurla nell’urna. Indichiamo con \\(B_i\\) l’evento: “esce una pallina bianca alla \\(i\\)-esima estrazione” e con \\(N_i\\) l’estrazione di una pallina nera. L’evento: “escono due palline bianche nelle prime due estrazioni” è rappresentato dalla intersezione \\(\\{B_1 \\cap B_2\\}\\) e la sua probabilità vale, per la (6.2) \\[ P(B_1 \\cap B_2) = P(B_1)P(B_2 \\mid B_1). \\] \\(P(B_1)\\) vale 6/10, perché nella prima estrazione \\(\\Omega\\) è costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilità condizionata \\(P(B_2 \\mid B_1)\\) vale 5/9, perché nella seconda estrazione, se è verificato l’evento \\(B_1\\), lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava pertanto: \\[ P(B_1 \\cap B_2) = \\frac{6}{10} \\cdot \\frac{5}{9} = \\frac{1}{3}. \\] In modo analogo si ha che \\[ P(N_1 \\cap N_2) = P(N_1)P(N_2 \\mid N_1) = \\frac{4}{10} \\cdot \\frac{3}{9} = \\frac{4}{30}. \\] Se l’esperimento consiste nell’estrazione successiva di 3 palline, la probabilità che queste siano tutte bianche vale, per la (5.1): \\[ P(B_1 \\cap B_2 \\cap B_3)=P(B_1)P(B_2 \\mid B_1)P(B_3 \\mid B_1 \\cap B_2), \\] dove la probabilità \\(P(B_3 \\mid B_1 \\cap B_2)\\) si calcola supponendo che si sia verificato l’evento condizionante \\(\\{B_1 \\cap B_2\\}\\). Lo spazio campionario per questa probabilità condizionata è costituito da 4 palline bianche e 4 nere, per cui \\(P(B_3 \\mid B_1 \\cap B_2) = 1/2\\) e quindi: \\[ P (B_1 \\cap B_2 \\cap B_3) = \\frac{6}{10}\\cdot\\frac{5}{9} \\cdot\\frac{4}{8} = \\frac{1}{6}. \\] La probabilità dell’estrazione di tre palline nere è invece: \\[ \\begin{aligned} P(N_1 \\cap N_2 \\cap N_3) &amp;= P(N_1)P(N_2 \\mid N_1)P(N_3 \\mid N_1 \\cap N_2)\\notag\\\\ &amp;= \\frac{4}{10} \\cdot \\frac{3}{9} \\cdot \\frac{2}{8} = \\frac{1}{30}.\\notag \\end{aligned} \\] 6.3 L’indipendendenza stocastica Un concetto molto importante per le applicazioni statistiche della probabilità è quello dell’indipendenza stocastica. La definizione (6.1) esprime il concetto intuitivo di indipendenza di un evento da un altro, nel senso che il verificarsi di \\(A\\) non influisce sulla probabilità del verificarsi di \\(B\\), ovvero non la condiziona. Infatti, per la definizione (6.1) di probabilità condizionata, si ha che, se \\(A\\) e \\(B\\) sono due eventi indipendenti, risulta: \\[ P(A \\mid B) = \\frac{P(A)P(B)}{P(B)} = P(A).\\notag \\] Possiamo dunque dire che due eventi \\(A\\) e \\(B\\) sono indipendenti se \\[ \\begin{split} P(A \\mid B) &amp;= P(A), \\\\ P(B \\mid A) &amp;= P(B). \\end{split} \\] Exercizio 6.4 Nel lancio di due dadi non truccati, si considerino gli eventi: A = {esce un 1 o un 2 nel primo lancio} e B = {il punteggio totale è 8}. Gli eventi A e B sono indipendenti? Soluzione. Rappresentiamo qui sotto lo spazio campionario dell’esperimento casuale. Figura 6.2: Rappresentazione dello spazio campionario dei risultati dell’esperimento casuale corrispondente al lancio di due dadi bilanciati. Sono evidenziati gli eventi elementari che costituiscono l’evento A: esce un 1 o un 2 nel primo lancio. Gli eventi A e B non sono statisticamente indipendenti. Infatti, le loro probabilità valgono P(A) = 12/36 e P(B) = 5/36 e la probabilità della loro intersezione è \\[ P(A \\cap B) = 1/36 = 3/108 \\neq P(A)P(B) = 5/108. \\] Osservazione. Si noti che il concetto di indipendenza è del tutto differente da quello di incompatibilità. Due eventi A e B incompatibili (per i quali si ha \\(A \\cap B = \\emptyset\\)) sono statisticamente dipendenti, poiché il verificarsi dell’uno esclude il verificarsi dell’altro: \\(P(A \\cap B)=0 \\neq P(A)P(B)\\). Osservazione. Se due eventi con probabilità non nulla sono statisticamente indipendenti, la legge delle probabilità totali espressa dalla (5.2) si modifica nella relazione seguente: \\[\\begin{equation} P(A \\cup B) = P(A) + P(B) - P(A)P(B). \\end{equation}\\] Conclusioni La probabilità condizionata è importante perché ci fornisce uno strumento per precisare il concetto di indipendenza statistica. Una delle più importanti domande delle analisi statistiche è infatti quella che si chiede se due variabili siano o meno associate. In questo capitolo abbiamo discusso il concetto di indipendenza (come contrapposto al concetto di associazione); nel capitolo 4 abbiamo descritto poi uno dei modi possibili che ci consentono di quantificare l’associazione tra due variabili. In seguito vedremo come sia possibile fare inferenza sull’associazione tra variabili – ovvero, come stabilire il livello di fiducia nel verificarsi dell’evento esaminato nel campione in un contesto più ampio, cioè quello della popolazione. "],["chapter-bayes-theo.html", "Capitolo 7 Il teorema di Bayes 7.1 Il teorema della probabilità totale 7.2 Il teorema della probabilità delle cause Conclusioni", " Capitolo 7 Il teorema di Bayes Il teorema di Bayes ha un ruolo centrale nella statistica Bayesiana, anche se viene utilizzato anche dall’approccio frequentista. Prima di esaminare il teorema di Bayes introdurremo una sua componente, ovvero il teorema della probabilità totale. 7.1 Il teorema della probabilità totale Il teorema della probabilità totale fa uso della legge della probabilità composta (5.1) per calcolare le probabilità di casi più complessi di quelli considerati fino ad ora. La notazione sembra complessa, ma l’idea sottostante è semplice. Discutiamo qui il teorema della probabilità totale considerando il caso di una partizione dello spazio campionario in tre sottoinsiemi. È facile estendere tale situazione al caso di una partizione in un qualunque numero di sottoinsiemi. Teorema 7.1 Sia \\(\\{A_1, A_2, A_3\\}\\) una partizione dello spazio campionario \\(\\Omega\\). Se \\(E\\) è un qualunque altro evento, allora: \\[\\begin{equation} P(E) = P(E \\cap A_1) + P(E \\cap A_2) + P(E \\cap A_3) \\notag \\tag{7.1} \\end{equation}\\] ovvero \\[\\begin{equation} P(E) = P(E \\mid A_1) P(A_1) + P (E \\mid A_2) P(A_2) + P(E \\mid A_3) P(A_3). \\tag{7.2} \\end{equation}\\] Il teorema della probabilità totale afferma che, se l’evento \\(E\\) è costituito da tutti gli eventi elementari in \\(E \\cap A_1\\), \\(E \\cap A_2\\) e \\(E \\cap A_3\\), allora la probabilità \\(P(E)\\) è data dalla somma delle probabilità di queti tre eventi. Ciò è illustrato nella figura seguente. Exercizio 7.1 Si considerino tre urne, ciascuna delle quali contiene 100 palline: Urna 1: 75 palline rosse e 25 palline blu, Urna 2: 60 palline rosse e 40 palline blu, Urna 3: 45 palline rosse e 55 palline blu. Una pallina viene estratta a caso da un’urna anch’essa scelta a caso. Qual è la probabilità che la pallina estratta sia di colore rosso? Soluzione. Sia \\(R\\) l’evento “la pallina estratta è rossa” e sia \\(U_i\\) l’evento che corrisponde alla scelta dell’\\(i\\)-esima urna. Sappiamo che \\[ P(R \\mid U_1) = 0.75, \\qquad P(R \\mid U_2) = 0.60, \\qquad P(R \\mid U_3) = 0.45. \\] Gli eventi \\(U_1\\), \\(U_2\\) e \\(U_3\\) costituiscono una partizione dello spazio campionario in quanto \\(U_1\\), \\(U_2\\) e \\(U_3\\) sono eventi mutualmente esclusivi ed esaustivi, \\(P(U_1 \\cup U_2 \\cup U_3) = 1.0\\). In base al teorema della probabilità totale, la probabilità di estrarre una pallina rossa è \\[ \\begin{aligned} P(R) &amp;= P(R \\mid U_1)P(U_1)+P(R \\mid U_2)P(U_2)+P(R \\mid U_3)P(U_3)\\notag\\\\ &amp;= 0.75 \\cdot \\frac{1}{3}+0.60 \\cdot \\frac{1}{3}+0.45 \\cdot \\frac{1}{3} =0.60.\\notag \\end{aligned} \\] Exercizio 7.2 Consideriamo un’urna che contiene 5 palline rosse e 2 palline verdi. Due palline vengono estratte, una dopo l’altra. Vogliamo sapere la probabilità dell’evento “la seconda pallina estratta è rossa.” Soluzione. Lo spazio campionario è \\(\\Omega = \\{RR, RV, VR, VV\\}\\). Chiamiamo \\(R_1\\) l’evento “la prima pallina estratta è rossa,” \\(V_1\\) l’evento “la prima pallina estratta è verde,” \\(R_2\\) l’evento “la seconda pallina estratta è rossa” e \\(V_2\\) l’evento “la seconda pallina estratta è verde.” Dobbiamo trovare \\(P(R_2)\\) e possiamo risolvere il problema usando il teorema della probabilità totale (7.2): \\[\\begin{equation} \\begin{aligned} P(R_2) &amp;= P(R_2 \\mid R_1) P(R_1) + P(R_2 \\mid V_1)P(V_1)\\notag\\\\ &amp;= \\frac{4}{6} \\cdot \\frac{5}{7} + \\frac{5}{6} \\cdot \\frac{2}{7} = \\frac{30}{42} = \\frac{5}{7}.\\notag \\end{aligned} \\end{equation}\\] Se la prima estrazione è quella di una pallina rossa, nell’urna restano 4 palline rosse e due verdi, dunque, la probabilità che la seconda estrazione produca una pallina rossa è uguale a 4/6. La probabilità di una pallina rossa nella prima estrazione è 5/7. Se la prima estrazione è quella di una pallina verde, nell’urna restano 5 palline rosse e una pallina verde, dunque, la probabilità che la seconda estrazione produca una pallina rossa è uguale a 5/6. La probabilità di una pallina verde nella prima estrazione è 2/7. 7.2 Il teorema della probabilità delle cause Il teorema di Bayes rappresenta uno dei fondamenti della teoria della probabilità e della statistica. Lo presentiamo qui considerando prima un caso specifico per poi descriverlo nella sua forma più generale. Sia \\(\\{A_1, A_2\\}\\) una partizione dello spazio campionario \\(\\Omega\\). Consideriamo un terzo evento \\(E \\subset \\Omega\\) con probabilità non nulla di cui si conoscono le probabilità condizionate rispetto ad \\(A_1\\) e a \\(A_2\\), ovvero \\(P(E \\mid A_1)\\) e \\(P(E \\mid A_2)\\). È chiaro per le ipotesi fatte che se si verifica \\(E\\) deve anche essersi verificato almeno uno degli eventi \\(A_1\\) e \\(A_2\\). Supponendo che si sia verificato l’evento \\(E\\), ci chiediamo: qual è la probabilità che si sia verificato \\(A_1\\) piuttosto che \\(A_2\\)? Per rispondere alla domanda precedente scriviamo: \\[\\begin{equation} \\begin{aligned} P(A_1 \\mid E) &amp;= \\frac{P(E \\cap A_1)}{P(E)}\\notag\\\\ &amp;= \\frac{P(E \\mid A_1)P(A_1)}{P(E)}\\notag.\\end{aligned} \\end{equation}\\] Sapendo che \\(E = (E \\cap A_1) \\cup (E \\cap A_2)\\) e che \\(A_1\\) e \\(A_2\\) sono eventi disgiunti, ovvero \\(A_1 \\cap A_2 = \\emptyset\\), ne segue che possiamo calcolare \\(P(E)\\) utilizzando il teorema della probabilità totale: \\[\\begin{equation} \\begin{aligned} P(E) &amp;= P(E \\cap A_1) + P(E \\cap A_2)\\notag\\\\ &amp;= P(E \\mid A_1)P(A_1) + P(E \\mid A_2)P(A_2).\\notag \\end{aligned} \\end{equation}\\] Sostituendo il risultato precedente nella formula della probabilità condizionata \\(P(A_1 \\mid E)\\) otteniamo: \\[\\begin{equation} P(A_1 \\mid E) = \\frac{P(E \\mid A_1)P(A_1)}{P(E \\mid A_1)P(A_1) + P(E \\mid A_2)P(A_2)}. \\tag{7.3} \\end{equation}\\] La (7.3) si generalizza facilmente al caso di più di due eventi disgiunti, come indicato di seguito. Teorema 7.2 (Teorema di Bayes) Siano \\(A_1\\), \\(A_2,\\) …, \\(A_n\\) \\(n\\) eventi disgiunti con \\(P(A_i) &gt; 0\\) e tali che \\(\\bigcup_{i=1}^{n} A_i = \\Omega\\). Per l’evento \\(E \\subset \\Omega\\) con \\(P(E) &gt; 0\\), abbiamo \\[\\begin{equation} P(A_j \\mid E) = \\frac{P(E \\mid A_j)P(A_j)}{\\sum_{i=1}^{n}P(E \\mid A_i)P(A_i)}. \\tag{7.4} \\end{equation}\\] La formula (7.4) prende il nome di Teorema di Bayes e mostra che la conoscenza del verificarsi dell’evento \\(E\\) modifica la probabilità che abbiamo attribuito all’evento \\(A_j\\). 7.2.1 Aggiornamento Bayesiano Consideriamo ora un’altra applicazione del teorema di Bayes che ci fa capire come l’applicazione di questo teorema ci consente di modificare una credenza a priori in maniera dinamica, via via che nuove evidenze vengono raccolta, in modo tale da formulare una credenza a posteriori la quale non è mai definitiva, ma può essere sempre aggiornata in base alle nuove evidenze disponibili. Questo processo si chiama aggiornamento Bayesiano. Supponiamo che, per qualche strano errore di produzione, una fabbrica produca due tipi di monete. Il primo tipo di monete ha la caratteristica che, quando una moneta viene lanciata, la probabilità di osservare l’esito “testa” è 0.6. Per semplicità, sia \\(\\theta\\) la probabilità di osservare l’esito “testa.” Per una moneta del primo tipo, dunque, \\(\\theta = 0.6\\). Per una moneta del secondo tipo, invece, la probabilità di produrre l’esito “testa” è 0.4. Ovvero, \\(\\theta = 0.4\\). Noi possediamo una moneta, ma non sappiamo se è del primo tipo o del secondo tipo. Sappiamo solo che il 75% delle monete sono del primo tipo e il 25% sono del secondo tipo. Sulla base di questa conoscenza a priori – ovvero sulla base di una conoscenza ottenuta senza avere eseguito l’esperimento che consiste nel lanciare la moneta una serie di volte per osservare gli esiti prodotti – possiamo dire che la probabilità di una prima ipotesi, secondo la quale \\(\\theta = 0.6\\), è 3 volte più grande della probabilità di una seconda ipotesi, secondo la quale \\(\\theta = 0.4\\). Senza avere eseguito alcun esperimento casuale con la moneta, questo è quello che sappiamo. Ora immaginiamo di lanciare una moneta due volte e di ottenere il risultato seguente: \\(\\{T, C\\}\\). Quello che ci chiediamo è: sulla base di questa evidenza, come cambiano le probabilità che associamo alle due ipotesi? In altre parole, ci chiediamo qual è la probabilità di ciascuna ipotesi alla luce dei dati che sono stati osservati: \\(P(H \\mid x)\\), laddove \\(x\\) sono i dati osservati. Tale probabilità si chiama probabilità a posteriori. Inoltre, se confrontiamo le due ipotesi, ci chiediamo quale valore assuma il rapporto \\(\\frac{P(H_1 \\mid x)}{P(H_2 \\mid x)}\\). Tale rapporto ci dice quanto è più probabile \\(H_1\\) rispetto ad \\(H_2\\), alla luce dei dati osservati. Infine, ci chiediamo come cambia il rapporto definito sopra, quando osserviamo via via nuovi risultati prodotti dal lancio della moneta. Definiamo il problema in maniera più chiara. Conosciamo le probabilità a priori, ovvero \\(P(H_1) = 0.75\\) e \\(P(H_1) = 0.25\\). Quello che vogliamo conoscere sono le probabilità a posteriori \\(P(H_1 \\mid x)\\) e \\(P(H_2 \\mid x)\\). Per trovare le probabilità a posteriori applichiamo il teorema di Bayes: \\[P(H_1 \\mid x) = \\frac{P(x \\mid H_1) P(H_1)}{P(x)} = \\frac{P(x \\mid H_1) P(H_1)}{P(x \\mid H_1) P(H_1) + P(x \\mid H_2) P(H_2)},\\] laddove lo sviluppo del denominatore deriva da un’applicazione del teorema della probabilità totale. Inoltre, \\[P(H_2 \\mid x) = \\frac{P(x \\mid H_2) P(H_2)}{P(x \\mid H_1) P(H_1) + P(x \\mid H_2) P(H_2)}.\\] La probabilità \\(P(x \\mid H_1)\\) si chiama verosimiglianza e descrive la plausibilità dei dati osservati in base all’ipotesi considerata. Se consideriamo l’ipotesi \\(H_1\\) = “la probabilità di testa è 0.6,” allora la verosimiglianza dei dati \\(\\{T, C\\}\\) è \\(0.6 \\times 0.4 = 0.24.\\) Dunque, \\(P(x \\mid H_1) = 0.24\\). Se invece consideriamo l’ipotesi \\(H_2\\) = “la probabilità di testa è 0.4,” allora la verosimiglianza dei dati \\(\\{T, C\\}\\) è \\(0.4 \\times 0.6 = 0.24\\), ovvero, \\(P(x \\mid H_2) = 0.24\\). In base alle due ipotesi \\(H_1\\) e \\(H_2\\), dunque, i dati osservati hanno la medesima plausibilità. Per semplicità, calcoliamo anche \\[\\begin{aligned} P(x) &amp;= P(x \\mid H_1) P(H_1) + P(x \\mid H_2) P(H_2) = 0.24 \\cdot 0.75 + 0.24 \\cdot 0.25 = 0.24.\\notag\\end{aligned}\\] Le probabilità a posteriori diventano: \\[\\begin{aligned} P(H_1 \\mid x) &amp;= \\frac{P(x \\mid H_1) P(H_1)}{P(x)} = \\frac{0.24 \\cdot 0.75}{0.24} = 0.75,\\notag\\end{aligned}\\] \\[\\begin{aligned} P(H_2 \\mid x) &amp;= \\frac{P(x \\mid H_2) P(H_2)}{P(x)} = \\frac{0.24 \\cdot 0.25}{0.24} = 0.25.\\notag\\end{aligned}\\] Possiamo dunque concludere dicendo che, sulla base dei dati osservati, l’ipotesi \\(H_1\\) ha una probabilità 3 volte maggiore di essere vera dell’ipotesi \\(H_2\\). È tuttavia possibile raccogliere più evidenze e, sulla base di esse, le probabilità a posteriori cambieranno. Supponiamo di lanciare la moneta una terza volta e di osservare croce. I nostri dati saranno dunque \\(\\{T, C, C\\}\\). Di conseguenza, \\(P(x \\mid H_1) = 0.6 \\cdot 0.4 \\cdot 0.4 = 0.096\\) e \\(P(x \\mid H_2) = 0.4 \\cdot 0.6 \\cdot 0.6 = 0.144\\). Ne segue che le probabilità a posteriori diventano: \\[\\begin{aligned} P(H_1 \\mid x) &amp;= \\frac{P(x \\mid H_1) P(H_1)}{P(x)} = \\frac{0.096 \\cdot 0.75}{0.096 \\cdot 0.75 + 0.144 \\cdot 0.25} = 0.667,\\notag\\end{aligned}\\] \\[\\begin{aligned} P(H_2 \\mid x) &amp;= \\frac{P(x \\mid H_2) P(H_2)}{P(x)} = \\frac{0.144 \\cdot 0.25}{0.096 \\cdot 0.75 + 0.144 \\cdot 0.25} = 0.333.\\notag\\end{aligned}\\] In queste circostanze, le evidenze che favoriscono \\(H_1\\) nei confronti di \\(H_2\\) sono pari solo ad un fattore di 2. Se otteniamo ancora croce in un quarto lancio della moneta, i nostri dati saranno: \\(\\{T, C, C, C\\}\\). Ripetendo il ragionamento fatto sopra, \\(P(x \\mid H_1) = 0.6 \\cdot 0.4 \\cdot 0.4 \\cdot 0.4 = 0.0384\\) e \\(P(x \\mid H_2) = 0.4 \\cdot 0.6 \\cdot 0.6 \\cdot 0.6 = 0.0864\\). Dunque \\[\\begin{aligned} P(H_1 \\mid x) &amp;= \\frac{0.0384 \\cdot 0.75}{0.0384 \\cdot 0.75 + 0.0864 \\cdot 0.25} = 0.571,\\notag\\end{aligned}\\] \\[\\begin{aligned} P(H_2 \\mid x) &amp;= \\frac{0.0864 \\cdot 0.25}{0.0384 \\cdot 0.75 + 0.0864 \\cdot 0.25} = 0.429.\\notag\\end{aligned}\\] e le evidenze a favore di \\(H_1\\) si riducono a 1.33. Se si ottenesse un altro esito croce in un sesto lancio della moneta, l’ipotesi \\(H2\\) diventerebbe più probabile dell’ipotesi \\(H_1\\). In conclusione, questo esercizio ci fa capire come sia possibile, sulla base delle evidenze disponibili, passare da credenze a priori a credenze a posteriori. Se prima di lanciare la moneta ritenevamo che l’ipotesi \\(H_1\\) fosse tre volte più plausibile dell’ipotesi \\(H_2\\), dopo avere osservato uno specifico campione di dati siamo giunti alla conclusione opposta. Il processo di aggiornamento Bayesiano ci fornisce dunque un metodo per modificare il livello di fiducia in una data ipotesi, alla luce di nuova informazione. Conclusioni Il teorema di Bayes costituisce il fondamento dell’approccio più moderno della statistica, quello appunto detto Bayesiano. Chi usa il teorema di Bayes non è, solo per questo motivo, “bayesiano.” Ci vuole ben altro. Ci vuole un modo diverso per intendere il significato della probabilità e un modo diverso per intendere gli obiettivi dell’inferenza statistica. L’approccio bayesiano è stato, negli scorsi decenni, un approccio piuttosto dogmatico a questi temi e, a causa di ciò, è stato considerato da alcuni come un metodo un po’ troppo lontano dall’atteggiamento critico e non dogmatico che costituisce il fondamento della comunità scientifica. In anni recenti, questi aspetti più “ruvidi” dell’approccio bayesiano sono stati abbandonati e una gran parte della comunità scientifica riconosce all’approccio bayesiano il merito di consentire lo sviluppo di modelli anche molto complessi senza, d’altra parte, richiedere conoscenze matematiche troppo avanzate all’utente. Per questa ragione l’approccio bayesiano sta prendendo sempre più piede, anche in psicologia. Un introduzione a questi temi sarà presentata nell’ultima parte di queste dispense. "],["bibliografia.html", "Bibliografia", " Bibliografia Cesario, J., Johnson, D. J., &amp; Terrill, W. (2019). Is there evidence of racial disparity in police use of deadly force? Analyses of officer-involved fatal shootings in 2015–2016. Social Psychological and Personality Science, 10(5), 586–595. Ross, C. T., Winterhalder, B., &amp; McElreath, R. (2020). Racial disparities in police use of deadly force against unarmed individuals persist after appropriately benchmarking shooting data on violent crime rates. Social Psychological and Personality Science, 1–10. Stevens, S. S. (1946). On the theory of scales of measurement. Science, 103(2684), 677–680. Tufte, E. R. (2001). The visual display of quantitative information. Graphics press Cheshire, CT. Zetsche, U., Bürkner, P.-C., &amp; Renneberg, B. (2019). Future expectations in clinical depression: Biased or realistic? Journal of Abnormal Psychology, 128(7), 678–688. "]]
