<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capitolo 2 {r twinmono1, echo=FALSE, fig.cap="Quoziente di intelligenza del secondo nato in funzione del quoziente di intelligenza del primo nato.", out.width = '100%'} # knitr::include_graphics("images/fig_anderson_finn_1996.pdf") # | PSICOMETRIA</title>
  <meta name="description" content="Queste dispense si propongono di fornire un’introduzione all’analisi dei dati psicologici agli studenti del primo anno del Corso di Laurea in Scienze e Tecniche Psicologiche. Particolare attenzione sarà posta ai seguenti aspetti: l’uso del linguaggio R per lo svolgimento delle analisi statistiche, la rappresentazione grafica dei dati e l’inferenza Bayesiana." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Capitolo 2 {r twinmono1, echo=FALSE, fig.cap="Quoziente di intelligenza del secondo nato in funzione del quoziente di intelligenza del primo nato.", out.width = '100%'} # knitr::include_graphics("images/fig_anderson_finn_1996.pdf") # | PSICOMETRIA" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Queste dispense si propongono di fornire un’introduzione all’analisi dei dati psicologici agli studenti del primo anno del Corso di Laurea in Scienze e Tecniche Psicologiche. Particolare attenzione sarà posta ai seguenti aspetti: l’uso del linguaggio R per lo svolgimento delle analisi statistiche, la rappresentazione grafica dei dati e l’inferenza Bayesiana." />
  <meta name="github-repo" content="ccaudek/bookdown_psicometria" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capitolo 2 {r twinmono1, echo=FALSE, fig.cap="Quoziente di intelligenza del secondo nato in funzione del quoziente di intelligenza del primo nato.", out.width = '100%'} # knitr::include_graphics("images/fig_anderson_finn_1996.pdf") # | PSICOMETRIA" />
  <meta name="twitter:site" content="@ccaudek" />
  <meta name="twitter:description" content="Queste dispense si propongono di fornire un’introduzione all’analisi dei dati psicologici agli studenti del primo anno del Corso di Laurea in Scienze e Tecniche Psicologiche. Particolare attenzione sarà posta ai seguenti aspetti: l’uso del linguaggio R per lo svolgimento delle analisi statistiche, la rappresentazione grafica dei dati e l’inferenza Bayesiana." />
  

<meta name="author" content="Corrado Caudek" />


<meta name="date" content="2020-12-31" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon" />
<link rel="prev" href="chapter-reglin.html"/>
<link rel="next" href="bibliografia.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A.A. 2020/2021</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefazione</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#perché-tanta-statistica-in-psicologia"><i class="fa fa-check"></i>Perché tanta statistica in psicologia?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#come-studiare"><i class="fa fa-check"></i>Come studiare?</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="chapter-reglin.html"><a href="chapter-reglin.html"><i class="fa fa-check"></i><b>1</b> Regressione lineare semplice</a>
<ul>
<li class="chapter" data-level="" data-path="chapter-reglin.html"><a href="chapter-reglin.html#obiettivi-di-apprendimento"><i class="fa fa-check"></i>Obiettivi di apprendimento</a></li>
<li class="chapter" data-level="" data-path="chapter-reglin.html"><a href="chapter-reglin.html#motivazione"><i class="fa fa-check"></i>Motivazione</a></li>
<li class="chapter" data-level="1.1" data-path="chapter-reglin.html"><a href="chapter-reglin.html#la-funzione-lineare"><i class="fa fa-check"></i><b>1.1</b> La funzione lineare</a></li>
<li class="chapter" data-level="1.2" data-path="chapter-reglin.html"><a href="chapter-reglin.html#lerrore-di-misurazione"><i class="fa fa-check"></i><b>1.2</b> L’errore di misurazione</a></li>
<li class="chapter" data-level="1.3" data-path="chapter-reglin.html"><a href="chapter-reglin.html#scopi-della-regressione-lineare"><i class="fa fa-check"></i><b>1.3</b> Scopi della regressione lineare</a></li>
<li class="chapter" data-level="1.4" data-path="chapter-reglin.html"><a href="chapter-reglin.html#quantificare-lassociazione-fra-due-caratteri-quantitativi"><i class="fa fa-check"></i><b>1.4</b> Quantificare l’associazione fra due caratteri quantitativi</a></li>
<li class="chapter" data-level="1.5" data-path="chapter-reglin.html"><a href="chapter-reglin.html#stime-dei-minimi-quadrati"><i class="fa fa-check"></i><b>1.5</b> Stime dei minimi quadrati</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="chapter-reglin.html"><a href="chapter-reglin.html#monotwinsiq"><i class="fa fa-check"></i><b>1.5.1</b> Un esempio concreto</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html"><i class="fa fa-check"></i><b>2</b> <code>{r twinmono1, echo=FALSE, fig.cap="Quoziente di intelligenza del secondo nato in funzione del quoziente di intelligenza del primo nato.", out.width = '100%'} # knitr::include_graphics("images/fig_anderson_finn_1996.pdf") #</code></a>
<ul>
<li class="chapter" data-level="2.0.1" data-path="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#sec:beta_r"><i class="fa fa-check"></i><b>2.0.1</b> Coefficiente angolare e correlazione di Pearson</a></li>
<li class="chapter" data-level="2.0.2" data-path="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#regressione-verso-la-media"><i class="fa fa-check"></i><b>2.0.2</b> Regressione verso la media</a></li>
<li class="chapter" data-level="2.0.3" data-path="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#punti-influenti-e-valori-anomali"><i class="fa fa-check"></i><b>2.0.3</b> Punti influenti e valori anomali</a></li>
<li class="chapter" data-level="2.1" data-path="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#bontà-delladattamento"><i class="fa fa-check"></i><b>2.1</b> Bontà dell’adattamento</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#errore-standard-della-stima."><i class="fa fa-check"></i><b>2.1.1</b> Errore standard della stima.</a></li>
<li class="chapter" data-level="2.1.2" data-path="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#indice-di-determinazione."><i class="fa fa-check"></i><b>2.1.2</b> Indice di determinazione.</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#inferenza-sullassociazione-tra-x-e-y-nella-popolazione"><i class="fa fa-check"></i><b>2.2</b> Inferenza sull’associazione tra <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> nella popolazione</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#modello-statistico-di-regressione-lineare"><i class="fa fa-check"></i><b>2.2.1</b> Modello statistico di regressione lineare</a></li>
<li class="chapter" data-level="2.2.2" data-path="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#i-test-diagnostici-sulla-regressione-lineare"><i class="fa fa-check"></i><b>2.2.2</b> I test diagnostici sulla regressione lineare</a></li>
<li class="chapter" data-level="2.2.3" data-path="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#proprietà-degli-stimatori-dei-minimi-quadrati"><i class="fa fa-check"></i><b>2.2.3</b> Proprietà degli stimatori dei minimi quadrati</a></li>
<li class="chapter" data-level="2.2.4" data-path="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#ipotesi-statistiche-e-statistica-test"><i class="fa fa-check"></i><b>2.2.4</b> Ipotesi statistiche e statistica test</a></li>
<li class="chapter" data-level="2.2.5" data-path="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#riportare-i-risultati"><i class="fa fa-check"></i><b>2.2.5</b> Riportare i risultati</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#considerazioni-conclusive"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliografia.html"><a href="bibliografia.html"><i class="fa fa-check"></i>Bibliografia</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">PSICOMETRIA</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="r-twinmono1-echofalse-fig.capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato.-out.width-100-knitrinclude_graphicsimagesfig_anderson_finn_1996.pdf" class="section level1" number="2">
<h1><span class="header-section-number">Capitolo 2</span> <code>{r twinmono1, echo=FALSE, fig.cap="Quoziente di intelligenza del secondo nato in funzione del quoziente di intelligenza del primo nato.", out.width = '100%'} # knitr::include_graphics("images/fig_anderson_finn_1996.pdf") #</code></h1>
<p>I coefficienti di regressione si trovano con le formule dei minimi quadrati. Usando R, per <span class="math inline">\(b\)</span> otteniamo</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#cb3-1" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fu">cov</span>(df<span class="sc">$</span>iq1, df<span class="sc">$</span>iq2) <span class="sc">/</span> <span class="fu">var</span>(df<span class="sc">$</span>iq1) </span>
<span id="cb3-2"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#cb3-2" aria-hidden="true" tabindex="-1"></a>b</span>
<span id="cb3-3"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.8498545</span></span></code></pre></div>
<p>e per <span class="math inline">\(a\)</span> otteniamo</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#cb4-1" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fu">mean</span>(df<span class="sc">$</span>iq2) <span class="sc">-</span> b <span class="sc">*</span> <span class="fu">mean</span>(df<span class="sc">$</span>iq1)</span>
<span id="cb4-2"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#cb4-2" aria-hidden="true" tabindex="-1"></a>a</span>
<span id="cb4-3"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 1.838871</span></span></code></pre></div>
<p>Tali risultati corrispondono ai valori trovati dalla funzione <code>lm()</code> con la seguente sintassi:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#cb5-1" aria-hidden="true" tabindex="-1"></a>fm <span class="ot">&lt;-</span> <span class="fu">lm</span>(iq2 <span class="sc">~</span> iq1, <span class="at">data =</span> df)</span></code></pre></div>
<p>L’oggetto creato da <code>{lm()</code> può essere visionato utilizzando <code>coef(fm)</code> o con <code>summary(fm)</code>.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fm)</span>
<span id="cb6-2"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb6-3"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb6-4"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; lm(formula = iq2 ~ iq1, data = df)</span></span>
<span id="cb6-5"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb6-6"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Residuals:</span></span>
<span id="cb6-7"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></span>
<span id="cb6-8"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; -11.0342  -3.8218  -0.5852   3.4658  12.5635 </span></span>
<span id="cb6-9"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb6-10"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb6-11"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb6-12"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (Intercept)   1.8389     3.0269   0.608    0.548    </span></span>
<span id="cb6-13"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; iq1           0.8499     0.1155   7.357 2.29e-08 ***</span></span>
<span id="cb6-14"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb6-15"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb6-16"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb6-17"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 6.102 on 32 degrees of freedom</span></span>
<span id="cb6-18"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Multiple R-squared:  0.6285, Adjusted R-squared:  0.6169 </span></span>
<span id="cb6-19"><a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; F-statistic: 54.13 on 1 and 32 DF,  p-value: 2.288e-08</span></span></code></pre></div>
<p>I valori predetti dal modello di regressione sono dati da</p>
<pre><code>yhat &lt;- a + b * df$iq1</code></pre>
<p>o, in maniera equivalente, possono essere trovati con <code>predict(fm)</code>. I
residui di regressione, ovvero la differenza tra il valore osservato e
il valore predetto dal modello, si trovano mediante l’istruzione</p>
<pre><code>e &lt;- df$iq2 - yhat </code></pre>
<p>o, in maniera equivalente, con <code>residuals(fm)</code>, e possono essere
rappresentanti graficamente come riportato nella
Figura <a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#fig:reg_twins_2" reference-type="ref" reference="fig:reg_twins_2">1.2</a>.</p>
<div class="figure">
<img src="fig_anderson_finn_1996_2" id="fig:reg_twins_2" alt="" />
<p class="caption">Residui del modello di regressione che esprime il quoziente di
intelligenza del secondo nato in funzione del quoziente di intelligenza
del primo nato.</p>
</div>
<div id="sec:beta_r" class="section level3" number="2.0.1">
<h3><span class="header-section-number">2.0.1</span> Coefficiente angolare e correlazione di Pearson</h3>
<p>Ricordando che <span class="math inline">\(r_{xy}=s_{xy} / (s_x s_y)\)</span> è il coefficiente di
correlazione lineare e che <span class="math inline">\(b=s_{xy} /s_x^2\)</span> è la stima dei minimi
quadrati del coefficiente angolare della retta di regressione,
sostituendo <span class="math inline">\(r_{xy}s_xs_y\)</span> al numeratore dell’equazione di <span class="math inline">\(b\)</span> e
semplificando, si ottiene <span class="math display">\[b = r_{yx}\frac{s_y}{s_x}.\]</span> Se i dati
vengono standardizzati, dunque, l’equazione della retta di regressione
campionaria diventa <span class="math display">\[z_{y_i} = r_{xy} z_{x_i} + e_i,\]</span> in quanto
<span class="math inline">\(a = \bar{z}_y - b\bar{z}_x =0\)</span> e <span class="math inline">\(s_x = s_y = 1\)</span>. Si può dunque
assegnare al coefficiente di correlazione di Pearson la seguente
interpretazione: <span class="math inline">\(r_{xy}\)</span> è uguale alla pendenza <span class="math inline">\(b\)</span> della retta di
regressione quando le variabili <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> vengono standardizzate
(Rodgers &amp; Nicewander, 1988).</p>
<p>Calcolando i coefficienti di regressione sui punteggi standardizzati del
quoziente di intelligenza dei gemelli monozigoti
dell’esempio <a href="#exmp:mono_twins" reference-type="ref" reference="exmp:mono_twins"><span class="math display">\[exmp:mono_twins\]</span></a></p>
<pre><code>ziq1 &lt;- scale(df$iq1)
ziq2 &lt;- scale(df$iq2)
fm1 &lt;- lm(ziq2 ~ ziq1)
coef(fm1)
#&gt;   (Intercept)         ziq1 
#&gt;  1.818206e-16 7.927594e-01 </code></pre>
<p>si nota che l’intercetta è zero e la pendenza della retta di regressione
è uguale alla correlazione tra le due variabili:
<code>with(df, cor(iq1, iq2)) = 0.7928</code>.</p>
</div>
<div id="regressione-verso-la-media" class="section level3" number="2.0.2">
<h3><span class="header-section-number">2.0.2</span> Regressione verso la media</h3>
<p>Il termine regressione fu introdotto da Francis Galton (1822-1911), un
antropologo che fu, tra le altre cose, promotore dell’eugenetica. Nel
1886, nell’ambito dei suoi studi sull’ereditarietà dei caratteri, Galton
raccolse le stature di <span class="math inline">\(928\)</span> figli adulti e dei loro <span class="math inline">\(205\)</span> genitori
(padri e madri) – i dati sono disponibili nel data.frame <code>Galton</code>
contenuto nel pacchetto R  <code>HistData</code>. Galton esaminò la relazione tra
l’altezza media dei figli e l’altezza media dei genitori, che chiamò
“mid-parent height.” In questi dati, genitori e figli hanno la stessa
altezza media di <span class="math inline">\(68.2\)</span> pollici. Galton osservò però come l’altezza
media dei figli nati da genitori di una data altezza era più simile al
valore dell’altezza media della popolazione intera di quanto lo fosse la
mid-height dei genitori. Ad esempio, per genitori con una mid-height
compresa tra <span class="math inline">\(70\)</span> e <span class="math inline">\(71\)</span> pollici, l’altezza media dei figli risultò
essere di <span class="math inline">\(69.5\)</span> pollici. Nelle parole di Galton, questo corrispondeva
ad una <em>regression toward mediocrity</em>, un concetto che noi oggi
chiamiamo “regressione verso la media.” Nonostante l’interpretazione
(errata) di Galton, è importante capire come questo sia un fenomeno
statistico, non genetico. Esaminiamo la ragione per cui ciò si verifica.</p>
<p>Nel <a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#sec:beta_r" reference-type="ref" reference="sec:beta_r">1.3.1</a>
abbiamo visto come, nel caso di dati standardizzati, la retta di
regressione campionaria diventa: <span class="math display">\[\hat{z}_{y_i} = r_{xy} z_{x_i}.\]</span> Dal
momento che <span class="math inline">\(r_{xy}\)</span> è il coefficiente di regressione, esso assume
valori compresi tra <span class="math inline">\(-1\)</span> e <span class="math inline">\(1\)</span>. Assumiamo che <span class="math inline">\(r_{xy}\)</span> sia positivo e
minore di <span class="math inline">\(1\)</span> (ovvero, assumiamo che la correlazione tra <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span> sia
positiva ma non perfetta). La formula <span class="math inline">\(\hat{z}_{y_i} = r_{xy} z_{x_i}\)</span>
implica che, se <span class="math inline">\(z_{x_i}\)</span> è positivo, allora il valore predetto
<span class="math inline">\(\hat{z}_{y_i}\)</span> deve essere minore di <span class="math inline">\(z_{x_i}\)</span>. In maniera equivalente,
si può dire che la ‘distanza’ tra il valore predetto <span class="math inline">\(\hat{y}\)</span> della
variabile di risposta e la media <span class="math inline">\(\bar{y}\)</span> tende ad essere minore della
distanza tra <span class="math inline">\(x\)</span> e <span class="math inline">\(\bar{x}\)</span>:
<span class="math display">\[\frac{\hat{y} - \bar{y}}{s_y} &lt; \frac{x - \bar{x}}{s_x}.\]</span> Il termine
‘distanza’ è stato messo tra virgolette in quanto è necessario tenere in
considerazione l’unità di misura delle variabili. Per fare questo, la
distanza tra le osservazioni e il centro della distribuzione viene
misurata solo dopo avere standardizzato le variabili – ovvero, viene
misurata in unità di deviazioni standard.</p>
</div>
<div id="punti-influenti-e-valori-anomali" class="section level3" number="2.0.3">
<h3><span class="header-section-number">2.0.3</span> Punti influenti e valori anomali</h3>
<p>La soluzione dei minimi quadrati è fortemente influenzata dalla presenza
di punti influenti che sono anche punti anomali. Un punto anomalo è
un’osservazione con un residuo elevato (ovvero, avente un valore anomalo
di <span class="math inline">\(Y\)</span> rispetto alla previsione). Un punto di leva è valore anomalo
della variabile indipendente (<span class="math inline">\(X\)</span>). Un punto influente è un’osservazione
che influenza in maniera rilevante le stime dei minimi quadrati. Non
sempre un punto anomalo è anche un punto influente. Per contro esistono
punti non anomali che influiscono notevolmente sulle stime dei minimi
quadrati (si veda la Figura <a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#fig:leverage" reference-type="ref" reference="fig:leverage">1.3</a>).</p>
<div class="figure">
<embed src="leverage_outliers.pdf" id="fig:leverage" style="width:80.0%" />
<p class="caption">Punti anomali e punti influenti.</p>
</div>
</div>
<div id="bontà-delladattamento" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Bontà dell’adattamento</h2>
<p>Il secondo obiettivo dell’analisi della regressione è quello di misurare
la bontà di adattamento del modello di regressione ai dati.</p>
<div id="errore-standard-della-stima." class="section level3" number="2.1.1">
<h3><span class="header-section-number">2.1.1</span> Errore standard della stima.</h3>
<p>Un indice assoluto della bontà di adattamento è fornito dalla deviazione
standard dei residui, <span class="math inline">\(s_e\)</span>, chiamata anche <em>errore standard della
stima</em>. Uno stimatore non distorto della varianza dei residui nella
popolazione è dato da <span class="math display">\[s^2_e = \frac{\sum e_i^2}{n-2}\]</span> e quindi
l’errore standard della stima sarà
<span class="math display">\[s_e = \sqrt{\frac{\sum e_i^2}{n-2}}.\]</span> Dato che <span class="math inline">\(s_e\)</span> è possiede la
stessa unità di misura della variabile <span class="math inline">\(y\)</span>, l’errore standard della
stima può essere considerato come una sorta di “residuo medio.”</p>
<p>Consideriamo nuovamente l’esempio dei gemelli monozigoti separati alla
nascita. L’errore standard della regressione</p>
<pre><code>sqrt(sum(e^2) / (length(e) - 2)) 
#&gt; [1] 6.102</code></pre>
<p>è simile, ma non identico, al valore medio dei residui</p>
<pre><code>mean(abs(fm$residuals)) 
#&gt; [1] 4.917</code></pre>
<p>In conclusione, se usiamo la retta di regressione per predire il
quoziente di intelligenza del gemello nato per secondo a partire dal
quoziente di intelligenza del gemello nato per primo compiamo, in media,
un errore di circa 6 punti.</p>
</div>
<div id="indice-di-determinazione." class="section level3" number="2.1.2">
<h3><span class="header-section-number">2.1.2</span> Indice di determinazione.</h3>
<p>Un importante risultato dei minimi quadrati riguarda la cosiddetta
<em>scomposizione della devianza di regressione</em> mediante la quale si
definisce l’indice di determinazione, il quale fornisce una misura
relativa della bontà di adattamento del modello di regressione ai dati
del campione. Come indicato nella
figura <a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#fig:scomposizione" reference-type="ref" reference="fig:scomposizione">1.4</a>, per una generica osservazione
<span class="math inline">\(x_i, y_i\)</span>, la variazione di <span class="math inline">\(y_i\)</span> rispetto alla media <span class="math inline">\(\bar{y}\)</span> può
essere descritta come la somma di due componenti: il residuo
<span class="math inline">\(e_i=y_i- \hat{y}_i\)</span> e lo scarto di <span class="math inline">\(\hat{y}_i\)</span> rispetto alla media
<span class="math inline">\(\bar{y}\)</span>:
<span class="math display">\[y_i - \bar{y} = (y_i- \hat{y}_i) + (\hat{y}_i - \bar{y}) = e_i + (\hat{y}_i - \bar{y}).\]</span></p>
<div class="figure">
<img src="scomposizione" id="fig:scomposizione" style="width:6cm" alt="" />
<p class="caption">Scomposizione della devianza.</p>
</div>
<p>Se consideriamo tutte le osservazioni, la devianza delle <span class="math inline">\(y\)</span> può essere
scomposta nel seguente modo: <span class="math display">\[\begin{aligned}
 \sum (y_i - \bar{y})^2 &amp;= \sum \left[ e_i + (\hat{y}_i - \bar{y})
 \right]^2 
 = \sum e_i^2 + \sum (\hat{y}_i - \bar{y})^2 + 2 \sum e_i (\hat{y}_i -
 \bar{y}) \notag\end{aligned}\]</span> Per i vincoli imposti sui residui dalle
equazioni normali, il doppio prodotto si annulla, infatti
<span class="math display">\[\begin{aligned}
\sum e_i (\hat{y}_i - \bar{y}) &amp;= \sum e_i \hat{y}_i - \bar{y}\sum e_i = \sum e_i (a + b x_i) \notag \\
&amp;= a \sum e_i + b \sum e_i x_i = 0 \notag\end{aligned}\]</span> Di conseguenza,
possiamo concludere che la devianza totale (<span class="math inline">\(\dev_T\)</span>) si scompone nella
somma della devianza di dispersione (<span class="math inline">\(dev_E\)</span>) e della devianza di
regressione (<span class="math inline">\(\dev_T\)</span>): <span class="math display">\[\begin{aligned}
\underbrace{\sum_{i=1}^n (y_i - \bar{y})^2}_{\tiny{\text{Devianza
totale}}} &amp;= \underbrace{\sum_{i=1}^n e_i^2}_{\tiny{\text{Devianza
di dispersione}}} + \underbrace{\sum_{i=1}^n  (\hat{y}_i -
\bar{y})^2}_{\tiny{\text{Devianza di regressione}}} \notag\end{aligned}\]</span>
La devianza di regressione, <span class="math inline">\(\dev_R \triangleq \dev_T - \dev_E\)</span>, indica
dunque la riduzione degli errori al quadrato che è imputabile alla
regressione lineare. Il rapporto <span class="math inline">\(\dev_T/\dev_T\)</span>, detto <em>indice di
determinazione</em>, esprime tale riduzione degli errori in termini
proporzionali e definisce il coefficiente di correlazione al quadrato:
<span class="math display">\[r^2 \triangleq \frac{\dev_R}{\dev_T} = 1 - \frac{\dev_E}{\dev_T}.\]</span>
Quando l’insieme di tutte le deviazioni della <span class="math inline">\(y\)</span> dalla media è spiegato
dall’insieme di tutte le deviazioni della variabile teorica <span class="math inline">\(\hat{y}\)</span>
dalla media, si ha che l’adattamento (o accostamento) del modello al
campione di dati è perfetto, la devianza residua è nulla ed <span class="math inline">\(r^2 = 1\)</span>;
nel caso opposto, la variabilità totale coincide con quella residua, per
cui <span class="math inline">\(r^2 = 0\)</span>. Tra questi due estremi, <span class="math inline">\(r\)</span> indica l’intensità della
relazione lineare tra le due variabili e <span class="math inline">\(r^2\)</span>, con <span class="math inline">\(0 \leq r^2 \leq 1\)</span>,
esprime la porzione della devianza totale della <span class="math inline">\(y\)</span> che è spiegata dalla
regressione lineare sulla <span class="math inline">\(x\)</span>.</p>
<p>Per i dati dei gemelli monozitoti separati alla nascita, la devianza
totale si scompone nelle componenti di “devianza spiegata” e “devianza
non spiegata” nel modo seguente:</p>
<pre><code>dev_t &lt;- sum((df$iq2 - mean(df$iq2))^2) 
dev_r &lt;- sum((yhat - mean(df$iq2))^2)
dev_e &lt;- sum((df$iq2 - yhat)^2)</code></pre>
<p>le quali assumono i valori, rispettivamente, pari a <span class="math inline">\(3206.618\)</span>,
<span class="math inline">\(2015.255\)</span> e <span class="math inline">\(1191.363\)</span>. Ne segue che il coefficiente di determinazione
è <code>dev_r / dev_t = 0.628</code>, ovvero <code>1 - dev_e / dev_t = 0.628</code>. Questo
risultato coincide con quello trovato con <code>summary(fm)$r.squared</code>.
Possiamo quindi concludere che, nel caso del campione esaminato, i
fattori genetici spiegano circa il 63% della varianza del quoziente di
intelligenza dei gemelli monozigoti.</p>
</div>
</div>
<div id="inferenza-sullassociazione-tra-x-e-y-nella-popolazione" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Inferenza sull’associazione tra <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> nella popolazione</h2>
<p>Il terzo obiettivo dell’analisi di regressione è quello di fare
inferenze sull’associazione tra le due variabili nella popolazione da
cui il campione deriva. Ci chiediamo se l’associazione osservata nel
campione rifletta le proprietà della popolazione oppure sia imputabile
agli errori di campionamento.</p>
<p>Se si segue la scuola frequentista, nella regressione bivariata il
problema dell’inferenza statistica è basato sulla stessa logica seguita
nel caso di una singola variabile aleatoria. Nell’inferenza su una
media, per esempio, viene valutata l’ipotesi nulla <span class="math inline">\(H_0: \mu=0\)</span> e il
parametro di interesse, la media <span class="math inline">\(\mu\)</span> della popolazione, viene stimato
mediante un’opportuna statistica, ovvero la media campionaria <span class="math inline">\(\bar{y}\)</span>.
Le inferenze statistiche sono basate sulla conoscenza delle proprietà
della distribuzione della statistica campionaria <span class="math inline">\(\bar{y}\)</span>.</p>
<p>È possibile però anche definire degli stimatori che dipendono da due (o
più) caratteri. Per esempio, il coefficiente <span class="math inline">\(b\)</span> della retta di
regressione campionaria, che viene usato quale stimatore del
coefficiente angolare <span class="math inline">\(\beta\)</span> della funzione di regressione nella
popolazione <span class="math inline">\(Y = \alpha + \beta X + \varepsilon\)</span>, è definito rispetto a
due caratteri, <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>. Per ciascun campione casuale di <span class="math inline">\(n\)</span>
osservazioni <span class="math inline">\(x, y\)</span>, lo stimatore <span class="math inline">\(b\)</span> di <span class="math inline">\(\beta\)</span> assume un diverso
valore (<span class="math inline">\(b\)</span> è una variabile aleatoria). L’insieme delle stime <span class="math inline">\(b\)</span> di
<span class="math inline">\(\beta\)</span> nell’universo dei campioni di ampiezza <span class="math inline">\(n\)</span> costituisce la
<em>distribuzione campionaria</em> di <span class="math inline">\(b\)</span>. Analogamente si può dire dello
stimatore <span class="math inline">\(a\)</span> di <span class="math inline">\(\alpha\)</span>. Il problema che ci poniamo ora è appunto
quello di descrivere le proprietà delle distribuzioni campionarie dei
due stimatori dei minimi quadrati <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span>. Per fare questo, dobbiamo
però prima introdurre il modello statistico della regressione lineare.</p>
<div id="modello-statistico-di-regressione-lineare" class="section level3" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> Modello statistico di regressione lineare</h3>
<p>In corrispondenza di a ciascun valore della variabile <span class="math inline">\(X\)</span>, che si
ipotizza essere costante da campione a campione, corrisponde nella
popolazione una distribuzione di valori <span class="math inline">\(Y\)</span>. Ci chiediamo che relazione
intercorra tra le medie condizionali <span class="math inline">\(\bar{y}_i \mid x_i\)</span> e la variabile
<span class="math inline">\(X\)</span>. Se disponiamo di un campione di ciascuna distribuzione condizionata
<span class="math inline">\(y_i \mid x_i\)</span>, allora possiamo calcolare la media condizionale nel
campione per stimare la corrispondente media nella popolazione. Una tale
situazione si può verificare in un contesto sperimentale, in cui,
mantenendo fissi i valori del carattere <span class="math inline">\(X\)</span>, la ripetizione delle prove
produce un campione del carattere <span class="math inline">\(Y\)</span> subordinatamente ad ogni <span class="math inline">\(X=x\)</span>.
Nel caso di dati di tipo osservazionale, invece, vengono osservate
coppie di valori (<span class="math inline">\(x_i, y_i\)</span>), con <span class="math inline">\(i=1, \dots, n\)</span>, e per ogni valore
<span class="math inline">\(X=x\)</span> si ha a disposizione un unico valore <span class="math inline">\(y\)</span>.</p>
<p>Allo scopo di attenuare le conseguenze derivanti dalle limitazioni di
cui soffrono i dati a disposizione, si definisce il <em>modello statistico
di regressione lineare</em> introducendo nell’analisi delle ipotesi sulla
popolazione. Il modello statistico di regressione
(figura <a href="#fig:mod_reg_bivariata" reference-type="ref" reference="fig:mod_reg_bivariata"><span class="math display">\[fig:mod_reg_bivariata\]</span></a>) è basato sulle quattro seguenti
ipotesi a proposito della struttura della popolazione.</p>
<ol style="list-style-type: decimal">
<li><p>La funzione di regressione è lineare (<em>linearità</em>):
<span class="math display">\[E(y_i \mid x_1, \dots, x_n) = \alpha + \beta x_i, \quad
i=1, \dots, n.\]</span> Le medie delle distribuzioni condizionali
<span class="math inline">\(y \mid x_i\)</span> sono linearmente associate alla variabile esplicativa
<span class="math inline">\(x\)</span>.</p></li>
<li><p>Le varianze delle distribuzioni condizionali <span class="math inline">\(y \mid x_i\)</span> sono
costanti al variare della <span class="math inline">\(x\)</span> (<em>omoschedasticità</em>):
<span class="math display">\[\var(y_i \mid x_1, \dots,  x_n) = \sigma^2, \quad i=1,
\dots, n.\]</span></p></li>
<li><p>Le osservazioni <span class="math inline">\(y_i\)</span> sono tra loro incorrelate subordinatamente
alle <span class="math inline">\(x_i\)</span> (<em>indipendenza</em>):
<span class="math display">\[\cov(y_i, y_j \mid x_1, \dots, x_n) = 0, \quad per \hskip.1 in i \neq j,\]</span>
ovvero, l’osservazione <span class="math inline">\(y_i\)</span> è selezionata dalla distribuzione
condizionale <span class="math inline">\(y_i \mid x_i\)</span> tramite un campionamento casuale
indipendente.</p></li>
<li><p>La distribuzione di <span class="math inline">\(y_i\)</span> subordinata a <span class="math inline">\(X=x_i\)</span> segue la
distribuzione gaussiana (<em>normalità</em>):
<span class="math display">\[(y_i \mid x_i) \sim \mathcal{N}(\alpha+\beta x_i, \sigma^2).\]</span></p></li>
</ol>
</div>
<div id="i-test-diagnostici-sulla-regressione-lineare" class="section level3" number="2.2.2">
<h3><span class="header-section-number">2.2.2</span> I test diagnostici sulla regressione lineare</h3>
<p>Nell’ambito della regressione, il termine “diagnostica” identifica un
insieme di tecniche volte a verificare la plausibilità delle ipotesi
classiche alla base del modello di regressione lineare. A questo fine
particolare rilievo assumono i residui, ovvero gli scarti tra i valori
osservati e quelli stimati dal modello. L’analisi dei residui permette
di validare la plausibilità delle ipotesi del modello e consente inoltre
di identificare l’eventuale presenza di casi outlier (ovvero, casi
anomali rispetto alla variabile dipendente <span class="math inline">\(Y\)</span>), di <em>leverage</em> (ovvero,
casi anomali rispetto alla <span class="math inline">\(X\)</span>), influenti (ovvero, casi la cui
esclusione modifica molto le stime dei minimi quadrati).</p>
<div id="normalità" class="section level4 unnumbered">
<h4>Normalità</h4>
<p>La normalità dei residui può essere verificata come abbiamo fatto in
precedenza. Molto usato, in questo contesto, è usato il diagramma
quantitle-quantile. Per i dati di Anderson e Finn (1996), il diagramma
quantile-quantile è fornito dalla
Figura <a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#fig:diagnostics_norm" reference-type="ref" reference="fig:diagnostics_norm">1.5</a>.</p>
<div class="figure">
<img src="Rplot_twins_2" id="fig:diagnostics_norm" alt="" />
<p class="caption">Verifica della normalità: diagramma quantile-quantile dei
residui.</p>
</div>
</div>
<div id="linearità" class="section level4 unnumbered">
<h4>Linearità</h4>
<p>La linearità della relazione viene solitamente verificata costruendo un
diagramma che riporta sulle ascisse i valori predetti dal modello e,
sulle ordinate, i residui. Evidenze che l’associazione tra <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> sia
lineare sono fornite nel caso in cui non vi sia alcuna relazione tra
<span class="math inline">\(\hat{Y}\)</span> ed <span class="math inline">\(E\)</span>. È importante che non esista alcuna relazione tra i
residui e i valori predetti. Se ciò non accadesse, esisterebbe una
relazione tra regressore e variabilità residua e quindi il modello
lineare non riuscirebbe a cogliere compiutamente la relazione
effettivamente esistente tra <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>. Per i dati di Anderson e Finn
(1996), non ci sono evidenze che suggeriscono la presenza di
un’associazione non lineare, come indicato nella
Figura <a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#fig:diagnostics_lin" reference-type="ref" reference="fig:diagnostics_lin">1.6</a>.</p>
<div class="figure">
<img src="Rplot_twins_1" id="fig:diagnostics_lin" alt="" />
<p class="caption">Verifica della linearità: residui in funzione dei valori
predetti.</p>
</div>
</div>
<div id="omoschedasticità" class="section level4 unnumbered">
<h4>Omoschedasticità</h4>
<p>L’assunzione di omoschedasticità si valuta mediante un diagramma detto
<em>Scale-Location</em> (o <em>Spread-Location</em>) che riporta sulle ascisse i
valori predetti dal modello e, sulle ordinate, la radice quadrata dei
residui standardizzati. I residui standardizzati devono distribuirsi, al
crescere di <span class="math inline">\(n\)</span>, secondo una Normale standardizzata, ovvero
<span class="math display">\[e_i^* = \frac{e_i}{s_e} \sim \mathcal{N}(0, 1),\]</span> laddove <span class="math inline">\(s_e\)</span> è
l’errore standard della regressione (ovvero, la stima della deviazione
stanard dei residui nella popolazione). L’assunzione di omoschedasticità
è verificata se i residui così trasformati oscillano intorno allo 0 in
modo casuale con un’ampiezza approssimativamente costante. Per i dati di
Anderson e Finn (1996), non ci sono evidenze che suggeriscono la
violazione dell’assunzione di omoschedasticità, come indicato nella
Figura <a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#fig:diagnostics_homosc" reference-type="ref" reference="fig:diagnostics_homosc">1.7</a>.</p>
<div class="figure">
<img src="Rplot_twins_3" id="fig:diagnostics_homosc" alt="" />
<p class="caption">Verifica dell’omoschedasticità: radice quadrata dei residui
standardizzati in funzione dei valori
predetti.</p>
</div>
</div>
<div id="outlier-e-osservazioni-influenti" class="section level4 unnumbered">
<h4>Outlier e osservazioni influenti</h4>
<p>Gli outlier possono essere identificati esaminando i residui
standardizzati. I residui standardizzati possono essere interpretati
come il numero di deviazioni standard che separano le osservazioni dalla
retta di regressione.</p>
<p>Osservazioni con un alto valore di leva (<em>leverage</em>) sono delle
osservazioni con alti valori della <span class="math inline">\(X\)</span>. Il valore di leva delle
osservazioni può essere determinato in base alla statistica di leverage.
Se tale valore supera la soglia <span class="math inline">\(2(p + 1)/n\)</span>, dove <span class="math inline">\(p\)</span> è il numero di
predittori (nella regressione semplice, <span class="math inline">\(p=1\)</span>), e <span class="math inline">\(n\)</span> è il numero di
osservazioni, allora ciò indica che l’osservazione in questione ha un
alto valore di leva (Bruce e Bruce, 2017). Il grafico <em>Residuals vs
Leverage</em> viene utilizzato per identificare gli outlier e i casi
influenti. Per i dati di Anderson e Finn (1996), la
Figura <a href="r-twinmono1-echofalse-fig-capquoziente-di-intelligenza-del-secondo-nato-in-funzione-del-quoziente-di-intelligenza-del-primo-nato-out-width-100-knitrinclude-graphicsimagesfig-anderson-finn-1996-pdf.html#fig:diagnostics_leverage" reference-type="ref" reference="fig:diagnostics_leverage">1.8</a> mostra che non vi sono né valori
anomali né osservazioni influenti.</p>
<div class="figure">
<img src="Rplot_twins_4" id="fig:diagnostics_leverage" alt="" />
<p class="caption">Esame dei valori anomali e dei valori influenti: residui
standardizzati in funzione dei punti di leva
(leverage).</p>
</div>
</div>
</div>
<div id="proprietà-degli-stimatori-dei-minimi-quadrati" class="section level3" number="2.2.3">
<h3><span class="header-section-number">2.2.3</span> Proprietà degli stimatori dei minimi quadrati</h3>
<p>Il coefficiente dei minimi quadrati <span class="math inline">\(b\)</span> è una combinazione lineare delle
osservazioni <span class="math inline">\(y_i\)</span>. Tale proprietà è importante perché consente di
derivare la distribuzione di <span class="math inline">\(b\)</span> dalla distribuzione delle <span class="math inline">\(y_i\)</span>. Può
essere dimostrato che la formula per il calcolo di <span class="math inline">\(b\)</span> si può scrivere
nel modo seguente: <span class="math display">\[\begin{aligned}
b &amp;= \sum_i \left[\frac{x_i-\bar{x}}{\sum_j(x_j-\bar{x})^2}\right]y_i = \textstyle\sum m_i y_i,\end{aligned}\]</span>
dove <span class="math inline">\(m_i \triangleq (x_i-\bar{x}) / \sum (x_j-\bar{x})^2\)</span> è il peso
associato a ciascun valore <span class="math inline">\(y_i\)</span>. Dato che i valori <span class="math inline">\(x_i\)</span> sono fissi e
<span class="math inline">\(m_i\)</span> dipende solo da <span class="math inline">\(x_i\)</span>, anche i pesi <span class="math inline">\(m_i\)</span> sono fissi.</p>
<p>Il valore atteso di <span class="math inline">\(b\)</span> è uguale a <span class="math display">\[\begin{aligned}
E(b) &amp;= \textstyle\sum m_i E(y_i)\notag\\ 
&amp;= \textstyle\sum m_i (\alpha + \beta x_i)\notag\\ 
&amp;= \textstyle\alpha\sum m_i + \beta \sum m_i x_i\notag\\
&amp;= \frac{\alpha \sum(x_i-\bar{x})}{\sum(x_i-\bar{x})^2} + \beta \frac{\sum(x_i-\bar{x})x_i}{\sum(x_i-\bar{x})^2}\notag\\
&amp;= 0 + \beta \frac{\sum x_i^2 -\bar{x}\sum x_i}{\sum(x_i-\bar{x})^2}\notag\\ 
&amp;= \beta \frac{\sum x_i^2 - n\bar{x}^2}{\sum(x_i-\bar{x})^2}\notag\\ 
&amp;= \beta.\end{aligned}\]</span> Il coefficiente dei minimi quadrati <span class="math inline">\(b\)</span> è
dunque uno stimatore corretto di <span class="math inline">\(\beta\)</span>. In maniera equivalente si può
dimostrare che <span class="math inline">\(E(a) = \alpha\)</span>.</p>
<p>Sotto le ipotesi di omoschedasticità
<span class="math inline">\(\big[ \var(y_i) = \var(\varepsilon_i)=\sigma^2_{\varepsilon}\big]\)</span> e
indipendenza, la varianza di <span class="math inline">\(b\)</span> è <span class="math display">\[\begin{aligned}
\var(b) &amp;= \textstyle\var\big(\sum m_i y_i\big)\notag\\
&amp;= \textstyle\mathop{\sum m_i^2} \var(y_i)\notag\\ 
&amp;= \textstyle\mathop{\sum m_i^2} \sigma^2_{\varepsilon}\notag\\
&amp;= \frac{\mathop{\sigma^2_{\varepsilon}} \textstyle\sum(x_i-\bar{x})^2}{\big[\textstyle\sum(x_i-\bar{x})^2\big]^2}\notag\\
&amp;= \frac{\sigma^2_{\varepsilon}}{\sum(x_i-\bar{x})^2}.\end{aligned}\]</span> In
maniera simile si dimostra che la varianza di <span class="math inline">\(a\)</span> è
<span class="math display">\[\var(a)= \frac{\sigma^2_{\varepsilon} \textstyle\sum x_i^2}{n \textstyle\sum (x_i-\bar{x})^2}.\]</span></p>
<p>Dato che sia <span class="math inline">\(a\)</span> che <span class="math inline">\(b\)</span> sono funzioni lineari di <span class="math inline">\(y_i\)</span>, se i valori
<span class="math inline">\(y_i\)</span> seguono la distribuzione gaussiana, allora anche <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> saranno
distribuiti secondo una distribuzione normale. In conclusione,
<span class="math display">\[\begin{aligned}
b &amp;\sim \mathcal{N}\bigg(\beta,  \frac{\sigma^2_{\varepsilon}}{\sum(x_i-\bar{x})^2}\bigg),\\
a &amp;\sim \mathcal{N}\bigg(\alpha, \frac{\sigma^2_{\varepsilon}\textstyle\sum x_i^2}{n \textstyle\sum (x_i-\bar{x})^2} \bigg).\end{aligned}\]</span></p>
</div>
<div id="ipotesi-statistiche-e-statistica-test" class="section level3" number="2.2.4">
<h3><span class="header-section-number">2.2.4</span> Ipotesi statistiche e statistica test</h3>
<p>Una volta definite le proprietà delle distribuzioni degli stimatori dei
minimi quadrati è possibile procedere con l’inferenza sui parametri del
modello di regressione. L’inferenza statistica si articola nella
formulazione degli intervalli di confidenza per i parametri di interesse
e nei test di significatività statistica.</p>
<p>Un’ipotesi che viene frequentemente sottoposta a verifica è quella di
significatività, cioè l’ipotesi che alla variabile esplicativa sia
associato un coefficiente nullo. In tal caso, l’ipotesi nulla è
<span class="math display">\[H_0:\beta=0\]</span> e l’ipotesi alternativa è <span class="math display">\[H_1:\beta \neq 0.\]</span> Sotto
l’ipotesi nulla <span class="math inline">\(H_0: \beta = 0\)</span> la statistica
<span class="math display">\[t_{\hat{\beta}} = \frac{\hat{\beta}}{s_{\hat{\beta}}}\]</span> si
distribuisce come una variabile aleatoria <span class="math inline">\(t\)</span> di Student con <span class="math inline">\(n-2\)</span> gradi
di libertà.</p>
<p>Di fronte al problema di decidere se il valore stimato <span class="math inline">\(\hat{\beta}\)</span> sia
sufficientemente ‘distante’ da zero, in modo da respingere l’ipotesi
nulla che il vero valore <span class="math inline">\(\beta\)</span> sia nullo, non è sufficiente basarsi
soltanto sul valore numerico assunto da <span class="math inline">\(\hat{\beta}\)</span>, ma occorre tener
conto della variabilità campionaria. La statistica ottenuta dividendo
<span class="math inline">\(\hat{\beta}\)</span> per la stima del suo errore standard, <span class="math inline">\(s_{\hat{\beta}}\)</span>,
ci permette di utilizzare la distribuzione <span class="math inline">\(t\)</span> di Student come metrica
per stabilire se la stima trovata si debba considerare ‘diversa’ da
quanto ipotizzato sotto <span class="math inline">\(H_0\)</span>.</p>
<p>L’ipotesi nulla viene rifiutata quando il valore assoluto del rapporto è
esterno alla regione di accettazione, i cui limiti sono definiti dai
valori critici della distribuzione <span class="math inline">\(t\)</span> di Student con <span class="math inline">\(n - 2\)</span> gradi di
libertà per il livello di significatività <span class="math inline">\(\alpha\)</span> prescelto. Se
l’ipotesi nulla viene rifiutata si dice che il coefficiente
<span class="math inline">\(\hat{\beta}\)</span> è “statisticamente significativo” ammettendo così la
possibilità di descrivere con un modello lineare la relazione esistente
tra le variabili <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>. Quando non si può rifiutare l’ipotesi nulla
nel modello di regressione, si conclude che il coefficiente angolare
della retta non risulta significativamente diverso da zero, individuando
così nella popolazione una retta parallela all’asse delle ascisse.</p>
</div>
<div id="riportare-i-risultati" class="section level3" number="2.2.5">
<h3><span class="header-section-number">2.2.5</span> Riportare i risultati</h3>
<p>È consuetudine riportare i risultati dell’analisi di regressione in modo
che sotto le stime dei coefficienti vengano riportati i rispettivi
errori standard stimati:</p>
<table>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\hat{Y}_i\)</span></td>
<td align="center">=</td>
<td align="center"><span class="math inline">\(\hat{\alpha}\)</span></td>
<td align="center">+</td>
<td align="center"><span class="math inline">\(\hat{\beta} x_i\)</span>.</td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="center"></td>
<td align="center"><span class="math inline">\(s_{\hat{\alpha}}\)</span></td>
<td align="center"></td>
<td align="center"><span class="math inline">\(s_{\hat{\beta}}\)</span></td>
</tr>
</tbody>
</table>
<p>Il valore-<span class="math inline">\(p\)</span> esprime la probabilità di ottenere un valore del test
uguale o superiore a quello ottenuto nel campione esaminato, utilizzando
la distribuzione campionaria del test sotto l’ipotesi nulla. Se
<span class="math inline">\(t_{\hat{\beta}}\)</span> è il valore osservato del rapporto <span class="math inline">\(t\)</span> per il
coefficiente angolare della retta di regressione, allora il <span class="math inline">\(p\)</span>-valore è
dato da <span class="math display">\[p = 2 \times Pr(t \geq |t_{\hat{\beta}}|),\]</span> dove <span class="math inline">\(t\)</span> è il
valore di una variabile aleatoria <span class="math inline">\(t\)</span> di Student con <span class="math inline">\((n-2)\)</span> gradi di
libertà.</p>
<div id="regola-di-decisione" class="section level5" number="2.2.5.0.1">
<h5><span class="header-section-number">2.2.5.0.1</span> Regola di decisione</h5>
<p>Ogni volta che il <span class="math inline">\(p\)</span>-valore del test è inferiore al livello di
significatività che si è scelto per <span class="math inline">\(H_0\)</span>, il test porta al rifiuto
dell’ipotesi nulla. Solitamente si sceglie un livello <span class="math inline">\(\alpha\)</span> pari a
0.05 o 0.01.</p>
<p>Per la regressione di <code>Foster</code> su <code>Biological</code>, usando i dati contenuti
nel data.frame <code>twins</code> del pacchetto <code>UsingR</code>, la statistica test è:
<span class="math display">\[t = \frac{B}{s_{\hat{\beta}}}=\frac{0.901}{0.096} = 9.36.\]</span> Supponendo
un’ipotesi alternativa bidirezionale, <span class="math inline">\(H_1: \beta \neq 0\)</span>, la regione
critica sarà suddivisa nelle due code della distribuzione <span class="math inline">\(t\)</span> di Student
con <span class="math inline">\(25\)</span> gradi di libertà. Essendo il valore critico
<span class="math inline">\(t_{n-2, 1-\alpha/2}\)</span> pari a <span class="math inline">\(2.06\)</span>, si può rifiutare <span class="math inline">\(H_0\)</span>.</p>
<p>In maniera corrispondente, possiamo considerare il <span class="math inline">\(p\)</span>-valore. I l
<span class="math inline">\(p\)</span>-valore è l’area sottesa alla funzione di densità <span class="math inline">\(t\)</span> di Student con
<span class="math inline">\(n-2=25\)</span> gradi di libertà nei due intervalli
<span class="math inline">\([-\infty, -t_{\hat{\beta}}]\)</span> e <span class="math inline">\([t_{\hat{\beta}}, \infty]\)</span>, ovvero
minore di <span class="math inline">\(0.0001\)</span>. Dato che il <span class="math inline">\(p\)</span>-valore è minore di <span class="math inline">\(\alpha = 0.05\)</span>,
il risultato è statisticamente significativo e può essere riportato nel
modo seguente:</p>
<blockquote>
<p>L’analisi della regressione bivariata ha rivelato una relazione
lineare positiva tra il QI dei gemelli adottati alla nascita e il QI
dei gemelli rimasti con i genitori biologici, <span class="math inline">\(\hat{\beta} = 0.90\)</span>,
<span class="math inline">\(t_{25} = 9.36\)</span>, <span class="math inline">\(p = .0001\)</span>.</p>
</blockquote>
<p>I test di significatività possono essere eseguiti con R  utilizzando la
funzione <code>summary()</code> applicata all’oggetto creato dal <code>lm()</code>: Il test
statistico sul parametro <span class="math inline">\(\beta\)</span> del modello di regressione verifica
l’ipotesi nulla di indipendenza, ovvero l’ipotesi che, nella
popolazione, la pendenza della retta di regressione sia uguale a zero.
Più informativo del test statistico <span class="math inline">\(H_0: \beta=0\)</span> è l’intervallo di
confidenza per il parametro <span class="math inline">\(\beta\)</span>:
<span class="math display">\[\hat{\beta} \pm t_{\alpha/2} s_{\hat{\beta}}.\]</span> Nel caso presente,
abbiamo <span class="math display">\[\begin{aligned}
\hat{\beta} \pm t_{\alpha/2} s_{\hat{\beta}}\notag\\
.90  \pm 2.06 \times .096\notag\\
0.70 \quad 1.10\notag\end{aligned}\]</span> Dato che l’intervallo di confidenza
al 95% è piuttosto piccolo, e considerato che il limite inferiore
dell’intervallo di confidenza è parecchio superiore allo zero, possiamo
concludere che vi è un’<em>associazione</em> (lineare) <em>positiva</em> tra il QI dei
gemelli monozigoti rimasti con la famiglia biologica e quelli adottati.</p>
</div>
</div>
</div>
<div id="considerazioni-conclusive" class="section level2 unnumbered">
<h2>Considerazioni conclusive</h2>
<p>Il modello di regressione lineare semplice viene usato per descrivere la
relazione tra due variabili e per determinare il segno e l’intensità di
tale relazione. Inoltre, il modello di regressione ci consente di
prevedere il valore della variabile dipendente in base ad alcuni nuovi
valori della variabile indipendente. Il modello di regressione lineare
semplice è in realtà molto limitato, in quanto descrive soltanto la
relazione tra la variabile dipendente <span class="math inline">\(Y\)</span> e una sola variabile
esplicativa <span class="math inline">\(X\)</span>. Esso diventa molto più utile quando incorpora più
variabili indipendenti. In questo secondo caso, però, i calcoli per la
stima dei coefficienti del modello diventano più complicati. Abbiamo
deciso qui di presentare solo il modello di regressione lineare semplice
perché, in quel caso, sia la logica dell’inferenza sia le procedure di
calcolo sono facilmente maneggiabili. Nel caso più generale, quello del
modello di regressione multipla, la logica dell’inferenza rimarrà
identica a quella discussa qui, ma le procedure di calcolo richiedono
l’uso dell’algebra matriciale che esula dagli scopi del presente
insegnamento. Il modello di regressione multipla può includere sia
regressori quantitativi, sia regressori qualitativi, utilizzando un
opportuna schema di codifica. È interessante notare come un modello di
regressione multipla che include una sola variabile esplicativa
quantitativa corrisponde all’analisi della varianza ad una via; un
modello di regressione multipla che include più di una variabile
esplicativa quantitativa corrisponde all’analisi della varianza più vie.
Questi argomenti verranno sviluppati negli insegnamenti di carattere
quantitativo più avanzati. Possiamo qui concludere dicendo che il
modello di regressione, nelle sue varie forme e varianti, costituisce la
tecnica di analisi dei dati maggiormente usata in psicologia.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chapter-reglin.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bibliografia.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/ccaudek/bookdown_psicometria/edit/master/40_reglin.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/ccaudek/bookdown_psicometria/blob/master/40_reglin.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
