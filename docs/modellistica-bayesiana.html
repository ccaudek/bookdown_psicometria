<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Capitolo 24 Modellistica bayesiana | Data Science per psicologi</title>
<meta name="author" content="Corrado Caudek">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.7/header-attrs.js"></script><script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.5.3/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.5.3/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.4/tabs.js"></script><script src="libs/bs3compat-0.2.4/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Data Science per psicologi</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Benvenuti</a></li>
<li class="book-part">Obiettivi formativi</li>
<li><a class="" href="conoscenza-dichiarativa-e-imperativa.html"><span class="header-section-number">1</span> Conoscenza dichiarativa e imperativa</a></li>
<li class="book-part">Introduzione al linguaggio R</li>
<li><a class="" href="introduzione.html">Introduzione</a></li>
<li><a class="" href="chapter-pacchetti.html"><span class="header-section-number">2</span> Pacchetti</a></li>
<li><a class="" href="chapter-install-r.html"><span class="header-section-number">3</span> Per cominciare</a></li>
<li><a class="" href="chapter-sintassi.html"><span class="header-section-number">4</span> Sintassi di base</a></li>
<li><a class="" href="chapter-strutture-dati.html"><span class="header-section-number">5</span> Strutture di dati</a></li>
<li><a class="" href="chapter-strut-contr.html"><span class="header-section-number">6</span> Strutture di controllo</a></li>
<li><a class="" href="chapter-input-output.html"><span class="header-section-number">7</span> Input/Output</a></li>
<li><a class="" href="manipolazione-dei-dati.html"><span class="header-section-number">8</span> Manipolazione dei dati</a></li>
<li><a class="" href="flusso-di-lavoro-riproducibile.html"><span class="header-section-number">9</span> Flusso di lavoro riproducibile</a></li>
<li class="book-part">Statistica descrittiva ed analisi esplorativa dei dat̀i</li>
<li><a class="" href="introduzione-1.html">Introduzione</a></li>
<li><a class="" href="terminologia.html"><span class="header-section-number">10</span> Terminologia</a></li>
<li><a class="" href="chapter-misurazione.html"><span class="header-section-number">11</span> La misurazione in psicologia</a></li>
<li><a class="" href="chapter-descript.html"><span class="header-section-number">12</span> Statistica descrittiva</a></li>
<li class="book-part">Nozioni di base</li>
<li><a class="" href="introduzione-2.html">Introduzione</a></li>
<li><a class="" href="il-calcolo-delle-probabilit%C3%A0.html"><span class="header-section-number">13</span> Il calcolo delle probabilità</a></li>
<li><a class="" href="chapter-prob-cond.html"><span class="header-section-number">14</span> Probabilità condizionata</a></li>
<li><a class="" href="chapter-teo-bayes.html"><span class="header-section-number">15</span> Il teorema di Bayes</a></li>
<li><a class="" href="chapter-prob-congiunta.html"><span class="header-section-number">16</span> Probabilità congiunta</a></li>
<li><a class="" href="la-distribuzione-binomiale.html"><span class="header-section-number">17</span> La distribuzione binomiale</a></li>
<li><a class="" href="funzioni-di-densit%C3%A0-di-probabilit%C3%A0.html"><span class="header-section-number">18</span> Funzioni di densità di probabilità</a></li>
<li><a class="" href="la-funzione-di-verosimiglianza.html"><span class="header-section-number">19</span> La funzione di verosimiglianza</a></li>
<li class="book-part">Inferenza frequentista</li>
<li><a class="" href="introduzione-3.html">Introduzione</a></li>
<li><a class="" href="distribuzione-campionaria.html"><span class="header-section-number">20</span> Distribuzione campionaria</a></li>
<li><a class="" href="significativit%C3%A0-statistica.html"><span class="header-section-number">21</span> Significatività statistica</a></li>
<li><a class="" href="inferenza-sulle-medie.html"><span class="header-section-number">22</span> Inferenza sulle medie</a></li>
<li><a class="" href="critiche-e-difese.html"><span class="header-section-number">23</span> Critiche e difese</a></li>
<li class="book-part">Inferenza Bayesiana</li>
<li><a class="" href="introduzione-4.html">Introduzione</a></li>
<li><a class="active" href="modellistica-bayesiana.html"><span class="header-section-number">24</span> Modellistica bayesiana</a></li>
<li><a class="" href="stima-della-funzione-a-posteriori.html"><span class="header-section-number">25</span> Stima della funzione a posteriori</a></li>
<li><a class="" href="sintesi-a-posteriori.html"><span class="header-section-number">26</span> Sintesi a posteriori</a></li>
<li><a class="" href="una-breve-introduzione-al-modello-di-regressione.html"><span class="header-section-number">27</span> Una breve introduzione al modello di regressione</a></li>
<li><a class="" href="il-modello-statistico-della-regressione-lineare.html"><span class="header-section-number">28</span> Il modello statistico della regressione lineare</a></li>
<li><a class="" href="inferenza-bayesiana.html"><span class="header-section-number">29</span> Inferenza Bayesiana</a></li>
<li class="book-part">Informazioni generali</li>
<li><a class="" href="citazione.html">Citazione</a></li>
<li class="book-part">Appendici</li>
<li><a class="" href="un-piccolo-ripasso.html">Un piccolo ripasso</a></li>
<li><a class="" href="bibliografia.html">Bibliografia</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="modellistica-bayesiana" class="section level1" number="24">
<h1>
<span class="header-section-number">Capitolo 24</span> Modellistica bayesiana<a class="anchor" aria-label="anchor" href="#modellistica-bayesiana"><i class="fas fa-link"></i></a>
</h1>
<div id="modelli-statistici" class="section level2" number="24.1">
<h2>
<span class="header-section-number">24.1</span> Modelli statistici<a class="anchor" aria-label="anchor" href="#modelli-statistici"><i class="fas fa-link"></i></a>
</h2>
<p>I dati non interpretati non sono informativi. Non possiamo generalizzare, trarre inferenze o tentare di fare previsioni a meno di non fare ipotesi (per quanto minime) sui dati a disposizione: cosa rappresenta, come sono stati generati, quali aspetti dei dati sono associati a quali altri aspetti, ecc. I modelli statistici rappresentano un modo per rendere esplicite le nostre assunzioni sui dati.</p>

<div class="definition">
<span id="def:unnamed-chunk-236" class="definition"><strong>Definizione 24.1  </strong></span>Un modello statistico è una rappresentazione formale delle ipotesi relative ai dati e al processo che li ha generati.
</div>
<p><br></p>
<p>Nel suo senso naturale più comune, un “modello” è un modello di qualcosa. Intende rappresentare qualcos’altro in una forma semplificata, astratta e più maneggevole; ovviamente, le caratteristiche di un modello dipendono dallo scopo per il quale il modello verrà usato. In generale, un buon modello è in grado di riprodurre alcuni aspetti della realtà, mentre nel contempo ignora tutte quelle caratteristiche irrilevanti che potrebbero altrimenti offuscare la nostra comprensione di ciò che il modello vuole rappresentare.</p>
<p>Lo scopo più comune di un modello statistico è quello di imparare qualcosa sulla realtà traendo inferenze dai dati - possibilmente con l’ulteriore obiettivo di consentirci di prendere una decisione razionale - o di fare previsioni su eventi sconosciuti (futuri, presenti o passati).</p>
<p>Un modello statistico <em>M</em> è un modello di un processo aleatorio <em>R</em> che potrebbe aver generato i dati che abbiamo osservato. Il modello <em>M</em> descrive quindi in un modo formale le nostre ipotesi sul processo aleatorio <em>R</em>.</p>
<p>Spesso vogliamo spiegare una parte dei nostri dati, le variabili dipendenti <span class="math inline">\(D_{DV}\)</span>
nei termini di altre osservazioni, le variabili indipendenti <span class="math inline">\(D_{IV}\)</span>. Ma è anche possibile che non ci siano variabili indipendenti in termini di cui vorremmo modellare la variabile dipendente <span class="math inline">\(D_{DV}\)</span>.</p>
<p>Un modello <em>M</em> per i dati <em>D</em> stabilisce una <em>fuzione di verosimiglianza</em> per <span class="math inline">\(D_{DV}\)</span>.</p>
<p>La funzione di verosimiglianza determina la plausibilità di qualsiasi potenziale osservazione
<span class="math inline">\(D_{DV}\)</span> alla luce delle corrispondenti osservazioni <span class="math inline">\(D_{IV}\)</span>. Molto spesso, la funzione di verosimiglianza ha anche dei parametri liberi, rappresentati da un vettore <span class="math inline">\(\theta\)</span>. La funzione di verosimiglianza del modello <em>M</em> per i dati <em>D</em> con parametri <span class="math inline">\(\theta\)</span> si può dunque scrivere come:</p>
<p><span class="math display">\[
P_M(D_{DV} \mid D_{IV}, \theta).
\]</span>
I modelli bayesiani hanno una componente aggiuntiva, vale a dire una distribuzione a priori sui valori dei parametri, comunemente scritta come:</p>
<p><span class="math display">\[
P_M(\theta).
\]</span>
La distribuzione a priori sui valori dei parametri può essere utilizzata per rappresentare qualsiasi ipotesi a priori motivata e giustificabile sui valori dei parametri che possiamo ritenere plausibili alla luce delle nostre conoscenze presenti.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-237" class="example"><strong>Esempio 24.1  </strong></span>Supponiamo che il nostro campione di dati sia costituito dagli esiti di una sequenza di lanci di una moneta avente probabilità di successo (testa) <span class="math inline">\(\theta \in [0, 1]\)</span>. Abbiamo osservato <em>k</em> successi in <em>N</em> prove. Dunque, conosciamo <em>N</em> e <em>k</em> ma non conosciamo <span class="math inline">\(\theta\)</span>. Il parametro <span class="math inline">\(\theta\)</span> è l’unico parametro di questo modello statistico. La variabile dipendente è <em>k</em>. Possiamo pensare a <em>N</em> come alla nostra variabile indipendente.</p>
<p>La funzione di verosimiglianza per questo modello statistico è la distribuzione Binomiale:</p>
<p><span class="math display">\[
P_M(k \mid \theta, N) = \text{Binomial}(k, N, \theta) = {N \choose k} \theta^k (1 - \theta)^{N-k}.
\]</span></p>
<p>Per ragioni che diventeranno chiare in seguito, è possibile usare una distribuzione Beta per la distribuzione a priori di <span class="math inline">\(\theta\)</span>. Ad esempio, potremmo definire i parametri della distribuzione Beta in modo tale che la distribuzione risultante sia piatta, così da generare una “distribuzione a priori non informativa”:</p>
<span class="math display">\[
P_M(\theta) = \text{Beta}(\theta, 1, 1).
\]</span>
</div>
</div>
<div id="notazine" class="section level2" number="24.2">
<h2>
<span class="header-section-number">24.2</span> Notazine<a class="anchor" aria-label="anchor" href="#notazine"><i class="fas fa-link"></i></a>
</h2>
<p>Per rappresentare in un modo conciso i modelli statistici viene usata una notazione speciale, che è molto intuitiva se pensiamo al processo del campionamento. Ad esempio, invece di scrivere</p>
<p><span class="math display">\[
P_M(\theta) = \text{Beta}(\theta, 1, 1),
\]</span></p>
<p>scriviamo:</p>
<p><span class="math display">\[
\theta \sim \text{Beta}(1, 1).
\]</span>
Il simbolo “<span class="math inline">\(\sim\)</span>” viene spesso letto “è distribuito come.” Possiamo anche pensare che significhi che <span class="math inline">\(\theta\)</span> costituisce un campione estratto dalla distribuzione Beta(1, 1). Allo stesso modo, per la funzione di verosimiglianza dell’esempio precedente possiamo scrivere:</p>
<p><span class="math display">\[
k \sim \text{Binomial}(k, N, \theta).
\]</span></p>
</div>
<div id="parametri-e-distribuzioni-a-priori" class="section level2" number="24.3">
<h2>
<span class="header-section-number">24.3</span> Parametri e distribuzioni a priori<a class="anchor" aria-label="anchor" href="#parametri-e-distribuzioni-a-priori"><i class="fas fa-link"></i></a>
</h2>
<p>Un modello Bayesiano è costituito da una funzione di verosimiglianza e da una distribuzione a priori dei parametri di interesse:</p>
<p><span class="math display">\[ 
\begin{aligned}
  &amp; \text{Verosimiglianza: } &amp; P_M(D \mid \theta) \\ 
  &amp; \text{Distribuzione a priori: } &amp; P_M(\theta) 
\end{aligned}
\]</span></p>
<p>In questa sezione, approfondiremo cos’è un parametro, cos’è una distribuzione a priori precedente <span class="math inline">\(P_M(\theta)\)</span> e come possiamo usare un modello per fare previsioni sui dati.</p>
<p>L’esempio che considereremo per questa sezione è il <em>modello binomiale</em> che è stato introdotto in èrecedenza.
Come esempio concreto di dati, consideriamo un caso con <span class="math inline">\(N = 24\)</span> lanci di monete e <span class="math inline">\(k = 7\)</span> esiti testa.</p>
<div id="cosè-un-parametro-del-modello" class="section level3" number="24.3.1">
<h3>
<span class="header-section-number">24.3.1</span> Cos’è un parametro del modello?<a class="anchor" aria-label="anchor" href="#cos%C3%A8-un-parametro-del-modello"><i class="fas fa-link"></i></a>
</h3>
<p>Un parametro del modello è un valore da cui dipende la verosimiglianza. Ad esempio, il singolo parametro <span class="math inline">\(\theta\)</span> nel modello Binomiale determina la forma della funzione di verosimiglianza Binomiale.
Ricordiamo che la funzione di verosimiglianza per il modello Binomiale è:</p>
<p><span class="math display">\[ 
P_M(k \mid \theta, N) = \text{Binomial}(k, N, \theta) = \binom{N}{k}\theta^k(1-\theta)^{N-k}. 
\]</span>
Per comprendere il ruolo del parametro <span class="math inline">\(\theta\)</span>, possiamo generare un grafico della verosimiglianza dei dati osservati (qui: <span class="math inline">\(k = 7\)</span> e <span class="math inline">\(N = 24\)</span>) come funzione di <span class="math inline">\(\theta\)</span>.</p>
<p>Per ogni possibile valore di <span class="math inline">\(\theta \in [0; 1]\)</span> sull’asse orizzontale, la figura mostra sull’asse verticale la verosimiglianza dei dati osservati.
Il grafico mostra che la verosimiglianza dei dati dipende dal valore del parametro <span class="math inline">\(\theta\)</span>:
valori diversi di <span class="math inline">\(\theta\)</span> rendono più o meno verosimili i dati che abbiamo effettivamente osservato.</p>
<div class="figure" style="text-align: center">
<span id="fig:ch-03-02-LH-Binomial-Model"></span>
<img src="Data-Science-per-psicologi_files/figure-html/ch-03-02-LH-Binomial-Model-1.png" alt="Funzione di verosimiglianza per il modello Binomiale con $k=7$ e $N=24$." width="90%"><p class="caption">
Figura 24.1: Funzione di verosimiglianza per il modello Binomiale con <span class="math inline">\(k=7\)</span> e <span class="math inline">\(N=24\)</span>.
</p>
</div>
</div>
<div id="distribuzione-a-priori-sui-parametri" class="section level3" number="24.3.2">
<h3>
<span class="header-section-number">24.3.2</span> Distribuzione a priori sui parametri<a class="anchor" aria-label="anchor" href="#distribuzione-a-priori-sui-parametri"><i class="fas fa-link"></i></a>
</h3>
<p>La distribuzione a priori sui valori dei parametri <span class="math inline">\(P_M (\theta)\)</span> è parte integrante di un modello quando adottiamo un approccio Bayesiano all’analisi dei dati. Ciò implica che due modelli (bayesiani) possono condividere la stessa funzione di verosimiglianza, e tuttavia devono essere considerati come modelli diversi, se specificano diverse distribuzioni a priori. Ciò significa che, quando diciamo “Modello binomiale,” intendiamo in realtà un’intera classe di modelli, ovvero tutti i modelli con la stessa verosimiglianza ma diverse distribuzioni a priori su <span class="math inline">\(\theta\)</span>.</p>
<p>Nell’analisi dei dati Bayesiana, la distribuzione a priori <span class="math inline">\(P_M(\theta)\)</span> codifica le credenze del ricercatore a proposito dei valori dei parametri, prima di avere osservato i dati.
Idealmente, le credenze a priori che supportano la specificazione di una distribuzione a priori dovrebbero essere supportate da una qualche motivazione, come ad esempio i risultati di ricerche precedenti o altre motivazioni giustificabili.
Tuttavia, le credenze soggettive sono solo uno dei modi per giustificare le distribuzioni a priori sui parametri.</p>
<p>Ci sono tre tipi principali di motivazioni per le distribuzioni a priori <span class="math inline">\(P_M (\theta)\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Le <strong>distribuzioni a priori soggettive</strong> catturano le credenze soggettive del ricercatore nel senso sopra descritto.</li>
<li>Le <strong>distribuzioni a priori con finalità pratiche</strong> sono distribuzioni a priori che vengono utilizzate pragmaticamente a causa di una loro utilità specifica, ad esempio, perché semplificano un calcolo matematico o una simulazione al computer, o perché aiutano nel ragionamento statistico, come ad esempio quando vengono formulate i <em>skeptical priors</em> che hanno l’obiettivo di lavorare in senso contrario ad una particolare conclusione.</li>
<li>Le <strong>distribuzioni a priori oggettive</strong> sono distribuzioni a priori che, come alcuni sostengono, <em>dovrebbero</em> essere adottate per una data funzione di verosimiglianza per evitare conseguenze concettualmente paradossali. <strong>Non tratteremo le distribuzioni a priori oggettive in questo corso introduttivo e le menzioniamo qui solo per completezza.</strong>
</li>
</ol>
<p>Oltre alla motivazione che giustifica una distribuzione a priori, possiamo distinguere tra distribuzioni a priori in base a quanto fortemente impegnano il ricercatore a ritenere come plausibile un particolare intervallo di valori dei parametri. Il caso più estremo è quello che rivela una totale assenza di conoscenze a priori, il che conduce alle <strong>distribuzioni a priori non informative</strong>, ovvero quelle che assegnano lo stesso livello di credibilità a tutti i valori dei parametri. Le distribuzioni a priori informative, d’altra parte, possono essere <em>debolmente informative</em> o <em>fortemente informative</em>, a seconda della forza della credenza che esprimono. Il caso più estremo di credenza a priori è quello che riassume il punto di vista del ricercatore nei termini di un <strong>unico valore</strong> del parametro, il che assegna tutta la probabilità (massa o densità) su di un singolo valore di un parametro. Poiché questa non è più una distribuzione di probabilità, sebbene ne soddisfi la definizione, in questo caso si parla di una <em>distribuzione a priori degenerata</em>.</p>
<p>La figura seguente mostra esempi di distribuzioni a priori non informative, debolmente o fortemente informative, così come una distribuzione a priori espressa nei termini di un valore puntuale per il modello Binomiale. Le distribuzione a priori illustrate di seguito sono le seguenti:</p>
<ul>
<li>
<em>non informativa</em> : <span class="math inline">\(\theta_c \sim \text{Beta}(1,1)\)</span>;</li>
<li>
<em>debolmente informativa</em> : <span class="math inline">\(\theta_c \sim \text{Beta}(5,2)\)</span>;</li>
<li>
<em>fortemente informativa</em> : <span class="math inline">\(\theta_c \sim \text{Beta}(50,20)\)</span>;</li>
<li>
<em>valore puntuale</em> : <span class="math inline">\(\theta_c \sim \text{Beta}(\alpha, \beta)\)</span> con <span class="math inline">\(\alpha, \beta \rightarrow \infty\)</span> e <span class="math inline">\(\frac{\alpha}{\beta} = \frac{5}{2}\)</span>.</li>
</ul>
<div class="figure" style="text-align: center">
<span id="fig:ch-03-02-models-types-of-priors"></span>
<img src="Data-Science-per-psicologi_files/figure-html/ch-03-02-models-types-of-priors-1.png" alt="Examples of different kinds of Bayesian priors for coin bias $\theta_c$ in the Binomial Model." width="90%"><p class="caption">
Figura 24.2: Examples of different kinds of Bayesian priors for coin bias <span class="math inline">\(\theta_c\)</span> in the Binomial Model.
</p>
</div>
<p>La selezione delle distribuzioni a priori è stata spesso vista come una delle
scelte più importanti che un ricercatore fa quando implementa un modello
Bayesiano in quanto può avere un impatto sostanziale sui risultati
finali.</p>
<p>La soggettività delle distribuzioni a priori è evidenziata dai critici
come un potenziale svantaggio dei metodi Bayesiani. A questa critica,
<span class="citation"><a href="bibliografia.html#ref-vandeSchoot2021modelling" role="doc-biblioref">Schoot et al.</a> (<a href="bibliografia.html#ref-vandeSchoot2021modelling" role="doc-biblioref">2021</a>)</span> rispondono dicendo che, al di là
della scelta delle distribuzioni a priori, ci sono molti elementi del processo di inferenza statistica che sono soggettivi, ovvero la scelta del modello statistico e le ipotesi sulla distribuzione degli errori. In secondo luogo, <span class="citation"><a href="bibliografia.html#ref-vandeSchoot2021modelling" role="doc-biblioref">Schoot et al.</a> (<a href="bibliografia.html#ref-vandeSchoot2021modelling" role="doc-biblioref">2021</a>)</span> notano come le distribuzioni a priori svolgono due ruoli statistici importanti: quello della “regolarizzazione della stima,” ovvero, quel processo che porta ad indebolire l’influenza
indebita di osservazioni estreme, e quello del miglioramento dell’efficienza
della stima, ovvero, la facilitazione dei processi di calcolo numerico
di stima della distribuzione a posteriori.</p>
</div>
</div>
<div id="procedura-bayesiana-di-stima-dei-parametri" class="section level2" number="24.4">
<h2>
<span class="header-section-number">24.4</span> Procedura Bayesiana di stima dei parametri<a class="anchor" aria-label="anchor" href="#procedura-bayesiana-di-stima-dei-parametri"><i class="fas fa-link"></i></a>
</h2>
<div id="finalità" class="section level3" number="24.4.1">
<h3>
<span class="header-section-number">24.4.1</span> Finalità<a class="anchor" aria-label="anchor" href="#finalit%C3%A0"><i class="fas fa-link"></i></a>
</h3>
<p>Sulla base di un modello statistico <span class="math inline">\(M\)</span> di parametri <span class="math inline">\(\theta\)</span>, l’analisi statistica Bayesiana si pone il problema di trovare i valori più plausibili di <span class="math inline">\(\theta\)</span> alla luce dei dati <span class="math inline">\(D\)</span>.
Il teorema di Bayes viene usato per aggiornare le credenze a priori su <span class="math inline">\(\theta\)</span> in modo tale da produrre nuove <em>credenze a posteriori</em> <span class="math inline">\(P_M(\theta \mid D)\)</span> che combinano le informazioni fornite dai dati <span class="math inline">\(D\)</span> con le credenze precedenti. La distribuzione a posteriori riflette dunque le nuove conoscenze del ricercatore che sono state aggiornate utilizzando le evidenze fornite dai dati.</p>
</div>
<div id="metodi" class="section level3" number="24.4.2">
<h3>
<span class="header-section-number">24.4.2</span> Metodi<a class="anchor" aria-label="anchor" href="#metodi"><i class="fas fa-link"></i></a>
</h3>
<p>Ci sono due diversi metodi per calcolare la distribuzione a posteriori
<span class="math inline">\(P_M(\theta \mid D)\)</span>:</p>
<ul>
<li>una precisa derivazione matematica formulata nei termini della distribuzione a priori coniugata alla distribuzione a posteriori; tale procedura però ha un’applicabilità molto limitata;</li>
<li>un metodo approssimato, molto facile da utilizzare in pratica, che dipende da metodi Monte Carlo basati su Catena di Markov (MCMC).</li>
</ul>
<p>In questo capitolo introdurremo la terminologia e le idee di base che stanno alla base della stima delle funzione a posteriori. In seguito ci porremo il problema di sviluppare un’intuizione dei metodi MCMC.</p>
</div>
<div id="terminologia-2" class="section level3" number="24.4.3">
<h3>
<span class="header-section-number">24.4.3</span> Terminologia<a class="anchor" aria-label="anchor" href="#terminologia-2"><i class="fas fa-link"></i></a>
</h3>
<p>Consideriamo un modello Bayesiano <span class="math inline">\(M\)</span> avente una verosimiglianza <span class="math inline">\(P(D \mid \theta)\)</span> sui dati osservati <span class="math inline">\(D\)</span> e una distribuzione a priori <span class="math inline">\(P(\theta)\)</span> sui parametri. Applichiamo il teorema di Bayes per produrre la distribuzione a posteriori:</p>
<p><span class="math display">\[
P(\theta \mid D) = \frac{P(D \mid \theta) \ P(\theta)}{P(D)}.
\]</span></p>
<p>L’equazione precedente è costituita dalle seguenti componenti:</p>
<ul>
<li>la <strong>distribuzione a posteriori</strong> <span class="math inline">\(P(\theta \mid D)\)</span> - la nuova credenza a posteriori relativamente alla plausibilità di ciascun valore <span class="math inline">\(\theta\)</span> alla luce di <span class="math inline">\(D\)</span>;</li>
<li>la <strong>funzione di verosimiglianza</strong> <span class="math inline">\(P(D \mid \theta)\)</span> - quanto sono verosimili i dati <span class="math inline">\(D\)</span> per ciascun valore fisso <span class="math inline">\(\theta\)</span>;</li>
<li>la <strong>distribuzione a priori</strong> <span class="math inline">\(P(\theta)\)</span> - la credenza iniziale riguardo alla plausibilità di ciascun valore <span class="math inline">\(\theta\)</span>;</li>
<li>la <strong>verosimiglianza marginale</strong> <span class="math inline">\(P(D) = \int P(D \mid \theta) \ P(\theta) \ \text{d}\theta\)</span> - quanto sono verosimili i dati <span class="math inline">\(D\)</span> alla luce della nostra credenza a priori relativamente a <span class="math inline">\(\theta\)</span>.</li>
</ul>
<p>La formula precedente applica il teorema di Bayes per produrre la distribuzione a posteriori dei parametri sconosciuti <span class="math inline">\(\theta\)</span>. Tuttavia, molto spesso la probabilità a posteriori è scritta nel modo seguente:</p>
<p><span class="math display">\[
\underbrace{P(\theta \, | \, D)}_{posterior} \propto \underbrace{P(\theta)}_{prior} \ \underbrace{P(D \, | \, \theta)}_{likelihood},
\]</span></p>
<p>dove il segno di proporzionalità indica che le probabilità a sinistra del simbolo <span class="math inline">\(\propto\)</span> sono definite dai termini a destra di <span class="math inline">\(\propto\)</span> a meno di una costante di normalizzazione. Se <span class="math inline">\(F \colon X \rightarrow \mathbb{R}^+\)</span> è una funzione positiva non normalizzata di probabilità, <span class="math inline">\(P(x) \propto F(x)\)</span> è equivalente a <span class="math inline">\(P(x) = \frac{F(x)}{\sum_{x' \in X} F(x')}\)</span>.</p>
</div>
</div>
<div id="le-aspettative-dei-pazienti-con-disturbo-depressivo-maggiore" class="section level2" number="24.5">
<h2>
<span class="header-section-number">24.5</span> Le aspettative dei pazienti con disturbo depressivo maggiore<a class="anchor" aria-label="anchor" href="#le-aspettative-dei-pazienti-con-disturbo-depressivo-maggiore"><i class="fas fa-link"></i></a>
</h2>
<p>Discuteremo ora un esempio che ha lo scopo di chiarite le relazioni
che legano tra loro le tre distribuzioni che abbiamo introdotto sopra:
la distribuzione a priori, la verosimiglianza e la distribuzioni a
posteriori. Nell’esempio faremo riferimento alla ricerca di <span class="citation"><a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">Zetsche et al.</a> (<a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">2019</a>)</span>.</p>
<p><span class="citation"><a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">Zetsche et al.</a> (<a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">2019</a>)</span> si sono chiesti se gli individui depressi manifestino delle aspettative accurate circa il loro umore futuro, oppure se tali aspettative siano distorte negativamente.
Esamineremo qui i 30 partecipanti dello studio di <span class="citation"><a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">Zetsche et al.</a> (<a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">2019</a>)</span>
che hanno riportato la presenza di un episodio di depressione maggiore
in atto. All’inizio della settimana di test, a questi pazienti è stato
chiesto di valutare l’umore che si aspettavano di esperire nei giorni
seguenti della settimana. Mediante una app, i partecipanti dovevano poi
valutare il proprio umore in cinque momenti diversi di ciascuno dei
cinque giorni successivi. Lo studio considera diverse emozioni, ma qui
ci concentriamo solo sulla tristezza.</p>
<p>Sulla base dei dati forniti dagli autori, abbiamo calcolato la media dei
giudizi relativi al livello di tristezza raccolti da ciascun
partecipante tramite la app. Tale media è stata poi sottratta
dall’aspettativa del livello di tristezza fornita all’inizio della
settimana. Per semplificare l’analisi abbiamo considerato la discrepanza
tra aspettative e realtà come un evento dicotomico: valori positivi di
tale differenza indicano che le aspettative circa il livello di
tristezza sono maggiori del livello di tristezza che in seguito viene
effettivamente esperito; ciò significa che le aspettative sono
negativamente distorte (evento codificato con “1”). Si può dire il
contrario (le aspettative sono positivamente distorte) se tale
differenza assume valori negativi (evento codificato con “0”).</p>
<p>Nel campione dei 30 partecipanti clinici esaminati da
<span class="citation"><a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">Zetsche et al.</a> (<a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">2019</a>)</span>, 23 partecipanti manifestano delle aspettative
negativamente distorte e 7 partecipanti manifestano delle aspettative
positivamente distorte. Nella seguente discussione, chiameremo <span class="math inline">\(\theta\)</span>
la probabilità dell’evento “le aspettative del partecipante sono
distorte negativamente.” Il problema che ci poniamo è quello di ottenere
la stima a posteriori di <span class="math inline">\(\theta\)</span>, avendo osservato 23 “successi” in 30
prove, ovvero <span class="math inline">\(\hat{\theta}\)</span> = 23/30 = 0.77.</p>
<p>Si noti un punto importante qui: un problema di scrivere semplicemente la stima di <span class="math inline">\(\theta\)</span> come 0.77 è che tale valore ignora l’incertezza della nostra stima. Infatti, il valore di 0.77 si può ottenere come 23/30, o come 230/300, o 2300/3000, o 23000/30000. L’incertezza della stima 0.77 è diversa in ciascuno di questi casi e questo è molto importante quando si traggono conclusioni dai dati.</p>
<p>Nell’approccio frequentista, l’unico strumento che abbiamo per caratterizzare la nostra incertezza relativa alla stima di <span class="math inline">\(\theta\)</span> è la distribuzione campionaria della stima di questo parametro nel caso di un ipotetico campionamento ripetuto; non è invece possibile fare riferimento ad un’incertezza relativa al vero valore del parametro stesso. Per una dimensione campionaria pari a 30, la nostra incertezza deriva dalle caratteristiche della distribuzione campionaria e viene calcolata trovando la varianza campionaria – ovvero, <span class="math inline">\(n \cdot \hat{\theta} (1 - \hat{\theta}) = 30 \cdot 0.77 (1 - 0.77) = 5.31\)</span> – e poi l’errore standard, <span class="math inline">\(\sigma / \sqrt{n}\)</span> – qui 0.42. Per la stessa proporzione di successi pari a 0.77, l’aumento della dimensione del campione rende questo errore standard sempre più piccolo. Questa maggiore precisione corrisponde alle proprietà della distribuzione campionaria di <span class="math inline">\(\hat{\theta}\)</span>, ma non quantifica l’incertezza relativa al vero valore di <span class="math inline">\(\theta\)</span>.</p>
<p>L’approccio Bayesiano procede in modo diverso e ci fornisce invece l’opportunità di quantificare direttamente la nostra incertezza relativa al vero valore del parametro <span class="math inline">\(\theta\)</span>, alla luce dei dati – non della distribuzione campionaria di <span class="math inline">\(\hat{\theta}\)</span>. Tale quantificazione dell’incertezza si trova costruendo la distribuzione a posteriori di <span class="math inline">\(\theta\)</span> mediante il teorema di Bayes.</p>
<p>Per costruire la distribuzione a posteriori di <span class="math inline">\(\theta\)</span>, in questo esempio utilizzeremo l’approccio chiamato <em>grid-based</em>. Il metodo basato su griglia è un metodo di approsimazione numerica basato su una griglia di punti uniformemente spaziati (si veda
il capitolo <a href="#chapter-stima-distr-posteriori">Stima della funzione a posteriori</a>). Anche se la maggior parte dei parametri è continua (ovvero, in linea di principio ciascun parametro può assumere un numero infinito di valori), possiamo ottenere un’eccellente approssimazione della distribuzione a posteriori considerando solo una griglia finita di valori dei parametri. In un tale metodo, la densità di probabilità a posteriori può dunque essere approssimata tramite le densità di probabilità cacolate in ciascuna cella della griglia.</p>
<p>Per calcolare la probabilità a posteriori si procede come indicato di seguito.
<span style="background-color: #FFFF00">
Per ciascuno specifico valore <span class="math inline">\(\theta'\)</span> (ovvero, per ciascun elemento della griglia) è necessario moltiplicare l’ordinata della distribuzione di probabilità a priori in corrispondenza di <span class="math inline">\(\theta'\)</span> per l’ordinata della funzione di verosimiglianza in corrispondenza di <span class="math inline">\(\theta'\)</span>. Tale procedura va ripetuta per ciascun elemento della griglia.
</span>
C’è ovviamente bisogno di una griglia molto densa per ottenere buone approssimazioni.</p>
<p>Il metodo basato su griglia è, in primo luogo, un utile strumento didattico in quanto rende trasparente la logica del processo dell’aggiornamento Bayesiano. Per ragioni che vedremo in seguito, tale metodo non può essere usato per la stima di modelli complessi che includono un grande numero di parametri – ma non è questo il nostro scopo qui. Ma, al di là di questo limite del metodo basato su griglia, è importante sottolineare che, quale che sia il <em>metodo</em> che si usa per stimare la funzione a posteriori, il <em>significato</em> della funzione a posteriori non cambia ed è ben illustrato dall’esempio qui discusso.</p>
<p>Iniziamo a costruire la griglia di valori del parametro <span class="math inline">\(\theta\)</span>. In questo esempio considereremo 50 valori egualmente spaziati nell’intervallo [0, 1]: 0.000, 0.0204, …, 0.978, 1.000. Per ottenere i valori griglia procediamo nel modo seguente:</p>
<div class="sourceCode" id="cb216"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">n_points</span> <span class="op">&lt;-</span> <span class="fl">50</span>
<span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="va">n_points</span><span class="op">)</span>
<span class="va">p_grid</span>
<span class="co">#&gt;  [1] 0.00000000 0.02040816 0.04081633 0.06122449 0.08163265 0.10204082 0.12244898 0.14285714</span>
<span class="co">#&gt;  [9] 0.16326531 0.18367347 0.20408163 0.22448980 0.24489796 0.26530612 0.28571429 0.30612245</span>
<span class="co">#&gt; [17] 0.32653061 0.34693878 0.36734694 0.38775510 0.40816327 0.42857143 0.44897959 0.46938776</span>
<span class="co">#&gt; [25] 0.48979592 0.51020408 0.53061224 0.55102041 0.57142857 0.59183673 0.61224490 0.63265306</span>
<span class="co">#&gt; [33] 0.65306122 0.67346939 0.69387755 0.71428571 0.73469388 0.75510204 0.77551020 0.79591837</span>
<span class="co">#&gt; [41] 0.81632653 0.83673469 0.85714286 0.87755102 0.89795918 0.91836735 0.93877551 0.95918367</span>
<span class="co">#&gt; [49] 0.97959184 1.00000000</span></code></pre></div>
<div id="distribuzione-a-priori" class="section level3" number="24.5.1">
<h3>
<span class="header-section-number">24.5.1</span> Distribuzione a priori<a class="anchor" aria-label="anchor" href="#distribuzione-a-priori"><i class="fas fa-link"></i></a>
</h3>
<p>Supponiamo che le nostre credenze a priori sulla tendenza di un individuo clinicamente depresso a manifestare delle aspettative distorte negativamente circa il suo umore futuro siano molto scarse. Assumiamo quindi per <span class="math inline">\(\theta\)</span> una distribuzione a priori non informativa – ovvero, ipotizziamo che la distribuzione a priori sia una distribuzione uniforme nell’intervallo [0, 1]. Dato che consideriamo soltanto <span class="math inline">\(n = 50\)</span> valori possibili per il parametro <span class="math inline">\(\theta\)</span>, creiamo un vettore di 50 elementi che conterrà i valori della distribuzione a priori scalando ciascun valore del vettore per <span class="math inline">\(n\)</span> in modo tale che la somma di tutti i valori sia uguale a 1.0 (in questo modo viene definita una funzione di massa di probabilità):</p>
<div class="sourceCode" id="cb217"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">prior1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">dbeta</a></span><span class="op">(</span><span class="va">p_grid</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">dbeta</a></span><span class="op">(</span><span class="va">p_grid</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span>
<span class="va">prior1</span>
<span class="co">#&gt;  [1] 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02</span>
<span class="co">#&gt; [19] 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02</span>
<span class="co">#&gt; [37] 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02</span></code></pre></div>
<p>Verifichiamo:</p>
<div class="sourceCode" id="cb218"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">prior1</span><span class="op">)</span>
<span class="co">#&gt; [1] 1</span></code></pre></div>
<p>La distribuzione a priori così costruita è rappresentata nella figura <a href="modellistica-bayesiana.html#fig:gridappr1">24.3</a>.</p>
<div class="sourceCode" id="cb219"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">p1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">p_grid</span>, <span class="va">prior1</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">p_grid</span>, xend<span class="op">=</span><span class="va">p_grid</span>, y<span class="op">=</span><span class="fl">0</span>, yend<span class="op">=</span><span class="va">prior1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_segment.html">geom_segment</a></span><span class="op">(</span>color <span class="op">=</span> <span class="st">"#8184FC"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/lims.html">ylim</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.17</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>
    x <span class="op">=</span> <span class="st">"Parametro \U03B8"</span>,
    y <span class="op">=</span> <span class="st">"Probabilità a priori"</span>,
    title <span class="op">=</span> <span class="st">"50 punti"</span>
  <span class="op">)</span>
<span class="va">p1</span></code></pre></div>
<div class="figure" style="text-align: center">
<span id="fig:gridappr1"></span>
<img src="Data-Science-per-psicologi_files/figure-html/gridappr1-1.png" alt="Rappresentazione grafica della distribuzione a priori per il parametro $\theta$, ovvero la probabilità di aspettative future distorte negativamente [@zetsche_future_2019]." width="90%"><p class="caption">
Figura 24.3: Rappresentazione grafica della distribuzione a priori per il parametro <span class="math inline">\(\theta\)</span>, ovvero la probabilità di aspettative future distorte negativamente <span class="citation">(<a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">Zetsche et al., 2019</a>)</span>.
</p>
</div>
</div>
<div id="funzione-di-verosimiglianza" class="section level3" number="24.5.2">
<h3>
<span class="header-section-number">24.5.2</span> Funzione di verosimiglianza<a class="anchor" aria-label="anchor" href="#funzione-di-verosimiglianza"><i class="fas fa-link"></i></a>
</h3>
<p>Calcoliamo ora la funzione di verosimiglianza utilizzando i 50 valori griglia per <span class="math inline">\(\theta\)</span> che abbiamo definito in precedenza. Per ciascuno dei valori della griglia applichiamo la formula della probabilità binomiale, tendendo sempre costanti i valori dei dati (ovvero 23 “successi” in 30 prove).</p>
<p>Considderiamo, ad esempio, il valore griglia <span class="math inline">\(\theta = 0.816\)</span>. Per tale elemento della griglia l’ordinata della funzione di verosimiglianza è pari a</p>
<p><span class="math display">\[
\begin{aligned}
\binom{30}{23}&amp; \cdot 0.816^{23} \cdot (1 - 0.816)^{7} = 0.135.\notag
\end{aligned}
\]</span></p>
<p>Per fare un secondo esempio, consideriamo il valore griglia <span class="math inline">\(\theta = 0.837\)</span>. Per tale elemento della griglia l’ordinata della funzione di verosimiglianza è uguale a</p>
<p><span class="math display">\[
\begin{aligned}
\binom{30}{23}&amp; \cdot 0.837^{23} \cdot (1 - 0.837)^{7} = 0.104.\notag
\end{aligned}
\]</span></p>
<p>Dobbiamo svolgere questo calcolo per tutti gli elementi della griglia. Usando R il risultato cercato si trova nel modo seguente:</p>
<div class="sourceCode" id="cb220"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">23</span>, size <span class="op">=</span> <span class="fl">30</span>, prob <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span>
<span class="va">likelihood</span>
<span class="co">#&gt;  [1] 0.000000e+00 2.352564e-33 1.703051e-26 1.644169e-22 1.053708e-19 1.525217e-17 8.602222e-16</span>
<span class="co">#&gt;  [8] 2.528440e-14 4.606907e-13 5.819027e-12 5.499269e-11 4.105534e-10 2.520191e-09 1.311195e-08</span>
<span class="co">#&gt; [15] 5.919348e-08 2.362132e-07 8.456875e-07 2.749336e-06 8.196948e-06 2.259614e-05 5.798673e-05</span>
<span class="co">#&gt; [22] 1.393165e-04 3.148623e-04 6.720574e-04 1.359225e-03 2.611870e-03 4.778973e-03 8.340230e-03</span>
<span class="co">#&gt; [29] 1.390025e-02 2.214199e-02 3.372227e-02 4.909974e-02 6.830377e-02 9.068035e-02 1.146850e-01</span>
<span class="co">#&gt; [36] 1.378206e-01 1.568244e-01 1.681749e-01 1.688979e-01 1.575211e-01 1.348746e-01 1.043545e-01</span>
<span class="co">#&gt; [43] 7.133007e-02 4.165680e-02 1.972669e-02 6.936821e-03 1.535082e-03 1.473375e-04 1.868105e-06</span>
<span class="co">#&gt; [50] 0.000000e+00</span></code></pre></div>
<p>Il vettore <code>likelihood</code> è stato ottenuto passando alla funzione <code><a href="https://rdrr.io/r/stats/Binomial.html">dbinom()</a></code> un vettore di valori, ovvero gli elementi della griglia <code>p_grid</code>. La funzione <code><a href="https://rdrr.io/r/stats/Binomial.html">dbinom(x, size, prob)</a></code> richiede che vengano specificati tre parametri: il numero di “successi,” il numero di prove e la probabilità di successo. Dato che <code>x</code> (numero di successi) e <code>size</code> (numero di prove bernoulliane) sono degli scalari e <code>prob</code> è un vettore, questo significa che la formula della probabilità binomiale verrà applicata a ciascun elemento di <code>p_grid</code> tenendo costanti i valori di <code>x</code> e <code>size</code>, ovvero i dati. In questo modo otteniamo in output un vettore i cui valori corrispondono all’ordinata della funzione di verosimiglianza per il corrispondente valore griglia di <span class="math inline">\(\theta\)</span>. La funzione di verosimiglianza così ottenuta è riportata nella figura <a href="modellistica-bayesiana.html#fig:gridappr2">24.4</a>.</p>
<div class="sourceCode" id="cb221"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">p2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">p_grid</span>, <span class="va">likelihood</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">p_grid</span>, xend<span class="op">=</span><span class="va">p_grid</span>, y<span class="op">=</span><span class="fl">0</span>, yend<span class="op">=</span><span class="va">likelihood</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_segment.html">geom_segment</a></span><span class="op">(</span>color <span class="op">=</span> <span class="st">"#8184FC"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/lims.html">ylim</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.17</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>
    x <span class="op">=</span> <span class="st">"Parametro \U03B8"</span>,
    y <span class="op">=</span> <span class="st">"Verosimiglianza"</span>
  <span class="op">)</span>
<span class="va">p2</span></code></pre></div>
<div class="figure" style="text-align: center">
<span id="fig:gridappr2"></span>
<img src="Data-Science-per-psicologi_files/figure-html/gridappr2-1.png" alt="Rappresentazione della funzione di verosimiglianza per il parametro $\theta$, ovvero la probabilità di aspettative future distorte negativamente [@zetsche_future_2019]." width="90%"><p class="caption">
Figura 24.4: Rappresentazione della funzione di verosimiglianza per il parametro <span class="math inline">\(\theta\)</span>, ovvero la probabilità di aspettative future distorte negativamente <span class="citation">(<a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">Zetsche et al., 2019</a>)</span>.
</p>
</div>
</div>
<div id="la-stima-della-distribuzione-a-posteriori" class="section level3" number="24.5.3">
<h3>
<span class="header-section-number">24.5.3</span> La stima della distribuzione a posteriori<a class="anchor" aria-label="anchor" href="#la-stima-della-distribuzione-a-posteriori"><i class="fas fa-link"></i></a>
</h3>
<p>La distribuzione a posteriori per il parametro <span class="math inline">\(\theta\)</span> si ottiene facendo prima il prodotto della verosimiglianza e della distribuzione a priori, e poi scalando tale prodotto per una costante di normalizzazione. Quindi, se ci limitiamo a fare il prodotto dei valori della distribuzione a priori e dei valori della funzione di verosimiglianza otteniamo la funzione a posteriori <em>non standardizzata</em>.</p>
<p>Ricordiamo che, usando il metodo basato su griglia, stiamo manipolando funzioni di massa di probabilità. Ovvero, siamo in un “mondo discreto.” In questo contesto, una funzione di massa di probabilità non è altro che un’elenco di valori la cui somma deve essere uguale a 1.0. In un “mondo continuo,” invece, le probabilità sono definite in un modo completamente diverso: corrispondo all’area in un intervallo di valori sotteso alla funzione di densità. Ma nel nostro esempio corrente ci limitiamo al caso discreto in cui, per calcolare le probabilità, è sufficiente fare delle somme, non sono necessari gli integrali.</p>
<p>Nel caso presente abbiamo deciso di usare una distribuzione a priori non informativa, ovvero una distribuzione uniforme. Per ottenere la funzione a posteriori (di massa di probabilità) non standardizzata è dunque sufficiente moltiplicare ciascun valore della funzione di verosimiglianza per 0.02. Per esempio, per il primo valore della funzione di verosimiglianza che abbiamo discusso quale esempio nella sezione precedente, avremo</p>
<p><span class="math display">\[
0.135 \cdot 0.02;
\]</span></p>
<p>per il secondo valore della funzione di verosimiglianza che abbiamo discusso nell’esempio precedente avremo</p>
<p><span class="math display">\[
0.104 \cdot 0.02;
\]</span></p>
<p>e così via.</p>
<p>Usando R, possiamo svolgere tutti i calcoli necessari nel modo seguente:</p>
<div class="sourceCode" id="cb222"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">unstd_posterior</span> <span class="op">&lt;-</span> <span class="va">likelihood</span> <span class="op">*</span> <span class="va">prior1</span>
<span class="va">unstd_posterior</span>
<span class="co">#&gt;  [1] 0.000000e+00 4.705127e-35 3.406102e-28 3.288337e-24 2.107415e-21 3.050433e-19 1.720444e-17</span>
<span class="co">#&gt;  [8] 5.056880e-16 9.213813e-15 1.163805e-13 1.099854e-12 8.211068e-12 5.040382e-11 2.622390e-10</span>
<span class="co">#&gt; [15] 1.183870e-09 4.724263e-09 1.691375e-08 5.498671e-08 1.639390e-07 4.519229e-07 1.159735e-06</span>
<span class="co">#&gt; [22] 2.786331e-06 6.297247e-06 1.344115e-05 2.718450e-05 5.223741e-05 9.557946e-05 1.668046e-04</span>
<span class="co">#&gt; [29] 2.780049e-04 4.428398e-04 6.744454e-04 9.819948e-04 1.366075e-03 1.813607e-03 2.293700e-03</span>
<span class="co">#&gt; [36] 2.756411e-03 3.136488e-03 3.363497e-03 3.377958e-03 3.150422e-03 2.697491e-03 2.087091e-03</span>
<span class="co">#&gt; [43] 1.426601e-03 8.331361e-04 3.945339e-04 1.387364e-04 3.070164e-05 2.946751e-06 3.736209e-08</span>
<span class="co">#&gt; [50] 0.000000e+00</span></code></pre></div>
<p>Ricordiamo il principio dell’aritmetica vettorializzata: il vettore <code>likelihood</code> è costituito da 50 elementi e il vettore <code>prior1</code> è anch’esso costituito da 50 elementi. Se facciamo il prodotto tra i due vettori otteniamo un vettore di 50 elementi ciascuno dei quali uguale al prodotto dei corrispondenti elementi di <code>likelihood</code> e <code>prior1</code>.</p>
<p>Avendo calcolato i valori della funzione a posteriori non standardizzata è poi necessario dividere per una costante di normalizzazione. Nel caso discreto, trovare il denominatore del teorema di Bayes è molto facile: esso è dato semplicemente dalla somma di tutti i valori della distribuzione a posteriori non normalizzata. Per i dati presenti, tale costante di
normalizzazione è uguale a 0.032:</p>
<div class="sourceCode" id="cb223"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd_posterior</span><span class="op">)</span>
<span class="co">#&gt; [1] 0.0316129</span></code></pre></div>
<p>Per fare un esempio, standardizziamo i due valori che abbiamo discusso negli esempi precedenti: <span class="math inline">\(0.135 \cdot 0.02 / 0.032\)</span> e <span class="math inline">\(0.104 \cdot 0.02 / 0.032\)</span>.
Così facendo, otteniamo il risultato per cui la somma di tutti e 50 i valori della distribuzione a posteriori normalizzata diventa uguale a 1.0.</p>
<p>Svolgiamo tutti i calcoli in R:</p>
<div class="sourceCode" id="cb224"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">posterior</span> <span class="op">&lt;-</span> <span class="va">unstd_posterior</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd_posterior</span><span class="op">)</span>
<span class="va">posterior</span>
<span class="co">#&gt;  [1] 0.000000e+00 1.488357e-33 1.077440e-26 1.040188e-22 6.666313e-20 9.649330e-18 5.442222e-16</span>
<span class="co">#&gt;  [8] 1.599625e-14 2.914574e-13 3.681425e-12 3.479129e-11 2.597379e-10 1.594406e-09 8.295316e-09</span>
<span class="co">#&gt; [15] 3.744893e-08 1.494410e-07 5.350268e-07 1.739376e-06 5.185824e-06 1.429552e-05 3.668548e-05</span>
<span class="co">#&gt; [22] 8.813904e-05 1.991986e-04 4.251792e-04 8.599178e-04 1.652408e-03 3.023432e-03 5.276472e-03</span>
<span class="co">#&gt; [29] 8.794033e-03 1.400820e-02 2.133450e-02 3.106310e-02 4.321259e-02 5.736920e-02 7.255582e-02</span>
<span class="co">#&gt; [36] 8.719259e-02 9.921545e-02 1.063963e-01 1.068538e-01 9.965619e-02 8.532881e-02 6.602021e-02</span>
<span class="co">#&gt; [43] 4.512719e-02 2.635430e-02 1.248015e-02 4.388601e-03 9.711744e-04 9.321354e-05 1.181862e-06</span>
<span class="co">#&gt; [50] 0.000000e+00</span></code></pre></div>
<p>Verifichiamo:</p>
<div class="sourceCode" id="cb225"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">posterior</span><span class="op">)</span>
<span class="co">#&gt; [1] 1</span></code></pre></div>
<p>In questo particolare esempio, la distribuzione a posteriori trovata
come descritto sopra non è altro che la versione normalizzata della
funzione di verosimiglianza: questo avviene perché la distribuzione a
priori uniforme non ha aggiunto altre informazioni oltre a quelle che
erano già fornite dalla funzione di verosimiglianza.</p>
<p>La funzione a posteriori che abbiamo calcolato con il metodo <em>grid-based</em> è riportata nella figura <a href="modellistica-bayesiana.html#fig:gridappr3">24.5</a>.</p>
<div class="sourceCode" id="cb226"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">p3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">p_grid</span>, <span class="va">posterior</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">p_grid</span>, xend<span class="op">=</span><span class="va">p_grid</span>, y<span class="op">=</span><span class="fl">0</span>, yend<span class="op">=</span><span class="va">posterior</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_segment.html">geom_segment</a></span><span class="op">(</span>color <span class="op">=</span> <span class="st">"#8184FC"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/lims.html">ylim</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.17</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>
    x <span class="op">=</span> <span class="st">"Parametro \U03B8"</span>,
    y <span class="op">=</span> <span class="st">"Probabilità a posteriori"</span>
  <span class="op">)</span>
<span class="va">p3</span></code></pre></div>
<div class="figure" style="text-align: center">
<span id="fig:gridappr3"></span>
<img src="Data-Science-per-psicologi_files/figure-html/gridappr3-1.png" alt="Rappresentazione della distribuzione a posteriori per il parametro $\theta$, ovvero la probabilità di aspettative future distorte negativamente [@zetsche_future_2019]." width="90%"><p class="caption">
Figura 24.5: Rappresentazione della distribuzione a posteriori per il parametro <span class="math inline">\(\theta\)</span>, ovvero la probabilità di aspettative future distorte negativamente <span class="citation">(<a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">Zetsche et al., 2019</a>)</span>.
</p>
</div>
<p>Le funzioni rappresentate nelle figure <a href="modellistica-bayesiana.html#fig:gridappr1">24.3</a>, <a href="modellistica-bayesiana.html#fig:gridappr2">24.4</a> e <a href="modellistica-bayesiana.html#fig:gridappr3">24.5</a> sono state calcolate utilizzando una griglia di 50 valori equi-spaziati per il parametro <span class="math inline">\(\theta\)</span>. I segmenti verticali rappresentano l’intensità della funzione in corrispondenza di ciascuna modalità parametro <span class="math inline">\(\theta\)</span>. Nella figura <a href="modellistica-bayesiana.html#fig:gridappr1">24.3</a> e nella figura <a href="modellistica-bayesiana.html#fig:gridappr3">24.5</a> la somma delle lunghezze dei segmenti verticali è pari ad 1.0 (in altri termini, la funzione a priori e la funzione a posteriori sono delle funzioni di massa di probabilità, in questo esempio); ciò non si verifica, invece, nel caso della figura <a href="modellistica-bayesiana.html#fig:gridappr3">24.5</a> (la funzione di verosimiglianza non è mai una funzione di probabilità, né nel caso discreto né in quello continuo).</p>
</div>
<div id="la-stima-della-distribuzione-a-posteriori-versione-2" class="section level3" number="24.5.4">
<h3>
<span class="header-section-number">24.5.4</span> La stima della distribuzione a posteriori (versione 2)<a class="anchor" aria-label="anchor" href="#la-stima-della-distribuzione-a-posteriori-versione-2"><i class="fas fa-link"></i></a>
</h3>
<p>Continuiamo la discussione dell’esempio precedente ed esaminiamo l’impatto sulla distribuzione a posteriori di una distribuzione a priori informativa. Una distribuzione a priori informativa riflette un alto grado di certezza sui parametri del modello da stimare.
Un ricercatore può utilizzare una distribuzione a priori informativa per introdurre nel processo di stima le informazioni esistenti che suggeriscono delle restrizioni sulla possibile gamma di valori di un particolare parametro.</p>
<p>Nel caso presente, supponiamo che la letteratura psicologica fornisca delle informazioni a proposito del valore di <span class="math inline">\(\theta\)</span>, ovvero ci fornisca delle informazioni sul valore della probabilità che le aspettative future di un individuo clinicamente depresso siano distorte negativamente – in altri termini, sono già state svolte ricerche precedenti su questo aspetto e risultati empirici sono già stati raccolti: in una serie di ricerche precedenti è stato trovato che <span class="math inline">\(\theta\)</span> assumeva valori compresi in una certa gamma. In tali circostanze, anziché utilizzare una distribuzione a priori non informativa per <span class="math inline">\(p(\theta)\)</span>, il ricercatore può decidere di utilizzare una distribuzione a priori informativa che riflette le conoscenze che sono state acquisite in precedenza sul possibile valore del parametro. Nel caso presente, supponiamo (irrealisticamente) che tali conoscenze pregresse si possano esprimere nei termini di una distribuzione che ha la forma di una Beta di parametri <span class="math inline">\(\alpha = 2\)</span> e <span class="math inline">\(\beta = 10\)</span>. Tali ipotetiche conoscenze pregresse (ripeto, del tutto irrealistiche) le quali si riflettono in una Beta(2, 10) ritengono molto plausibili valori bassi di <span class="math inline">\(\theta\)</span> e considerano come impossibili i valori <span class="math inline">\(\theta\)</span> superiori a 0.5. Questo è equivalente a dire che ci aspettiamo che le aspettative relative all’umore futuro siano distorte negativamente solo per pochissimi individui clinicamente depressi – in altre parole, ci aspettiamo che la maggioranza degli individui clinicamente depressi sia inguaribilmente ottimista. Questa è, ovviamente, una credenza a priori del tutto irrealistica. La esamino qui, non perché abbia alcun senso nel contesto dei dati di <span class="citation"><a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">Zetsche et al.</a> (<a href="bibliografia.html#ref-zetsche_future_2019" role="doc-biblioref">2019</a>)</span>, ma soltanto per fare un esempio che illustra come la distribuzione a posteriori fornisca una sorta di “compromesso” tra la distribuzione a priori e la verosimiglianza, ovvero per chiarire l’impatto che la distribuzione a priori ha sulla distribuzione a posteriori.</p>
<p>Con calcoli del tutto simili a quelli descritti sopra si giunge alla distribuzione a posteriori rappresentata nella figura <a href="modellistica-bayesiana.html#fig:gridappr4">24.6</a>. Iniziamo a definire una griglia
unidimensionale equispaziata di possibili valori del parametro <span class="math inline">\(\theta\)</span>. Anche in questo caso usiamo 50 valori possibili del parametro <span class="math inline">\(\theta\)</span>:</p>
<div class="sourceCode" id="cb227"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">n_points</span> <span class="op">&lt;-</span> <span class="fl">50</span>
<span class="va">p_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">0</span>, to <span class="op">=</span> <span class="fl">1</span>, length.out <span class="op">=</span> <span class="va">n_points</span><span class="op">)</span></code></pre></div>
<p>Per la distribuzione a priori scelgo una Beta(2, 10).</p>
<div class="sourceCode" id="cb228"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">alpha</span> <span class="op">&lt;-</span> <span class="fl">2</span>
<span class="va">beta</span> <span class="op">&lt;-</span> <span class="fl">10</span>
<span class="va">prior2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">dbeta</a></span><span class="op">(</span><span class="va">p_grid</span>, <span class="va">alpha</span>, <span class="va">beta</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Beta.html">dbeta</a></span><span class="op">(</span><span class="va">p_grid</span>, <span class="va">alpha</span>, <span class="va">beta</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">prior2</span><span class="op">)</span>
<span class="co">#&gt; [1] 1</span></code></pre></div>
<p>Tale distribuzione a priori è rappresentata nella figura
<a href="modellistica-bayesiana.html#fig:gridappr4">24.6</a>.</p>
<div class="sourceCode" id="cb229"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">plot_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">p_grid</span>, <span class="va">prior2</span><span class="op">)</span>
<span class="va">p4</span> <span class="op">&lt;-</span> <span class="va">plot_df</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">p_grid</span>, xend<span class="op">=</span><span class="va">p_grid</span>, y<span class="op">=</span><span class="fl">0</span>, yend<span class="op">=</span><span class="va">prior2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_segment.html">geom_segment</a></span><span class="op">(</span>color <span class="op">=</span> <span class="st">"#8184FC"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/lims.html">ylim</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.17</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>
    x <span class="op">=</span> <span class="st">""</span>,
    y <span class="op">=</span> <span class="st">"Probabilità a priori"</span>,
    title <span class="op">=</span> <span class="st">"50 punti"</span>
  <span class="op">)</span>
<span class="va">p4</span></code></pre></div>
<div class="figure" style="text-align: center">
<span id="fig:gridappr4"></span>
<img src="Data-Science-per-psicologi_files/figure-html/gridappr4-1.png" alt="Rappresentazione di una funzione a priori informativa per il parametro $\theta$." width="90%"><p class="caption">
Figura 24.6: Rappresentazione di una funzione a priori informativa per il parametro <span class="math inline">\(\theta\)</span>.
</p>
</div>
<p>Calcoliamo il valore della funzione di verosimiglianza in corrispondenza
di ciascun punto della griglia. La funzione di verosimiglianza è
identica a quella considerata nell’esempio precedente.</p>
<div class="sourceCode" id="cb230"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">likelihood</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">23</span>, size <span class="op">=</span> <span class="fl">30</span>, prob <span class="op">=</span> <span class="va">p_grid</span><span class="op">)</span></code></pre></div>
<p>Calcolo il prodotto tra la verosimiglianza e la distribuzione a priori,
per ciascun punto della griglia:</p>
<div class="sourceCode" id="cb231"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">unstd_posterior2</span> <span class="op">&lt;-</span> <span class="va">likelihood</span> <span class="op">*</span> <span class="va">prior2</span></code></pre></div>
<p>Normalizzo la distribuzione a posteriori in modo tale che la somma sia
1.</p>
<div class="sourceCode" id="cb232"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">posterior2</span> <span class="op">&lt;-</span> <span class="va">unstd_posterior2</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">unstd_posterior2</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">posterior2</span><span class="op">)</span>
<span class="co">#&gt; [1] 1</span></code></pre></div>
<p>La nuova funzione a posteriori è rappresentata nella figura
<a href="modellistica-bayesiana.html#fig:gridappr5">24.7</a>.</p>
<div class="sourceCode" id="cb233"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">plot_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">p_grid</span>, <span class="va">posterior2</span><span class="op">)</span>
<span class="va">p5</span> <span class="op">&lt;-</span> <span class="va">plot_df</span> <span class="op">%&gt;%</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">p_grid</span>, xend <span class="op">=</span> <span class="va">p_grid</span>, y <span class="op">=</span> <span class="fl">0</span>, yend <span class="op">=</span> <span class="va">posterior2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_segment.html">geom_segment</a></span><span class="op">(</span>color <span class="op">=</span> <span class="st">"#8184FC"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/lims.html">ylim</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.17</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>
    x <span class="op">=</span> <span class="st">"Parametro \U03B8"</span>,
    y <span class="op">=</span> <span class="st">"Probabilità a posteriori"</span>
  <span class="op">)</span>
<span class="va">p5</span></code></pre></div>
<div class="figure" style="text-align: center">
<span id="fig:gridappr5"></span>
<img src="Data-Science-per-psicologi_files/figure-html/gridappr5-1.png" alt="Rappresentazione della funzione a posteriori per il parametro $\theta$ calcolata utilizzando una distribuzione a priori informativa." width="90%"><p class="caption">
Figura 24.7: Rappresentazione della funzione a posteriori per il parametro <span class="math inline">\(\theta\)</span> calcolata utilizzando una distribuzione a priori informativa.
</p>
</div>
<p>Facendo un confronto tra le figure <a href="modellistica-bayesiana.html#fig:gridappr4">24.6</a> e
<a href="modellistica-bayesiana.html#fig:gridappr5">24.7</a> si nota come la distribuzione a priori per il
parametro <span class="math inline">\(\theta\)</span> e la distribuzione a posteriori per il parametro
<span class="math inline">\(\theta\)</span> sono molto diverse. In particolare, si noti che la
distribuzione a posteriori rappresentata nella <a href="modellistica-bayesiana.html#fig:gridappr5">24.7</a>
risulta spostata verso destra su posizioni più vicine a quelle della
verosimiglianza, rappresentata nella figura <a href="modellistica-bayesiana.html#fig:gridappr2">24.4</a>. Si
noti anche, a causa dell’effetto della distribuzione a priori, le
distribuzioni a posteriori riportate nelle figure <a href="modellistica-bayesiana.html#fig:gridappr3">24.5</a> e
<a href="modellistica-bayesiana.html#fig:gridappr5">24.7</a> sono molto diverse tra loro. Discuteremo in seguito
l’influenza della distribuzione a priori sull’inferenza finale.</p>
</div>
<div id="sommario-della-funzione-a-posteriori" class="section level3" number="24.5.5">
<h3>
<span class="header-section-number">24.5.5</span> Sommario della funzione a posteriori<a class="anchor" aria-label="anchor" href="#sommario-della-funzione-a-posteriori"><i class="fas fa-link"></i></a>
</h3>
<p>Una volta calcolata la distribuzione a posteriori dobbiamo riassumerla
in qualche modo. Nel caso in cui venga usato un metodo <em>grid-based</em>, il
problema del calcolo delle aree sottese alla funzione a posteriori in
qualunque intervallo può essere risolto in vari modi. Tuttavia, questo
problema trova una soluzione molto più semplice se viene utilizzato un
metodo diverso per la stima della distribuzione a posteriori, come
vedremo di seguito. Non discuteremo dunque la possibile soluzione di
questo problema nel caso presente, in quanto il metodo metodo
<em>grid-based</em> per il calcolo della distribuzione a posteriori è solo un
esempio didattico.</p>
</div>
</div>
<div id="differenza-tra-intervalli-di-confidenza-e-di-credibilità" class="section level2" number="24.6">
<h2>
<span class="header-section-number">24.6</span> Differenza tra intervalli di confidenza e di credibilità<a class="anchor" aria-label="anchor" href="#differenza-tra-intervalli-di-confidenza-e-di-credibilit%C3%A0"><i class="fas fa-link"></i></a>
</h2>
<p>L’approccio frequentista generalmente ipotizza che il mondo abbia certe proprietà (ad esempio, un parametro viene assunto che un dato parametro ha un particolare valore vero) e cercano di condurre esperimenti la cui conclusione risultante sarà corretta con almeno un livello minimo di probabilità. Per esprimere l’incertezza della nostra conoscenza dopo un esperimento, l’approccio frequentista utilizza un “intervallo di confidenza” – ovvero, un intervallo di valori progettato per includere il vero valore del parametro con una probabilità minima, diciamo il 95%. Un frequentista progetterà l’esperimento e la procedura di calcolo dell’intervallo di confidenza al 95% in modo tale che su ogni 100 esperimenti eseguiti si prevede che almeno 95 degli intervalli di confidenza risultanti includano il vero valore del parametro; gli altri 5 potrebbero essere leggermente sbagliati, o potrebbero essere del tutto assurdi. Dal punto di vista dell’approccio frequentista, questo è accettabile, purché 95 inferenze su 100 siano corrette (ma ovviamente noi preferiremmo che i 5 risultati sbagliati fossero leggermente sbagliati, non totalmente assurdi).</p>
<p>L’approccio Bayesiano formula il problema in modo diverso. Invece di dire che il parametro ha un valore vero (ma sconosciuto), il metodo Bayesiano dice che, prima di eseguire l’esperimento, è possibile assegnare una distribuzione di probabilità, che chiamano stato di credenza, a quello che è il vero valore del parametro. Questa distribuzione a priori potrebbe essere nota (per esempio, sappiamo che la distribuzione dei punteggi del QI è normale con media 100 e deviazione standard 15) o potrebbe essere del tutto arbitraria. L’inferenza Bayesiana è semplice: si raccolgono alcuni dati e si calcola la probabilità di diversi valori del parametro <strong>dati</strong> i dati. Questa nuova distribuzione di probabilità è chiamata “distribuzione a posteriori.” L’approccio Bayesiano riassumere l’incertezza descrivendo un intervallo di valori sulla distribuzione di probabilità a posteriori che include il 95% della probabilità – questo intervallo è chiamato “intervallo di credibilità del 95%.”</p>
<p>Un proponente dell’approccio Bayesiano potrebbe criticare l’intervallo di confidenza frequentista in questo modo: “Perché dovrei dare importanza al fatto che 95 esperimenti su 100 producono un intervallo di confidenza che include il vero valore del parametro sconosciuto? Non mi interessano 95 esperimenti <strong>che non ho eseguito</strong>; mi interessa l’unico esperimento <strong>che ho effettivamente eseguito</strong>. La regola decisionale frequentista consente che 5 risultati su 100 siano completamente privi di senso [es., valori negativi, valori impossibili] purché gli altri 95 siano corretti. Ma questo è inaccettabile.”</p>
<p>Un proponente dell’approccio frequentista potrebbe criticare l’intervallo di credibilità Bayesiano in questo modo: “Perché dovrei dare importanza al fatto che il 95% della probabilità a posteriori è incluso in un dato intervallo? La risposta Bayesiana è corretta solo se la distribuzione a priori è corretta. Ma chi mi garantisce che tale distribuzione non sia stata scelta in un modo del tutto inappropriato?”</p>
<p>Vorrei rendere esplicito il fatto che, in questo insegnamento, io mi schiero in maniera chiara a favore dell’approccio Bayesiano. La critica che i Bayesiani rivolgono all’approccio frequentista mi sembra sensata. La critica che i frequentisti rivolgono all’approccio Bayesiano mi sembra, invece, debole e poco convincente. Spero che ciò che verrà detto in seguito chiarirà questo punto.</p>
</div>
<div id="conclusioni-10" class="section level2 unnumbered">
<h2>Conclusioni<a class="anchor" aria-label="anchor" href="#conclusioni-10"><i class="fas fa-link"></i></a>
</h2>
<p>Possiamo specificare un modello Bayesiano definendo una distribuzione congiunta su variabili osservate, <span class="math inline">\(\mathcal Y\)</span>, e un insieme di parametri sconosciuti, <span class="math inline">\(\theta\)</span>.</p>
<p><span class="math display">\[
p(\mathcal Y, \theta).
\]</span>
Questa distribuzione congiunta si decompone convenientemente in due termini,</p>
<p><span class="math display">\[
  p(\mathcal Y, \theta) = p(\theta)  p(\mathcal Y \mid \theta).
\]</span></p>
<p>Il primo termine, <span class="math inline">\(p(\theta)\)</span>, è la densità a priori e codifica l’insieme di valori plausibili dei parametri, con i valori più plausibili aventi una densità maggiore. È chiamato “a priori” perché racchiude la nostra conoscenza - e la sua mancanza - sui parametri da stimare prima di osservare i dati. Il secondo termine, <span class="math inline">\(p(\mathcal Y \mid \theta)\)</span>, è la verosimiglianza. Dati i parametri del modello <span class="math inline">\(\theta\)</span>, <span class="math inline">\(p(\mathcal Y \mid \theta)\)</span> definisce il processo di generazione per <span class="math inline">\(\mathcal Y\)</span>.</p>
<p>L’inferenza esegue il <em>reverse engineering</em> del processo di generazione dei dati e si chiede:</p>
<blockquote>
<p>dato un modello e un campione di osservazioni, <span class="math inline">\(\mathcal Y\)</span>, quali sono i valori più plausibili dei parametri che potrebbero aver generato le osservazioni?</p>
</blockquote>
<p>In un contesto Bayesiano, l’insieme dei valori plausibili dei parametri condizionati ai dati è caratterizzato dalla distribuzione a posteriori, <span class="math inline">\(p(\theta \mid \mathcal Y)\)</span>. La regola di Bayes stabilisce che</p>
<p><span class="math display">\[
  p(\theta \mid \mathcal Y) \propto p(\theta)  p(\mathcal Y \mid \theta),
\]</span></p>
<p>dove <span class="math inline">\(\propto\)</span> sta per “proporzionale a” e indica che la distribuzione a posteriori combina le informazioni fornite dai dati e la nostra conoscenza precedente. Un’espressione analitica per <span class="math inline">\(p(\theta \mid \mathcal Y)\)</span> è raramente disponibile e dobbiamo fare affidamento su algoritmi di calcolo numerico per conoscere la distribuzione a posteriori. Una strategia generale che esamineremo in seguito consiste nel prelevare campioni approssimativi dalla distribuzione a posteriori e utilizzarli per costruire stime empiriche della media a posteriori, della varianza, della mediana, dei quantili e di altre quantità di interesse. Qui abbiamo presentato il metodo <em>grid-based</em> per il calcolo della distribuzione a posteriori. I metodi basati su griglia funzionano benissimo quando la distribuzione a posteriori dipende da un numero molto piccolo di parametri sconosciuti, ma non possono essere usati nel caso di modelli statistici più complessi che includono un numero maggiore di parametri.</p>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="introduzione-4.html">Introduzione</a></div>
<div class="next"><a href="stima-della-funzione-a-posteriori.html"><span class="header-section-number">25</span> Stima della funzione a posteriori</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#modellistica-bayesiana"><span class="header-section-number">24</span> Modellistica bayesiana</a></li>
<li><a class="nav-link" href="#modelli-statistici"><span class="header-section-number">24.1</span> Modelli statistici</a></li>
<li><a class="nav-link" href="#notazine"><span class="header-section-number">24.2</span> Notazine</a></li>
<li>
<a class="nav-link" href="#parametri-e-distribuzioni-a-priori"><span class="header-section-number">24.3</span> Parametri e distribuzioni a priori</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#cos%C3%A8-un-parametro-del-modello"><span class="header-section-number">24.3.1</span> Cos’è un parametro del modello?</a></li>
<li><a class="nav-link" href="#distribuzione-a-priori-sui-parametri"><span class="header-section-number">24.3.2</span> Distribuzione a priori sui parametri</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#procedura-bayesiana-di-stima-dei-parametri"><span class="header-section-number">24.4</span> Procedura Bayesiana di stima dei parametri</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#finalit%C3%A0"><span class="header-section-number">24.4.1</span> Finalità</a></li>
<li><a class="nav-link" href="#metodi"><span class="header-section-number">24.4.2</span> Metodi</a></li>
<li><a class="nav-link" href="#terminologia-2"><span class="header-section-number">24.4.3</span> Terminologia</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#le-aspettative-dei-pazienti-con-disturbo-depressivo-maggiore"><span class="header-section-number">24.5</span> Le aspettative dei pazienti con disturbo depressivo maggiore</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#distribuzione-a-priori"><span class="header-section-number">24.5.1</span> Distribuzione a priori</a></li>
<li><a class="nav-link" href="#funzione-di-verosimiglianza"><span class="header-section-number">24.5.2</span> Funzione di verosimiglianza</a></li>
<li><a class="nav-link" href="#la-stima-della-distribuzione-a-posteriori"><span class="header-section-number">24.5.3</span> La stima della distribuzione a posteriori</a></li>
<li><a class="nav-link" href="#la-stima-della-distribuzione-a-posteriori-versione-2"><span class="header-section-number">24.5.4</span> La stima della distribuzione a posteriori (versione 2)</a></li>
<li><a class="nav-link" href="#sommario-della-funzione-a-posteriori"><span class="header-section-number">24.5.5</span> Sommario della funzione a posteriori</a></li>
</ul>
</li>
<li><a class="nav-link" href="#differenza-tra-intervalli-di-confidenza-e-di-credibilit%C3%A0"><span class="header-section-number">24.6</span> Differenza tra intervalli di confidenza e di credibilità</a></li>
<li><a class="nav-link" href="#conclusioni-10">Conclusioni</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Data Science per psicologi</strong>" was written by Corrado Caudek. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
