<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Capitolo 18 Covarianza | Data Science per psicologi</title>
<meta name="author" content="Corrado Caudek">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.7.3/header-attrs.js"></script><script src="libs/jquery-3.5.1/jquery-3.5.1.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.5.3/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.5.3/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.4/tabs.js"></script><script src="libs/bs3compat-0.2.4/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Data Science per psicologi</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Benvenuti</a></li>
<li class="book-part">Obiettivi formativi</li>
<li><a class="" href="conoscenza-dichiarativa-e-imperativa.html"><span class="header-section-number">1</span> Conoscenza dichiarativa e imperativa</a></li>
<li class="book-part">Introduzione al linguaggio R</li>
<li><a class="" href="introduzione.html">Introduzione</a></li>
<li><a class="" href="chapter-pacchetti.html"><span class="header-section-number">2</span> Pacchetti</a></li>
<li><a class="" href="chapter-install-r.html"><span class="header-section-number">3</span> Per cominciare</a></li>
<li><a class="" href="chapter-sintassi.html"><span class="header-section-number">4</span> Sintassi di base</a></li>
<li><a class="" href="chapter-strutture-dati.html"><span class="header-section-number">5</span> Strutture di dati</a></li>
<li><a class="" href="chapter-strut-contr.html"><span class="header-section-number">6</span> Strutture di controllo</a></li>
<li><a class="" href="chapter-input-output.html"><span class="header-section-number">7</span> Input/Output</a></li>
<li><a class="" href="manipolazione-dei-dati.html"><span class="header-section-number">8</span> Manipolazione dei dati</a></li>
<li><a class="" href="flusso-di-lavoro-riproducibile.html"><span class="header-section-number">9</span> Flusso di lavoro riproducibile</a></li>
<li class="book-part">Statistica descrittiva ed analisi esplorativa dei dat̀i</li>
<li><a class="" href="introduzione-1.html">Introduzione</a></li>
<li><a class="" href="terminologia.html"><span class="header-section-number">10</span> Terminologia</a></li>
<li><a class="" href="chapter-misurazione.html"><span class="header-section-number">11</span> La misurazione in psicologia</a></li>
<li><a class="" href="chapter-descript.html"><span class="header-section-number">12</span> Statistica descrittiva</a></li>
<li class="book-part">Nozioni di base</li>
<li><a class="" href="introduzione-2.html">Introduzione</a></li>
<li><a class="" href="il-calcolo-delle-probabilit%C3%A0.html"><span class="header-section-number">13</span> Il calcolo delle probabilità</a></li>
<li><a class="" href="chapter-prob-cond.html"><span class="header-section-number">14</span> Probabilità condizionata</a></li>
<li><a class="" href="chapter-teo-bayes.html"><span class="header-section-number">15</span> Il teorema di Bayes</a></li>
<li><a class="" href="chapter-prob-congiunta.html"><span class="header-section-number">16</span> Probabilità congiunta</a></li>
<li><a class="" href="valore-atteso-e-varianza-di-variabili-aleatorie-discrete.html"><span class="header-section-number">17</span> Valore atteso e varianza di variabili aleatorie discrete</a></li>
<li><a class="active" href="covarianza-1.html"><span class="header-section-number">18</span> Covarianza</a></li>
<li><a class="" href="la-distribuzione-binomiale.html"><span class="header-section-number">19</span> La distribuzione binomiale</a></li>
<li><a class="" href="funzioni-di-densit%C3%A0-di-probabilit%C3%A0.html"><span class="header-section-number">20</span> Funzioni di densità di probabilità</a></li>
<li><a class="" href="la-funzione-di-verosimiglianza.html"><span class="header-section-number">21</span> La funzione di verosimiglianza</a></li>
<li class="book-part">Inferenza frequentista</li>
<li><a class="" href="introduzione-3.html">Introduzione</a></li>
<li><a class="" href="distribuzione-campionaria.html"><span class="header-section-number">22</span> Distribuzione campionaria</a></li>
<li><a class="" href="significativit%C3%A0-statistica.html"><span class="header-section-number">23</span> Significatività statistica</a></li>
<li><a class="" href="inferenza-sulle-medie.html"><span class="header-section-number">24</span> Inferenza sulle medie</a></li>
<li><a class="" href="critiche-e-difese.html"><span class="header-section-number">25</span> Critiche e difese</a></li>
<li class="book-part">Inferenza Bayesiana</li>
<li><a class="" href="introduzione-4.html">Introduzione</a></li>
<li><a class="" href="modellistica-bayesiana.html"><span class="header-section-number">26</span> Modellistica bayesiana</a></li>
<li><a class="" href="stima-della-funzione-a-posteriori.html"><span class="header-section-number">27</span> Stima della funzione a posteriori</a></li>
<li><a class="" href="sintesi-a-posteriori.html"><span class="header-section-number">28</span> Sintesi a posteriori</a></li>
<li><a class="" href="una-breve-introduzione-al-modello-di-regressione.html"><span class="header-section-number">29</span> Una breve introduzione al modello di regressione</a></li>
<li><a class="" href="il-modello-statistico-della-regressione-lineare.html"><span class="header-section-number">30</span> Il modello statistico della regressione lineare</a></li>
<li><a class="" href="inferenza-bayesiana.html"><span class="header-section-number">31</span> Inferenza Bayesiana</a></li>
<li class="book-part">Informazioni generali</li>
<li><a class="" href="citazione.html">Citazione</a></li>
<li class="book-part">Appendici</li>
<li><a class="" href="un-piccolo-ripasso.html">Un piccolo ripasso</a></li>
<li><a class="" href="bibliografia.html">Bibliografia</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="covarianza-1" class="section level1" number="18">
<h1>
<span class="header-section-number">Capitolo 18</span> Covarianza<a class="anchor" aria-label="anchor" href="#covarianza-1"><i class="fas fa-link"></i></a>
</h1>
<p>Le domande più interessanti dell’analisi dei dati riguardano non tanto
la descrizione del comportamento di una variabile considerata
indipendentemente dalle altre, quanto bensì l’associazione tra due (o
più) variabili. Vedremo in seguito come, per descrivere l’associazione
tra più variabili, è necessario fare uso di un <em>modello statistico</em>. Nel
caso più semplice, però, possiamo considerare l’associazione lineare tra
due sole variabili. La teoria della probabilità ci mette a disposizione
due strumenti per affrontare il problema di descrivere l’associazione
lineare tra due variabili: il concetto di covarianza e il concetto di
correlazione. Abbiamo già incontrato questi concetti quando abbiamo
descritto le proprietà di un campione. Ora li consideriamo nuovamente
nel contesto della discussione delle variabili aleatorie.</p>
<div id="covarianza" class="section level2" number="18.1">
<h2>
<span class="header-section-number">18.1</span> Covarianza<a class="anchor" aria-label="anchor" href="#covarianza"><i class="fas fa-link"></i></a>
</h2>
<p>La covarianza quantifica la tendenza delle variabili aleatorie <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>
a “variare assieme.” Per esempio, l’altezza e il peso delle giraffe
producono una covarianza positiva perché all’aumentare di una di queste
due quantità tende ad aumentare anche l’altra. La covarianza misura la
forza e la direzione del legame lineare tra due variabili aleatorie <span class="math inline">\(X\)</span>
ed <span class="math inline">\(Y\)</span>. Si utilizza la notazione <span class="math inline">\(Cov(X,Y)=\sigma_{xy}\)</span>.</p>

<div class="definition">
<span id="def:defcovariane" class="definition"><strong>Definizione 18.1  </strong></span>Date due variabili aleatorie <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>, chiamiamo covarianza tra <span class="math inline">\(X\)</span> ed
<span class="math inline">\(Y\)</span> il numero
<span class="math display" id="eq:covariancedef">\[\begin{equation}
Cov(X,Y) = \mathbb{E}\Bigl(\bigl(X - \mathbb{E}(X)\bigr) \bigl(Y - \mathbb{E}(Y)\bigr)\Bigr),
\tag{18.1}
\end{equation}\]</span>
dove <span class="math inline">\(\mathbb{E}(X)\)</span> e <span class="math inline">\(\mathbb{E}(Y)\)</span> sono i valori attesi di <span class="math inline">\(X\)</span> ed <span class="math inline">\(Y\)</span>.
</div>
<p><br></p>
<p>Scritta in forma esplicita, l’eq. <a href="covarianza-1.html#eq:covariancedef">(18.1)</a> diventa
<span class="math display">\[
Cov(X,Y) = \sum_{(x,y) \in \Omega} (x - \mu_X) (y - \mu_Y) f(x, y).
\]</span>
La definizione è analoga, algebricamente, a quella di varianza e risulta infatti
<span class="math display">\[
Var(x) = Cov(X, X)
\]</span>
e
<span class="math display" id="eq:covariancealt">\[\begin{equation}
Cov(X,Y) = \mathbb{E}(XY) - \mathbb{E}(Y)\mathbb{E}(X).
\tag{18.2}
\end{equation}\]</span></p>

<div class="proof">
 <span class="proof"><em>Dimostrazione. </em></span> La precedente proprietà si dimostra nel modo seguente:
<span class="math display">\[
\begin{aligned}
Cov(X,Y) &amp;= \mathbb{E}\Bigl(\bigl(X-\mathbb{E}(X)\bigr) \bigl(Y-\mathbb{E}(Y)\bigr)\Bigr)\notag\\
          %&amp;= \mathbb{E}(XY) - \mathbb{E}(Y)X -\mathbb{E}(X)Y + \mathbb{E}(X)\mathbb{E}(Y) )\notag\\
          &amp;= \mathbb{E}(XY) - \mathbb{E}(Y)\mathbb{E}(X) - \mathbb{E}(X)\mathbb{E}(Y) + \mathbb{E}(X)\mathbb{E}(Y)\notag\\
          &amp;= \mathbb{E}(XY) - \mathbb{E}(Y)\mathbb{E}(X)\notag.
\end{aligned}
\]</span> 
</div>
<p>Consideriamo il seguente esempio.
Supponiamo che <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> abbiano la funzione di massa di probabilità
congiunta riportata nella tabella che ripetiamo qui sotto e si riferisce all’esercizio sul lancio di tre monete che abbiamo discusso in precedenza. Si
calcoli la covarianza di <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>.</p>
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th align="center">x / y</th>
<th align="center">0</th>
<th align="center">1</th>
<th align="center">p(x)</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center">0</td>
<td align="center">1/8</td>
<td align="center">0</td>
<td align="center">1/8</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">2/8</td>
<td align="center">1/8</td>
<td align="center">3/8</td>
</tr>
<tr class="odd">
<td align="center">2</td>
<td align="center">1/8</td>
<td align="center">2/8</td>
<td align="center">3/8</td>
</tr>
<tr class="even">
<td align="center">3</td>
<td align="center">0</td>
<td align="center">1/8</td>
<td align="center">1/8</td>
</tr>
<tr class="odd">
<td align="center"><strong>p(y)</strong></td>
<td align="center">4/8</td>
<td align="center">4/8</td>
<td align="center">1.0</td>
</tr>
</tbody>
</table></div>
<p>Applichiamo l’eq. <a href="covarianza-1.html#eq:covariancedef">(18.1)</a>. Abbiamo che <span class="math inline">\(\mu_X = 1.5\)</span> e <span class="math inline">\(\mu_Y = 0.5\)</span>. Ne
segue che la covarianza di <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> è:</p>
<p><span class="math display">\[\begin{equation}
\begin{aligned}
Cov(X,Y) &amp;= \sum_{(x,y) \in\ \Omega} (x - \mu_X) (y - \mu_Y) f(x, y)\\
         &amp;= (0-1.5)(0-0.5)\cdot \frac{1}{8} + (0-1.5)(1-0.5) \cdot 0 \\
         &amp; \quad + (1-1.5)(0-0.5)\cdot \frac{2}{8} + (1-1.5)(1-0.5) \cdot \frac{1}{8} \\
         &amp; \quad + (2-1.5)(0-0.5) \cdot \frac{1}{8} + (2-1.5)(1-0.5) \cdot \frac{2}{8} \\
         &amp; \quad + (3-1.5)(0-0.5) \cdot 0 +  (3-1.5)(1-0.5)\cdot\frac{1}{8} \\
         &amp;= \frac{1}{4}. \notag
 \end{aligned}
\end{equation}\]</span></p>
<p>Lo stesso risultato può essere trovato utilizzando l’equazione <a href="covarianza-1.html#eq:covariancealt">(18.2)</a>. Iniziamo a calcolare il valore atteso del prodotto <span class="math inline">\(XY\)</span>:</p>
<p><span class="math display">\[
\mathbb{E}(XY) = 0 \cdot\frac{4}{8} + 1 \cdot\frac{1}{8} + 2 \cdot\frac{2}{8} + 3 \cdot\frac{1}{8} = 1.0.
\]</span></p>
<p>Pertanto la covarianza tra <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> diventa
<span class="math display">\[
\begin{aligned}
 Cov(X,Y) &amp;= \mathbb{E}(XY) - \mathbb{E}(X)\mathbb{E}(Y)\notag\\ 
 &amp;= 1 -  1.5\cdot 0.5 \notag\\ 
 &amp;= 0.25.\notag
\end{aligned}
\]</span></p>
<div id="interpretazione-della-covarianza" class="section level3" number="18.1.1">
<h3>
<span class="header-section-number">18.1.1</span> Interpretazione della covarianza<a class="anchor" aria-label="anchor" href="#interpretazione-della-covarianza"><i class="fas fa-link"></i></a>
</h3>
<p>Per fornire un’interpretazione geometrica al concetto di covarianza, iniziamo con il rappresentare mediante un diagramma a dispersione le otto coppie <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span> della tabella che rappresenta la distribuzione della probabilità congiunta nell’esperimento del lancio di tre monete ponendo <span class="math inline">\(X\)</span> sull’asse delle ascisse e <span class="math inline">\(Y\)</span> sull’asse delle ordinate.</p>
<div class="figure" style="text-align: center">
<span id="fig:figurecovariancedef"></span>
<img src="images/covariance_def.png" alt="Diagramma a dispersione per le variabili $X$ e $Y$ di cui abbiamo riportato sopra la distribuzione di probabilità congiunta. I cerchi con diametro maggiore indicano la presenza di due osservazioni sovrapposte." width="90%"><p class="caption">
Figura 18.1: Diagramma a dispersione per le variabili <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> di cui abbiamo riportato sopra la distribuzione di probabilità congiunta. I cerchi con diametro maggiore indicano la presenza di due osservazioni sovrapposte.
</p>
</div>
<p>Riportando nel medesimo grafico anche le rette individuate dai due
valori attesi, rispettivamente, di <span class="math inline">\(X\)</span> e di <span class="math inline">\(Y\)</span>, si ottiene che la
nuvola di punti viene suddivisa in 4 quadrati, numerati in senso
antiorario e partendo da quello in alto a destra. Per i punti che si
trovano nel I quadrante vale che:</p>
<p><span class="math display">\[
x &gt; \mathbb{E}(X) \quad \text{e} \quad y &gt; \mathbb{E}(Y) \quad \rightarrow \quad
\big(x - \mathbb{E}(X)\big)\left(y - \mathbb{E}(Y)\right) &gt; 0.
\]</span>
Per i punti che si trovano nel II quadrante vale che:
<span class="math display">\[
x &lt; \mathbb{E}(X) \quad \text{e} \quad y &gt; \mathbb{E}(Y) \quad \rightarrow \quad
\big(x - \mathbb{E}(X)\big)\left(y - \mathbb{E}(Y)\right) &lt; 0.
\]</span>
Per i punti che si trovano nel III quadrante vale che:
<span class="math display">\[
x &lt; \mathbb{E}(X) \quad \text{e} \quad y &lt; \mathbb{E}(Y) \quad \rightarrow \quad
\big(x - \mathbb{E}(X)\big)\left(y - \mathbb{E}(Y)\right) &gt; 0.
\]</span>
Per i punti che si trovano nel IV quadrante vale che:
<span class="math display">\[
x &gt; \mathbb{E}(X) \quad \text{e} \quad y &lt; \mathbb{E}(Y) \quad \rightarrow \quad
\big(x - \mathbb{E}(X)\big)\left(y - \mathbb{E}(Y)\right) &lt; 0.
\]</span>
Il valore atteso dei prodotti degli scarti non è altro che la covarianza:
<span class="math display">\[
Cov(X,Y) = \sum_x \sum_y\big(x - \mathbb{E}(X)\big)\big(y - \mathbb{E}(Y)\big)p(x,y).
\]</span>
Se prevalgono punti nel I e III quadrante la nuvola di punti avrà un
andamento crescente (per cui a valori bassi di <span class="math inline">\(X\)</span> tendono ad associarsi
valori bassi di <span class="math inline">\(Y\)</span> e a valori elevati di <span class="math inline">\(X\)</span> tendono ad associarsi
valori elevati di <span class="math inline">\(Y\)</span>) e la covarianza segno positivo; mentre se
prevalgono punti nel II e IV quadrante la nuvola di punti avrà un
andamento decrescente (per cui a valori bassi di <span class="math inline">\(X\)</span> tendono ad
associarsi valori elevati di <span class="math inline">\(Y\)</span> e a valori elevati di <span class="math inline">\(X\)</span> tendono ad
associarsi valori bassi di <span class="math inline">\(Y\)</span>) e la covarianza segno negativo.</p>
<p>Per la figura <a href="covarianza-1.html#fig:figurecovariancedef">18.1</a> ci sono 3 osservazioni in
ciascuno dei quadranti I e III, e un’osservazione ciascuno nei quadranti
II e IV. Pertanto la covarianza ha valore positivo: infatti
<span class="math inline">\(Cov(x,y) = +0.25\)</span>. Il segmento blu nel grafico rappresenta la retta
che meglio approssima i punti del diagramma a dispersione. Per questi
dati, tale retta ha una pendenza positiva (all’aumentare di <span class="math inline">\(X\)</span> aumenta
<span class="math inline">\(Y\)</span>), il che è coerente con il segno della covarianza.</p>
</div>
</div>
<div id="correlazione-1" class="section level2" number="18.2">
<h2>
<span class="header-section-number">18.2</span> Correlazione<a class="anchor" aria-label="anchor" href="#correlazione-1"><i class="fas fa-link"></i></a>
</h2>
<p>La covarianza dipende dall’unità di misura delle due variabili e quindi
non consente di stabilire l’intensità della relazione. Una misura
standardizzata della relazione che intercorre fra due variabili è invece
rappresentata dalla correlazione. La correlazione si ottiene dividendo
la covarianza per le deviazioni standard delle due variabili aleatorie.</p>
<p>Il coefficiente di correlazione tra <span class="math inline">\(X\)</span> ed <span class="math inline">\(Y\)</span> è il numero definito da</p>
<p><span class="math display" id="eq:rho">\[\begin{equation}
\rho(X,Y) =\frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}.
\tag{18.3}
\end{equation}\]</span></p>
<p>Si può anche scrivere <span class="math inline">\(\rho_{X,Y}\)</span> al posto di <span class="math inline">\(\rho(X,Y)\)</span>.</p>
<p>Il coefficiente di correlazione <span class="math inline">\(\rho_{xy}\)</span> è un numero puro, cioè non
dipende dall’unità di misura delle variabili, e assume valori compresi
tra -1 e +1. Ad esso possiamo assegnare la seguente interpretazione:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\rho_{X,Y} = -1\)</span> <span class="math inline">\(\rightarrow\)</span> perfetta relazione negativa: tutti i
punti si trovano esattamente su una retta con pendenza negativa (dal
quadrante in alto a sinistra al quadrante in basso a destra);</p></li>
<li><p><span class="math inline">\(\rho_{X,Y} = +1\)</span> <span class="math inline">\(\rightarrow\)</span> perfetta relazione positiva: tutti i
punti si trovano esattamente su una retta con pendenza positiva (dal
quadrante in basso a sinistra al quadrante in alto a destra);</p></li>
<li><p><span class="math inline">\(-1 &lt; \rho_{X,Y} &lt; +1\)</span> <span class="math inline">\(\rightarrow\)</span> presenza di una relazione
lineare di intensità diversa;</p></li>
<li><p><span class="math inline">\(\rho_{X,Y} = 0\)</span> <span class="math inline">\(\rightarrow\)</span> assenza di relazione lineare tra <span class="math inline">\(X\)</span>
e <span class="math inline">\(Y\)</span>.</p></li>
</ol>
</div>
<div id="proprietà-1" class="section level2" number="18.3">
<h2>
<span class="header-section-number">18.3</span> Proprietà<a class="anchor" aria-label="anchor" href="#propriet%C3%A0-1"><i class="fas fa-link"></i></a>
</h2>
<ol style="list-style-type: decimal">
<li><p>La covarianza tra una variabile aleatoria <span class="math inline">\(X\)</span> e una costante <span class="math inline">\(c\)</span> è
nulla:
<span class="math display">\[
Cov(c,X) = 0,
\]</span></p></li>
<li><p>la covarianza è simmetrica: <span class="math display">\[Cov(X,Y) = Cov(Y,X),\]</span></p></li>
<li><p>vale <span class="math display">\[-1 \leq \rho(X,Y) \leq 1,\]</span></p></li>
<li><p>la correlazione non dipende dall’unità di misura:
<span class="math display">\[\rho(aX, bY) = \rho(X,Y), \qquad \forall a, b &gt; 0,\]</span></p></li>
<li><p>se <span class="math inline">\(Y = a + bX\)</span> è una funzione lineare di <span class="math inline">\(X\)</span> con costanti <span class="math inline">\(a\)</span> e
<span class="math inline">\(b\)</span>, allora <span class="math inline">\(\rho(X,Y) = \pm 1\)</span>, a seconda del segno di <span class="math inline">\(b\)</span>,</p></li>
<li><p>la covarianza tra <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>, ciascuna moltiplicata per una costante,
è uguale al prodotto delle costanti per la covarianza tra <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>:
<span class="math display">\[Cov(aX,bY) = ab \;Cov(X,Y), \qquad \forall a,b \in \mathbb{R},\]</span></p></li>
<li><p><span class="math display">\[Var(X \pm Y) = Var(X) + Var(Y) \pm 2 \cdot Cov(X,Y),\]</span></p></li>
<li><p><span class="math display">\[Cov(X + Y, Z) = Cov(X,Z) + Cov(Y,Z),\]</span></p></li>
<li><p>per una sequenza di variabili aleatorie <span class="math inline">\(X_1, \dots, X_n\)</span>, si ha
<span class="math display">\[
Var\left( \sum_{i=1}^n X_i\right) = \sum_{i=1}^n
 Var(X_i) + 2\sum_{i,j: i&lt;j}Cov(X_i, X_j),
 \]</span></p></li>
<li><p><span class="math display">\[
Cov\left(\sum_{i=1}^n a_i X_i, \sum_{j=1}^m b_jY_j\right) = \sum_{i=1}^n \sum_{j=1}^m a_j b_jCov(X_j, Y_j),
\]</span></p></li>
<li><p>se <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> sono indipendenti, allora
<span class="math display">\[
Cov\left(\sum_{i=1}^n a_i X_i, \sum_{j=1}^n b_jX_j\right) = \sum_{i=1}^n a_i b_i Var(X_i).
\]</span></p></li>
</ol>
</div>
<div id="incorrelazione" class="section level2" number="18.4">
<h2>
<span class="header-section-number">18.4</span> Incorrelazione<a class="anchor" aria-label="anchor" href="#incorrelazione"><i class="fas fa-link"></i></a>
</h2>
<p>Si dice che <span class="math inline">\(X\)</span> ed <span class="math inline">\(Y\)</span> sono incorrelate, o linermente indipendenti, se la loro covarianza è nulla,
<span class="math display">\[
\sigma_{XY} = \mathbb{E} \big[(X - \mu_X) (y-\mu_u) \big] = 0,
\]</span></p>
<p>che si può anche scrivere come</p>
<p><span class="math display">\[
\rho_{XY} = 0, \quad \mathbb{E}(XY) = \mathbb{E}(X) \mathbb{E}(Y).
\]</span></p>
<p>Si introduce così un secondo tipo di indipendenza, più debole, dopo quello di indipendenza stocastica. Viceversa, però, se <span class="math inline">\(Cov (X, Y) = 0\)</span>, non è detto che <span class="math inline">\(X\)</span> ed <span class="math inline">\(Y\)</span> siano indipendenti.</p>
<p>In conclusione, anche se la condizione di indipendenza implica una covarianza nulla, questo esempio mostra come l’inverso non sia necessariamente vero. La covarianza può essere zero anche quando le due variabili aleatorie non sono indipendenti.</p>

<div class="exercise">
<span id="exr:unnamed-chunk-180" class="exercise"><strong>Esercizio 18.1  </strong></span>Siano <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> due variabili aleatorie discrete avente una
distribuzione di massa di probabilità congiunta pari a
<span class="math display">\[f_{XY}(x,y) = \frac{1}{4} \quad (x,y) \in \{(0,0), (1,1), (1, -1), (2,0) \}\]</span>
e zero altrimenti. Si calcoli la covarianza <span class="math inline">\(\rho_{XY}\)</span>. Le due
variabili aleatorie <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> sono mutuamente indipendenti?
</div>

<div class="solution">
<p> <span class="solution"><em>Soluzione. </em></span> La distribuzione marginale della <span class="math inline">\(X\)</span> è <span class="math display">\[\begin{cases} 
X = 0, \quad  P_X = 1/4, \\
X = 1, \quad P_X = 2/4, \\
X = 2, \quad P_X = 1/4. 
\end{cases}\]</span>
<span class="math display">\[\mathbb{E}(X) = 0 \frac{1}{4} + 1 \frac{2}{4} + 2 \frac{1}{4} = 1.\]</span>
<span class="math display">\[\mathbb{E}(X^2) = 0^2 \frac{1}{4} + 1^2 \frac{2}{4} + 2^2 \frac{1}{4} = \frac{3}{2}.\]</span>
<span class="math display">\[
  Var(X) = \frac{3}{2} - 1^2 = \frac{1}{2}.
\]</span>
La distribuzione marginale della <span class="math inline">\(Y\)</span> è
<span class="math display">\[
\begin{cases} 
Y = -1, \quad  P_Y = 1/4, \\
Y = 0, \quad P_Y = 2/4, \\
Y = 1, \quad P_Y = 1/4. 
\end{cases}
\]</span>
<span class="math display">\[
  \mathbb{E}(Y) = 0 \frac{2}{4} + 1 \frac{1}{4} + (-1) \frac{1}{4} = 0.
\]</span>
<span class="math display">\[
  \mathbb{E}(Y^2) = 0^2 \frac{2}{4} + 1^2 \frac{1}{4} + (-1)^2 \frac{1}{4} = \frac{1}{2}.
\]</span>
<span class="math display">\[
  Var(Y) = \frac{1}{2} - 0^2 = \frac{1}{2}.
\]</span>
Calcoliamo ora la covarianza tra <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>:
<span class="math display">\[
  \mathbb{E}(XY) = \sum_x\sum_y xy f_{XY} (x,y) = 
(0\cdot 0)\frac{1}{4} + 
(1\cdot 1)\frac{1}{4} +
(1\cdot -1)\frac{1}{4} +
(2\cdot 0)\frac{1}{4} = 0.
\]</span>
<span class="math display">\[
Cov(X,Y) = \mathbb{E}(XY) - \mathbb{E}(X)\mathbb{E}(Y) = 0 - 1\cdot0 = 0.
\]</span></p>
<p>Quindi le due variabili aleatorie hanno covarianza pari a zero. Tuttavia, esse non
sono indipendenti, in quanto non è vero che</p>
<p><span class="math display">\[
  f_{XY} (x,y) = f_X(x) f_Y(y), \quad \forall x,y.
\]</span></p>
</div>
</div>
<div id="conclusioni-6" class="section level2 unnumbered">
<h2>Conclusioni<a class="anchor" aria-label="anchor" href="#conclusioni-6"><i class="fas fa-link"></i></a>
</h2>
<p>La densità di probabilità congiunta tiene simultaneamente conto del comportamento
di due variabili aleatorie <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> e di come esse si influenzino.
Se <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> sono legati linearmente, allora il coefficiente di
correlazione
<span class="math display">\[
\rho = \frac{\sigma_{XY}}{\sigma_X \sigma_Y}
\]</span>
fornisce l’indice maggiormente utilizzato per descrivere l’intensità e
il segno dell’associazione lineare. Nel caso di un’associazione lineare
perfetta, <span class="math inline">\(Y = a + bX\)</span>, avremmo <span class="math inline">\(\rho = 1\)</span> con <span class="math inline">\(b\)</span> positivo ed
<span class="math inline">\(\rho = -1\)</span> con <span class="math inline">\(b\)</span> negativo. Se il coefficiente di correlazione è pari
a 0 le variabili si dicono scorrelate. Condizione sufficiente (ma non
necessaria) perché tale coefficiente sia nullo è che le due variabili
siano tra loro indipendenti.</p>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="valore-atteso-e-varianza-di-variabili-aleatorie-discrete.html"><span class="header-section-number">17</span> Valore atteso e varianza di variabili aleatorie discrete</a></div>
<div class="next"><a href="la-distribuzione-binomiale.html"><span class="header-section-number">19</span> La distribuzione binomiale</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#covarianza-1"><span class="header-section-number">18</span> Covarianza</a></li>
<li>
<a class="nav-link" href="#covarianza"><span class="header-section-number">18.1</span> Covarianza</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#interpretazione-della-covarianza"><span class="header-section-number">18.1.1</span> Interpretazione della covarianza</a></li></ul>
</li>
<li><a class="nav-link" href="#correlazione-1"><span class="header-section-number">18.2</span> Correlazione</a></li>
<li><a class="nav-link" href="#propriet%C3%A0-1"><span class="header-section-number">18.3</span> Proprietà</a></li>
<li><a class="nav-link" href="#incorrelazione"><span class="header-section-number">18.4</span> Incorrelazione</a></li>
<li><a class="nav-link" href="#conclusioni-6">Conclusioni</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Data Science per psicologi</strong>" was written by Corrado Caudek. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
